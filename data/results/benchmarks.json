{
    "algorithms.Duplicated.time_duplicated": {
        "code": "class Duplicated:\n    def time_duplicated(self, unique, keep, dtype):\n        self.idx.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self, unique, keep, dtype):\n        N = 10**5\n        if dtype in [\"int64\", \"uint64\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=\"float64\")\n        elif dtype == \"string\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype in [\"timestamp[ms][pyarrow]\", \"duration[s][pyarrow]\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        else:\n            raise NotImplementedError\n        if not unique:\n            data = data.repeat(5)\n        self.idx = data\n        # cache is_unique\n        self.idx.is_unique",
        "min_run_count": 2,
        "name": "algorithms.Duplicated.time_duplicated",
        "number": 0,
        "param_names": [
            "unique",
            "keep",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'first'",
                "'last'",
                "False"
            ],
            [
                "'int64'",
                "'uint64'",
                "'float64'",
                "'string'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'",
                "'timestamp[ms][pyarrow]'",
                "'duration[s][pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fe53c1038d7b25e9c8911c3bea6fb5a1548d97c07d68025391c8e89c96d7e9ad",
        "warmup_time": -1
    },
    "algorithms.DuplicatedMaskedArray.time_duplicated": {
        "code": "class DuplicatedMaskedArray:\n    def time_duplicated(self, unique, keep, dtype):\n        self.ser.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DuplicatedMaskedArray:\n    def setup(self, unique, keep, dtype):\n        N = 10**5\n        data = pd.Series(np.arange(N), dtype=dtype)\n        data[list(range(1, N, 100))] = pd.NA\n        if not unique:\n            data = data.repeat(5)\n        self.ser = data\n        # cache is_unique\n        self.ser.is_unique",
        "min_run_count": 2,
        "name": "algorithms.DuplicatedMaskedArray.time_duplicated",
        "number": 0,
        "param_names": [
            "unique",
            "keep",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'first'",
                "'last'",
                "False"
            ],
            [
                "'Int64'",
                "'Float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9401d32efa9cbe647d328e01c1b90df12183cdceba73825c1c4d98e81f254886",
        "warmup_time": -1
    },
    "algorithms.Factorize.peakmem_factorize": {
        "code": "class Factorize:\n    def peakmem_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10**5\n    \n        if dtype in [\"int64\", \"uint64\", \"Int64\", \"object\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=dtype)\n        elif dtype == \"boolean\":\n            data = pd.array(np.random.randint(0, 2, N), dtype=dtype)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype == \"object_str\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"string[pyarrow]\":\n            data = pd.array(\n                pd.Index([f\"i-{i}\" for i in range(N)], dtype=object),\n                dtype=\"string[pyarrow]\",\n            )\n        else:\n            raise NotImplementedError\n    \n        if not unique:\n            data = data.repeat(5)\n        self.data = data",
        "name": "algorithms.Factorize.peakmem_factorize",
        "param_names": [
            "unique",
            "sort",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'int64'",
                "'uint64'",
                "'float64'",
                "'object'",
                "'object_str'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'",
                "'Int64'",
                "'boolean'",
                "'string[pyarrow]'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "ec743de3d9c5a026a891feb9ab8ecffae4612dcf9fba25aea48c6525c0fb7c0e"
    },
    "algorithms.Factorize.time_factorize": {
        "code": "class Factorize:\n    def time_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10**5\n    \n        if dtype in [\"int64\", \"uint64\", \"Int64\", \"object\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=dtype)\n        elif dtype == \"boolean\":\n            data = pd.array(np.random.randint(0, 2, N), dtype=dtype)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype == \"object_str\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"string[pyarrow]\":\n            data = pd.array(\n                pd.Index([f\"i-{i}\" for i in range(N)], dtype=object),\n                dtype=\"string[pyarrow]\",\n            )\n        else:\n            raise NotImplementedError\n    \n        if not unique:\n            data = data.repeat(5)\n        self.data = data",
        "min_run_count": 2,
        "name": "algorithms.Factorize.time_factorize",
        "number": 0,
        "param_names": [
            "unique",
            "sort",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'int64'",
                "'uint64'",
                "'float64'",
                "'object'",
                "'object_str'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'",
                "'Int64'",
                "'boolean'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7a47cb209b293a023d7673dfacf5f33fc761ee2bb76ef52d7ba9c2b0cf69f50f",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_frame": {
        "code": "class Hashing:\n    def time_frame(self, df):\n        hashing.hash_pandas_object(df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_frame",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:134",
        "type": "time",
        "unit": "seconds",
        "version": "4a05c799caa1b1f5e373a44ae3039987540f271f87111d92653f37c426c76443",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_categorical": {
        "code": "class Hashing:\n    def time_series_categorical(self, df):\n        hashing.hash_pandas_object(df[\"categories\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_categorical",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:134",
        "type": "time",
        "unit": "seconds",
        "version": "c402e5979cad298ee4e24b9fb8fc1c18002315ac518eb757fc3dfdda2dfa8a70",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_dates": {
        "code": "class Hashing:\n    def time_series_dates(self, df):\n        hashing.hash_pandas_object(df[\"dates\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_dates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:134",
        "type": "time",
        "unit": "seconds",
        "version": "480afaa0dc2d1bcfebbb58644d666d5e0110dce44f34335c99f3fc79ec3d7157",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_float": {
        "code": "class Hashing:\n    def time_series_float(self, df):\n        hashing.hash_pandas_object(df[\"floats\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_float",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:134",
        "type": "time",
        "unit": "seconds",
        "version": "214d3d8f8bad077c365dabffe78fc06579e82078aaef4ea7f87b4a9154f3b17d",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_int": {
        "code": "class Hashing:\n    def time_series_int(self, df):\n        hashing.hash_pandas_object(df[\"ints\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:134",
        "type": "time",
        "unit": "seconds",
        "version": "1e1e48b3441cae94aaaa9f1821af6faeb0ffb83a0e757306651eb81e6883ef37",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_string": {
        "code": "class Hashing:\n    def time_series_string(self, df):\n        hashing.hash_pandas_object(df[\"strings\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:134",
        "type": "time",
        "unit": "seconds",
        "version": "1f1baa73746106531f50db15fbbbbb902f1b33f8c128829138fb6b494b91953e",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_timedeltas": {
        "code": "class Hashing:\n    def time_series_timedeltas(self, df):\n        hashing.hash_pandas_object(df[\"timedeltas\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_timedeltas",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:134",
        "type": "time",
        "unit": "seconds",
        "version": "03ae26b3725783046ce19f735dfb622e46318830e1297575ea97d8b9f5928199",
        "warmup_time": -1
    },
    "algorithms.Quantile.time_quantile": {
        "code": "class Quantile:\n    def time_quantile(self, quantile, interpolation, dtype):\n        self.ser.quantile(quantile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, quantile, interpolation, dtype):\n        N = 10**5\n        if dtype in [\"int64\", \"uint64\"]:\n            data = np.arange(N, dtype=dtype)\n        elif dtype == \"float64\":\n            data = np.random.randn(N)\n        else:\n            raise NotImplementedError\n        self.ser = pd.Series(data.repeat(5))",
        "min_run_count": 2,
        "name": "algorithms.Quantile.time_quantile",
        "number": 0,
        "param_names": [
            "quantile",
            "interpolation",
            "dtype"
        ],
        "params": [
            [
                "0",
                "0.5",
                "1"
            ],
            [
                "'linear'",
                "'nearest'",
                "'lower'",
                "'higher'",
                "'midpoint'"
            ],
            [
                "'float64'",
                "'int64'",
                "'uint64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "820d0dca81e53ef4f34628fac8053f5a961e38b58bf3b780a6b0f25372409868",
        "warmup_time": -1
    },
    "algorithms.SortIntegerArray.time_argsort": {
        "code": "class SortIntegerArray:\n    def time_argsort(self, N):\n        self.array.argsort()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIntegerArray:\n    def setup(self, N):\n        data = np.arange(N, dtype=float)\n        data[40] = np.nan\n        self.array = pd.array(data, dtype=\"Int64\")",
        "min_run_count": 2,
        "name": "algorithms.SortIntegerArray.time_argsort",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "712d4e0ba6b3b003618d30611818ce2c36c039fe0900eafca3896d3863ebbc51",
        "warmup_time": -1
    },
    "algos.isin.IsIn.time_isin": {
        "code": "class IsIn:\n    def time_isin(self, dtype):\n        self.series.isin(self.values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object)._values,\n                    dtype=dtype,\n                )\n            except ImportError as err:\n                raise NotImplementedError from err\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)",
        "min_run_count": 2,
        "name": "algos.isin.IsIn.time_isin",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'uint64'",
                "'object'",
                "'Int64'",
                "'boolean'",
                "'bool'",
                "'datetime64[ns]'",
                "'category[object]'",
                "'category[int]'",
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "865fbf7191863eeb821be25fad0a63ffe777808ff8616e4cab0031c8301e7153",
        "warmup_time": -1
    },
    "algos.isin.IsIn.time_isin_categorical": {
        "code": "class IsIn:\n    def time_isin_categorical(self, dtype):\n        self.series.isin(self.cat_values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object)._values,\n                    dtype=dtype,\n                )\n            except ImportError as err:\n                raise NotImplementedError from err\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)",
        "min_run_count": 2,
        "name": "algos.isin.IsIn.time_isin_categorical",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'uint64'",
                "'object'",
                "'Int64'",
                "'boolean'",
                "'bool'",
                "'datetime64[ns]'",
                "'category[object]'",
                "'category[int]'",
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9369a8f4f0ec062e426a751644ce01ca508d066ce35ee6ff28d4c4c83c41eb3d",
        "warmup_time": -1
    },
    "algos.isin.IsIn.time_isin_empty": {
        "code": "class IsIn:\n    def time_isin_empty(self, dtype):\n        self.series.isin([])\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object)._values,\n                    dtype=dtype,\n                )\n            except ImportError as err:\n                raise NotImplementedError from err\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)",
        "min_run_count": 2,
        "name": "algos.isin.IsIn.time_isin_empty",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'uint64'",
                "'object'",
                "'Int64'",
                "'boolean'",
                "'bool'",
                "'datetime64[ns]'",
                "'category[object]'",
                "'category[int]'",
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b9d421da039cb9b85f0c4f38a7b6d4598c0df5ad2743f8bb6d22196225360df9",
        "warmup_time": -1
    },
    "algos.isin.IsIn.time_isin_mismatched_dtype": {
        "code": "class IsIn:\n    def time_isin_mismatched_dtype(self, dtype):\n        self.series.isin(self.mismatched)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object)._values,\n                    dtype=dtype,\n                )\n            except ImportError as err:\n                raise NotImplementedError from err\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)",
        "min_run_count": 2,
        "name": "algos.isin.IsIn.time_isin_mismatched_dtype",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'uint64'",
                "'object'",
                "'Int64'",
                "'boolean'",
                "'bool'",
                "'datetime64[ns]'",
                "'category[object]'",
                "'category[int]'",
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f0d4da28d0ffe353bb16748a63a1f7767990a4d22696a561e495e0d6526f4fdc",
        "warmup_time": -1
    },
    "algos.isin.IsInFloat64.time_isin": {
        "code": "class IsInFloat64:\n    def time_isin(self, dtype, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, title):\n        N_many = 10**5\n        N_few = 10**6\n        self.series = Series([1, 2], dtype=dtype)\n    \n        if title == \"many_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.arange(N_many, dtype=np.float64)\n        elif title == \"few_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.zeros(N_few, dtype=np.float64)\n        elif title == \"only_nans_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.full(N_few, np.nan, dtype=np.float64)\n        else:\n            raise ValueError(title)",
        "min_run_count": 2,
        "name": "algos.isin.IsInFloat64.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "title"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "'Float64'"
            ],
            [
                "'many_different_values'",
                "'few_different_values'",
                "'only_nans_values'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "59baee11ef880339f8490c7d07fdf4f25b649d22624afd1242eefd4877e7c0bd",
        "warmup_time": -1
    },
    "algos.isin.IsInForObjects.time_isin": {
        "code": "class IsInForObjects:\n    def time_isin(self, series_type, vals_type):\n        self.series.isin(self.values)\n\n    def setup(self, series_type, vals_type):\n        N_many = 10**5\n    \n        if series_type == \"nans\":\n            ser_vals = np.full(10**4, np.nan)\n        elif series_type == \"short\":\n            ser_vals = np.arange(2)\n        elif series_type == \"long\":\n            ser_vals = np.arange(N_many)\n        elif series_type == \"long_floats\":\n            ser_vals = np.arange(N_many, dtype=np.float64)\n    \n        self.series = Series(ser_vals).astype(object)\n    \n        if vals_type == \"nans\":\n            values = np.full(10**4, np.nan)\n        elif vals_type == \"short\":\n            values = np.arange(2)\n        elif vals_type == \"long\":\n            values = np.arange(N_many)\n        elif vals_type == \"long_floats\":\n            values = np.arange(N_many, dtype=np.float64)\n    \n        self.values = values.astype(object)",
        "min_run_count": 2,
        "name": "algos.isin.IsInForObjects.time_isin",
        "number": 0,
        "param_names": [
            "series_type",
            "vals_type"
        ],
        "params": [
            [
                "'nans'",
                "'short'",
                "'long'",
                "'long_floats'"
            ],
            [
                "'nans'",
                "'short'",
                "'long'",
                "'long_floats'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "51416b624c4176717e96bb897c59ee9f59c2e4a9079df5c3893b1fb877979d84",
        "warmup_time": -1
    },
    "algos.isin.IsInIndexes.time_isin_index": {
        "code": "class IsInIndexes:\n    def time_isin_index(self):\n        self.series.isin(self.index)\n\n    def setup(self):\n        self.range_idx = Index(range(1000))\n        self.index = Index(list(range(1000)))\n        self.series = Series(np.random.randint(100_000, size=1000))",
        "min_run_count": 2,
        "name": "algos.isin.IsInIndexes.time_isin_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ce5b0b4c6a85e2c007c90998aa18d4db0fb69a82cefb1549856c75004e42fbec",
        "warmup_time": -1
    },
    "algos.isin.IsInIndexes.time_isin_range_index": {
        "code": "class IsInIndexes:\n    def time_isin_range_index(self):\n        self.series.isin(self.range_idx)\n\n    def setup(self):\n        self.range_idx = Index(range(1000))\n        self.index = Index(list(range(1000)))\n        self.series = Series(np.random.randint(100_000, size=1000))",
        "min_run_count": 2,
        "name": "algos.isin.IsInIndexes.time_isin_range_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f37d428d46aff6ec8ce8a340df54e194946db8454b6da0c7a39c2e85139b4efb",
        "warmup_time": -1
    },
    "algos.isin.IsInLongSeriesLookUpDominates.time_isin": {
        "code": "class IsInLongSeriesLookUpDominates:\n    def time_isin(self, dtypes, MaxNumber, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, MaxNumber, series_type):\n        N = 10**7\n    \n        if series_type == \"random_hits\":\n            array = np.random.randint(0, MaxNumber, N)\n        if series_type == \"random_misses\":\n            array = np.random.randint(0, MaxNumber, N) + MaxNumber\n        if series_type == \"monotone_hits\":\n            array = np.repeat(np.arange(MaxNumber), N // MaxNumber)\n        if series_type == \"monotone_misses\":\n            array = np.arange(N) + MaxNumber\n    \n        self.series = Series(array).astype(dtype)\n    \n        self.values = np.arange(MaxNumber).astype(dtype.lower())",
        "min_run_count": 2,
        "name": "algos.isin.IsInLongSeriesLookUpDominates.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "MaxNumber",
            "series_type"
        ],
        "params": [
            [
                "'int64'",
                "'int32'",
                "'float64'",
                "'float32'",
                "'object'",
                "'Int64'",
                "'Float64'"
            ],
            [
                "5",
                "1000"
            ],
            [
                "'random_hits'",
                "'random_misses'",
                "'monotone_hits'",
                "'monotone_misses'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0634a100f682c1a73f9cb5d84afc1695f117d58377c8ac19e9a1d4ecf3918bc4",
        "warmup_time": -1
    },
    "algos.isin.IsInLongSeriesValuesDominate.time_isin": {
        "code": "class IsInLongSeriesValuesDominate:\n    def time_isin(self, dtypes, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, series_type):\n        N = 10**7\n    \n        if series_type == \"random\":\n            vals = np.random.randint(0, 10 * N, N)\n        if series_type == \"monotone\":\n            vals = np.arange(N)\n    \n        self.values = vals.astype(dtype.lower())\n        M = 10**6 + 1\n        self.series = Series(np.arange(M)).astype(dtype)",
        "min_run_count": 2,
        "name": "algos.isin.IsInLongSeriesValuesDominate.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "series_type"
        ],
        "params": [
            [
                "'int64'",
                "'int32'",
                "'float64'",
                "'float32'",
                "'object'",
                "'Int64'",
                "'Float64'"
            ],
            [
                "'random'",
                "'monotone'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8202afa03ab08eab3d80cdb10c821a35f6b73f1b178354429054668f213b8920",
        "warmup_time": -1
    },
    "algos.isin.IsInWithLongTupples.time_isin": {
        "code": "class IsInWithLongTupples:\n    def time_isin(self):\n        self.series.isin(self.values)\n\n    def setup(self):\n        t = tuple(range(1000))\n        self.series = Series([t] * 1000)\n        self.values = [t]",
        "min_run_count": 2,
        "name": "algos.isin.IsInWithLongTupples.time_isin",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "55c634e065a928f8f1e9146932290a0b894f6f9f6f25b0d57ab2597ce60972ad",
        "warmup_time": -1
    },
    "algos.isin.IsinAlmostFullWithRandomInt.time_isin": {
        "code": "class IsinAlmostFullWithRandomInt:\n    def time_isin(self, dtype, exponent, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, exponent, title):\n        M = 3 * 2 ** (exponent - 2)\n        # 0.77-the maximal share of occupied buckets\n        self.series = Series(np.random.randint(0, M, M)).astype(dtype)\n    \n        values = np.random.randint(0, M, M).astype(dtype)\n        if title == \"inside\":\n            self.values = values\n        elif title == \"outside\":\n            self.values = values + M\n        else:\n            raise ValueError(title)",
        "min_run_count": 2,
        "name": "algos.isin.IsinAlmostFullWithRandomInt.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "exponent",
            "title"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.object_'>"
            ],
            [
                "10",
                "11",
                "12",
                "13",
                "14",
                "15",
                "16",
                "17",
                "18",
                "19",
                "20"
            ],
            [
                "'inside'",
                "'outside'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4511839e6a4402d9c6a3c41e95fbfd6c61eb07d38c9d0069b10c837a5dfb0bb4",
        "warmup_time": -1
    },
    "algos.isin.IsinWithArange.time_isin": {
        "code": "class IsinWithArange:\n    def time_isin(self, dtype, M, offset_factor):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, M, offset_factor):\n        offset = int(M * offset_factor)\n        tmp = Series(np.random.randint(offset, M + offset, 10**6))\n        self.series = tmp.astype(dtype)\n        self.values = np.arange(M).astype(dtype)",
        "min_run_count": 2,
        "name": "algos.isin.IsinWithArange.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "M",
            "offset_factor"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.object_'>"
            ],
            [
                "1000",
                "2000",
                "8000"
            ],
            [
                "-2",
                "0",
                "2"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a595ea736176046325e6461769d666e50df44bc5ea923058dfbdf81bc2fa9848",
        "warmup_time": -1
    },
    "algos.isin.IsinWithArangeSorted.time_isin": {
        "code": "class IsinWithArangeSorted:\n    def time_isin(self, dtype, size):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size):\n        self.series = Series(np.arange(size)).astype(dtype)\n        self.values = np.arange(size).astype(dtype)",
        "min_run_count": 2,
        "name": "algos.isin.IsinWithArangeSorted.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "size"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.object_'>"
            ],
            [
                "1000",
                "2000",
                "8000",
                "100000",
                "1000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b3b173cabf5fb2d94e06a9a5bce98458bf646cecae54b0966cfe66adcded0fdf",
        "warmup_time": -1
    },
    "algos.isin.IsinWithRandomFloat.time_isin": {
        "code": "class IsinWithRandomFloat:\n    def time_isin(self, dtype, size, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size, title):\n        self.values = np.random.rand(size)\n        self.series = Series(self.values).astype(dtype)\n        np.random.shuffle(self.values)\n    \n        if title == \"outside\":\n            self.values = self.values + 0.1",
        "min_run_count": 2,
        "name": "algos.isin.IsinWithRandomFloat.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "size",
            "title"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.object_'>"
            ],
            [
                "1300",
                "2000",
                "7000",
                "8000",
                "70000",
                "80000",
                "750000",
                "900000"
            ],
            [
                "'inside'",
                "'outside'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "15f9f9bb41efd706d95b1a43ff72e5572dedbb074050cd2b857e7a91213c60a8",
        "warmup_time": -1
    },
    "arithmetic.ApplyIndex.time_apply_index": {
        "code": "class ApplyIndex:\n    def time_apply_index(self, offset):\n        self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyIndex:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng",
        "min_run_count": 2,
        "name": "arithmetic.ApplyIndex.time_apply_index",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3a6382c9a7754ab42a9c9d4af8bdaeb073d03dbe05f80288c151c0cce34ffbb7",
        "warmup_time": -1
    },
    "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex": {
        "code": "class BinaryOpsMultiIndex:\n    def time_binary_op_multiindex(self, func):\n        getattr(self.df, func)(self.arg_df, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BinaryOpsMultiIndex:\n    def setup(self, func):\n        array = date_range(\"20200101 00:00\", \"20200102 0:00\", freq=\"s\")\n        level_0_names = [str(i) for i in range(30)]\n    \n        index = pd.MultiIndex.from_product([level_0_names, array])\n        column_names = [\"col_1\", \"col_2\"]\n    \n        self.df = DataFrame(\n            np.random.rand(len(index), 2), index=index, columns=column_names\n        )\n    \n        self.arg_df = DataFrame(\n            np.random.randint(1, 10, (len(level_0_names), 2)),\n            index=level_0_names,\n            columns=column_names,\n        )",
        "min_run_count": 2,
        "name": "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex",
        "number": 0,
        "param_names": [
            "func"
        ],
        "params": [
            [
                "'sub'",
                "'add'",
                "'mul'",
                "'div'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f972c5787a16a41749c4e8447ef1ff42b310cd8aa3ef3b75ab7012164ff6cd12",
        "warmup_time": -1
    },
    "arithmetic.CategoricalComparisons.time_categorical_op": {
        "code": "class CategoricalComparisons:\n    def time_categorical_op(self, op):\n        getattr(self.cat, op)(\"b\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalComparisons:\n    def setup(self, op):\n        N = 10**5\n        self.cat = pd.Categorical(list(\"aabbcd\") * N, ordered=True)",
        "min_run_count": 2,
        "name": "arithmetic.CategoricalComparisons.time_categorical_op",
        "number": 0,
        "param_names": [
            "op"
        ],
        "params": [
            [
                "'__lt__'",
                "'__le__'",
                "'__eq__'",
                "'__ne__'",
                "'__ge__'",
                "'__gt__'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2f0300d246b7a2099eaf59bd3d8baf6c12093061ade66b97a650fa54a8b028f1",
        "warmup_time": -1
    },
    "arithmetic.DateInferOps.time_add_timedeltas": {
        "code": "class DateInferOps:\n    def time_add_timedeltas(self, df):\n        df[\"timedelta\"] + df[\"timedelta\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df",
        "min_run_count": 2,
        "name": "arithmetic.DateInferOps.time_add_timedeltas",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "arithmetic:375",
        "type": "time",
        "unit": "seconds",
        "version": "d304b19271ea5e636b026bf3da9f4297f153721c9a2c3e0173d635d70bf17047",
        "warmup_time": -1
    },
    "arithmetic.DateInferOps.time_subtract_datetimes": {
        "code": "class DateInferOps:\n    def time_subtract_datetimes(self, df):\n        df[\"datetime64\"] - df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df",
        "min_run_count": 2,
        "name": "arithmetic.DateInferOps.time_subtract_datetimes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "arithmetic:375",
        "type": "time",
        "unit": "seconds",
        "version": "0d0d777174d233a423d74dfef6d81ae5628aaf0098dd2ba538d20b71fa74a3a4",
        "warmup_time": -1
    },
    "arithmetic.DateInferOps.time_timedelta_plus_datetime": {
        "code": "class DateInferOps:\n    def time_timedelta_plus_datetime(self, df):\n        df[\"timedelta\"] + df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df",
        "min_run_count": 2,
        "name": "arithmetic.DateInferOps.time_timedelta_plus_datetime",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "arithmetic:375",
        "type": "time",
        "unit": "seconds",
        "version": "d88c202e97a70579bbbc882c3e1887e44880bc361f354c724dfce863a33f80b3",
        "warmup_time": -1
    },
    "arithmetic.FrameWithFrameWide.time_op_different_blocks": {
        "code": "class FrameWithFrameWide:\n    def time_op_different_blocks(self, op, shape):\n        # blocks (and dtypes) are not aligned\n        op(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shouldn't need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2",
        "min_run_count": 2,
        "name": "arithmetic.FrameWithFrameWide.time_op_different_blocks",
        "number": 0,
        "param_names": [
            "op",
            "shape"
        ],
        "params": [
            [
                "<built-in function add>",
                "<built-in function floordiv>",
                "<built-in function gt>"
            ],
            [
                "(1000000, 10)",
                "(100000, 100)",
                "(10000, 1000)",
                "(1000, 10000)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "08d4888de43a21340c4ca998981b96bc41102332e11cc5e9f3fa24786b3387df",
        "warmup_time": -1
    },
    "arithmetic.FrameWithFrameWide.time_op_same_blocks": {
        "code": "class FrameWithFrameWide:\n    def time_op_same_blocks(self, op, shape):\n        # blocks (and dtypes) are aligned\n        op(self.left, self.left)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shouldn't need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2",
        "min_run_count": 2,
        "name": "arithmetic.FrameWithFrameWide.time_op_same_blocks",
        "number": 0,
        "param_names": [
            "op",
            "shape"
        ],
        "params": [
            [
                "<built-in function add>",
                "<built-in function floordiv>",
                "<built-in function gt>"
            ],
            [
                "(1000000, 10)",
                "(100000, 100)",
                "(10000, 1000)",
                "(1000, 10000)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5a9a092d047b1965d0bc9f942b0cf7c15def8265241bbeedb67e2fceab345e22",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_add": {
        "code": "class IndexArithmetic:\n    def time_add(self, dtype):\n        self.index + 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_add",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e3b336a2b91023f69241b1e98b2ab708a462124c6efae19a34cbfc4088ac5c30",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_divide": {
        "code": "class IndexArithmetic:\n    def time_divide(self, dtype):\n        self.index / 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_divide",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "34015b0ed303b7d7c8f55d6a9ad20ca0fa33aadc3daa21cd5aad136f74b8dd5a",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_modulo": {
        "code": "class IndexArithmetic:\n    def time_modulo(self, dtype):\n        self.index % 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_modulo",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "79e85d4d52e5fba7c78d4758aca6497d19481845699965996f6c198f8052f100",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_multiply": {
        "code": "class IndexArithmetic:\n    def time_multiply(self, dtype):\n        self.index * 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_multiply",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5969c44239435c557404661c30a6b18f3fdef2422cd4683cc4baa5856db98617",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_subtract": {
        "code": "class IndexArithmetic:\n    def time_subtract(self, dtype):\n        self.index - 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_subtract",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "064e28755b44443edfc8d9a9e01aa56cd0b70fde6e6ea290d84284e9bb03268a",
        "warmup_time": -1
    },
    "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar": {
        "code": "class IntFrameWithScalar:\n    def time_frame_op_with_scalar(self, dtype, scalar, op):\n        op(self.df, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntFrameWithScalar:\n    def setup(self, dtype, scalar, op):\n        arr = np.random.randn(20000, 100)\n        self.df = DataFrame(arr.astype(dtype))",
        "min_run_count": 2,
        "name": "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar",
        "number": 0,
        "param_names": [
            "dtype",
            "scalar",
            "op"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.int64'>"
            ],
            [
                "2",
                "3.0",
                "4",
                "5.0"
            ],
            [
                "<built-in function add>",
                "<built-in function sub>",
                "<built-in function mul>",
                "<built-in function truediv>",
                "<built-in function floordiv>",
                "<built-in function pow>",
                "<built-in function mod>",
                "<built-in function eq>",
                "<built-in function ne>",
                "<built-in function gt>",
                "<built-in function ge>",
                "<built-in function lt>",
                "<built-in function le>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "17cc3015c45764be50024cbe52247cfe2100d4020bdf03e0b04bea2f932fe975",
        "warmup_time": -1
    },
    "arithmetic.IrregularOps.time_add": {
        "code": "class IrregularOps:\n    def time_add(self):\n        self.left + self.right\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IrregularOps:\n    def setup(self):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        s = Series(np.random.randn(N), index=idx)\n        self.left = s.sample(frac=1)\n        self.right = s.sample(frac=1)",
        "min_run_count": 2,
        "name": "arithmetic.IrregularOps.time_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c48f5ee66f4fba32ce66ca585b4550f976b5632cf96bb22e9be34d3c2ea0a194",
        "warmup_time": -1
    },
    "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0": {
        "code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis0(self, opname):\n        getattr(self.df, opname)(self.ser, axis=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10**6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]",
        "min_run_count": 2,
        "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0",
        "number": 0,
        "param_names": [
            "opname"
        ],
        "params": [
            [
                "'eq'",
                "'ne'",
                "'lt'",
                "'le'",
                "'ge'",
                "'gt'",
                "'add'",
                "'sub'",
                "'truediv'",
                "'floordiv'",
                "'mul'",
                "'pow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2ec044d527bdcad8450ef35a26f4caee5ca2d8cf69f36b99665adedc140d4b71",
        "warmup_time": -1
    },
    "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1": {
        "code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis1(self, opname):\n        getattr(operator, opname)(self.df, self.ser)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10**6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]",
        "min_run_count": 2,
        "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1",
        "number": 0,
        "param_names": [
            "opname"
        ],
        "params": [
            [
                "'add'",
                "'sub'",
                "'truediv'",
                "'floordiv'",
                "'mul'",
                "'pow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1c5761284f2cd8adf60d3f65efee5881b415f0c986cfbbc8e313f298eb349a3e",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_add": {
        "code": "class NumericInferOps:\n    def time_add(self, dtype):\n        self.df[\"A\"] + self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_add",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d8c4f5e6dc0c54cff731395cacf041f5ccf4d5fdf6605e5aea2767fdea959165",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_divide": {
        "code": "class NumericInferOps:\n    def time_divide(self, dtype):\n        self.df[\"A\"] / self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_divide",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a435004455cc72252be9ec940814e96fbe3afb17fb5329b5d7c51208c9796979",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_modulo": {
        "code": "class NumericInferOps:\n    def time_modulo(self, dtype):\n        self.df[\"A\"] % self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_modulo",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "44d71d818e38047c0a9a5903a9d5707c2ff4eae84631c776e3dba9448493a767",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_multiply": {
        "code": "class NumericInferOps:\n    def time_multiply(self, dtype):\n        self.df[\"A\"] * self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_multiply",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fe621ddecbe036b8b2a50405324b8024f35d0412d89bf916c6adec56d4c5f360",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_subtract": {
        "code": "class NumericInferOps:\n    def time_subtract(self, dtype):\n        self.df[\"A\"] - self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_subtract",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2e26ca6727d932af0269ec66a57701c64b061d05601a076e2524ebf79e1b5cd6",
        "warmup_time": -1
    },
    "arithmetic.OffsetArrayArithmetic.time_add_dti_offset": {
        "code": "class OffsetArrayArithmetic:\n    def time_add_dti_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng\n        self.ser = Series(rng)",
        "min_run_count": 2,
        "name": "arithmetic.OffsetArrayArithmetic.time_add_dti_offset",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "773a2fe8364b7487aee29003e6fa3d183f2fb484205a9b055d70067c056ed277",
        "warmup_time": -1
    },
    "arithmetic.OffsetArrayArithmetic.time_add_series_offset": {
        "code": "class OffsetArrayArithmetic:\n    def time_add_series_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.ser + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng\n        self.ser = Series(rng)",
        "min_run_count": 2,
        "name": "arithmetic.OffsetArrayArithmetic.time_add_series_offset",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "14f080de541934c9cd028a210635eb42296006292989ffde9a52ae195ca39452",
        "warmup_time": -1
    },
    "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas": {
        "code": "class OpWithFillValue:\n    def time_frame_op_with_fill_value_no_nas(self):\n        self.df.add(self.df, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10**6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser",
        "min_run_count": 2,
        "name": "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "162ff770e3fdcbc51f2d5140c2cf46f028d48a27268957104ac69d7d800cc1a0",
        "warmup_time": -1
    },
    "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas": {
        "code": "class OpWithFillValue:\n    def time_series_op_with_fill_value_no_nas(self):\n        self.ser.add(self.ser, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10**6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser",
        "min_run_count": 2,
        "name": "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "81d51758d1b72e5df11be69874e29ffab5fdbe1e4cd1816754c197a4833d5d8e",
        "warmup_time": -1
    },
    "arithmetic.Ops.time_frame_add": {
        "code": "class Ops:\n    def time_frame_add(self, use_numexpr, threads):\n        self.df + self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)",
        "min_run_count": 2,
        "name": "arithmetic.Ops.time_frame_add",
        "number": 0,
        "param_names": [
            "use_numexpr",
            "threads"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'default'",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "173dfb8c14d4f1e45058ae77d74a28966785fc801b28902fd8448d30ac4ff7d8",
        "warmup_time": -1
    },
    "arithmetic.Ops.time_frame_comparison": {
        "code": "class Ops:\n    def time_frame_comparison(self, use_numexpr, threads):\n        self.df > self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)",
        "min_run_count": 2,
        "name": "arithmetic.Ops.time_frame_comparison",
        "number": 0,
        "param_names": [
            "use_numexpr",
            "threads"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'default'",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b9edf1afa79c0a69d8e9647b98beb73e32760b78ff938a190dc6b42ccac38b11",
        "warmup_time": -1
    },
    "arithmetic.Ops.time_frame_mult": {
        "code": "class Ops:\n    def time_frame_mult(self, use_numexpr, threads):\n        self.df * self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)",
        "min_run_count": 2,
        "name": "arithmetic.Ops.time_frame_mult",
        "number": 0,
        "param_names": [
            "use_numexpr",
            "threads"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'default'",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "911cfaa0ecf7737245490bf8a69723a5301ce60c296a33915a8eb9c09d7cd279",
        "warmup_time": -1
    },
    "arithmetic.Ops.time_frame_multi_and": {
        "code": "class Ops:\n    def time_frame_multi_and(self, use_numexpr, threads):\n        self.df[(self.df > 0) & (self.df2 > 0)]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)",
        "min_run_count": 2,
        "name": "arithmetic.Ops.time_frame_multi_and",
        "number": 0,
        "param_names": [
            "use_numexpr",
            "threads"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'default'",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "27fe96278213fdc7fe35ca52941a5bf4e3def23517666891d790d2d443a98ef2",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_dot": {
        "code": "class Ops2:\n    def time_frame_dot(self):\n        self.df.dot(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_dot",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "efdf52d3f6066f576d98f9b78aef45d706022d5fdf431ac33a3d411c8915c028",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_float_div": {
        "code": "class Ops2:\n    def time_frame_float_div(self):\n        self.df // self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_float_div",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "859b0f256d5a19376ac8c740779c53fb2287fd0c6f8f0d2f48052d7a57050a0a",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_float_div_by_zero": {
        "code": "class Ops2:\n    def time_frame_float_div_by_zero(self):\n        self.df / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_float_div_by_zero",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bacba426dd7890d79b38fd7575e9ba633c7ebc2252b393414e19e8838317b7a9",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_float_floor_by_zero": {
        "code": "class Ops2:\n    def time_frame_float_floor_by_zero(self):\n        self.df // 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_float_floor_by_zero",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5096a00c147e73e2a7a0be3156a440a3dd813fff99c8ed11456981814df947a2",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_float_mod": {
        "code": "class Ops2:\n    def time_frame_float_mod(self):\n        self.df % self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_float_mod",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "72aa4cef09d38e4af67ae6e35e15b1304bd371e85fc3613e817cedd372852517",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_int_div_by_zero": {
        "code": "class Ops2:\n    def time_frame_int_div_by_zero(self):\n        self.df_int / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_int_div_by_zero",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cdab6c35545be907f3db670b2114ccd527c652b9b3992d2ef767b26d538cc342",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_int_mod": {
        "code": "class Ops2:\n    def time_frame_int_mod(self):\n        self.df_int % self.df2_int\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_int_mod",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cb4f4230cb2354cccaed2ae0cd0fdfaf8ef908fbcf616544289f44a42a0f2eb4",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_series_dot": {
        "code": "class Ops2:\n    def time_frame_series_dot(self):\n        self.df.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_series_dot",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "30c45d8348c1f30ed5962671b11e5a31ae976f64b960b8cbe8eceb8c1f3716b8",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_series_dot": {
        "code": "class Ops2:\n    def time_series_dot(self):\n        self.s.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_series_dot",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "524f0eb5deba6ae021936a6721c4fec9cb92fccf0ac27c1799ab70139a436fdc",
        "warmup_time": -1
    },
    "arithmetic.TimedeltaOps.time_add_td_ts": {
        "code": "class TimedeltaOps:\n    def time_add_td_ts(self):\n        self.td + self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimedeltaOps:\n    def setup(self):\n        self.td = to_timedelta(np.arange(1000000))\n        self.ts = Timestamp(\"2000\")",
        "min_run_count": 2,
        "name": "arithmetic.TimedeltaOps.time_add_td_ts",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee3abda2771a3808efc316e236cd6de15f8678b03e2a27e6f75792edbbe543ec",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_series_timestamp_compare": {
        "code": "class Timeseries:\n    def time_series_timestamp_compare(self, tz):\n        self.s <= self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_series_timestamp_compare",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2ed5f17ee3263c0675f3f6293f63a1432f5f306de89d694585642001a6522d84",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_series_timestamp_different_reso_compare": {
        "code": "class Timeseries:\n    def time_series_timestamp_different_reso_compare(self, tz):\n        self.s <= self.ts_different_reso\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_series_timestamp_different_reso_compare",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3c7524e8c0a4069313b1ec51d6e534e708d5b1d735d3b48c3c2443ee4a65f1c8",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_timestamp_ops_diff": {
        "code": "class Timeseries:\n    def time_timestamp_ops_diff(self, tz):\n        self.s2.diff()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_timestamp_ops_diff",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "93c02a9bd33f19256f321c09451b0f35b9b4b1b1f54c9c3ff180aad5c57503ce",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift": {
        "code": "class Timeseries:\n    def time_timestamp_ops_diff_with_shift(self, tz):\n        self.s - self.s.shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8cab7c77baffeef8c23dde710dd4e428b68beaad2631fd5add6969cc56fb326a",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_timestamp_series_compare": {
        "code": "class Timeseries:\n    def time_timestamp_series_compare(self, tz):\n        self.ts >= self.s\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_timestamp_series_compare",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ef8d8e370d78f1580db60bb5b8997ef11749938452601dbe3816c0a1b7184c75",
        "warmup_time": -1
    },
    "array.ArrowExtensionArray.time_to_numpy": {
        "code": "class ArrowExtensionArray:\n    def time_to_numpy(self, dtype, hasna):\n        self.arr.to_numpy()\n\n    def setup(self, dtype, hasna):\n        N = 100_000\n        if dtype == \"boolean[pyarrow]\":\n            data = np.random.choice([True, False], N, replace=True)\n        elif dtype == \"float64[pyarrow]\":\n            data = np.random.randn(N)\n        elif dtype == \"int64[pyarrow]\":\n            data = np.arange(N)\n        elif dtype == \"string[pyarrow]\":\n            data = np.array([str(i) for i in range(N)], dtype=object)\n        elif dtype == \"timestamp[ns][pyarrow]\":\n            data = pd.date_range(\"2000-01-01\", freq=\"s\", periods=N)\n        else:\n            raise NotImplementedError\n    \n        arr = pd.array(data, dtype=dtype)\n        if hasna:\n            arr[::2] = pd.NA\n        self.arr = arr",
        "min_run_count": 2,
        "name": "array.ArrowExtensionArray.time_to_numpy",
        "number": 0,
        "param_names": [
            "dtype",
            "hasna"
        ],
        "params": [
            [
                "'boolean[pyarrow]'",
                "'float64[pyarrow]'",
                "'int64[pyarrow]'",
                "'string[pyarrow]'",
                "'timestamp[ns][pyarrow]'"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ae6d3539d4bf1ab5add70aed593a5fd7a6e541a28b7a0eb633a73bb9abd71cc2",
        "warmup_time": -1
    },
    "array.ArrowStringArray.time_setitem": {
        "code": "class ArrowStringArray:\n    def time_setitem(self, multiple_chunks):\n        for i in range(200):\n            self.array[i] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))",
        "min_run_count": 2,
        "name": "array.ArrowStringArray.time_setitem",
        "number": 0,
        "param_names": [
            "multiple_chunks"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "82acb0306b4f74cfc3a9251e34f34e48f9d75f55cc88e4561cdfe665c404b57c",
        "warmup_time": -1
    },
    "array.ArrowStringArray.time_setitem_list": {
        "code": "class ArrowStringArray:\n    def time_setitem_list(self, multiple_chunks):\n        indexer = list(range(50)) + list(range(-1000, 0, 50))\n        self.array[indexer] = [\"foo\"] * len(indexer)\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))",
        "min_run_count": 2,
        "name": "array.ArrowStringArray.time_setitem_list",
        "number": 0,
        "param_names": [
            "multiple_chunks"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3e18cf0ca3737e5f73e1077a467c9830fe02ddd6eb40a1445b2f2e1ef9201c39",
        "warmup_time": -1
    },
    "array.ArrowStringArray.time_setitem_null_slice": {
        "code": "class ArrowStringArray:\n    def time_setitem_null_slice(self, multiple_chunks):\n        self.array[:] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))",
        "min_run_count": 2,
        "name": "array.ArrowStringArray.time_setitem_null_slice",
        "number": 0,
        "param_names": [
            "multiple_chunks"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ef3c4fb5f84005a87d9d784f8909aa263278e37b51b46700c42b11198ed40b1c",
        "warmup_time": -1
    },
    "array.ArrowStringArray.time_setitem_slice": {
        "code": "class ArrowStringArray:\n    def time_setitem_slice(self, multiple_chunks):\n        self.array[::10] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))",
        "min_run_count": 2,
        "name": "array.ArrowStringArray.time_setitem_slice",
        "number": 0,
        "param_names": [
            "multiple_chunks"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6a0d09a5d23eb6dc7d6bb95140476cc1c1a896640e9d7bd005861c59072edc0d",
        "warmup_time": -1
    },
    "array.ArrowStringArray.time_tolist": {
        "code": "class ArrowStringArray:\n    def time_tolist(self, multiple_chunks):\n        self.array.tolist()\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))",
        "min_run_count": 2,
        "name": "array.ArrowStringArray.time_tolist",
        "number": 0,
        "param_names": [
            "multiple_chunks"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4f9947fe763b0abb9ed39a4a36de404cc91fc722c4cff1a0a5cf37ad0e99796f",
        "warmup_time": -1
    },
    "array.BooleanArray.time_constructor": {
        "code": "class BooleanArray:\n    def time_constructor(self):\n        pd.arrays.BooleanArray(self.data, self.mask)\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_constructor",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "31f0c0638e5908b3b2f79ec954e3e3c5f9b247f04708fe2a8ba53b4df1b161d5",
        "warmup_time": -1
    },
    "array.BooleanArray.time_from_bool_array": {
        "code": "class BooleanArray:\n    def time_from_bool_array(self):\n        pd.array(self.values_bool, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_from_bool_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "49de818c0d3213d4624b41ad1583ffa3da28d65f2dd89a30c9ed9ce4d8902300",
        "warmup_time": -1
    },
    "array.BooleanArray.time_from_float_array": {
        "code": "class BooleanArray:\n    def time_from_float_array(self):\n        pd.array(self.values_float, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_from_float_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "00f65facf261a9f506e825a7a84d17cc35d7f00ff17f090622cbbdb8e6a538dc",
        "warmup_time": -1
    },
    "array.BooleanArray.time_from_integer_array": {
        "code": "class BooleanArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_from_integer_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d27d54d2b7793c51154ffb049d0e1508e27dc0b3cdfa4f734789da01a48e0abf",
        "warmup_time": -1
    },
    "array.BooleanArray.time_from_integer_like": {
        "code": "class BooleanArray:\n    def time_from_integer_like(self):\n        pd.array(self.values_integer_like, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_from_integer_like",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6c37947cc0814a4fabfcf5fc4ebcb76a3e8d231c4fb5ca15eb3d0f502617a17d",
        "warmup_time": -1
    },
    "array.IntegerArray.time_constructor": {
        "code": "class IntegerArray:\n    def time_constructor(self):\n        pd.arrays.IntegerArray(self.data, self.mask)\n\n    def setup(self):\n        N = 250_000\n        self.values_integer = np.tile(np.array([1, 0, 1, 0]), N)\n        self.data = np.tile(np.array([1, 2, 3, 4], dtype=\"int64\"), N)\n        self.mask = np.tile(np.array([False, False, True, False]), N)",
        "min_run_count": 2,
        "name": "array.IntegerArray.time_constructor",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0ff5c1d57429763cebb625bcfc125d262aed2b7dc0532117078c943ad05a59d8",
        "warmup_time": -1
    },
    "array.IntegerArray.time_from_integer_array": {
        "code": "class IntegerArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"Int64\")\n\n    def setup(self):\n        N = 250_000\n        self.values_integer = np.tile(np.array([1, 0, 1, 0]), N)\n        self.data = np.tile(np.array([1, 2, 3, 4], dtype=\"int64\"), N)\n        self.mask = np.tile(np.array([False, False, True, False]), N)",
        "min_run_count": 2,
        "name": "array.IntegerArray.time_from_integer_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5030e9d654d92c3c38ca4b4c07b3883d555809c78cb492b2ed1be77342068a36",
        "warmup_time": -1
    },
    "array.IntervalArray.time_from_tuples": {
        "code": "class IntervalArray:\n    def time_from_tuples(self):\n        pd.arrays.IntervalArray.from_tuples(self.tuples)\n\n    def setup(self):\n        N = 10_000\n        self.tuples = [(i, i + 1) for i in range(N)]",
        "min_run_count": 2,
        "name": "array.IntervalArray.time_from_tuples",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ba4b21278924821c6bf31f74072230f7b2a24d7c87f7b4f0e1f99025ff60cdb8",
        "warmup_time": -1
    },
    "array.StringArray.time_from_list": {
        "code": "class StringArray:\n    def time_from_list(self):\n        pd.array(self.values_list, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()",
        "min_run_count": 2,
        "name": "array.StringArray.time_from_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b59bfa587e60de31e3429e020a9a8949d3d221a3932af12a9624990f3a988291",
        "warmup_time": -1
    },
    "array.StringArray.time_from_np_object_array": {
        "code": "class StringArray:\n    def time_from_np_object_array(self):\n        pd.array(self.values_obj, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()",
        "min_run_count": 2,
        "name": "array.StringArray.time_from_np_object_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5578afbd13efc40a2a7d729b43dd2c6bdc53313d61fb124133a837ade72dae9c",
        "warmup_time": -1
    },
    "array.StringArray.time_from_np_str_array": {
        "code": "class StringArray:\n    def time_from_np_str_array(self):\n        pd.array(self.values_str, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()",
        "min_run_count": 2,
        "name": "array.StringArray.time_from_np_str_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "70416c5ccb3bddcfddc25060580b22d14a9fb8f45a6ff0cb06fb0c2ecf4a08ce",
        "warmup_time": -1
    },
    "attrs_caching.DataFrameAttributes.time_get_index": {
        "code": "class DataFrameAttributes:\n    def time_get_index(self):\n        self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index",
        "min_run_count": 2,
        "name": "attrs_caching.DataFrameAttributes.time_get_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3246f297f11fb6074032907dde5fb9690d93465c80b45bc0b29e284fd5c9c17c",
        "warmup_time": -1
    },
    "attrs_caching.DataFrameAttributes.time_set_index": {
        "code": "class DataFrameAttributes:\n    def time_set_index(self):\n        self.df.index = self.cur_index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index",
        "min_run_count": 2,
        "name": "attrs_caching.DataFrameAttributes.time_set_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b34bb7eb8426bdd2eb9d8e0550ea2573475694ddc9f971fd9a29f15bf16732b0",
        "warmup_time": -1
    },
    "attrs_caching.SeriesArrayAttribute.time_array": {
        "code": "class SeriesArrayAttribute:\n    def time_array(self, dtype):\n        self.series.array\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))",
        "min_run_count": 2,
        "name": "attrs_caching.SeriesArrayAttribute.time_array",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'numeric'",
                "'object'",
                "'category'",
                "'datetime64'",
                "'datetime64tz'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "71871bee8b7f7a74c594352ad1177b3201818e5ffe6296b02844d93f2e74c57b",
        "warmup_time": -1
    },
    "attrs_caching.SeriesArrayAttribute.time_extract_array": {
        "code": "class SeriesArrayAttribute:\n    def time_extract_array(self, dtype):\n        extract_array(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))",
        "min_run_count": 2,
        "name": "attrs_caching.SeriesArrayAttribute.time_extract_array",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'numeric'",
                "'object'",
                "'category'",
                "'datetime64'",
                "'datetime64tz'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5c9e10a019a9c3c1a6f4016572eac561387c3cc14086cde81066ae5d495b6bae",
        "warmup_time": -1
    },
    "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy": {
        "code": "class SeriesArrayAttribute:\n    def time_extract_array_numpy(self, dtype):\n        extract_array(self.series, extract_numpy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))",
        "min_run_count": 2,
        "name": "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'numeric'",
                "'object'",
                "'category'",
                "'datetime64'",
                "'datetime64tz'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "34310e30090bb516b844f357295ebbe46f2980040632e1178dffc041a7635892",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_and_array": {
        "code": "class TimeLogicalOps:\n    def time_and_array(self):\n        self.left & self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_and_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6f948c075c42597b3abbe166b111d3f02c0aa11a2fd01b376b96547a7a0ece18",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_and_scalar": {
        "code": "class TimeLogicalOps:\n    def time_and_scalar(self):\n        self.left & True\n        self.left & False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_and_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "73483ccace6f6debdb2fd885f8fd8ffee9883f4e6dad1587a13239b8be135868",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_or_array": {
        "code": "class TimeLogicalOps:\n    def time_or_array(self):\n        self.left | self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_or_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "dc01bb9cbcdc979b4fbe050df208268a15ff5f328081a7fd09c41283c33bfa5d",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_or_scalar": {
        "code": "class TimeLogicalOps:\n    def time_or_scalar(self):\n        self.left | True\n        self.left | False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_or_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a9dcf90a110c0c703887ee44358e18a6930758987f7f1e9f921dd5ff4c84234e",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_xor_array": {
        "code": "class TimeLogicalOps:\n    def time_xor_array(self):\n        self.left ^ self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_xor_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e093e59c2f51a4998acf114ad54d2ab5d62d38548aab71f3f5c6adbe6bc46792",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_xor_scalar": {
        "code": "class TimeLogicalOps:\n    def time_xor_scalar(self):\n        self.left ^ True\n        self.left ^ False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_xor_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "eb50d9fee1d2beff8da51a2f128bb84bfa76379e9a699ae60dec8e82655bef3c",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_bool_array": {
        "code": "class CategoricalSlicing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_bool_array",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "392935c7d25151142e1191d330ed461794b00830ba9e56c8f000ae6eeb6e5d45",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_list": {
        "code": "class CategoricalSlicing:\n    def time_getitem_list(self, index):\n        self.data[self.list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_list",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5ba8074c37da942843683f8b852bf64ef44ae6f2be96c77aba4bccac3bce8f10",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_list_like": {
        "code": "class CategoricalSlicing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_list_like",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "30460a50c9cb11dd9282ec072489495e0335dcccb727a27666919c81757c0dde",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_scalar": {
        "code": "class CategoricalSlicing:\n    def time_getitem_scalar(self, index):\n        self.data[self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_scalar",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cede26e07c3b0d4aab9f6039da5d92a27c78c09893576e4fac2591b9115d35bb",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_slice": {
        "code": "class CategoricalSlicing:\n    def time_getitem_slice(self, index):\n        self.data[: self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_slice",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9c3df2609445fec8c3f08508d3bef72e89181594564d1d1d6aa4916879ddd608",
        "warmup_time": -1
    },
    "categoricals.Concat.time_append_non_overlapping_index": {
        "code": "class Concat:\n    def time_append_non_overlapping_index(self):\n        self.idx_a.append(self.idx_b)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_append_non_overlapping_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7c08f6f4a37c69d20540206d1bb4eac69032087283c327ea354e4e58b28e8e8a",
        "warmup_time": -1
    },
    "categoricals.Concat.time_append_overlapping_index": {
        "code": "class Concat:\n    def time_append_overlapping_index(self):\n        self.idx_a.append(self.idx_a)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_append_overlapping_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "86138129674bef3e164dd5e409ec0b275c1168e83dd747378cf52b02eb2311ea",
        "warmup_time": -1
    },
    "categoricals.Concat.time_concat": {
        "code": "class Concat:\n    def time_concat(self):\n        pd.concat([self.s, self.s])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_concat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "60e2b37af13d3ba791a2c5fa40b92f67b1d3f6421e301d9dfcfcd4ff1da10041",
        "warmup_time": -1
    },
    "categoricals.Concat.time_concat_non_overlapping_index": {
        "code": "class Concat:\n    def time_concat_non_overlapping_index(self):\n        pd.concat([self.df_a, self.df_b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_concat_non_overlapping_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "471ef66a2a2b2f051d1de9ad1ff46d1f9db09d862d97bedea6868f6ddd1f19f8",
        "warmup_time": -1
    },
    "categoricals.Concat.time_concat_overlapping_index": {
        "code": "class Concat:\n    def time_concat_overlapping_index(self):\n        pd.concat([self.df_a, self.df_a])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_concat_overlapping_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ecdea66fab8e41b9f198da14c16f2281c65bcff35fb98ddab2baf37924133287",
        "warmup_time": -1
    },
    "categoricals.Concat.time_union": {
        "code": "class Concat:\n    def time_union(self):\n        union_categoricals([self.a, self.b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_union",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b7637f08baccfad51b169c40b0d317647c40413dadb0068206d81bc916c9d71b",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_all_nan": {
        "code": "class Constructor:\n    def time_all_nan(self):\n        pd.Categorical(self.values_all_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_all_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fc34b2fc1aa3a8d989b3d4d4f43309050920b518ccb22742b8c9880fd2daeaa7",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_datetimes": {
        "code": "class Constructor:\n    def time_datetimes(self):\n        pd.Categorical(self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_datetimes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "21491bf24e30bce0fd02220d64dbbcf27433999a19ebeb8a4c2ada9323fffcec",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_datetimes_with_nat": {
        "code": "class Constructor:\n    def time_datetimes_with_nat(self):\n        pd.Categorical(self.datetimes_with_nat)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_datetimes_with_nat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fad1bc1045c1ecae82586b1bfc6206bd68dbf453b3c341f8b9626217a0dc98b6",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_existing_categorical": {
        "code": "class Constructor:\n    def time_existing_categorical(self):\n        pd.Categorical(self.categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_existing_categorical",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9630a83b0e8907ccdd4ba4448efef4f94833f2b6c0de71b2b6c499f816eb2f9a",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_existing_series": {
        "code": "class Constructor:\n    def time_existing_series(self):\n        pd.Categorical(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_existing_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e8f7fc0eafb5c42ec91db342f88e7ff30be72baf37daaeb01219128d72e36762",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_fastpath": {
        "code": "class Constructor:\n    def time_fastpath(self):\n        dtype = pd.CategoricalDtype(categories=self.cat_idx)\n        pd.Categorical._simple_new(self.codes, dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_fastpath",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a49c74359c6fac84f510b14b52c3b65bf4607a99672b5008c8e90d02ed151535",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_from_codes_all_int8": {
        "code": "class Constructor:\n    def time_from_codes_all_int8(self):\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_from_codes_all_int8",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7169835f266c2b716c0c53e03822c6b61e9364df39defea9a72e65866e9e799e",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_interval": {
        "code": "class Constructor:\n    def time_interval(self):\n        pd.Categorical(self.datetimes, categories=self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_interval",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a7acd5b43515c344aee35540db9d9e9ec60826748cc1ba87b0c033825ec7f8c3",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_regular": {
        "code": "class Constructor:\n    def time_regular(self):\n        pd.Categorical(self.values, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_regular",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c754dc01772b33919c14f0db934ba900c9aae6bf7c650f0d3556c912c7a6a080",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_with_nan": {
        "code": "class Constructor:\n    def time_with_nan(self):\n        pd.Categorical(self.values_some_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_with_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "da4358563a341dff6688a7cd1f87a7ce42556de3a84132ec7d02247774bc922a",
        "warmup_time": -1
    },
    "categoricals.Contains.time_categorical_contains": {
        "code": "class Contains:\n    def time_categorical_contains(self):\n        self.key in self.c\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N))\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]",
        "min_run_count": 2,
        "name": "categoricals.Contains.time_categorical_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "32365d05fca5315293e957770f928baaa798b4cd2133f97632aef854e0cbaf52",
        "warmup_time": -1
    },
    "categoricals.Contains.time_categorical_index_contains": {
        "code": "class Contains:\n    def time_categorical_index_contains(self):\n        self.key in self.ci\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N))\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]",
        "min_run_count": 2,
        "name": "categoricals.Contains.time_categorical_index_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "761e6e22b7fea3c9293e4bc5bfb69fb4843ae255301402ca5202bab136712748",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_align": {
        "code": "class Indexing:\n    def time_align(self):\n        pd.DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_align",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f218e6d543ab19db3fea1db2b664146198dd39dadac2966494426b556613d32d",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_get_loc": {
        "code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.category)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5f38e85f8450cba2264bb47680c1a9cd76458677f62e8ec8b53aac9e29c4fe62",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_intersection": {
        "code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_intersection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a413f3ef1a42a84770cc263a3ffc018c0623a71a70d26e58676660ab47210939",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_reindex": {
        "code": "class Indexing:\n    def time_reindex(self):\n        self.index.reindex(self.index[:500])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_reindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f068d9fbc3b599870598bc5ca8891b88762d7882d98234cd287b7021ae6ebdc2",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_reindex_missing": {
        "code": "class Indexing:\n    def time_reindex_missing(self):\n        self.index.reindex([\"a\", \"b\", \"c\", \"d\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_reindex_missing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8b7b5234b7e636fd26fb1d2ab98bfc3f744be66628ba69f7642a1f723887547f",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_shallow_copy": {
        "code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_shallow_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a719f97efeb6e929cfd555a6be02dce8108efd04f1f5bda591f52a642f5adbf9",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_sort_values": {
        "code": "class Indexing:\n    def time_sort_values(self):\n        self.index.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_sort_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "57dcf263eeda37b74d296554b77303db6387683cbff9d7e4ec8fbd03cab2f4d4",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_unique": {
        "code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_unique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "410cd9935506da614c2c46ec84a159befdeefe6b74e61c91bd5daa01f7d3e677",
        "warmup_time": -1
    },
    "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing": {
        "code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_decreasing(self):\n        self.c.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)",
        "min_run_count": 2,
        "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c4d103c6279f0b80ce554b92ebb3e5bc2c44dc1e40f2fa4ab07455ea280ab8cb",
        "warmup_time": -1
    },
    "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing": {
        "code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_increasing(self):\n        self.c.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)",
        "min_run_count": 2,
        "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fcebf885784c8e801b36cabd669598864a44b3d464eaef9eda7ca74df92105ad",
        "warmup_time": -1
    },
    "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing": {
        "code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_decreasing(self):\n        self.s.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)",
        "min_run_count": 2,
        "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fa8a5687d97343fae36bb22d0c776cfb090faec43b933d9f88facde7ba72c762",
        "warmup_time": -1
    },
    "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing": {
        "code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_increasing(self):\n        self.s.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)",
        "min_run_count": 2,
        "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "834fbde98d28981a9f726086c81fcfaed2914996bff27fdcdafe4769d95bb3d3",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_int": {
        "code": "class Rank:\n    def time_rank_int(self):\n        self.s_int.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7341bab0d3444509ae6d5889790fdd91da0b1c61f6f9417809486f6fd9ea7b41",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_int_cat": {
        "code": "class Rank:\n    def time_rank_int_cat(self):\n        self.s_int_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_int_cat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "73d1356f38bf95ad1cb847a06f70e5b406869b4257c3d29cda2b3324f960af3c",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_int_cat_ordered": {
        "code": "class Rank:\n    def time_rank_int_cat_ordered(self):\n        self.s_int_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_int_cat_ordered",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "12fcb558345d99ff95da65bdfa35893f93ebf3851a96a7e82adb63a959b2f501",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_string": {
        "code": "class Rank:\n    def time_rank_string(self):\n        self.s_str.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1234230d925b2b0fb2ead89ed4cab63499e7382657ae6bb6de6149643645185c",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_string_cat": {
        "code": "class Rank:\n    def time_rank_string_cat(self):\n        self.s_str_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_string_cat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "03fe33c89451ca7fb520c8aec7c05066e1ec116e56df2993a738b4e57ab9fbf8",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_string_cat_ordered": {
        "code": "class Rank:\n    def time_rank_string_cat_ordered(self):\n        self.s_str_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_string_cat_ordered",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "73135df6f2f87a366fb11675cc71b241c448b8d91ca00b54a9e95c3a239d1cb6",
        "warmup_time": -1
    },
    "categoricals.RemoveCategories.time_remove_categories": {
        "code": "class RemoveCategories:\n    def time_remove_categories(self):\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RemoveCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")",
        "min_run_count": 2,
        "name": "categoricals.RemoveCategories.time_remove_categories",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f41a55fefb120d979e5bcb1f387b4b8b8929b1b97c1b49370b42482deb07b426",
        "warmup_time": -1
    },
    "categoricals.Repr.time_rendering": {
        "code": "class Repr:\n    def time_rendering(self):\n        str(self.sel)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        self.sel = pd.Series([\"s1234\"]).astype(\"category\")",
        "min_run_count": 2,
        "name": "categoricals.Repr.time_rendering",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8d10d682b8918c4fac813851a9bf9304346e145623189c433d8d75ac72c1e1e6",
        "warmup_time": -1
    },
    "categoricals.SearchSorted.time_categorical_contains": {
        "code": "class SearchSorted:\n    def time_categorical_contains(self):\n        self.c.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N)).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]",
        "min_run_count": 2,
        "name": "categoricals.SearchSorted.time_categorical_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f33b78283987333ad6f166fd3f25a3cdf67998d5924b845d1372b1ac943eed47",
        "warmup_time": -1
    },
    "categoricals.SearchSorted.time_categorical_index_contains": {
        "code": "class SearchSorted:\n    def time_categorical_index_contains(self):\n        self.ci.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N)).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]",
        "min_run_count": 2,
        "name": "categoricals.SearchSorted.time_categorical_index_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7490e013ffd75c03cef3c770842c908f9b3f2e947c41b4f7398e117b125ff1ae",
        "warmup_time": -1
    },
    "categoricals.SetCategories.time_set_categories": {
        "code": "class SetCategories:\n    def time_set_categories(self):\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")",
        "min_run_count": 2,
        "name": "categoricals.SetCategories.time_set_categories",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee0d827baaa17c4f7f69783df06df5805e927698ff8dca902182228231f975c1",
        "warmup_time": -1
    },
    "categoricals.ValueCounts.time_value_counts": {
        "code": "class ValueCounts:\n    def time_value_counts(self, dropna):\n        self.ts.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dropna):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")",
        "min_run_count": 2,
        "name": "categoricals.ValueCounts.time_value_counts",
        "number": 0,
        "param_names": [
            "dropna"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4866939b81ce70129183c8d44e1a9d6b42c864346912c27670eb457cdf9fcfbb",
        "warmup_time": -1
    },
    "ctors.DatetimeIndexConstructor.time_from_list_of_dates": {
        "code": "class DatetimeIndexConstructor:\n    def time_from_list_of_dates(self):\n        DatetimeIndex(self.list_of_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()",
        "min_run_count": 2,
        "name": "ctors.DatetimeIndexConstructor.time_from_list_of_dates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bacd3eaca4814bb06e43ffa8586971974452ebd4e463efae8cac42b893d58a82",
        "warmup_time": -1
    },
    "ctors.DatetimeIndexConstructor.time_from_list_of_datetimes": {
        "code": "class DatetimeIndexConstructor:\n    def time_from_list_of_datetimes(self):\n        DatetimeIndex(self.list_of_datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()",
        "min_run_count": 2,
        "name": "ctors.DatetimeIndexConstructor.time_from_list_of_datetimes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "365ef0bfc846c299de2e9ec59316033adc76ea95a7f73a97d4ca958b3d6e913e",
        "warmup_time": -1
    },
    "ctors.DatetimeIndexConstructor.time_from_list_of_str": {
        "code": "class DatetimeIndexConstructor:\n    def time_from_list_of_str(self):\n        DatetimeIndex(self.list_of_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()",
        "min_run_count": 2,
        "name": "ctors.DatetimeIndexConstructor.time_from_list_of_str",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "11575c62b8c3127835edd05f4d19329b690f6ef06c30d58b8e772d2b7e7f0abf",
        "warmup_time": -1
    },
    "ctors.DatetimeIndexConstructor.time_from_list_of_timestamps": {
        "code": "class DatetimeIndexConstructor:\n    def time_from_list_of_timestamps(self):\n        DatetimeIndex(self.list_of_timestamps)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()",
        "min_run_count": 2,
        "name": "ctors.DatetimeIndexConstructor.time_from_list_of_timestamps",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1aba152c467ee66bcd374fe2d77743a9eef413d7057a74818aa8426b86441b71",
        "warmup_time": -1
    },
    "ctors.MultiIndexConstructor.time_multiindex_from_iterables": {
        "code": "class MultiIndexConstructor:\n    def time_multiindex_from_iterables(self):\n        MultiIndex.from_product(self.iterables)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexConstructor:\n    def setup(self):\n        N = 10**4\n        self.iterables = [Index([f\"i-{i}\" for i in range(N)], dtype=object), range(20)]",
        "min_run_count": 2,
        "name": "ctors.MultiIndexConstructor.time_multiindex_from_iterables",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7f0175b308859072a4a56134ed322bfc0508e9bbe03567849e74731bd45665b6",
        "warmup_time": -1
    },
    "ctors.SeriesConstructors.time_series_constructor": {
        "code": "class SeriesConstructors:\n    def time_series_constructor(self, data_fmt, with_index, dtype):\n        Series(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructors:\n    def setup(self, data_fmt, with_index, dtype):\n        if data_fmt in (gen_of_str, gen_of_tuples) and with_index:\n            raise NotImplementedError(\n                \"Series constructors do not support using generators with indexes\"\n            )\n        N = 10**4\n        if dtype == \"float\":\n            arr = np.random.randn(N)\n        else:\n            arr = np.arange(N)\n        self.data = data_fmt(arr)\n        self.index = np.arange(N) if with_index else None",
        "min_run_count": 2,
        "name": "ctors.SeriesConstructors.time_series_constructor",
        "number": 1,
        "param_names": [
            "data_fmt",
            "with_index",
            "dtype"
        ],
        "params": [
            [
                "<function no_change>",
                "<class 'list'>",
                "<function list_of_str>",
                "<function gen_of_str>",
                "<function arr_dict>",
                "<function list_of_tuples>",
                "<function gen_of_tuples>",
                "<function list_of_lists>",
                "<function list_of_tuples_with_none>",
                "<function list_of_lists_with_none>"
            ],
            [
                "False",
                "True"
            ],
            [
                "'float'",
                "'int'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "796b7e6dd06a06983968b54d6752714fff49f711f0da87ab239d7c33fe9306ba",
        "warmup_time": -1
    },
    "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series": {
        "code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_index_with_series(self):\n        Index(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )",
        "min_run_count": 2,
        "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "33f43d3855a48b47442f806cad0e6e7466e35fc29158753066509c648f173543",
        "warmup_time": -1
    },
    "ctors.SeriesDtypesConstructors.time_dtindex_from_series": {
        "code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_series(self):\n        DatetimeIndex(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )",
        "min_run_count": 2,
        "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "158ae6c81517f39c972e1bc3b7aab12bf753c0b37a15ca694e51998994283273",
        "warmup_time": -1
    },
    "ctors.SeriesDtypesConstructors.time_index_from_array_floats": {
        "code": "class SeriesDtypesConstructors:\n    def time_index_from_array_floats(self):\n        Index(self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )",
        "min_run_count": 2,
        "name": "ctors.SeriesDtypesConstructors.time_index_from_array_floats",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e0189b13b8400123e9a8d5d5c5d55240f975dd207efd63375f6fb000e228d534",
        "warmup_time": -1
    },
    "ctors.SeriesDtypesConstructors.time_index_from_array_string": {
        "code": "class SeriesDtypesConstructors:\n    def time_index_from_array_string(self):\n        Index(self.arr_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )",
        "min_run_count": 2,
        "name": "ctors.SeriesDtypesConstructors.time_index_from_array_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1403f63eb248697b83050c2515ddca96862bb42fdcd2fd7d5453bcafb3a9881e",
        "warmup_time": -1
    },
    "dtypes.CheckDtypes.time_is_extension_array_dtype_false": {
        "code": "class CheckDtypes:\n    def time_is_extension_array_dtype_false(self):\n        is_extension_array_dtype(self.np_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")",
        "min_run_count": 2,
        "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_false",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "81c7f57fc1b501fb5fe42b1928b850081d7fc62c6bda218e1faf99d2623a9dd7",
        "warmup_time": -1
    },
    "dtypes.CheckDtypes.time_is_extension_array_dtype_true": {
        "code": "class CheckDtypes:\n    def time_is_extension_array_dtype_true(self):\n        is_extension_array_dtype(self.ext_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")",
        "min_run_count": 2,
        "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_true",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "23b5bb2e01f5d1546ced81b111d6d84415d3945fe1392317283755c6205327cf",
        "warmup_time": -1
    },
    "dtypes.Dtypes.time_pandas_dtype": {
        "code": "class Dtypes:\n    def time_pandas_dtype(self, dtype):\n        pandas_dtype(dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)",
        "min_run_count": 2,
        "name": "dtypes.Dtypes.time_pandas_dtype",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "dtype('int64')",
                "dtype('int32')",
                "dtype('uint32')",
                "dtype('uint64')",
                "dtype('float32')",
                "dtype('float64')",
                "dtype('int16')",
                "dtype('int8')",
                "dtype('uint16')",
                "dtype('uint8')",
                "dtype('<M8')",
                "dtype('<m8')",
                "dtype('O')",
                "<class 'pandas.core.arrays.integer.Int8Dtype'>",
                "<class 'pandas.core.arrays.integer.Int16Dtype'>",
                "<class 'pandas.core.arrays.integer.Int32Dtype'>",
                "<class 'pandas.core.arrays.integer.Int64Dtype'>",
                "<class 'pandas.core.arrays.integer.UInt8Dtype'>",
                "<class 'pandas.core.arrays.integer.UInt16Dtype'>",
                "<class 'pandas.core.arrays.integer.UInt32Dtype'>",
                "<class 'pandas.core.arrays.integer.UInt64Dtype'>",
                "<class 'pandas.CategoricalDtype'>",
                "<class 'pandas.IntervalDtype'>",
                "datetime64[ns, UTC]",
                "period[D]",
                "'int64'",
                "'int32'",
                "'uint32'",
                "'uint64'",
                "'float32'",
                "'float64'",
                "'int16'",
                "'int8'",
                "'uint16'",
                "'uint8'",
                "'datetime64'",
                "'timedelta64'",
                "'object'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'category'",
                "'interval'",
                "'datetime64[ns, UTC]'",
                "'period[D]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fd9b99f460a442066f655fd285e96e7bc3a2fd5599a6e62433c98e0811c6d2ad",
        "warmup_time": -1
    },
    "dtypes.DtypesInvalid.time_pandas_dtype_invalid": {
        "code": "class DtypesInvalid:\n    def time_pandas_dtype_invalid(self, dtype):\n        try:\n            pandas_dtype(self.data_dict[dtype])\n        except TypeError:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)",
        "min_run_count": 2,
        "name": "dtypes.DtypesInvalid.time_pandas_dtype_invalid",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'scalar-string'",
                "'scalar-int'",
                "'list-string'",
                "'array-string'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7f3ba4b4c7fbd54b7a1820ab3b4dd151e482f73fe3403b9bc5250c8abb048f3b",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_bool_exclude": {
        "code": "class SelectDtypes:\n    def time_select_dtype_bool_exclude(self, dtype):\n        self.df_bool.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_bool_exclude",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "df61255244e9be8fc0d248c55f3e063ddbef5c245f81a5411c66a28002c4bb65",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_bool_include": {
        "code": "class SelectDtypes:\n    def time_select_dtype_bool_include(self, dtype):\n        self.df_bool.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_bool_include",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f0c2f1bc4901e7d306373868e213c49d8d54794baf5de80fb27088cfe9bd4eef",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_float_exclude": {
        "code": "class SelectDtypes:\n    def time_select_dtype_float_exclude(self, dtype):\n        self.df_float.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_float_exclude",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c3819287ad630000615230fed62878a437c4adaf18567017b87aa79f998a39c8",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_float_include": {
        "code": "class SelectDtypes:\n    def time_select_dtype_float_include(self, dtype):\n        self.df_float.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_float_include",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ec02ea504a673f4cff6ac450fe51e76ad048e83ded067055b143b3124192c38c",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_int_exclude": {
        "code": "class SelectDtypes:\n    def time_select_dtype_int_exclude(self, dtype):\n        self.df_int.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_int_exclude",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "63425c0b6c4bfde374a64deda9bf4636080d34b8f7af826fa3f1d71c549ebc06",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_int_include": {
        "code": "class SelectDtypes:\n    def time_select_dtype_int_include(self, dtype):\n        self.df_int.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_int_include",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ded41b293fecd74fd41f47735fe03f5f06ddb9a870a1a2cac4c88816f0d12210",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_string_exclude": {
        "code": "class SelectDtypes:\n    def time_select_dtype_string_exclude(self, dtype):\n        self.df_string.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_string_exclude",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f7ec4762bcc09823b04a3e5cb9713f0e1e7120a85eb2c1f040a944a491e88f1e",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_string_include": {
        "code": "class SelectDtypes:\n    def time_select_dtype_string_include(self, dtype):\n        self.df_string.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_string_include",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2d8ac290640b9e1ef5db1c2db3a2f6aac6007549995a6004381d6499370d2cff",
        "warmup_time": -1
    },
    "eval.Eval.time_add": {
        "code": "class Eval:\n    def time_add(self, engine, threads):\n        pd.eval(\"self.df + self.df2 + self.df3 + self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)",
        "min_run_count": 2,
        "name": "eval.Eval.time_add",
        "number": 0,
        "param_names": [
            "engine",
            "threads"
        ],
        "params": [
            [
                "'numexpr'",
                "'python'"
            ],
            [
                "1",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3b50f88f4cebf64200f50ab348ee13f8589e7dfb5962f7176004d30730f99112",
        "warmup_time": -1
    },
    "eval.Eval.time_and": {
        "code": "class Eval:\n    def time_and(self, engine, threads):\n        pd.eval(\n            \"(self.df > 0) & (self.df2 > 0) & (self.df3 > 0) & (self.df4 > 0)\",\n            engine=engine,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)",
        "min_run_count": 2,
        "name": "eval.Eval.time_and",
        "number": 0,
        "param_names": [
            "engine",
            "threads"
        ],
        "params": [
            [
                "'numexpr'",
                "'python'"
            ],
            [
                "1",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e48d6e775f144cea8cd29b74723eb86f939c566bd1c688845dd864d16d60de1b",
        "warmup_time": -1
    },
    "eval.Eval.time_chained_cmp": {
        "code": "class Eval:\n    def time_chained_cmp(self, engine, threads):\n        pd.eval(\"self.df < self.df2 < self.df3 < self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)",
        "min_run_count": 2,
        "name": "eval.Eval.time_chained_cmp",
        "number": 0,
        "param_names": [
            "engine",
            "threads"
        ],
        "params": [
            [
                "'numexpr'",
                "'python'"
            ],
            [
                "1",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0fe4b18c6cfabf06e6e4cac4c651276743a49df6a947913f8cabba517ba91786",
        "warmup_time": -1
    },
    "eval.Eval.time_mult": {
        "code": "class Eval:\n    def time_mult(self, engine, threads):\n        pd.eval(\"self.df * self.df2 * self.df3 * self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)",
        "min_run_count": 2,
        "name": "eval.Eval.time_mult",
        "number": 0,
        "param_names": [
            "engine",
            "threads"
        ],
        "params": [
            [
                "'numexpr'",
                "'python'"
            ],
            [
                "1",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a2085f987e1ce9ac0c43a0fe2cba5ad5be060d477671017c4323e892a23899a2",
        "warmup_time": -1
    },
    "eval.Query.time_query_datetime_column": {
        "code": "class Query:\n    def time_query_datetime_column(self):\n        self.df.query(\"dates < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()",
        "min_run_count": 2,
        "name": "eval.Query.time_query_datetime_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1d140272522b8968337a65f5bbde890d721057d547e6496ce5ac4cacf49a12c6",
        "warmup_time": -1
    },
    "eval.Query.time_query_datetime_index": {
        "code": "class Query:\n    def time_query_datetime_index(self):\n        self.df.query(\"index < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()",
        "min_run_count": 2,
        "name": "eval.Query.time_query_datetime_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e92d36300cfda073c91694f6d7c09a034bfef434123510ab0a1a271d6f82893f",
        "warmup_time": -1
    },
    "eval.Query.time_query_with_boolean_selection": {
        "code": "class Query:\n    def time_query_with_boolean_selection(self):\n        self.df.query(\"(a >= @self.min_val) & (a <= @self.max_val)\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()",
        "min_run_count": 2,
        "name": "eval.Query.time_query_with_boolean_selection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2e364600de60ccd8ec4ba833f5c80ab650db44896f1fc7b6b1c3271ae2750fe2",
        "warmup_time": -1
    },
    "finalize.Finalize.time_finalize_micro": {
        "code": "class Finalize:\n    def time_finalize_micro(self, param):\n        self.obj.__finalize__(self.obj, method=\"__finalize__\")\n\n    def setup(self, param):\n        N = 1000\n        obj = param(dtype=float)\n        for i in range(N):\n            obj.attrs[i] = i\n        self.obj = obj",
        "min_run_count": 2,
        "name": "finalize.Finalize.time_finalize_micro",
        "number": 0,
        "param_names": [
            "series"
        ],
        "params": [
            [
                "<class 'pandas.Series'>",
                "<class 'pandas.DataFrame'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bd2eab1eb436d45e913e54877c33d964695d4ac5fd0e7fd575f97eb347240a13",
        "warmup_time": -1
    },
    "frame_ctor.FromArrays.time_frame_from_arrays_float": {
        "code": "class FromArrays:\n    def time_frame_from_arrays_float(self):\n        self.df = DataFrame._from_arrays(\n            self.float_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))",
        "min_run_count": 2,
        "name": "frame_ctor.FromArrays.time_frame_from_arrays_float",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "325f63d87ecbf9ad645d78740a1aa8328bbd4c29f349c5b13a9117e526ce3866",
        "warmup_time": -1
    },
    "frame_ctor.FromArrays.time_frame_from_arrays_int": {
        "code": "class FromArrays:\n    def time_frame_from_arrays_int(self):\n        self.df = DataFrame._from_arrays(\n            self.int_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))",
        "min_run_count": 2,
        "name": "frame_ctor.FromArrays.time_frame_from_arrays_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0ea63af2ba6a6bc03ab7882f007240ed2d5183ed6fa7b85d15c9eb6f3c6f67f7",
        "warmup_time": -1
    },
    "frame_ctor.FromArrays.time_frame_from_arrays_sparse": {
        "code": "class FromArrays:\n    def time_frame_from_arrays_sparse(self):\n        self.df = DataFrame._from_arrays(\n            self.sparse_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))",
        "min_run_count": 2,
        "name": "frame_ctor.FromArrays.time_frame_from_arrays_sparse",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "225c22c0601994be668586bdb257030c2fd0d83e6dec0712bd820db812484318",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_dict_of_categoricals": {
        "code": "class FromDicts:\n    def time_dict_of_categoricals(self):\n        # dict of arrays that we won't consolidate\n        DataFrame(self.dict_of_categoricals)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_dict_of_categoricals",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "31bd8e5276983e0e0e3b54a1067e23e1e752f382dbb023f29dfb8b0e7ac5e72d",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_list_of_dict": {
        "code": "class FromDicts:\n    def time_list_of_dict(self):\n        DataFrame(self.dict_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_list_of_dict",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6c0dbbebd6c0771feeaf375a1d39dbba020a4c12fad6bfee70c573d4414e1469",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict": {
        "code": "class FromDicts:\n    def time_nested_dict(self):\n        DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6a72f77f78250c8d1bad34fed6e994a8fd896e30b59e0d1802ea0ea8193f587e",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict_columns": {
        "code": "class FromDicts:\n    def time_nested_dict_columns(self):\n        DataFrame(self.data, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e010dffc67442ff3250ce0a129b779c57637d00426ee53d397adc88b39992d63",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict_index": {
        "code": "class FromDicts:\n    def time_nested_dict_index(self):\n        DataFrame(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "48f1d011862f36806877b5da55102998d46466a016974d06f9495942c3585905",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict_index_columns": {
        "code": "class FromDicts:\n    def time_nested_dict_index_columns(self):\n        DataFrame(self.data, index=self.index, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict_index_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e8d48e85e7f0256d3a1429fba5e9eb60305bb9282b505830ecd2625e858835d4",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict_int64": {
        "code": "class FromDicts:\n    def time_nested_dict_int64(self):\n        # nested dict, integer indexes, regression described in #621\n        DataFrame(self.data2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict_int64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "90614f59dcc399707a19e251cedb7098d4a033b2c6a6436a0225cb69703c33e0",
        "warmup_time": -1
    },
    "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets": {
        "code": "class FromDictwithTimestamp:\n    def time_dict_with_timestamp_offsets(self, offset):\n        DataFrame(self.d)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDictwithTimestamp:\n    def setup(self, offset):\n        N = 10**3\n        idx = date_range(Timestamp(\"1/1/1900\"), freq=offset, periods=N)\n        df = DataFrame(np.random.randn(N, 10), index=idx)\n        self.d = df.to_dict()",
        "min_run_count": 2,
        "name": "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Nano>",
                "<Hour>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "edbcf77be1e9f491a8866f3f510790d47d2c68aa69eb8e349b4662c23e071ce4",
        "warmup_time": -1
    },
    "frame_ctor.FromLists.time_frame_from_lists": {
        "code": "class FromLists:\n    def time_frame_from_lists(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromLists:\n    def setup(self):\n        N = 1000\n        M = 100\n        self.data = [list(range(M)) for i in range(N)]",
        "min_run_count": 2,
        "name": "frame_ctor.FromLists.time_frame_from_lists",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "31e3e4ee69561a2f18687d4fe38117db21e57a6862eba4174561ab425ca7791a",
        "warmup_time": -1
    },
    "frame_ctor.FromNDArray.time_frame_from_ndarray": {
        "code": "class FromNDArray:\n    def time_frame_from_ndarray(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromNDArray:\n    def setup(self):\n        N = 100000\n        self.data = np.random.randn(N)",
        "min_run_count": 2,
        "name": "frame_ctor.FromNDArray.time_frame_from_ndarray",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "42412f191926bccd17fde73d100476018ba3e35421ee311ca6a8d71ef8817e04",
        "warmup_time": -1
    },
    "frame_ctor.FromRange.time_frame_from_range": {
        "code": "class FromRange:\n    def time_frame_from_range(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRange:\n    def setup(self):\n        N = 1_000_000\n        self.data = range(N)",
        "min_run_count": 2,
        "name": "frame_ctor.FromRange.time_frame_from_range",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8eac1f82a2a2f08e5f9e50dfcf68b362211c18712ce5adbbc12bc772d7d7f156",
        "warmup_time": -1
    },
    "frame_ctor.FromRecords.time_frame_from_records_generator": {
        "code": "class FromRecords:\n    def time_frame_from_records_generator(self, nrows):\n        # issue-6700\n        self.df = DataFrame.from_records(self.gen, nrows=nrows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRecords:\n    def setup(self, nrows):\n        N = 100000\n        self.gen = ((x, (x * 20), (x * 100)) for x in range(N))",
        "min_run_count": 2,
        "name": "frame_ctor.FromRecords.time_frame_from_records_generator",
        "number": 1,
        "param_names": [
            "nrows"
        ],
        "params": [
            [
                "None",
                "1000"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "37ac2364875f70b5e255d9371c8fd77229fbb2bb221090c4004cce2af1f510b4",
        "warmup_time": -1
    },
    "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64": {
        "code": "class FromScalar:\n    def time_frame_from_scalar_ea_float64(self):\n        DataFrame(\n            1.0,\n            index=range(self.nrows),\n            columns=list(\"abc\"),\n            dtype=Float64Dtype(),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromScalar:\n    def setup(self):\n        self.nrows = 100_000",
        "min_run_count": 2,
        "name": "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c0971ae1b0ebe91e20c2c53f71217475a9812d27e00b303f343bae2612d9828d",
        "warmup_time": -1
    },
    "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64_na": {
        "code": "class FromScalar:\n    def time_frame_from_scalar_ea_float64_na(self):\n        DataFrame(\n            NA,\n            index=range(self.nrows),\n            columns=list(\"abc\"),\n            dtype=Float64Dtype(),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromScalar:\n    def setup(self):\n        self.nrows = 100_000",
        "min_run_count": 2,
        "name": "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64_na",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9075f068d48f77d734b775cec79405c4847fd0a6e1abfac3461c0dc12981f0b0",
        "warmup_time": -1
    },
    "frame_ctor.FromSeries.time_mi_series": {
        "code": "class FromSeries:\n    def time_mi_series(self):\n        DataFrame(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromSeries:\n    def setup(self):\n        mi = MultiIndex.from_product([range(100), range(100)])\n        self.s = Series(np.random.randn(10000), index=mi)",
        "min_run_count": 2,
        "name": "frame_ctor.FromSeries.time_mi_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "00d66d6b3fb76fd4030a0096f492a7b2040615acbd38000c2317b116f3156fa2",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_axis_1": {
        "code": "class Apply:\n    def time_apply_axis_1(self):\n        self.df.apply(lambda x: x + 1, axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_axis_1",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1abb619fc583026b4a26e477881f01094dbeb880dded525e7cbea1815b8c3c7b",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_lambda_mean": {
        "code": "class Apply:\n    def time_apply_lambda_mean(self):\n        self.df.apply(lambda x: x.mean())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_lambda_mean",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e070e421516f44eee71e66e3fbf7ef0021872ca7eb578f4d11231ed83d441a64",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_pass_thru": {
        "code": "class Apply:\n    def time_apply_pass_thru(self):\n        self.df.apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_pass_thru",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7ab6875c70f560ff825c524d780a53db1cad1e43c32e17fe6707f66113694e4c",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_ref_by_name": {
        "code": "class Apply:\n    def time_apply_ref_by_name(self):\n        self.df3.apply(lambda x: x[\"A\"] + x[\"B\"], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_ref_by_name",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2195dd01ad2f3a289b3754239166687e0753c2a9d5efc0d8be4978c886628236",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_str_mean": {
        "code": "class Apply:\n    def time_apply_str_mean(self):\n        self.df.apply(\"mean\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_str_mean",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "521315810d8415e08556972f62c418fa4eabe181b49caea873ca989ae060e78f",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_user_func": {
        "code": "class Apply:\n    def time_apply_user_func(self):\n        self.df2.apply(lambda x: np.corrcoef(x, self.s)[(0, 1)])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_user_func",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f52de9d070093a84321a5d00e1ff6810b8c4b83e274a1daabf52699c0244b257",
        "warmup_time": -1
    },
    "frame_methods.AsType.time_astype": {
        "code": "class AsType:\n    def time_astype(self, from_to_dtypes, copy):\n        self.df.astype(from_to_dtypes[1], copy=copy)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsType:\n    def setup(self, from_to_dtypes, copy):\n        from_dtype = from_to_dtypes[0]\n        if from_dtype in (\"float64\", \"Float64\", \"float64[pyarrow]\"):\n            data = np.random.randn(100, 100)\n        elif from_dtype in (\"int64\", \"Int64\", \"int64[pyarrow]\"):\n            data = np.random.randint(0, 1000, (100, 100))\n        else:\n            raise NotImplementedError\n        self.df = DataFrame(data, dtype=from_dtype)",
        "min_run_count": 2,
        "name": "frame_methods.AsType.time_astype",
        "number": 0,
        "param_names": [
            "from_to_dtypes",
            "copy"
        ],
        "params": [
            [
                "('Float64', 'Float64')",
                "('float64[pyarrow]', 'float64[pyarrow]')",
                "('float64', 'Float64')",
                "('float64', 'float64[pyarrow]')",
                "('Float64', 'float64')",
                "('float64[pyarrow]', 'float64')",
                "('Int64', 'Float64')",
                "('int64[pyarrow]', 'float64[pyarrow]')"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a9374f8b9c978c55710c85c55c7a9fd7794a57da8cf27963be077ff661b3c688",
        "warmup_time": -1
    },
    "frame_methods.Clip.time_clip": {
        "code": "class Clip:\n    def time_clip(self, dtype):\n        self.df.clip(-1.0, 1.0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, dtype):\n        data = np.random.randn(100_000, 10)\n        df = DataFrame(data, dtype=dtype)\n        self.df = df",
        "min_run_count": 2,
        "name": "frame_methods.Clip.time_clip",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float64'",
                "'Float64'",
                "'float64[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e377218cbb14d1e57e275faade93ca8bb525a9a1b596836b7b181b935186f968",
        "warmup_time": -1
    },
    "frame_methods.Count.time_count": {
        "code": "class Count:\n    def time_count(self, axis):\n        self.df.count(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"",
        "min_run_count": 2,
        "name": "frame_methods.Count.time_count",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6d0fb3a3427b887565c31a8e63dda9d7ddd21b17b3f6da46237aac13dcc606e1",
        "warmup_time": -1
    },
    "frame_methods.Count.time_count_mixed_dtypes": {
        "code": "class Count:\n    def time_count_mixed_dtypes(self, axis):\n        self.df_mixed.count(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"",
        "min_run_count": 2,
        "name": "frame_methods.Count.time_count_mixed_dtypes",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7676f0fd5db04a5cff602ddb81b98c1ced3e13ae9438e99839dab87c73cfced6",
        "warmup_time": -1
    },
    "frame_methods.Describe.time_dataframe_describe": {
        "code": "class Describe:\n    def time_dataframe_describe(self):\n        self.df.describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10**6),\n                \"b\": np.random.randint(0, 100, 10**6),\n                \"c\": np.random.randint(0, 100, 10**6),\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Describe.time_dataframe_describe",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a874bed44cb683ca51210e26724792fcdf88f6ff721f785384c8fb834049538a",
        "warmup_time": -1
    },
    "frame_methods.Describe.time_series_describe": {
        "code": "class Describe:\n    def time_series_describe(self):\n        self.df[\"a\"].describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10**6),\n                \"b\": np.random.randint(0, 100, 10**6),\n                \"c\": np.random.randint(0, 100, 10**6),\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Describe.time_series_describe",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bec8143392a0ea823e7bb51cdbc8e7e85a7655f739b8e049e7568f9d33a744f4",
        "warmup_time": -1
    },
    "frame_methods.Dropna.time_dropna": {
        "code": "class Dropna:\n    def time_dropna(self, how, axis):\n        self.df.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"",
        "min_run_count": 2,
        "name": "frame_methods.Dropna.time_dropna",
        "number": 0,
        "param_names": [
            "how",
            "axis"
        ],
        "params": [
            [
                "'all'",
                "'any'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0ae9be10365366634edb6b6490363a365b53e5bb30376f429aa6cd8501e99f60",
        "warmup_time": -1
    },
    "frame_methods.Dropna.time_dropna_axis_mixed_dtypes": {
        "code": "class Dropna:\n    def time_dropna_axis_mixed_dtypes(self, how, axis):\n        self.df_mixed.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"",
        "min_run_count": 2,
        "name": "frame_methods.Dropna.time_dropna_axis_mixed_dtypes",
        "number": 0,
        "param_names": [
            "how",
            "axis"
        ],
        "params": [
            [
                "'all'",
                "'any'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "211ec5d6bd6568e1ab93ad31c07d7ea015f9540b948fa60ae1ce9846c9d0aaf8",
        "warmup_time": -1
    },
    "frame_methods.Dtypes.time_frame_dtypes": {
        "code": "class Dtypes:\n    def time_frame_dtypes(self):\n        self.df.dtypes\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dtypes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 1000))",
        "min_run_count": 2,
        "name": "frame_methods.Dtypes.time_frame_dtypes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a32eaac056e26349ac255f6354f2a8916b634a88bcf2fd8439b28dc9a21e4ff4",
        "warmup_time": -1
    },
    "frame_methods.Duplicated.time_frame_duplicated": {
        "code": "class Duplicated:\n    def time_frame_duplicated(self):\n        self.df.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T",
        "min_run_count": 2,
        "name": "frame_methods.Duplicated.time_frame_duplicated",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8a4abe4aaf65e24b3da4f462809f17932a37cc967c623d8b7ff091daba1eb543",
        "warmup_time": -1
    },
    "frame_methods.Duplicated.time_frame_duplicated_subset": {
        "code": "class Duplicated:\n    def time_frame_duplicated_subset(self):\n        self.df.duplicated(subset=[\"a\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T",
        "min_run_count": 2,
        "name": "frame_methods.Duplicated.time_frame_duplicated_subset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "23f21c0b6b3f598648f33cbab727152cfaee3599521704a18f47a8184502b9f2",
        "warmup_time": -1
    },
    "frame_methods.Duplicated.time_frame_duplicated_wide": {
        "code": "class Duplicated:\n    def time_frame_duplicated_wide(self):\n        self.df2.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T",
        "min_run_count": 2,
        "name": "frame_methods.Duplicated.time_frame_duplicated_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "097f9842171e94103f87e1898827b9193a138985565752f4880b1b4df539adb7",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_float_equal": {
        "code": "class Equals:\n    def time_frame_float_equal(self):\n        self.float_df.equals(self.float_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_float_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3e43e40c9afb93fdb9e4dc0b1153cb7e251f37639262f67e949b58d4cdec6de6",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_float_unequal": {
        "code": "class Equals:\n    def time_frame_float_unequal(self):\n        self.float_df.equals(self.float_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_float_unequal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "096c7821b123d68c85d2ed32adda440daf4043608ac9a04e121f66aef041e33a",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_nonunique_equal": {
        "code": "class Equals:\n    def time_frame_nonunique_equal(self):\n        self.nonunique_cols.equals(self.nonunique_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_nonunique_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ea0c51f42ef266ee9b0fafafaa48a2192674cd615ae9f7b648b83aafbc5dcdce",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_nonunique_unequal": {
        "code": "class Equals:\n    def time_frame_nonunique_unequal(self):\n        self.nonunique_cols.equals(self.nonunique_cols_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_nonunique_unequal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0afac18ed2411295c0adc10e398c9e4b02682bb882a28427a848f9b9455ad7dd",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_object_equal": {
        "code": "class Equals:\n    def time_frame_object_equal(self):\n        self.object_df.equals(self.object_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_object_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fcfdbbe9b7bbe39721d77c9ea49fde74df25c32913469a26570f9cedeeebe789",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_object_unequal": {
        "code": "class Equals:\n    def time_frame_object_unequal(self):\n        self.object_df.equals(self.object_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_object_unequal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8bb79f98af91ebb0756c6d77ad92778236c4b7ac8b01c041ed655dfb3fed7ce7",
        "warmup_time": -1
    },
    "frame_methods.Fillna.time_bfill": {
        "code": "class Fillna:\n    def time_bfill(self, inplace, dtype):\n        self.df.bfill(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()",
        "min_run_count": 2,
        "name": "frame_methods.Fillna.time_bfill",
        "number": 0,
        "param_names": [
            "inplace",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'float64'",
                "'float32'",
                "'object'",
                "'Int64'",
                "'Float64'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'",
                "'timedelta64[ns]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ab1619ca6d7bbaad9c0eac1f7dd4ea723ac82673224aa8dbce70c1984f22acb3",
        "warmup_time": -1
    },
    "frame_methods.Fillna.time_ffill": {
        "code": "class Fillna:\n    def time_ffill(self, inplace, dtype):\n        self.df.ffill(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()",
        "min_run_count": 2,
        "name": "frame_methods.Fillna.time_ffill",
        "number": 0,
        "param_names": [
            "inplace",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'float64'",
                "'float32'",
                "'object'",
                "'Int64'",
                "'Float64'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'",
                "'timedelta64[ns]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0912aa084abd2d5fc47d46ff25b6d897cec70cdab63de87d29937622654d060a",
        "warmup_time": -1
    },
    "frame_methods.Fillna.time_fillna": {
        "code": "class Fillna:\n    def time_fillna(self, inplace, dtype):\n        self.df.fillna(value=self.fill_values, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()",
        "min_run_count": 2,
        "name": "frame_methods.Fillna.time_fillna",
        "number": 0,
        "param_names": [
            "inplace",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'float64'",
                "'float32'",
                "'object'",
                "'Int64'",
                "'Float64'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'",
                "'timedelta64[ns]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ba97c9ea4cd6a522136714fca9cc26d5060c052e08f8ff392def7c3b1ce4578e",
        "warmup_time": -1
    },
    "frame_methods.FindValidIndex.time_first_valid_index": {
        "code": "class FindValidIndex:\n    def time_first_valid_index(self, dtype):\n        self.df.first_valid_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FindValidIndex:\n    def setup(self, dtype):\n        df = DataFrame(\n            np.random.randn(100000, 2),\n            columns=list(\"AB\"),\n            dtype=dtype,\n        )\n        df.iloc[:100, 0] = None\n        df.iloc[:200, 1] = None\n        df.iloc[-100:, 0] = None\n        df.iloc[-200:, 1] = None\n        self.df = df",
        "min_run_count": 2,
        "name": "frame_methods.FindValidIndex.time_first_valid_index",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'Float64'",
                "'float64[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "25a643509f423207f4a1c6d8a57a39a4a2fb113489c72c587ab77425b9d0ed8c",
        "warmup_time": -1
    },
    "frame_methods.FindValidIndex.time_last_valid_index": {
        "code": "class FindValidIndex:\n    def time_last_valid_index(self, dtype):\n        self.df.last_valid_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FindValidIndex:\n    def setup(self, dtype):\n        df = DataFrame(\n            np.random.randn(100000, 2),\n            columns=list(\"AB\"),\n            dtype=dtype,\n        )\n        df.iloc[:100, 0] = None\n        df.iloc[:200, 1] = None\n        df.iloc[-100:, 0] = None\n        df.iloc[-200:, 1] = None\n        self.df = df",
        "min_run_count": 2,
        "name": "frame_methods.FindValidIndex.time_last_valid_index",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'Float64'",
                "'float64[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7aa1cbbe0fc10c07e441950795f86f657072d95abb3fc53a6cd08af9ca145bb5",
        "warmup_time": -1
    },
    "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts": {
        "code": "class GetDtypeCounts:\n    def time_frame_get_dtype_counts(self):\n        with warnings.catch_warnings(record=True):\n            self.df.dtypes.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))",
        "min_run_count": 2,
        "name": "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d1e0466afc9058166debec31e7ff688df837d407655e8faf0621969115aee0dd",
        "warmup_time": -1
    },
    "frame_methods.GetDtypeCounts.time_info": {
        "code": "class GetDtypeCounts:\n    def time_info(self):\n        self.df.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))",
        "min_run_count": 2,
        "name": "frame_methods.GetDtypeCounts.time_info",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e08ed8e2402f26a376b2c946606fe2bc255214bd7eebee091fe34b3aa4df80db",
        "warmup_time": -1
    },
    "frame_methods.GetNumericData.time_frame_get_numeric_data": {
        "code": "class GetNumericData:\n    def time_frame_get_numeric_data(self):\n        self.df._get_numeric_data()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetNumericData:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 25))\n        self.df[\"foo\"] = \"bar\"\n        self.df[\"bar\"] = \"baz\"\n        self.df = self.df._consolidate()",
        "min_run_count": 2,
        "name": "frame_methods.GetNumericData.time_frame_get_numeric_data",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a6f6ccd03d2a3e6a5b9533bf09fd1f3d852fb8c066e10da43dee6c5b1b958b16",
        "warmup_time": -1
    },
    "frame_methods.Interpolate.time_interpolate": {
        "code": "class Interpolate:\n    def time_interpolate(self):\n        self.df.interpolate()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Interpolate.time_interpolate",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c596eeb3d29c229642e5985525a061a7048ea58730234346a6a62d19c92dbac7",
        "warmup_time": -1
    },
    "frame_methods.Interpolate.time_interpolate_some_good": {
        "code": "class Interpolate:\n    def time_interpolate_some_good(self):\n        self.df2.interpolate()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Interpolate.time_interpolate_some_good",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a33fc1bf97cd98d64d979695f6cd8a828368e681b17fd24a2064470b41e314f5",
        "warmup_time": -1
    },
    "frame_methods.Isna.time_isna": {
        "code": "class Isna:\n    def time_isna(self, dtype):\n        self.df.isna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isna:\n    def setup(self, dtype):\n        data = np.random.randn(10000, 1000)\n        # all-na columns\n        data[:, 600:800] = np.nan\n        # partial-na columns\n        data[800:1000, 4000:5000] = np.nan\n        self.df = DataFrame(data, dtype=dtype)",
        "min_run_count": 2,
        "name": "frame_methods.Isna.time_isna",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float64'",
                "'Float64'",
                "'float64[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "16c807e189d1c06f5c7693f87fb8211e7206b4807b9eba3c390f1dd2c5e5cf37",
        "warmup_time": -1
    },
    "frame_methods.Isnull.time_isnull": {
        "code": "class Isnull:\n    def time_isnull(self):\n        isnull(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)",
        "min_run_count": 2,
        "name": "frame_methods.Isnull.time_isnull",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "de22a45fa388dfa02f30c3a7cb1acae9fe966c2d1e68671882fa38eda4e52b3e",
        "warmup_time": -1
    },
    "frame_methods.Isnull.time_isnull_floats_no_null": {
        "code": "class Isnull:\n    def time_isnull_floats_no_null(self):\n        isnull(self.df_no_null)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)",
        "min_run_count": 2,
        "name": "frame_methods.Isnull.time_isnull_floats_no_null",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d52c0900c393b15f62670fa1ccbc7018957cad8e340de411ad4bd5b33da9ee72",
        "warmup_time": -1
    },
    "frame_methods.Isnull.time_isnull_obj": {
        "code": "class Isnull:\n    def time_isnull_obj(self):\n        isnull(self.df_obj)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)",
        "min_run_count": 2,
        "name": "frame_methods.Isnull.time_isnull_obj",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "02fc103a644b76b012203138d72c1aedc60734a2ca5eaa97a80a3cac46bcf039",
        "warmup_time": -1
    },
    "frame_methods.Isnull.time_isnull_strngs": {
        "code": "class Isnull:\n    def time_isnull_strngs(self):\n        isnull(self.df_strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)",
        "min_run_count": 2,
        "name": "frame_methods.Isnull.time_isnull_strngs",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ff2d41de239a32889b66173e7caa3c0017fac8052762ae9703e5f9e07e1ef5a5",
        "warmup_time": -1
    },
    "frame_methods.Iteration.mem_itertuples_raw_start": {
        "code": "class Iteration:\n    def mem_itertuples_raw_start(self):\n        return self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_raw_start",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "bde9d2373c7953bbf4a4d7fe73bd19e60eb7c15b50f8978637098fec3d837ed1"
    },
    "frame_methods.Iteration.mem_itertuples_raw_to_list": {
        "code": "class Iteration:\n    def mem_itertuples_raw_to_list(self):\n        return list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_raw_to_list",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "14959ad0e6b16ce24b2986d509e67eeccc6ad44f09ce481e44781dd903d37a04"
    },
    "frame_methods.Iteration.mem_itertuples_read_first": {
        "code": "class Iteration:\n    def mem_itertuples_read_first(self):\n        return next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_read_first",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "fa14a67958421e77045287ab0dfe58c2d22462f3b77070715024772201c64770"
    },
    "frame_methods.Iteration.mem_itertuples_start": {
        "code": "class Iteration:\n    def mem_itertuples_start(self):\n        return self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_start",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "cf2518d7a524f33405fe8b9f5e7dd8af1e52820e56cf14f92d6ff79ca33bbca9"
    },
    "frame_methods.Iteration.mem_itertuples_to_list": {
        "code": "class Iteration:\n    def mem_itertuples_to_list(self):\n        return list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_to_list",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "fc2c86822b2a65a5dd8df96b9003fe69eb2c82b3b8543140d1744b7d7fbc099f"
    },
    "frame_methods.Iteration.peakmem_itertuples": {
        "code": "class Iteration:\n    def peakmem_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f8c4bb246773a09f62d6963200ac6dd08accf63f8701099b39f34450db0baa76"
    },
    "frame_methods.Iteration.peakmem_itertuples_raw": {
        "code": "class Iteration:\n    def peakmem_itertuples_raw(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_raw",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "51be24a7edeb484ceaa5e24c608c890c59c56b210c778564af1c40cde9c6582b"
    },
    "frame_methods.Iteration.peakmem_itertuples_raw_read_first": {
        "code": "class Iteration:\n    def peakmem_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_raw_read_first",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "3bcec70cbf3d3ea880425ba6e3a7a604504d19716e82dbbb4a70fb8351eda7f3"
    },
    "frame_methods.Iteration.peakmem_itertuples_raw_start": {
        "code": "class Iteration:\n    def peakmem_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_raw_start",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "8d85d7a2d0ceb456c1eae16a3f138a7ea0a13edf1bd76492d262b00cc32013cf"
    },
    "frame_methods.Iteration.peakmem_itertuples_raw_to_list": {
        "code": "class Iteration:\n    def peakmem_itertuples_raw_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_raw_to_list",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "702541458ae59bd0fa6a7654edf93ba6de30013419a4591073b4077ffaaa9ec1"
    },
    "frame_methods.Iteration.peakmem_itertuples_start": {
        "code": "class Iteration:\n    def peakmem_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_start",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "2e9870eb171bfbc3718dac5dc495cf2a5fc860a65acca33db4110a97d819f905"
    },
    "frame_methods.Iteration.peakmem_itertuples_to_list": {
        "code": "class Iteration:\n    def peakmem_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_to_list",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "3b1c891c821d3baa961e2ac7bbba794eaaa5fdde90643e15273782165349694d"
    },
    "frame_methods.Iteration.time_items": {
        "code": "class Iteration:\n    def time_items(self):\n        # (monitor no-copying behaviour)\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_items",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "a6f7587a4f64433c91d33b1870cb0f27c4cf206efd215b5ef8c197f6515465e4",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_iteritems_indexing": {
        "code": "class Iteration:\n    def time_iteritems_indexing(self):\n        for col in self.df3:\n            self.df3[col]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_iteritems_indexing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "32a0d9e470a05a943e062be7e53224b0a8d3c4753f3ea203564451fe73e00be6",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_iterrows": {
        "code": "class Iteration:\n    def time_iterrows(self):\n        for row in self.df.iterrows():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_iterrows",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "1872356d18d8d38838ccef4e38aea113cb033fcd589da146758d76d6aba725c1",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples": {
        "code": "class Iteration:\n    def time_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "bc1f6d845378bd6d1c53d1ef7b8e0f725f9a6ca74b0b1bfe928c5a21e6829fd9",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_raw_read_first": {
        "code": "class Iteration:\n    def time_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_raw_read_first",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "78a787f4a6eb7dd27f3ac2434d4d26567eca763890c14bd2b86b54d88ade5db4",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_raw_start": {
        "code": "class Iteration:\n    def time_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_raw_start",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "e34eb99379456d0e4ff1da68c34d436747af447b5d80f49bca78a9095da18426",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_raw_tuples": {
        "code": "class Iteration:\n    def time_itertuples_raw_tuples(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_raw_tuples",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "ef2cf1b3767b908e25cbd488502ea2b91b43cfcd491b12389acfbea37699cc95",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_raw_tuples_to_list": {
        "code": "class Iteration:\n    def time_itertuples_raw_tuples_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_raw_tuples_to_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "f372d26bf89b90dd1e24ac2a01493a7435fdf11710e9e65324adc1d350725816",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_read_first": {
        "code": "class Iteration:\n    def time_itertuples_read_first(self):\n        next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_read_first",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "9ed674f5820c7707be515d2f9a891d84a09efcf8f785fc428335dac028a682a6",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_start": {
        "code": "class Iteration:\n    def time_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_start",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "beae2a24376ed50a9a214101ac7828899ca3db4436d6f61cc38ac099202d2dfd",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_to_list": {
        "code": "class Iteration:\n    def time_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_to_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "a5fc1a49acb90aa9c123ba866a88ff4f8c508c4cfef59faa117d0da770f63698",
        "warmup_time": -1
    },
    "frame_methods.MaskBool.time_frame_mask_bools": {
        "code": "class MaskBool:\n    def time_frame_mask_bools(self):\n        self.bools.mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)",
        "min_run_count": 2,
        "name": "frame_methods.MaskBool.time_frame_mask_bools",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "75d26deea512c14af4e7569f5dc1e43324ed79283c789db2fb4999d0d7853441",
        "warmup_time": -1
    },
    "frame_methods.MaskBool.time_frame_mask_floats": {
        "code": "class MaskBool:\n    def time_frame_mask_floats(self):\n        self.bools.astype(float).mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)",
        "min_run_count": 2,
        "name": "frame_methods.MaskBool.time_frame_mask_floats",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "77725b9d5309bb967bcd8a8abd4d5a8168f1759ac192d051fe68d191166e9b7e",
        "warmup_time": -1
    },
    "frame_methods.MemoryUsage.time_memory_usage": {
        "code": "class MemoryUsage:\n    def time_memory_usage(self):\n        self.df.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")",
        "min_run_count": 2,
        "name": "frame_methods.MemoryUsage.time_memory_usage",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "abaa03ed61b94b958c09bee89d52d1b87d72796639ec7588559d5b158f8dede9",
        "warmup_time": -1
    },
    "frame_methods.MemoryUsage.time_memory_usage_object_dtype": {
        "code": "class MemoryUsage:\n    def time_memory_usage_object_dtype(self):\n        self.df2.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")",
        "min_run_count": 2,
        "name": "frame_methods.MemoryUsage.time_memory_usage_object_dtype",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f25a399ce1ee970c20943c1c0c1d8359a80848bf10be1b7912eae51ee454231a",
        "warmup_time": -1
    },
    "frame_methods.NSort.time_nlargest_one_column": {
        "code": "class NSort:\n    def time_nlargest_one_column(self, keep):\n        self.df.nlargest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.NSort.time_nlargest_one_column",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ae8ee646412a2720d7755ec64e5f1a787ddb6242469e44c8e3f548a93c55eb32",
        "warmup_time": -1
    },
    "frame_methods.NSort.time_nlargest_two_columns": {
        "code": "class NSort:\n    def time_nlargest_two_columns(self, keep):\n        self.df.nlargest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.NSort.time_nlargest_two_columns",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fb06c1f8251bd2a6af6ab02b7dbf651402818b3898c88c5f634d4999eb180730",
        "warmup_time": -1
    },
    "frame_methods.NSort.time_nsmallest_one_column": {
        "code": "class NSort:\n    def time_nsmallest_one_column(self, keep):\n        self.df.nsmallest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.NSort.time_nsmallest_one_column",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "602770ac5530f5b88477e395308b8146dcf5adb79187c8d34b0201ba44680a2e",
        "warmup_time": -1
    },
    "frame_methods.NSort.time_nsmallest_two_columns": {
        "code": "class NSort:\n    def time_nsmallest_two_columns(self, keep):\n        self.df.nsmallest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.NSort.time_nsmallest_two_columns",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "27757c983389573bb278541de8a55e9ac92f47fc4c94a64054207953192b17d7",
        "warmup_time": -1
    },
    "frame_methods.Nunique.time_frame_nunique": {
        "code": "class Nunique:\n    def time_frame_nunique(self):\n        self.df.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nunique:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 1000))",
        "min_run_count": 2,
        "name": "frame_methods.Nunique.time_frame_nunique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7b4f1bb3132faa41cd11750a8882705594d2e2437af6d28e1c6648950e7d0c46",
        "warmup_time": -1
    },
    "frame_methods.Quantile.time_frame_quantile": {
        "code": "class Quantile:\n    def time_frame_quantile(self, axis):\n        self.df.quantile([0.1, 0.5], axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Quantile.time_frame_quantile",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e46972758e099994281698947a2e05eda1f226d307e25f58fb72796cedd8908f",
        "warmup_time": -1
    },
    "frame_methods.Rank.time_rank": {
        "code": "class Rank:\n    def time_rank(self, dtype):\n        self.df.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(10000, 10).astype(dtype), columns=range(10), dtype=dtype\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rank.time_rank",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4512f531d4398c0997ffb9c0b076476cab3bef280e5662032d20d3b76f2e26cb",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_axis0": {
        "code": "class Reindex:\n    def time_reindex_axis0(self):\n        self.df.reindex(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_axis0",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8e312cd3e03e3d1f3c1440ed72a1f0a6056d79a9045d8f1ee844b2188f613054",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_axis1": {
        "code": "class Reindex:\n    def time_reindex_axis1(self):\n        self.df.reindex(columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_axis1",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4a93950c7bd7528bd910907cda4f0ff4d5194febad4f498b87cc400feff0d1a6",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_axis1_missing": {
        "code": "class Reindex:\n    def time_reindex_axis1_missing(self):\n        self.df.reindex(columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_axis1_missing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7749b0b3b38ff50cbd6509455c235277f2f3cc7ea7bb8642397cfe79fcd2025d",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_both_axes": {
        "code": "class Reindex:\n    def time_reindex_both_axes(self):\n        self.df.reindex(index=self.idx, columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_both_axes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "06ce9de462c065fcb31edc17bbaa87b044287b757a29abc717d85764e418e727",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_upcast": {
        "code": "class Reindex:\n    def time_reindex_upcast(self):\n        self.df2.reindex(np.random.permutation(range(1200)))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_upcast",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8d05018638e09bdfc144121f846b4c2bef1cf019e84b76006bbdef08e268a466",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_dict_rename_both_axes": {
        "code": "class Rename:\n    def time_dict_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_dict_rename_both_axes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "060b0d33988e4009693f1109e6274a165c7e1b54c2ce817d60a436c7b6f46325",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_rename_axis0": {
        "code": "class Rename:\n    def time_rename_axis0(self):\n        self.df.rename(self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_rename_axis0",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7442ed7fc2e73ac7a280c1909b8a01ab6e5269f51652c483a3af6288beea66ea",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_rename_axis1": {
        "code": "class Rename:\n    def time_rename_axis1(self):\n        self.df.rename(columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_rename_axis1",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "95e21d6ec76ff34607840fa82609ec8b610013d6bd877d0092453f968a5384f6",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_rename_both_axes": {
        "code": "class Rename:\n    def time_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_rename_both_axes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "57060b21c7592bb4bd46070429134f61a772694a95ed1014c9c65df5e0f43873",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_rename_single": {
        "code": "class Rename:\n    def time_rename_single(self):\n        self.df.rename({0: 0})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_rename_single",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ddc80d464ece8f0b4fabad5fcb4cbb0729ffdb09e225469ff23f5e49ed1ac8c4",
        "warmup_time": -1
    },
    "frame_methods.Repr.time_frame_repr_wide": {
        "code": "class Repr:\n    def time_frame_repr_wide(self):\n        repr(self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))",
        "min_run_count": 2,
        "name": "frame_methods.Repr.time_frame_repr_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b7c902cd0a2f02eebcb938f83eb0bc567c8bf80146ce7c09a335b559e8715a33",
        "warmup_time": -1
    },
    "frame_methods.Repr.time_html_repr_trunc_mi": {
        "code": "class Repr:\n    def time_html_repr_trunc_mi(self):\n        self.df3._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))",
        "min_run_count": 2,
        "name": "frame_methods.Repr.time_html_repr_trunc_mi",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c5988920e0b3d00d1ec74379b4576a53ad6b17e4c9b71625316958d163ed4164",
        "warmup_time": -1
    },
    "frame_methods.Repr.time_html_repr_trunc_si": {
        "code": "class Repr:\n    def time_html_repr_trunc_si(self):\n        self.df4._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))",
        "min_run_count": 2,
        "name": "frame_methods.Repr.time_html_repr_trunc_si",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8fd8968223faa897090a27941e475b84b23f11c40bb5c7541e6f71c9fb9376a3",
        "warmup_time": -1
    },
    "frame_methods.Repr.time_repr_tall": {
        "code": "class Repr:\n    def time_repr_tall(self):\n        repr(self.df_tall)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))",
        "min_run_count": 2,
        "name": "frame_methods.Repr.time_repr_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "57c3fcd319895e084cdc6f5e24084880d4817e72dd3fe35856b00b69e7ea1742",
        "warmup_time": -1
    },
    "frame_methods.Round.peakmem_round": {
        "code": "class Round:\n    def peakmem_round(self):\n        self.df.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)",
        "name": "frame_methods.Round.peakmem_round",
        "param_names": [],
        "params": [],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "6030b93289557c8c988898eb2865291b8bbb65999e8761c6dedd7d32eeae984c"
    },
    "frame_methods.Round.peakmem_round_transposed": {
        "code": "class Round:\n    def peakmem_round_transposed(self):\n        self.df_t.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)",
        "name": "frame_methods.Round.peakmem_round_transposed",
        "param_names": [],
        "params": [],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "919cd08ae6984fe9193852f5e8b5432e1bc12537c5e39da7333f549a5e72ab37"
    },
    "frame_methods.Round.time_round": {
        "code": "class Round:\n    def time_round(self):\n        self.df.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)",
        "min_run_count": 2,
        "name": "frame_methods.Round.time_round",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "96ca48bf009b1f5637ae83a659df490757d37c26fee67d6a45104d6e0bf32219",
        "warmup_time": -1
    },
    "frame_methods.Round.time_round_transposed": {
        "code": "class Round:\n    def time_round_transposed(self):\n        self.df_t.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)",
        "min_run_count": 2,
        "name": "frame_methods.Round.time_round_transposed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "19596a27ad277a08b79ca33e2b9773ebc43379e2443ff070f4b60f930bcef9d8",
        "warmup_time": -1
    },
    "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan": {
        "code": "class SeriesNuniqueWithNan:\n    def time_series_nunique_nan(self):\n        self.ser.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesNuniqueWithNan:\n    def setup(self):\n        values = 100 * [np.nan] + list(range(100))\n        self.ser = Series(np.tile(values, 10000), dtype=float)",
        "min_run_count": 2,
        "name": "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bdb51c04637dc0c9c73bb2a3b6a2ffee3ae1b5517fb485dfb8f1c5e562c5c6c7",
        "warmup_time": -1
    },
    "frame_methods.Shift.time_shift": {
        "code": "class Shift:\n    def time_shift(self, axis):\n        self.df.shift(1, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.rand(10000, 500))",
        "min_run_count": 2,
        "name": "frame_methods.Shift.time_shift",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "09d28e1e7b36fe4dfa6ed22317da40bcde0164c120b61d4efff8f61b02c768af",
        "warmup_time": -1
    },
    "frame_methods.SortMultiKey.time_sort_index": {
        "code": "class SortMultiKey:\n    def time_sort_index(self, monotonic):\n        self.df_by_index.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortMultiKey:\n    def setup(self, monotonic):\n        N = 10000\n        K = 10\n        df = DataFrame(\n            {\n                \"key1\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"key2\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"value\": np.random.randn(N * K),\n            }\n        )\n        if monotonic:\n            df = df.sort_values([\"key1\", \"key2\"])\n        self.df_by_columns = df\n        self.df_by_index = df.set_index([\"key1\", \"key2\"])",
        "min_run_count": 2,
        "name": "frame_methods.SortMultiKey.time_sort_index",
        "number": 0,
        "param_names": [
            "monotonic"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "14e8d6aab1e556f8caea675776001969164ccf76049c529a3e0077ee8a56b7ba",
        "warmup_time": -1
    },
    "frame_methods.SortMultiKey.time_sort_values": {
        "code": "class SortMultiKey:\n    def time_sort_values(self, monotonic):\n        self.df_by_columns.sort_values(by=[\"key1\", \"key2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortMultiKey:\n    def setup(self, monotonic):\n        N = 10000\n        K = 10\n        df = DataFrame(\n            {\n                \"key1\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"key2\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"value\": np.random.randn(N * K),\n            }\n        )\n        if monotonic:\n            df = df.sort_values([\"key1\", \"key2\"])\n        self.df_by_columns = df\n        self.df_by_index = df.set_index([\"key1\", \"key2\"])",
        "min_run_count": 2,
        "name": "frame_methods.SortMultiKey.time_sort_values",
        "number": 0,
        "param_names": [
            "monotonic"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2742a8d577f8f9f13eee3c04ba10dec5ca223b766b72708333b2bb9240ff7007",
        "warmup_time": -1
    },
    "frame_methods.SortValues.time_frame_sort_values": {
        "code": "class SortValues:\n    def time_frame_sort_values(self, ascending):\n        self.df.sort_values(by=\"A\", ascending=ascending)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, ascending):\n        self.df = DataFrame(np.random.randn(1000000, 2), columns=list(\"AB\"))",
        "min_run_count": 2,
        "name": "frame_methods.SortValues.time_frame_sort_values",
        "number": 0,
        "param_names": [
            "ascending"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bf9c8ff877f2cd95431692cfe963e37b3de4634176be673d3de0b663177d7ad3",
        "warmup_time": -1
    },
    "frame_methods.ToDict.time_to_dict_datetimelike": {
        "code": "class ToDict:\n    def time_to_dict_datetimelike(self, orient):\n        self.datetimelike_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")",
        "min_run_count": 2,
        "name": "frame_methods.ToDict.time_to_dict_datetimelike",
        "number": 0,
        "param_names": [
            "orient"
        ],
        "params": [
            [
                "'dict'",
                "'list'",
                "'series'",
                "'split'",
                "'records'",
                "'index'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "939f612766529ae46a0b196a3dc13061331265310113f5a5c18d503fd623eb63",
        "warmup_time": -1
    },
    "frame_methods.ToDict.time_to_dict_ints": {
        "code": "class ToDict:\n    def time_to_dict_ints(self, orient):\n        self.int_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")",
        "min_run_count": 2,
        "name": "frame_methods.ToDict.time_to_dict_ints",
        "number": 0,
        "param_names": [
            "orient"
        ],
        "params": [
            [
                "'dict'",
                "'list'",
                "'series'",
                "'split'",
                "'records'",
                "'index'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8ca05db38583b86c56e9781a0ba1f399533c5e196accee6737c23ade9750f5c9",
        "warmup_time": -1
    },
    "frame_methods.ToHTML.time_to_html_mixed": {
        "code": "class ToHTML:\n    def time_to_html_mixed(self):\n        self.df2.to_html()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToHTML:\n    def setup(self):\n        nrows = 500\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\n        self.df2[0] = period_range(\"2000\", periods=nrows)\n        self.df2[1] = range(nrows)",
        "min_run_count": 2,
        "name": "frame_methods.ToHTML.time_to_html_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a63bfb2f9452ef12121452e5a13a47f1ddf16d3a2ecc961f1d143598ae48a31a",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_to_numpy_mixed_tall": {
        "code": "class ToNumpy:\n    def time_to_numpy_mixed_tall(self):\n        self.df_mixed_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_to_numpy_mixed_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5609d5ea9c8d63719954d185af31995af502969500f52a283b95dee96b206b21",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_to_numpy_mixed_wide": {
        "code": "class ToNumpy:\n    def time_to_numpy_mixed_wide(self):\n        self.df_mixed_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_to_numpy_mixed_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b8cf4cdbf480bfa101b1e9bbf6df8e6a9516540d5888f9acf40c29f0b39c4178",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_to_numpy_tall": {
        "code": "class ToNumpy:\n    def time_to_numpy_tall(self):\n        self.df_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_to_numpy_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5569b6deed04489b4f459b07dc638df2d11771fc68bd230503521874fd8280e9",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_to_numpy_wide": {
        "code": "class ToNumpy:\n    def time_to_numpy_wide(self):\n        self.df_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_to_numpy_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bf654b3ba6daa0281ee0f2802eb3d2aeda580273f37f51975c0a6949c7f80d88",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_values_mixed_tall": {
        "code": "class ToNumpy:\n    def time_values_mixed_tall(self):\n        self.df_mixed_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_values_mixed_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "63f9938602ca8bd629ccf01754db81ac30be79e67c04b0f0773bc5b0d042f33d",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_values_mixed_wide": {
        "code": "class ToNumpy:\n    def time_values_mixed_wide(self):\n        self.df_mixed_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_values_mixed_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fafed5c463a9d832b1c45ce00e7755cf10235ae288cb4939713e9e25b2884d1e",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_values_tall": {
        "code": "class ToNumpy:\n    def time_values_tall(self):\n        self.df_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_values_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d7415d8faba6d4a8ac5b59b9db979d88981de08547167f51ec5c31b322149dfb",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_values_wide": {
        "code": "class ToNumpy:\n    def time_values_wide(self):\n        self.df_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_values_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5f1b62f28c9211bb22340a6af83d5b86811950ef975bfd00e0684048cb2de22f",
        "warmup_time": -1
    },
    "frame_methods.ToRecords.time_to_records": {
        "code": "class ToRecords:\n    def time_to_records(self):\n        self.df.to_records(index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToRecords:\n    def setup(self):\n        N = 100_000\n        data = np.random.randn(N, 2)\n        mi = MultiIndex.from_arrays(\n            [\n                np.arange(N),\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\n            ]\n        )\n        self.df = DataFrame(data)\n        self.df_mi = DataFrame(data, index=mi)",
        "min_run_count": 2,
        "name": "frame_methods.ToRecords.time_to_records",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f42f25126b3a450ab55465c858ae504d2ded8b644488689fa856b421d41c0cba",
        "warmup_time": -1
    },
    "frame_methods.ToRecords.time_to_records_multiindex": {
        "code": "class ToRecords:\n    def time_to_records_multiindex(self):\n        self.df_mi.to_records(index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToRecords:\n    def setup(self):\n        N = 100_000\n        data = np.random.randn(N, 2)\n        mi = MultiIndex.from_arrays(\n            [\n                np.arange(N),\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\n            ]\n        )\n        self.df = DataFrame(data)\n        self.df_mi = DataFrame(data, index=mi)",
        "min_run_count": 2,
        "name": "frame_methods.ToRecords.time_to_records_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ba7c2132dec45f9679103e1739697a3c005f6921b9c766546d8535303d90777d",
        "warmup_time": -1
    },
    "frame_methods.ToString.time_to_string_floats": {
        "code": "class ToString:\n    def time_to_string_floats(self):\n        self.df.to_string()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToString:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100, 10))",
        "min_run_count": 2,
        "name": "frame_methods.ToString.time_to_string_floats",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e56ad6695cac3b92e88feb11d8c47fa92f10fb86e51634e87529d771f168cdbf",
        "warmup_time": -1
    },
    "frame_methods.Update.time_to_update_big_frame_small_arg": {
        "code": "class Update:\n    def time_to_update_big_frame_small_arg(self):\n        self.df.update(self.df_sample)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Update:\n    def setup(self):\n        rng = np.random.default_rng()\n        self.df = DataFrame(rng.uniform(size=(1_000_000, 10)))\n    \n        idx = rng.choice(range(1_000_000), size=1_000_000, replace=False)\n        self.df_random = DataFrame(self.df, index=idx)\n    \n        idx = rng.choice(range(1_000_000), size=100_000, replace=False)\n        cols = rng.choice(range(10), size=2, replace=False)\n        self.df_sample = DataFrame(\n            rng.uniform(size=(100_000, 2)), index=idx, columns=cols\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Update.time_to_update_big_frame_small_arg",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d30ce943b59f73cac30317b7fbc940e85ec5efc11638d04af2b7ccdeedc32dc0",
        "warmup_time": -1
    },
    "frame_methods.Update.time_to_update_random_indices": {
        "code": "class Update:\n    def time_to_update_random_indices(self):\n        self.df_random.update(self.df_sample)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Update:\n    def setup(self):\n        rng = np.random.default_rng()\n        self.df = DataFrame(rng.uniform(size=(1_000_000, 10)))\n    \n        idx = rng.choice(range(1_000_000), size=1_000_000, replace=False)\n        self.df_random = DataFrame(self.df, index=idx)\n    \n        idx = rng.choice(range(1_000_000), size=100_000, replace=False)\n        cols = rng.choice(range(10), size=2, replace=False)\n        self.df_sample = DataFrame(\n            rng.uniform(size=(100_000, 2)), index=idx, columns=cols\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Update.time_to_update_random_indices",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8b95fcbe44de6c6f894ae33695436745b5ac38ab262704a34b30f2ad6395be80",
        "warmup_time": -1
    },
    "frame_methods.Update.time_to_update_small_frame_big_arg": {
        "code": "class Update:\n    def time_to_update_small_frame_big_arg(self):\n        self.df_sample.update(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Update:\n    def setup(self):\n        rng = np.random.default_rng()\n        self.df = DataFrame(rng.uniform(size=(1_000_000, 10)))\n    \n        idx = rng.choice(range(1_000_000), size=1_000_000, replace=False)\n        self.df_random = DataFrame(self.df, index=idx)\n    \n        idx = rng.choice(range(1_000_000), size=100_000, replace=False)\n        cols = rng.choice(range(10), size=2, replace=False)\n        self.df_sample = DataFrame(\n            rng.uniform(size=(100_000, 2)), index=idx, columns=cols\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Update.time_to_update_small_frame_big_arg",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fe0be300fb64f1ec27a8b2258356397b32881365b73bc4871821a0e3342d4732",
        "warmup_time": -1
    },
    "frame_methods.Where.time_where": {
        "code": "class Where:\n    def time_where(self, inplace, dtype):\n        self.df.where(self.mask, other=0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Where:\n    def setup(self, inplace, dtype):\n        self.df = DataFrame(np.random.randn(100_000, 10), dtype=dtype)\n        self.mask = self.df < 0",
        "min_run_count": 2,
        "name": "frame_methods.Where.time_where",
        "number": 0,
        "param_names": [
            "dtype",
            "param2"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'float64'",
                "'Float64'",
                "'float64[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d16b5044f854c91f698425fe60c4f71b7f819334706ddf4e2e6bb35a27c1a928",
        "warmup_time": -1
    },
    "frame_methods.XS.time_frame_xs": {
        "code": "class XS:\n    def time_frame_xs(self, axis):\n        self.df.xs(self.N / 2, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass XS:\n    def setup(self, axis):\n        self.N = 10**4\n        self.df = DataFrame(np.random.randn(self.N, self.N))",
        "min_run_count": 2,
        "name": "frame_methods.XS.time_frame_xs",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4c10ba567aab8044d880b7e51f27220a7353cda967ee331f4bf88ebbc2406d4f",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_field_day": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_field_day(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.day\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_field_day",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "57949cef8376be9aca572d8c68a05289b9950b538c13e861ad1b71df817c3515",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_field_daysinmonth(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.days_in_month\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e08964e060471859275a5a734b94e650445f8e0db22890e06d5c36b207e103a8",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_field_normalize": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_field_normalize(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.normalize()\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_field_normalize",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "59282e48b58fc897cac7af777786d7dc152983bf0f08d5e8ca7049410a9edfb1",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_field_year": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_field_year(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.year\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_field_year",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4e6d8e9847ac5022c75aabaff81f2a4ce4528c29b8d2f44d50f8729b732bef51",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_to_period": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_to_period(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.to_period(\"s\")\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_to_period",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cf5a4f24f7ea1d7e1842a834d7a3ed311331d1375098ccb8bd2423d9df91f03c",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_period_to_datetime": {
        "code": "class ParallelDatetimeFields:\n    def time_period_to_datetime(self):\n        @test_parallel(num_threads=2)\n        def run(period):\n            period.to_timestamp()\n    \n        run(self.period)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_period_to_datetime",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3766967574deb647b538a27545eb395e8fce97e83e988ac9785f6865c97084d1",
        "warmup_time": -1
    },
    "gil.ParallelFactorize.time_loop": {
        "code": "class ParallelFactorize:\n    def time_loop(self, threads):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        strings = Index([f\"i-{i}\" for i in range(100000)], dtype=object)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop",
        "min_run_count": 2,
        "name": "gil.ParallelFactorize.time_loop",
        "number": 1,
        "param_names": [
            "threads"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ]
        ],
        "repeat": 5,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3d702042bf0b72599271c4f0aca5d1cc55c8de89f03071bd59d498a5dbdb8448",
        "warmup_time": -1
    },
    "gil.ParallelFactorize.time_parallel": {
        "code": "class ParallelFactorize:\n    def time_parallel(self, threads):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        strings = Index([f\"i-{i}\" for i in range(100000)], dtype=object)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop",
        "min_run_count": 2,
        "name": "gil.ParallelFactorize.time_parallel",
        "number": 1,
        "param_names": [
            "threads"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ]
        ],
        "repeat": 5,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7a105748ab3e006bf2a891c0883f2103a5c368902e13d14f3a64656e1968793a",
        "warmup_time": -1
    },
    "gil.ParallelGroupbyMethods.time_loop": {
        "code": "class ParallelGroupbyMethods:\n    def time_loop(self, threads, method):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop",
        "min_run_count": 2,
        "name": "gil.ParallelGroupbyMethods.time_loop",
        "number": 0,
        "param_names": [
            "threads",
            "method"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ],
            [
                "'count'",
                "'last'",
                "'max'",
                "'mean'",
                "'min'",
                "'prod'",
                "'sum'",
                "'var'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "eb7b8df45f4491f84224614922e1b5e9a4f93453147833890ec096562f96b248",
        "warmup_time": -1
    },
    "gil.ParallelGroupbyMethods.time_parallel": {
        "code": "class ParallelGroupbyMethods:\n    def time_parallel(self, threads, method):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop",
        "min_run_count": 2,
        "name": "gil.ParallelGroupbyMethods.time_parallel",
        "number": 0,
        "param_names": [
            "threads",
            "method"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ],
            [
                "'count'",
                "'last'",
                "'max'",
                "'mean'",
                "'min'",
                "'prod'",
                "'sum'",
                "'var'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee3c7c1d8ffe98d3bbc8c64cb4af33754566e6351c3bb50458012a695887b895",
        "warmup_time": -1
    },
    "gil.ParallelGroups.time_get_groups": {
        "code": "class ParallelGroups:\n    def time_get_groups(self, threads):\n        self.get_groups()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroups:\n    def setup(self, threads):\n        size = 2**22\n        ngroups = 10**3\n        data = Series(np.random.randint(0, ngroups, size=size))\n    \n        @test_parallel(num_threads=threads)\n        def get_groups():\n            data.groupby(data).groups\n    \n        self.get_groups = get_groups",
        "min_run_count": 2,
        "name": "gil.ParallelGroups.time_get_groups",
        "number": 0,
        "param_names": [
            "threads"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "171c8e07e2d81baa3dde5f287fa352a1692571b4e8ab6bc86a6f308969c770f0",
        "warmup_time": -1
    },
    "gil.ParallelKth.time_kth_smallest": {
        "code": "class ParallelKth:\n    def time_kth_smallest(self):\n        self.parallel_kth_smallest()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelKth:\n    def setup(self):\n        N = 10**7\n        k = 5 * 10**5\n        kwargs_list = [{\"arr\": np.random.randn(N)}, {\"arr\": np.random.randn(N)}]\n    \n        @test_parallel(num_threads=2, kwargs_list=kwargs_list)\n        def parallel_kth_smallest(arr):\n            algos.kth_smallest(arr, k)\n    \n        self.parallel_kth_smallest = parallel_kth_smallest",
        "min_run_count": 2,
        "name": "gil.ParallelKth.time_kth_smallest",
        "number": 1,
        "param_names": [],
        "params": [],
        "repeat": 5,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "728baeaaeac8eda248c8708b2a4bc45d00a0df43c2103cac65cbfc9c8aff7dcd",
        "warmup_time": -1
    },
    "gil.ParallelReadCSV.time_read_csv": {
        "code": "class ParallelReadCSV:\n    def time_read_csv(self, dtype):\n        self.parallel_read_csv()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelReadCSV:\n    def setup(self, dtype):\n        rows = 10000\n        cols = 50\n        if dtype == \"float\":\n            df = DataFrame(np.random.randn(rows, cols))\n        elif dtype == \"datetime\":\n            df = DataFrame(\n                np.random.randn(rows, cols), index=date_range(\"1/1/2000\", periods=rows)\n            )\n        elif dtype == \"object\":\n            df = DataFrame(\n                \"foo\", index=range(rows), columns=[\"object%03d\" for _ in range(5)]\n            )\n        else:\n            raise NotImplementedError\n    \n        self.fname = f\"__test_{dtype}__.csv\"\n        df.to_csv(self.fname)\n    \n        @test_parallel(num_threads=2)\n        def parallel_read_csv():\n            read_csv(self.fname)\n    \n        self.parallel_read_csv = parallel_read_csv",
        "min_run_count": 2,
        "name": "gil.ParallelReadCSV.time_read_csv",
        "number": 1,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'object'",
                "'datetime'"
            ]
        ],
        "repeat": 5,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8228e9d157c6aea95c1ffcdea89ba3331e5dec17b88134f572f22bbf274ea99c",
        "warmup_time": -1
    },
    "gil.ParallelRolling.time_rolling": {
        "code": "class ParallelRolling:\n    def time_rolling(self, method):\n        self.parallel_rolling()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelRolling:\n    def setup(self, method):\n        win = 100\n        arr = np.random.rand(100000)\n        if hasattr(DataFrame, \"rolling\"):\n            df = DataFrame(arr).rolling(win)\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                getattr(df, method)()\n    \n            self.parallel_rolling = parallel_rolling\n        elif have_rolling_methods:\n            rolling = {\n                \"median\": rolling_median,\n                \"mean\": rolling_mean,\n                \"min\": rolling_min,\n                \"max\": rolling_max,\n                \"var\": rolling_var,\n                \"skew\": rolling_skew,\n                \"kurt\": rolling_kurt,\n                \"std\": rolling_std,\n            }\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                rolling[method](arr, win)\n    \n            self.parallel_rolling = parallel_rolling\n        else:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "gil.ParallelRolling.time_rolling",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'median'",
                "'mean'",
                "'min'",
                "'max'",
                "'var'",
                "'skew'",
                "'kurt'",
                "'std'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "982eb24280f1da753438825641a9861564da7d7a000c415ab86a6bc7522c160b",
        "warmup_time": -1
    },
    "gil.ParallelTake1D.time_take1d": {
        "code": "class ParallelTake1D:\n    def time_take1d(self, dtype):\n        self.parallel_take1d()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelTake1D:\n    def setup(self, dtype):\n        N = 10**6\n        df = DataFrame({\"col\": np.arange(N, dtype=dtype)})\n        indexer = np.arange(100, len(df) - 100)\n    \n        @test_parallel(num_threads=2)\n        def parallel_take1d():\n            take_nd(df[\"col\"].values, indexer)\n    \n        self.parallel_take1d = parallel_take1d",
        "min_run_count": 2,
        "name": "gil.ParallelTake1D.time_take1d",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fd7379c21f5111cc9ec16f330e4ffc0e029ced1a7cd13e6b78511e7099f53926",
        "warmup_time": -1
    },
    "groupby.AggEngine.time_dataframe_cython": {
        "code": "class AggEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.AggEngine.time_dataframe_cython",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b631e4aa17bbb96c2171d4d72e155061807325d0b39f89014e9ce5de10bfebd2",
        "warmup_time": -1
    },
    "groupby.AggEngine.time_dataframe_numba": {
        "code": "class AggEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.AggEngine.time_dataframe_numba",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ac6601fa086e8c75d228fd781b72c5b02d2053fd155682b074b03fbd6562ccff",
        "warmup_time": -1
    },
    "groupby.AggEngine.time_series_cython": {
        "code": "class AggEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.AggEngine.time_series_cython",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e376d34069b9e05138d16b62f5314f36da3d7a957bb6f040793626df9edcb7ee",
        "warmup_time": -1
    },
    "groupby.AggEngine.time_series_numba": {
        "code": "class AggEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.AggEngine.time_series_numba",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c1e4164d5e903fe4335a07378a9a567a3e4f7c80cb9960c112d95f8919a292aa",
        "warmup_time": -1
    },
    "groupby.AggFunctions.time_different_str_functions": {
        "code": "class AggFunctions:\n    def time_different_str_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.AggFunctions.time_different_str_functions",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:316",
        "type": "time",
        "unit": "seconds",
        "version": "176cde1b06cc31bb98fa33e5c2d0b5b504f18a26bc5160ce4eba434ee86f286c",
        "warmup_time": -1
    },
    "groupby.AggFunctions.time_different_str_functions_multicol": {
        "code": "class AggFunctions:\n    def time_different_str_functions_multicol(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg([\"sum\", \"min\", \"max\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.AggFunctions.time_different_str_functions_multicol",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:316",
        "type": "time",
        "unit": "seconds",
        "version": "665a15402546613d3a9f8692562e3df5bb8e802b90bbaab60dc777323d8c2af2",
        "warmup_time": -1
    },
    "groupby.AggFunctions.time_different_str_functions_singlecol": {
        "code": "class AggFunctions:\n    def time_different_str_functions_singlecol(self, df):\n        df.groupby(\"key1\").agg({\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.AggFunctions.time_different_str_functions_singlecol",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:316",
        "type": "time",
        "unit": "seconds",
        "version": "f5e3f8571351af65c0ab394b69b2a896e28ad315f97c21d89abd45facf73ae1e",
        "warmup_time": -1
    },
    "groupby.Apply.time_copy_function_multi_col": {
        "code": "class Apply:\n    def time_copy_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.Apply.time_copy_function_multi_col",
        "number": 0,
        "param_names": [
            "factor"
        ],
        "params": [
            [
                "4",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "508a1bf90ae09cc26585902afd9774deccb6c4fd643ff3f6e3cd66018ca60057",
        "warmup_time": -1
    },
    "groupby.Apply.time_copy_overhead_single_col": {
        "code": "class Apply:\n    def time_copy_overhead_single_col(self, factor):\n        self.df.groupby(\"key\").apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.Apply.time_copy_overhead_single_col",
        "number": 0,
        "param_names": [
            "factor"
        ],
        "params": [
            [
                "4",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "004ee6e703ae1fbf983c0b4353be97cb81fcd0c0dde8175bbac3fe70f25e2eeb",
        "warmup_time": -1
    },
    "groupby.Apply.time_scalar_function_multi_col": {
        "code": "class Apply:\n    def time_scalar_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.Apply.time_scalar_function_multi_col",
        "number": 0,
        "param_names": [
            "factor"
        ],
        "params": [
            [
                "4",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c2684326af2c29dbc66ddff0ed5b88aa9ec425dbd70bb2874943b0ee3e8f916d",
        "warmup_time": -1
    },
    "groupby.Apply.time_scalar_function_single_col": {
        "code": "class Apply:\n    def time_scalar_function_single_col(self, factor):\n        self.df.groupby(\"key\").apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.Apply.time_scalar_function_single_col",
        "number": 0,
        "param_names": [
            "factor"
        ],
        "params": [
            [
                "4",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "69063f137e8f55d96073f5bed6cb8a4784eed89b8accd6d82bd386218d1d1e79",
        "warmup_time": -1
    },
    "groupby.ApplyDictReturn.time_groupby_apply_dict_return": {
        "code": "class ApplyDictReturn:\n    def time_groupby_apply_dict_return(self):\n        self.data.groupby(self.labels).apply(\n            lambda x: {\"first\": x.values[0], \"last\": x.values[-1]}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyDictReturn:\n    def setup(self):\n        self.labels = np.arange(1000).repeat(10)\n        self.data = Series(np.random.randn(len(self.labels)))",
        "min_run_count": 2,
        "name": "groupby.ApplyDictReturn.time_groupby_apply_dict_return",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5924f4088fcf382ce33f346ce7ddfd12e83ed70b71b93eaec422e9d9eebf6683",
        "warmup_time": -1
    },
    "groupby.ApplyNonUniqueUnsortedIndex.time_groupby_apply_non_unique_unsorted_index": {
        "code": "class ApplyNonUniqueUnsortedIndex:\n    def time_groupby_apply_non_unique_unsorted_index(self):\n        self.df.groupby(\"key\", group_keys=False).apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyNonUniqueUnsortedIndex:\n    def setup(self):\n        # GH 46527\n        # unsorted and non-unique index\n        idx = np.arange(100)[::-1]\n        idx = Index(np.repeat(idx, 200), name=\"key\")\n        self.df = DataFrame(np.random.randn(len(idx), 10), index=idx)",
        "min_run_count": 2,
        "name": "groupby.ApplyNonUniqueUnsortedIndex.time_groupby_apply_non_unique_unsorted_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f7c3bea0e579df6a33360dfc8c3303ce3a07b11bf0bd48d962a46d5522f4dcfd",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_extra_cat_nosort": {
        "code": "class Categories:\n    def time_groupby_extra_cat_nosort(self, observed):\n        self.df_extra_cat.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_extra_cat_nosort",
        "number": 0,
        "param_names": [
            "observed"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "62133a9620af8ea979a326f99617e0e3bbddcc3f3fe81c6bdbf1618701267fde",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_extra_cat_sort": {
        "code": "class Categories:\n    def time_groupby_extra_cat_sort(self, observed):\n        self.df_extra_cat.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_extra_cat_sort",
        "number": 0,
        "param_names": [
            "observed"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bfeb5009688d6d10146eaf165cd717a5783a74a5ec7f081c90f52eeb9663f708",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_nosort": {
        "code": "class Categories:\n    def time_groupby_nosort(self, observed):\n        self.df.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_nosort",
        "number": 0,
        "param_names": [
            "observed"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e21931e9e69907f384dfe0d9e8a359e13f8b1293c757b0702b3677c3c6d36e3e",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_ordered_nosort": {
        "code": "class Categories:\n    def time_groupby_ordered_nosort(self, observed):\n        self.df_ordered.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_ordered_nosort",
        "number": 0,
        "param_names": [
            "observed"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9e1ed16652daf9b539439c46eab3fc29bfd10b5ba12908c936274bc9d8dc6caa",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_ordered_sort": {
        "code": "class Categories:\n    def time_groupby_ordered_sort(self, observed):\n        self.df_ordered.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_ordered_sort",
        "number": 0,
        "param_names": [
            "observed"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e61e682f371daea64397593a361f55b612c4870d5c7d34a214d012e1f2e346f4",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_sort": {
        "code": "class Categories:\n    def time_groupby_sort(self, observed):\n        self.df.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_sort",
        "number": 0,
        "param_names": [
            "observed"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "27b91ff09ded66431067f94886fa27b9fafe051869103620cc7baffc8e0be7fb",
        "warmup_time": -1
    },
    "groupby.CountMultiDtype.time_multi_count": {
        "code": "class CountMultiDtype:\n    def time_multi_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiDtype:\n    def setup_cache(self):\n        n = 10000\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        dates[np.random.rand(n) > 0.5] = np.datetime64(\"nat\")\n        offsets[np.random.rand(n) > 0.5] = np.timedelta64(\"nat\")\n        value2 = np.random.randn(n)\n        value2[np.random.rand(n) > 0.5] = np.nan\n        obj = np.random.choice(list(\"ab\"), size=n).astype(object)\n        obj[np.random.randn(n) > 0.5] = np.nan\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"dates\": dates,\n                \"value2\": value2,\n                \"value3\": np.random.randn(n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"obj\": obj,\n                \"offsets\": offsets,\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.CountMultiDtype.time_multi_count",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:267",
        "type": "time",
        "unit": "seconds",
        "version": "781eccf167f79b9db2b42e6637dca3e0917b3ee82948078ab34ec1fdd55a8ba7",
        "warmup_time": -1
    },
    "groupby.CountMultiInt.time_multi_int_count": {
        "code": "class CountMultiInt:\n    def time_multi_int_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.CountMultiInt.time_multi_int_count",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:296",
        "type": "time",
        "unit": "seconds",
        "version": "c0c648960106b54be2a606e2093e04045e55e61c502f37ec87315025300cc688",
        "warmup_time": -1
    },
    "groupby.CountMultiInt.time_multi_int_nunique": {
        "code": "class CountMultiInt:\n    def time_multi_int_nunique(self, df):\n        df.groupby([\"key1\", \"key2\"]).nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.CountMultiInt.time_multi_int_nunique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:296",
        "type": "time",
        "unit": "seconds",
        "version": "02179b80a10ef56e163f7134b90b2b3a14e1e783c29bcd78e8c839cc49c2b89a",
        "warmup_time": -1
    },
    "groupby.Cumulative.time_frame_transform": {
        "code": "class Cumulative:\n    def time_frame_transform(self, dtype, method, with_nans):\n        self.df.groupby(\"key\").transform(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cumulative:\n    def setup(self, dtype, method, with_nans):\n        if with_nans and dtype == \"int64\":\n            raise NotImplementedError(\"Construction of df would raise\")\n    \n        N = 500_000\n        keys = np.random.randint(0, 100, size=N)\n        vals = np.random.randint(-10, 10, (N, 5))\n    \n        if with_nans:\n            null_vals = vals.astype(float, copy=True)\n            null_vals[::2, :] = np.nan\n            null_vals[::3, :] = np.nan\n            df = DataFrame(null_vals, columns=list(\"abcde\"), dtype=dtype)\n            df[\"key\"] = keys\n            self.df = df\n        else:\n            df = DataFrame(vals, columns=list(\"abcde\")).astype(dtype, copy=False)\n            df[\"key\"] = keys\n            self.df = df",
        "min_run_count": 2,
        "name": "groupby.Cumulative.time_frame_transform",
        "number": 0,
        "param_names": [
            "dtype",
            "method",
            "with_nans"
        ],
        "params": [
            [
                "'float64'",
                "'int64'",
                "'Float64'",
                "'Int64'"
            ],
            [
                "'cummin'",
                "'cummax'",
                "'cumsum'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "508bbc112e0877babc3aaf14b674b720e942cd27f59280bc4678e5cca617dd6d",
        "warmup_time": -1
    },
    "groupby.DateAttributes.time_len_groupby_object": {
        "code": "class DateAttributes:\n    def time_len_groupby_object(self):\n        len(self.ts.groupby([self.year, self.month, self.day]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateAttributes:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", \"12/31/2005\", freq=\"h\")\n        self.year, self.month, self.day = rng.year, rng.month, rng.day\n        self.ts = Series(np.random.randn(len(rng)), index=rng)",
        "min_run_count": 2,
        "name": "groupby.DateAttributes.time_len_groupby_object",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8afdc2d8ced7d3eae328dd9110607db5fb11b9f1345b32d6f85c95f2a0790f13",
        "warmup_time": -1
    },
    "groupby.Datelike.time_sum": {
        "code": "class Datelike:\n    def time_sum(self, grouper):\n        self.df.groupby(self.grouper).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datelike:\n    def setup(self, grouper):\n        N = 10**4\n        rng_map = {\n            \"period_range\": period_range,\n            \"date_range\": date_range,\n            \"date_range_tz\": partial(date_range, tz=\"US/Central\"),\n        }\n        self.grouper = rng_map[grouper](\"1900-01-01\", freq=\"D\", periods=N)\n        self.df = DataFrame(np.random.randn(10**4, 2))",
        "min_run_count": 2,
        "name": "groupby.Datelike.time_sum",
        "number": 0,
        "param_names": [
            "grouper"
        ],
        "params": [
            [
                "'period_range'",
                "'date_range'",
                "'date_range_tz'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e8e6e1030bf91e85db8d838621c86faee1e19b8f21d49efe9d147e58d9b54307",
        "warmup_time": -1
    },
    "groupby.Fillna.time_df_bfill": {
        "code": "class Fillna:\n    def time_df_bfill(self):\n        self.df.groupby(\"group\").bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")",
        "min_run_count": 2,
        "name": "groupby.Fillna.time_df_bfill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7ff1f9cf6c6df0928b8c57fd5409cd697220c5294222532ee686299c3410b840",
        "warmup_time": -1
    },
    "groupby.Fillna.time_df_ffill": {
        "code": "class Fillna:\n    def time_df_ffill(self):\n        self.df.groupby(\"group\").ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")",
        "min_run_count": 2,
        "name": "groupby.Fillna.time_df_ffill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "40586a88db43958ca78216d046b99f037c1d2538d8ecbb88e73f0f3fec775b8f",
        "warmup_time": -1
    },
    "groupby.Fillna.time_srs_bfill": {
        "code": "class Fillna:\n    def time_srs_bfill(self):\n        self.df.groupby(\"group\")[\"value\"].bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")",
        "min_run_count": 2,
        "name": "groupby.Fillna.time_srs_bfill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "579f258a2de5f21f32a2705c8b4de416b0d90092be5b8db9155802b3114e5eba",
        "warmup_time": -1
    },
    "groupby.Fillna.time_srs_ffill": {
        "code": "class Fillna:\n    def time_srs_ffill(self):\n        self.df.groupby(\"group\")[\"value\"].ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")",
        "min_run_count": 2,
        "name": "groupby.Fillna.time_srs_ffill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "836866b476636343cf2f78c006849b25914c07fb61542a85b138c258c1bdb0b2",
        "warmup_time": -1
    },
    "groupby.Float32.time_sum": {
        "code": "class Float32:\n    def time_sum(self):\n        self.df.groupby([\"a\"])[\"b\"].sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float32:\n    def setup(self):\n        tmp1 = (np.random.random(10000) * 0.1).astype(np.float32)\n        tmp2 = (np.random.random(10000) * 10.0).astype(np.float32)\n        tmp = np.concatenate((tmp1, tmp2))\n        arr = np.repeat(tmp, 10)\n        self.df = DataFrame({\"a\": arr, \"b\": arr})",
        "min_run_count": 2,
        "name": "groupby.Float32.time_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ffe9e34b1eb793ed006421668ab941faed0e6f0e51c5142f0940d4117f1aedb4",
        "warmup_time": -1
    },
    "groupby.GroupByCythonAgg.time_frame_agg": {
        "code": "class GroupByCythonAgg:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAgg:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(np.random.randn(N, 10), columns=list(\"abcdefghij\"))\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.GroupByCythonAgg.time_frame_agg",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'float64'"
            ],
            [
                "'sum'",
                "'prod'",
                "'min'",
                "'max'",
                "'idxmin'",
                "'idxmax'",
                "'mean'",
                "'median'",
                "'var'",
                "'first'",
                "'last'",
                "'any'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "08ae292d77e9806660d8e3c10232a024c7526f433635c0290aa62b6b313af20f",
        "warmup_time": -1
    },
    "groupby.GroupByCythonAggEaDtypes.time_frame_agg": {
        "code": "class GroupByCythonAggEaDtypes:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAggEaDtypes:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(\n            np.random.randint(0, high=100, size=(N, 10)),\n            columns=list(\"abcdefghij\"),\n            dtype=dtype,\n        )\n        df.loc[list(range(1, N, 5)), list(\"abcdefghij\")] = NA\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.GroupByCythonAggEaDtypes.time_frame_agg",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'Float64'",
                "'Int64'",
                "'Int32'"
            ],
            [
                "'sum'",
                "'prod'",
                "'min'",
                "'max'",
                "'mean'",
                "'median'",
                "'var'",
                "'first'",
                "'last'",
                "'any'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9d0957d40f08e9fb265f5ca8f466358e6742a3b6b934d1714c6cfc2f9604ded1",
        "warmup_time": -1
    },
    "groupby.GroupByMethods.time_dtype_as_field": {
        "code": "class GroupByMethods:\n    def time_dtype_as_field(self, dtype, method, application, ncols, engine):\n        self.as_field_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols, engine):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"describe\",\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        # Numba currently doesn't support\n        # multiple transform functions or strs for transform,\n        # grouping on multiple columns\n        # and we lack kernels for a bunch of methods\n        if (\n            (engine == \"numba\" and method in _numba_unsupported_methods)\n            or ncols > 1\n            or application == \"transformation\"\n            or dtype == \"datetime\"\n        ):\n            raise NotImplementedError\n    \n        if method == \"describe\":\n            ngroups = 20\n        elif method == \"skew\":\n            ngroups = 100\n        else:\n            ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype in (\"int16\", \"uint\"):\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        # Not everything supports the engine keyword yet\n        kwargs = {}\n        if engine == \"numba\":\n            kwargs[\"engine\"] = engine\n    \n        if application == \"transformation\":\n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(\n                method, **kwargs\n            )\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(\n                method, **kwargs\n            )\n        else:\n            self.as_group_method = partial(\n                getattr(df.groupby(\"key\")[cols], method), **kwargs\n            )\n            self.as_field_method = partial(\n                getattr(df.groupby(cols)[\"key\"], method), **kwargs\n            )",
        "min_run_count": 2,
        "name": "groupby.GroupByMethods.time_dtype_as_field",
        "number": 0,
        "param_names": [
            "dtype",
            "method",
            "application",
            "ncols",
            "param5"
        ],
        "params": [
            [
                "'int'",
                "'int16'",
                "'float'",
                "'object'",
                "'datetime'",
                "'uint'"
            ],
            [
                "'all'",
                "'any'",
                "'bfill'",
                "'count'",
                "'cumcount'",
                "'cummax'",
                "'cummin'",
                "'cumprod'",
                "'cumsum'",
                "'describe'",
                "'diff'",
                "'ffill'",
                "'first'",
                "'head'",
                "'last'",
                "'max'",
                "'min'",
                "'median'",
                "'mean'",
                "'nunique'",
                "'pct_change'",
                "'prod'",
                "'quantile'",
                "'rank'",
                "'sem'",
                "'shift'",
                "'size'",
                "'skew'",
                "'std'",
                "'sum'",
                "'tail'",
                "'unique'",
                "'value_counts'",
                "'var'"
            ],
            [
                "'direct'",
                "'transformation'"
            ],
            [
                "1",
                "5"
            ],
            [
                "'cython'",
                "'numba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4a0d02d2fd8fa6995ea8a55cc82dafbc7c15fe6a2c3973eaca14da8b7a16c993",
        "warmup_time": -1
    },
    "groupby.GroupByMethods.time_dtype_as_group": {
        "code": "class GroupByMethods:\n    def time_dtype_as_group(self, dtype, method, application, ncols, engine):\n        self.as_group_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols, engine):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"describe\",\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        # Numba currently doesn't support\n        # multiple transform functions or strs for transform,\n        # grouping on multiple columns\n        # and we lack kernels for a bunch of methods\n        if (\n            (engine == \"numba\" and method in _numba_unsupported_methods)\n            or ncols > 1\n            or application == \"transformation\"\n            or dtype == \"datetime\"\n        ):\n            raise NotImplementedError\n    \n        if method == \"describe\":\n            ngroups = 20\n        elif method == \"skew\":\n            ngroups = 100\n        else:\n            ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype in (\"int16\", \"uint\"):\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        # Not everything supports the engine keyword yet\n        kwargs = {}\n        if engine == \"numba\":\n            kwargs[\"engine\"] = engine\n    \n        if application == \"transformation\":\n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(\n                method, **kwargs\n            )\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(\n                method, **kwargs\n            )\n        else:\n            self.as_group_method = partial(\n                getattr(df.groupby(\"key\")[cols], method), **kwargs\n            )\n            self.as_field_method = partial(\n                getattr(df.groupby(cols)[\"key\"], method), **kwargs\n            )",
        "min_run_count": 2,
        "name": "groupby.GroupByMethods.time_dtype_as_group",
        "number": 0,
        "param_names": [
            "dtype",
            "method",
            "application",
            "ncols",
            "param5"
        ],
        "params": [
            [
                "'int'",
                "'int16'",
                "'float'",
                "'object'",
                "'datetime'",
                "'uint'"
            ],
            [
                "'all'",
                "'any'",
                "'bfill'",
                "'count'",
                "'cumcount'",
                "'cummax'",
                "'cummin'",
                "'cumprod'",
                "'cumsum'",
                "'describe'",
                "'diff'",
                "'ffill'",
                "'first'",
                "'head'",
                "'last'",
                "'max'",
                "'min'",
                "'median'",
                "'mean'",
                "'nunique'",
                "'pct_change'",
                "'prod'",
                "'quantile'",
                "'rank'",
                "'sem'",
                "'shift'",
                "'size'",
                "'skew'",
                "'std'",
                "'sum'",
                "'tail'",
                "'unique'",
                "'value_counts'",
                "'var'"
            ],
            [
                "'direct'",
                "'transformation'"
            ],
            [
                "1",
                "5"
            ],
            [
                "'cython'",
                "'numba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c29ed2bf3480091302fef3e2a837053440b872af4b447a58b03a9452c461ff1d",
        "warmup_time": -1
    },
    "groupby.GroupByNumbaAgg.time_frame_agg": {
        "code": "class GroupByNumbaAgg:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method, engine=\"numba\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByNumbaAgg:\n    def setup(self, dtype, method):\n        if method in _numba_unsupported_methods:\n            raise NotImplementedError\n        super().setup(dtype, method)",
        "min_run_count": 2,
        "name": "groupby.GroupByNumbaAgg.time_frame_agg",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'float64'"
            ],
            [
                "'sum'",
                "'prod'",
                "'min'",
                "'max'",
                "'idxmin'",
                "'idxmax'",
                "'mean'",
                "'median'",
                "'var'",
                "'first'",
                "'last'",
                "'any'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "485567a7945b89dfbcc8517d268d1572570c908383b9f7fdbc1b173bc67a292a",
        "warmup_time": -1
    },
    "groupby.GroupManyLabels.time_sum": {
        "code": "class GroupManyLabels:\n    def time_sum(self, ncols):\n        self.df.groupby(self.labels).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupManyLabels:\n    def setup(self, ncols):\n        N = 1000\n        data = np.random.randn(N, ncols)\n        self.labels = np.random.randint(0, 100, size=N)\n        self.df = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.GroupManyLabels.time_sum",
        "number": 0,
        "param_names": [
            "ncols"
        ],
        "params": [
            [
                "1",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "66b2e0c8c016da785fe5cc599d0ce7892b1c5657f8af53ff854fed498e28878a",
        "warmup_time": -1
    },
    "groupby.GroupStrings.time_multi_columns": {
        "code": "class GroupStrings:\n    def time_multi_columns(self):\n        self.df.groupby(list(\"abcd\")).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupStrings:\n    def setup(self):\n        n = 2 * 10**5\n        alpha = list(map(\"\".join, product(ascii_letters, repeat=4)))\n        data = np.random.choice(alpha, (n // 5, 4), replace=False)\n        data = np.repeat(data, 5, axis=0)\n        self.df = DataFrame(data, columns=list(\"abcd\"))\n        self.df[\"joe\"] = (np.random.randn(len(self.df)) * 10).round(3)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)",
        "min_run_count": 2,
        "name": "groupby.GroupStrings.time_multi_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e2cad1f849665339cebeef8f37279cd4824c4fa1e86e39fe618e4052a76b7dd6",
        "warmup_time": -1
    },
    "groupby.Groups.time_series_groups": {
        "code": "class Groups:\n    def time_series_groups(self, data, key):\n        self.ser.groupby(self.ser).groups\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                Index([f\"i-{i}\" for i in range(100)], dtype=object).take(\n                    np.random.randint(0, 100, size=size)\n                )\n            ),\n            \"object_large\": Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                    np.random.randint(0, 10000, size=size)\n                )\n            ),\n        }\n        return data",
        "min_run_count": 2,
        "name": "groupby.Groups.time_series_groups",
        "number": 0,
        "param_names": [
            "key"
        ],
        "params": [
            [
                "'int64_small'",
                "'int64_large'",
                "'object_small'",
                "'object_large'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:162",
        "type": "time",
        "unit": "seconds",
        "version": "dbc6b8b2b071005f9ce14efc5386fc68124c154c0787e714bcf9be17ee3b4bba",
        "warmup_time": -1
    },
    "groupby.Groups.time_series_indices": {
        "code": "class Groups:\n    def time_series_indices(self, data, key):\n        self.ser.groupby(self.ser).indices\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                Index([f\"i-{i}\" for i in range(100)], dtype=object).take(\n                    np.random.randint(0, 100, size=size)\n                )\n            ),\n            \"object_large\": Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                    np.random.randint(0, 10000, size=size)\n                )\n            ),\n        }\n        return data",
        "min_run_count": 2,
        "name": "groupby.Groups.time_series_indices",
        "number": 0,
        "param_names": [
            "key"
        ],
        "params": [
            [
                "'int64_small'",
                "'int64_large'",
                "'object_small'",
                "'object_large'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:162",
        "type": "time",
        "unit": "seconds",
        "version": "36d7245a7a3b2bd56d7270e0d6981e83fed5d32bed580a99567addff40ccbd17",
        "warmup_time": -1
    },
    "groupby.Int64.time_overflow": {
        "code": "class Int64:\n    def time_overflow(self):\n        self.df.groupby(self.cols).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Int64:\n    def setup(self):\n        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 17, 5))\n        i = np.random.choice(len(arr), len(arr) * 5)\n        arr = np.vstack((arr, arr[i]))\n        i = np.random.permutation(len(arr))\n        arr = arr[i]\n        self.cols = list(\"abcde\")\n        self.df = DataFrame(arr, columns=self.cols)\n        self.df[\"jim\"], self.df[\"joe\"] = np.random.randn(2, len(self.df)) * 10",
        "min_run_count": 2,
        "name": "groupby.Int64.time_overflow",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c59f5b180f618f9de6657c8e0c5a373add1e863a6f3969b4097836f1f4e40929",
        "warmup_time": -1
    },
    "groupby.MultiColumn.time_col_select_lambda_sum": {
        "code": "class MultiColumn:\n    def time_col_select_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.MultiColumn.time_col_select_lambda_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:358",
        "type": "time",
        "unit": "seconds",
        "version": "cada8d1efcf927c41db4c7b33b88a6816790e5d361e4cf10f3f03f390386a717",
        "warmup_time": -1
    },
    "groupby.MultiColumn.time_col_select_str_sum": {
        "code": "class MultiColumn:\n    def time_col_select_str_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.MultiColumn.time_col_select_str_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:358",
        "type": "time",
        "unit": "seconds",
        "version": "452b0de34f34dcbafb7d59c7c44e17908f0342ebb248d7b61f8ef1ee63c7d175",
        "warmup_time": -1
    },
    "groupby.MultiColumn.time_cython_sum": {
        "code": "class MultiColumn:\n    def time_cython_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.MultiColumn.time_cython_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:358",
        "type": "time",
        "unit": "seconds",
        "version": "9ba6f25ceb0666279babb6760f71ea64c8a52a817294261fed73699bc7b516f3",
        "warmup_time": -1
    },
    "groupby.MultiColumn.time_lambda_sum": {
        "code": "class MultiColumn:\n    def time_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.MultiColumn.time_lambda_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:358",
        "type": "time",
        "unit": "seconds",
        "version": "38b6452a313f2508f0dfd7fa593d129b13ec9c33f22753679877d5f06818a566",
        "warmup_time": -1
    },
    "groupby.MultipleCategories.time_groupby_extra_cat_nosort": {
        "code": "class MultipleCategories:\n    def time_groupby_extra_cat_nosort(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.MultipleCategories.time_groupby_extra_cat_nosort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "83cff68f64c01bc265f6f67706237d37c6f96f20ccb947373ea0fbdb9c5c605a",
        "warmup_time": -1
    },
    "groupby.MultipleCategories.time_groupby_extra_cat_sort": {
        "code": "class MultipleCategories:\n    def time_groupby_extra_cat_sort(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.MultipleCategories.time_groupby_extra_cat_sort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "96635202ed41a374fefefbfbd2317b32d2475a1d07384a99feb40c69b419e024",
        "warmup_time": -1
    },
    "groupby.MultipleCategories.time_groupby_nosort": {
        "code": "class MultipleCategories:\n    def time_groupby_nosort(self):\n        self.df.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.MultipleCategories.time_groupby_nosort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bd1d5b9e0fdabacec5cfdcbec5af5cf24e4a7871654e201e2e36e94e9d50bf9a",
        "warmup_time": -1
    },
    "groupby.MultipleCategories.time_groupby_ordered_nosort": {
        "code": "class MultipleCategories:\n    def time_groupby_ordered_nosort(self):\n        self.df_ordered.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.MultipleCategories.time_groupby_ordered_nosort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "efc218534283dc987433d4dda645ee117699de0a41f79f59cfcb381a56f55bfa",
        "warmup_time": -1
    },
    "groupby.MultipleCategories.time_groupby_ordered_sort": {
        "code": "class MultipleCategories:\n    def time_groupby_ordered_sort(self):\n        self.df_ordered.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.MultipleCategories.time_groupby_ordered_sort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "24d3606f6b66cd0cf252b6566e5c8a44adae7e06ecb2c17a06917ab0f801a0ab",
        "warmup_time": -1
    },
    "groupby.MultipleCategories.time_groupby_sort": {
        "code": "class MultipleCategories:\n    def time_groupby_sort(self):\n        self.df.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.MultipleCategories.time_groupby_sort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "869bac12201294cce4dabbed58d29db90d95b9d4060f99ab5acd2d7c3b1426a6",
        "warmup_time": -1
    },
    "groupby.MultipleCategories.time_groupby_transform": {
        "code": "class MultipleCategories:\n    def time_groupby_transform(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].cumsum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.MultipleCategories.time_groupby_transform",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9e6ce565eecb66a3cd8ceec5c6d78a2fc6aefeb48742cc69c8ad9a311a77873b",
        "warmup_time": -1
    },
    "groupby.Nth.time_frame_nth": {
        "code": "class Nth:\n    def time_frame_nth(self, dtype):\n        self.df.groupby(\"key\").nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_frame_nth",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e1d08a270138a89c0f1723213b6519ab3f5bf1373d8e8d2c2b54a43b065b76be",
        "warmup_time": -1
    },
    "groupby.Nth.time_frame_nth_any": {
        "code": "class Nth:\n    def time_frame_nth_any(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_frame_nth_any",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a44829e68092f64486a6572a1a5465f5a0d577ee765ee5ad2e38c472e85346bd",
        "warmup_time": -1
    },
    "groupby.Nth.time_groupby_nth_all": {
        "code": "class Nth:\n    def time_groupby_nth_all(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_groupby_nth_all",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "866ef9a468514b755b4464d8fd09949132454a4161d7a99770caeec775a2bba6",
        "warmup_time": -1
    },
    "groupby.Nth.time_series_nth": {
        "code": "class Nth:\n    def time_series_nth(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_series_nth",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c5b1e05da00cd08da75c885c95b13c18db12dc3332aafd79a79049e66f996c1e",
        "warmup_time": -1
    },
    "groupby.Nth.time_series_nth_all": {
        "code": "class Nth:\n    def time_series_nth_all(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_series_nth_all",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "42ed669cc8c03e7351add656e29a89d0fb07fc43ed2931e70701a559f09f12e1",
        "warmup_time": -1
    },
    "groupby.Nth.time_series_nth_any": {
        "code": "class Nth:\n    def time_series_nth_any(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_series_nth_any",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "011dc9ba29511d4b5f0b1bb7c6f5a991ef7a1590ce479e354646546de88cfea6",
        "warmup_time": -1
    },
    "groupby.RankWithTies.time_rank_ties": {
        "code": "class RankWithTies:\n    def time_rank_ties(self, dtype, tie_method):\n        self.df.groupby(\"key\").rank(method=tie_method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RankWithTies:\n    def setup(self, dtype, tie_method):\n        N = 10**4\n        if dtype == \"datetime64\":\n            data = np.array([Timestamp(\"2011/01/01\")] * N, dtype=dtype)\n        else:\n            data = np.ones(N, dtype=dtype)\n        self.df = DataFrame({\"values\": data, \"key\": [\"foo\"] * N})",
        "min_run_count": 2,
        "name": "groupby.RankWithTies.time_rank_ties",
        "number": 0,
        "param_names": [
            "dtype",
            "tie_method"
        ],
        "params": [
            [
                "'float64'",
                "'float32'",
                "'int64'",
                "'datetime64'"
            ],
            [
                "'first'",
                "'average'",
                "'dense'",
                "'min'",
                "'max'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "622ded2b5e5432518f83a22d3ed8f82cc9f43e2ca4ab46c97e7aa4dd1daf7f10",
        "warmup_time": -1
    },
    "groupby.Resample.time_resample": {
        "code": "class Resample:\n    def time_resample(self):\n        self.df.groupby(level=\"groups\").resample(\"10s\", on=\"timedeltas\").mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Resample:\n    def setup(self):\n        num_timedeltas = 20_000\n        num_groups = 3\n    \n        index = MultiIndex.from_product(\n            [\n                np.arange(num_groups),\n                to_timedelta(np.arange(num_timedeltas), unit=\"s\"),\n            ],\n            names=[\"groups\", \"timedeltas\"],\n        )\n        data = np.random.randint(0, 1000, size=(len(index)))\n    \n        self.df = DataFrame(data, index=index).reset_index(\"timedeltas\")\n        self.df_multiindex = DataFrame(data, index=index)",
        "min_run_count": 2,
        "name": "groupby.Resample.time_resample",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2f73c1abc5cfc408cd8604b1badf9ee4f00ceb2a76c77b5b5a78af2d74228f7b",
        "warmup_time": -1
    },
    "groupby.Resample.time_resample_multiindex": {
        "code": "class Resample:\n    def time_resample_multiindex(self):\n        self.df_multiindex.groupby(level=\"groups\").resample(\n            \"10s\", level=\"timedeltas\"\n        ).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Resample:\n    def setup(self):\n        num_timedeltas = 20_000\n        num_groups = 3\n    \n        index = MultiIndex.from_product(\n            [\n                np.arange(num_groups),\n                to_timedelta(np.arange(num_timedeltas), unit=\"s\"),\n            ],\n            names=[\"groups\", \"timedeltas\"],\n        )\n        data = np.random.randint(0, 1000, size=(len(index)))\n    \n        self.df = DataFrame(data, index=index).reset_index(\"timedeltas\")\n        self.df_multiindex = DataFrame(data, index=index)",
        "min_run_count": 2,
        "name": "groupby.Resample.time_resample_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "07304b920f854bdb1422e0b993c60857e6e2d6ad9ce2664f92ee8e113c3df234",
        "warmup_time": -1
    },
    "groupby.Sample.time_sample": {
        "code": "class Sample:\n    def time_sample(self):\n        self.df.groupby(self.groups).sample(n=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)",
        "min_run_count": 2,
        "name": "groupby.Sample.time_sample",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d06fc92a35cfb5f7ef26863259f097f3aabbef9d90438fde13891e042fa2cff9",
        "warmup_time": -1
    },
    "groupby.Sample.time_sample_weights": {
        "code": "class Sample:\n    def time_sample_weights(self):\n        self.df.groupby(self.groups).sample(n=1, weights=self.weights)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)",
        "min_run_count": 2,
        "name": "groupby.Sample.time_sample_weights",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "66bb261674cbd4d0e341aebd067908473e0734bca8091cd8bae8282d7706dd4d",
        "warmup_time": -1
    },
    "groupby.Shift.time_defaults": {
        "code": "class Shift:\n    def time_defaults(self):\n        self.df.groupby(\"g\").shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})",
        "min_run_count": 2,
        "name": "groupby.Shift.time_defaults",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6a3a41956cf53e5cacf8be90a4432268657d065e708f3681cb0da232d8442b7b",
        "warmup_time": -1
    },
    "groupby.Shift.time_fill_value": {
        "code": "class Shift:\n    def time_fill_value(self):\n        self.df.groupby(\"g\").shift(fill_value=99)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})",
        "min_run_count": 2,
        "name": "groupby.Shift.time_fill_value",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "92e908ccaf513773d03d593373379bb94d333da277d2214a08ee1905d58e0c3b",
        "warmup_time": -1
    },
    "groupby.Size.time_category_size": {
        "code": "class Size:\n    def time_category_size(self):\n        self.draws.groupby(self.cats, observed=True).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")",
        "min_run_count": 2,
        "name": "groupby.Size.time_category_size",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5eddb01370059c88e32f412a47746b638593daac39af9c786d43aafdf2e803b3",
        "warmup_time": -1
    },
    "groupby.Size.time_multi_size": {
        "code": "class Size:\n    def time_multi_size(self):\n        self.df.groupby([\"key1\", \"key2\"]).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")",
        "min_run_count": 2,
        "name": "groupby.Size.time_multi_size",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "34694723d47ec5028bd8d513e5986c685e58d7219113ca9a4be7e030a9a98aa1",
        "warmup_time": -1
    },
    "groupby.String.time_str_func": {
        "code": "class String:\n    def time_str_func(self, dtype, method):\n        self.df.groupby(\"a\")[self.df.columns[1:]].agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass String:\n    def setup(self, dtype, method):\n        cols = list(\"abcdefghjkl\")\n        self.df = DataFrame(\n            np.random.randint(0, 100, size=(10_000, len(cols))),\n            columns=cols,\n            dtype=dtype,\n        )",
        "min_run_count": 2,
        "name": "groupby.String.time_str_func",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'"
            ],
            [
                "'sum'",
                "'min'",
                "'max'",
                "'first'",
                "'last'",
                "'any'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b49dcaf61606c8e3e1fd9bd0ca3f1d1b8833147e2b729e1e363d481f98270ec4",
        "warmup_time": -1
    },
    "groupby.SumBools.time_groupby_sum_booleans": {
        "code": "class SumBools:\n    def time_groupby_sum_booleans(self):\n        self.df.groupby(\"ii\").sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumBools:\n    def setup(self):\n        N = 500\n        self.df = DataFrame({\"ii\": range(N), \"bb\": [True] * N})",
        "min_run_count": 2,
        "name": "groupby.SumBools.time_groupby_sum_booleans",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c3539588ce95b04f6cfe6c310ff1d827826da14d25eafe09e1d58cf28f0f2020",
        "warmup_time": -1
    },
    "groupby.SumMultiLevel.time_groupby_sum_multiindex": {
        "code": "class SumMultiLevel:\n    def time_groupby_sum_multiindex(self):\n        self.df.groupby(level=[0, 1]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumMultiLevel:\n    def setup(self):\n        N = 50\n        self.df = DataFrame(\n            {\"A\": list(range(N)) * 2, \"B\": range(N * 2), \"C\": 1}\n        ).set_index([\"A\", \"B\"])",
        "min_run_count": 2,
        "name": "groupby.SumMultiLevel.time_groupby_sum_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120.0,
        "type": "time",
        "unit": "seconds",
        "version": "b34947d529ea832ced0c45868dd46b91974ce4d6a23b4212210c255083673ef8",
        "warmup_time": -1
    },
    "groupby.SumTimeDelta.time_groupby_sum_int": {
        "code": "class SumTimeDelta:\n    def time_groupby_sum_int(self):\n        self.df_int.groupby(lambda x: x).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumTimeDelta:\n    def setup(self):\n        N = 10**4\n        self.df = DataFrame(\n            np.random.randint(1000, 100000, (N, 100)),\n            index=np.random.randint(200, size=(N,)),\n        ).astype(\"timedelta64[ns]\")\n        self.df_int = self.df.copy().astype(\"int64\")",
        "min_run_count": 2,
        "name": "groupby.SumTimeDelta.time_groupby_sum_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3ac04c1b47b978a60e2dd36712fe8b5546ca48524e482437ab7dd05d74d70b51",
        "warmup_time": -1
    },
    "groupby.SumTimeDelta.time_groupby_sum_timedelta": {
        "code": "class SumTimeDelta:\n    def time_groupby_sum_timedelta(self):\n        self.df.groupby(lambda x: x).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumTimeDelta:\n    def setup(self):\n        N = 10**4\n        self.df = DataFrame(\n            np.random.randint(1000, 100000, (N, 100)),\n            index=np.random.randint(200, size=(N,)),\n        ).astype(\"timedelta64[ns]\")\n        self.df_int = self.df.copy().astype(\"int64\")",
        "min_run_count": 2,
        "name": "groupby.SumTimeDelta.time_groupby_sum_timedelta",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2399de64ddcb9b1503469e78a45205ffbc8d6c7780eb674273569e1a06d55607",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_lambda_max": {
        "code": "class Transform:\n    def time_transform_lambda_max(self):\n        self.df.groupby(level=\"lev1\").transform(lambda x: max(x))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_lambda_max",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "291190f0a573b88f867178ceac1295c04bb53f214b480bc15fced8ee95dd4089",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_lambda_max_tall": {
        "code": "class Transform:\n    def time_transform_lambda_max_tall(self):\n        self.df_tall.groupby(level=0).transform(lambda x: np.max(x, axis=0))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_lambda_max_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0715fe48299e582fbe65937e99c6a8d54e797598178532c197eb7628502c9550",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_lambda_max_wide": {
        "code": "class Transform:\n    def time_transform_lambda_max_wide(self):\n        self.df_wide.groupby(level=0).transform(lambda x: np.max(x, axis=0))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_lambda_max_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e300e23373f04b050335813db183ab5f4fdc3090aa3c7c010731410139b922a2",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_multi_key1": {
        "code": "class Transform:\n    def time_transform_multi_key1(self):\n        self.df1.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_multi_key1",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "366e371c2918778eb64606950f5d97720245d6f5c1d70398a7d693b6806cff22",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_multi_key2": {
        "code": "class Transform:\n    def time_transform_multi_key2(self):\n        self.df2.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_multi_key2",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "07ba2bab8a423416e13164dea63101908acca0e0e9c2a38d7276dec381baa054",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_multi_key3": {
        "code": "class Transform:\n    def time_transform_multi_key3(self):\n        self.df3.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_multi_key3",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0535ec60ed264575ec4171ebd7c700b11428d714ccba8793dd6e2f3c2b093233",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_multi_key4": {
        "code": "class Transform:\n    def time_transform_multi_key4(self):\n        self.df4.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_multi_key4",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "909a4078e8d6a175f6cada96c1bdf3a92bb698109b6d4b03667bdae77cebbfb0",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_str_max": {
        "code": "class Transform:\n    def time_transform_str_max(self):\n        self.df.groupby(level=\"lev1\").transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_str_max",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f0a9ece43b99ebb197312d9bb8296b5f64c894b31c206c02264bf0bca0f4b27d",
        "warmup_time": -1
    },
    "groupby.TransformBools.time_transform_mean": {
        "code": "class TransformBools:\n    def time_transform_mean(self):\n        self.df[\"signal\"].groupby(self.g).transform(\"mean\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformBools:\n    def setup(self):\n        N = 120000\n        transition_points = np.sort(np.random.choice(np.arange(N), 1400))\n        transitions = np.zeros(N, dtype=np.bool_)\n        transitions[transition_points] = True\n        self.g = transitions.cumsum()\n        self.df = DataFrame({\"signal\": np.random.rand(N)})",
        "min_run_count": 2,
        "name": "groupby.TransformBools.time_transform_mean",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fbf9d5bd6f37110a204b7a248de7080198abd4d49e10d7e866f785439364bb84",
        "warmup_time": -1
    },
    "groupby.TransformEngine.time_dataframe_cython": {
        "code": "class TransformEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper.transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.TransformEngine.time_dataframe_cython",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d0c83497327280f78a5062c9717764f36483b50943b5eb9fe60025ca086edb53",
        "warmup_time": -1
    },
    "groupby.TransformEngine.time_dataframe_numba": {
        "code": "class TransformEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper.transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.TransformEngine.time_dataframe_numba",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "146b7844bad06cc92400f5337ad2abbbb2ef4e7262b9ecf7bf2f369e08df9e5c",
        "warmup_time": -1
    },
    "groupby.TransformEngine.time_series_cython": {
        "code": "class TransformEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper[1].transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.TransformEngine.time_series_cython",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2826562b07220b11d0e02a233f43f754b8f9b1b0dbed50ca3f2b3bf25b71995d",
        "warmup_time": -1
    },
    "groupby.TransformEngine.time_series_numba": {
        "code": "class TransformEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper[1].transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.TransformEngine.time_series_numba",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b20f5b20c80e1abd068634154b292c0cc05eaed4af84c3f95bdd4fb09e654937",
        "warmup_time": -1
    },
    "groupby.TransformNaN.time_first": {
        "code": "class TransformNaN:\n    def time_first(self):\n        self.df_nans.groupby(\"key\").transform(\"first\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformNaN:\n    def setup(self):\n        self.df_nans = DataFrame(\n            {\"key\": np.repeat(np.arange(1000), 10), \"B\": np.nan, \"C\": np.nan}\n        )\n        self.df_nans.loc[4::10, \"B\":\"C\"] = 5",
        "min_run_count": 2,
        "name": "groupby.TransformNaN.time_first",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "466258ae973db79b6c4ae80572d3424a11b6997e4ab98b9751eb9a5d30f468e8",
        "warmup_time": -1
    },
    "hash_functions.Float64GroupIndex.time_groupby": {
        "code": "class Float64GroupIndex:\n    def time_groupby(self):\n        self.df.groupby(self.group_index).last()\n\n    def setup(self):\n        self.df = pd.date_range(\n            start=\"1/1/2018\", end=\"1/2/2018\", periods=10**6\n        ).to_frame()\n        self.group_index = np.round(self.df.index.astype(int) / 10**9)",
        "min_run_count": 2,
        "name": "hash_functions.Float64GroupIndex.time_groupby",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "16fa99f7d4871f73a649b4eb9085ebd39124ac1b6451a2321c9fb1e2792d9569",
        "warmup_time": -1
    },
    "hash_functions.NumericSeriesIndexing.time_loc_slice": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, dtype, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype)\n        indices = pd.Index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)",
        "min_run_count": 2,
        "name": "hash_functions.NumericSeriesIndexing.time_loc_slice",
        "number": 0,
        "param_names": [
            "dtype",
            "N"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "10000",
                "100000",
                "500000",
                "1000000",
                "5000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bbd9b15d7f65d1d2a57335626da432a02c7db5e70cbd8098c13b4e3d4b391802",
        "warmup_time": -1
    },
    "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice": {
        "code": "class NumericSeriesIndexingShuffled:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, dtype, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype)\n        np.random.shuffle(vals)\n        indices = pd.Index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)",
        "min_run_count": 2,
        "name": "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice",
        "number": 0,
        "param_names": [
            "dtype",
            "N"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "10000",
                "100000",
                "500000",
                "1000000",
                "5000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "432c7f2c138c103e14be8ce799b1975974eeda009197320865b48b0310220376",
        "warmup_time": -1
    },
    "hash_functions.Unique.time_unique": {
        "code": "class Unique:\n    def time_unique(self, exponent):\n        pd.unique(self.ser_unique)\n\n    def setup(self, dtype):\n        self.ser = pd.Series(([1, pd.NA, 2] + list(range(100_000))) * 3, dtype=dtype)\n        self.ser_unique = pd.Series(list(range(300_000)) + [pd.NA], dtype=dtype)",
        "min_run_count": 2,
        "name": "hash_functions.Unique.time_unique",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'Int64'",
                "'Float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b4e9501a2d788652cf742d899e45ee6697865981d8caebbc02b5c662b0207edf",
        "warmup_time": -1
    },
    "hash_functions.Unique.time_unique_with_duplicates": {
        "code": "class Unique:\n    def time_unique_with_duplicates(self, exponent):\n        pd.unique(self.ser)\n\n    def setup(self, dtype):\n        self.ser = pd.Series(([1, pd.NA, 2] + list(range(100_000))) * 3, dtype=dtype)\n        self.ser_unique = pd.Series(list(range(300_000)) + [pd.NA], dtype=dtype)",
        "min_run_count": 2,
        "name": "hash_functions.Unique.time_unique_with_duplicates",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'Int64'",
                "'Float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "167e56c7e4063b7bb8cad24ce741ad07d7714185a453ada8f9296eb9acf885af",
        "warmup_time": -1
    },
    "hash_functions.UniqueAndFactorizeArange.time_factorize": {
        "code": "class UniqueAndFactorizeArange:\n    def time_factorize(self, exponent):\n        pd.factorize(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10**4, dtype=\"float64\")\n        self.a2 = (a + 10**exponent).repeat(100)",
        "min_run_count": 2,
        "name": "hash_functions.UniqueAndFactorizeArange.time_factorize",
        "number": 0,
        "param_names": [
            "exponent"
        ],
        "params": [
            [
                "4",
                "5",
                "6",
                "7",
                "8",
                "9",
                "10",
                "11",
                "12",
                "13",
                "14",
                "15"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0f26f4d8f2608aa8c5a85a0f06b3d3035de285c9a423a8f0f98688da07c40443",
        "warmup_time": -1
    },
    "hash_functions.UniqueAndFactorizeArange.time_unique": {
        "code": "class UniqueAndFactorizeArange:\n    def time_unique(self, exponent):\n        pd.unique(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10**4, dtype=\"float64\")\n        self.a2 = (a + 10**exponent).repeat(100)",
        "min_run_count": 2,
        "name": "hash_functions.UniqueAndFactorizeArange.time_unique",
        "number": 0,
        "param_names": [
            "exponent"
        ],
        "params": [
            [
                "4",
                "5",
                "6",
                "7",
                "8",
                "9",
                "10",
                "11",
                "12",
                "13",
                "14",
                "15"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "871707976cd021a306828a6723cac7ae71087078cf1b78c6d17c352b6b600d9c",
        "warmup_time": -1
    },
    "hash_functions.UniqueForLargePyObjectInts.time_unique": {
        "code": "class UniqueForLargePyObjectInts:\n    def time_unique(self):\n        pd.unique(self.arr)\n\n    def setup(self):\n        lst = [x << 32 for x in range(5000)]\n        self.arr = np.array(lst, dtype=np.object_)",
        "min_run_count": 2,
        "name": "hash_functions.UniqueForLargePyObjectInts.time_unique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2b911217a8295551fd862ba4e9a94107678d903c84a5a197b90acce421e6f8c6",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_engine": {
        "code": "class IndexCache:\n    def time_engine(self, index_type):\n        self.idx._engine\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_engine",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "740507bf126b994b6d6ebc6be8ebf07edb76586f565ac510ca9368d909d709d4",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_inferred_type": {
        "code": "class IndexCache:\n    def time_inferred_type(self, index_type):\n        self.idx.inferred_type\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_inferred_type",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f3ebbac92d68a71460a35d139fd438638cdb972b17c7453a5812797d0a732216",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_is_monotonic_decreasing": {
        "code": "class IndexCache:\n    def time_is_monotonic_decreasing(self, index_type):\n        self.idx.is_monotonic_decreasing\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_is_monotonic_decreasing",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0bb371064863d37bb2c6463fec281d4385b45e96f82db5c35dd8465a0914d022",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_is_monotonic_increasing": {
        "code": "class IndexCache:\n    def time_is_monotonic_increasing(self, index_type):\n        self.idx.is_monotonic_increasing\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_is_monotonic_increasing",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "de17e7db24a14fda30802ea91555a4f31065f43168acb8e3e31a1e92468b2ab5",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_is_unique": {
        "code": "class IndexCache:\n    def time_is_unique(self, index_type):\n        self.idx.is_unique\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_is_unique",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee6b34e14ea2eceb624910b4953fddcf15d45041d74a3636af086e47e0523800",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_shape": {
        "code": "class IndexCache:\n    def time_shape(self, index_type):\n        self.idx.shape\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_shape",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8546f1125c3d98d90e592f3e476bbea39ecc261b095952bcf45985ed5b90c619",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_values": {
        "code": "class IndexCache:\n    def time_values(self, index_type):\n        self.idx._values\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_values",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8fc19379f5cae741e4d0deaa9154de9d3ccffef1b639f850c8c2ace4093c3566",
        "warmup_time": -1
    },
    "index_object.Float64IndexMethod.time_get_loc": {
        "code": "class Float64IndexMethod:\n    def time_get_loc(self):\n        self.ind.get_loc(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float64IndexMethod:\n    def setup(self):\n        N = 100_000\n        a = np.arange(N, dtype=np.float64)\n        self.ind = Index(a * 4.8000000418824129e-08)",
        "min_run_count": 2,
        "name": "index_object.Float64IndexMethod.time_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "95061ed30b62c0b9d9cf95faffe63e95be78a617811548ad955f451532cb0fba",
        "warmup_time": -1
    },
    "index_object.GC.peakmem_gc_instances": {
        "code": "class GC:\n    def peakmem_gc_instances(self, N):\n        try:\n            gc.disable()\n    \n            for _ in range(N):\n                self.create_use_drop()\n        finally:\n            gc.enable()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)",
        "name": "index_object.GC.peakmem_gc_instances",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1",
                "2",
                "5"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "7b1c36ff9e60323ef8e4df7fa94a4764bdb5c6dce62bfea0095812ca55841ff9"
    },
    "index_object.IndexAppend.time_append_int_list": {
        "code": "class IndexAppend:\n    def time_append_int_list(self):\n        self.int_idx.append(self.int_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)\n        self.same_range_idx = [self.range_idx] * N",
        "min_run_count": 2,
        "name": "index_object.IndexAppend.time_append_int_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "187b4bea8d14dcc06f65835569b1c5e971944530ec8cb67458abf0a48d63a9fe",
        "warmup_time": -1
    },
    "index_object.IndexAppend.time_append_obj_list": {
        "code": "class IndexAppend:\n    def time_append_obj_list(self):\n        self.obj_idx.append(self.object_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)\n        self.same_range_idx = [self.range_idx] * N",
        "min_run_count": 2,
        "name": "index_object.IndexAppend.time_append_obj_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1eb3444e584db6402181f1963f7d223d14b319f378532e86d0026c1c4c7c951e",
        "warmup_time": -1
    },
    "index_object.IndexAppend.time_append_range_list": {
        "code": "class IndexAppend:\n    def time_append_range_list(self):\n        self.range_idx.append(self.range_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)\n        self.same_range_idx = [self.range_idx] * N",
        "min_run_count": 2,
        "name": "index_object.IndexAppend.time_append_range_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0e304a4e79c4ee646b5ebb948712ae73512cb69027375ac7df1bb411a938f290",
        "warmup_time": -1
    },
    "index_object.IndexAppend.time_append_range_list_same": {
        "code": "class IndexAppend:\n    def time_append_range_list_same(self):\n        self.range_idx.append(self.same_range_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)\n        self.same_range_idx = [self.range_idx] * N",
        "min_run_count": 2,
        "name": "index_object.IndexAppend.time_append_range_list_same",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ff402b8c39150bf9edff26f66ab0e7092c6dd67e49ec116b99e0d6b4abe54295",
        "warmup_time": -1
    },
    "index_object.IndexEquals.time_non_object_equals_multiindex": {
        "code": "class IndexEquals:\n    def time_non_object_equals_multiindex(self):\n        self.idx_non_object.equals(self.mi_large_slow)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexEquals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100_000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)",
        "min_run_count": 2,
        "name": "index_object.IndexEquals.time_non_object_equals_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bc0a852a1647f5faba1ff3d27b24d6f703432910d3e11571a9d33ab853b195fe",
        "warmup_time": -1
    },
    "index_object.Indexing.time_boolean_array": {
        "code": "class Indexing:\n    def time_boolean_array(self, dtype):\n        self.idx[self.array_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_boolean_array",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2872d6ea2933595acc8996735ecb7a9132a4426fb1407ccec9aa7efdd4ad85ad",
        "warmup_time": -1
    },
    "index_object.Indexing.time_boolean_series": {
        "code": "class Indexing:\n    def time_boolean_series(self, dtype):\n        self.idx[self.series_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_boolean_series",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "171ff47df045dded77e36fb401cca8017353337080c278f199fb8dcb639b5464",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get": {
        "code": "class Indexing:\n    def time_get(self, dtype):\n        self.idx[1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c57b57260524bc53aea830758c7b5709073ec090659a1d47c36095f2fb15dff7",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get_loc": {
        "code": "class Indexing:\n    def time_get_loc(self, dtype):\n        self.idx.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get_loc",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "69319b49f855f411ba4637d014498c805bf3ed2a7094c32bd645b68fc1cd4f0e",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get_loc_non_unique": {
        "code": "class Indexing:\n    def time_get_loc_non_unique(self, dtype):\n        self.non_unique.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get_loc_non_unique",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c8473ef7870230376ca8a19b46b05af3eca2e5e512dc4b793c2815ca20baf1d4",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get_loc_non_unique_sorted": {
        "code": "class Indexing:\n    def time_get_loc_non_unique_sorted(self, dtype):\n        self.non_unique_sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get_loc_non_unique_sorted",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d3b10e0134711d5f0ab40869cd8d2c7bdb5c3036812bcd69d10d62fb1747b2d9",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get_loc_sorted": {
        "code": "class Indexing:\n    def time_get_loc_sorted(self, dtype):\n        self.sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get_loc_sorted",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "739af3c9409d4e9d6c8df759ed8f56c0fd3d26f455934fbf3bb864fae82ad7df",
        "warmup_time": -1
    },
    "index_object.Indexing.time_slice": {
        "code": "class Indexing:\n    def time_slice(self, dtype):\n        self.idx[:-1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_slice",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "11119f3458bfba6b765f0d88bdf470a536cb9627fe0038c74fff6a0713250654",
        "warmup_time": -1
    },
    "index_object.Indexing.time_slice_step": {
        "code": "class Indexing:\n    def time_slice_step(self, dtype):\n        self.idx[::2]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_slice_step",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c9173d384d9c83e3f8d59ac1ffc9ef13805aa187d563490d88c3fe8968f7bc68",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_intersection": {
        "code": "class IntervalIndexMethod:\n    def time_intersection(self, N):\n        self.left.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_intersection",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4211da5ac938e20dc8e3ebad85e3fd809e9b9485898f7bc9fa4b78bf51836ba1",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_intersection_both_duplicate": {
        "code": "class IntervalIndexMethod:\n    def time_intersection_both_duplicate(self, N):\n        self.intv.intersection(self.intv2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_intersection_both_duplicate",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "51c27b25f860d486d8b165a9a8fff37e4de68c2b0a193957783434e9151daaaa",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_intersection_one_duplicate": {
        "code": "class IntervalIndexMethod:\n    def time_intersection_one_duplicate(self, N):\n        self.intv.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_intersection_one_duplicate",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d690ff28419653e49b71207cafa08bd0c7e2901de3773c422f3c20c5659c70da",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_is_unique": {
        "code": "class IntervalIndexMethod:\n    def time_is_unique(self, N):\n        self.intv.is_unique\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_is_unique",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b17a38c55c09eaaebc6e2a4010627e28285f0f0b8e734cf754a82d09ba25a090",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_monotonic_inc": {
        "code": "class IntervalIndexMethod:\n    def time_monotonic_inc(self, N):\n        self.intv.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_monotonic_inc",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2f556c42b4ba4b668eb1eb25dfddbcc31dc3735f52e12303ef99ae8a4b9243e0",
        "warmup_time": -1
    },
    "index_object.Range.time_get_loc_dec": {
        "code": "class Range:\n    def time_get_loc_dec(self):\n        self.idx_dec.get_loc(100_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_get_loc_dec",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cf79b8ebe5bba662336f38ac055b59d39696daca21fa516ec6f3d586ef77fbeb",
        "warmup_time": -1
    },
    "index_object.Range.time_get_loc_inc": {
        "code": "class Range:\n    def time_get_loc_inc(self):\n        self.idx_inc.get_loc(900_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_get_loc_inc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e65b3c2e45ffd07fe90c70762651887bf917e0004b33efeabc1a1513961834af",
        "warmup_time": -1
    },
    "index_object.Range.time_iter_dec": {
        "code": "class Range:\n    def time_iter_dec(self):\n        for _ in self.idx_dec:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_iter_dec",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0a8939329588ad2b3dccc5769b034e1cc2e6af1940fac168fcfa5dc2b425573c",
        "warmup_time": -1
    },
    "index_object.Range.time_iter_inc": {
        "code": "class Range:\n    def time_iter_inc(self):\n        for _ in self.idx_inc:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_iter_inc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "83fc9b98da37845cad00c4fbdc28fc193a5ba6fe4036f48c28387979e66deb80",
        "warmup_time": -1
    },
    "index_object.Range.time_max": {
        "code": "class Range:\n    def time_max(self):\n        self.idx_inc.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_max",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3fe3d3e0faeaa6aca9e99b56ed9428c2909cf685bc2777ad15b8b139f7f9b6fc",
        "warmup_time": -1
    },
    "index_object.Range.time_max_trivial": {
        "code": "class Range:\n    def time_max_trivial(self):\n        self.idx_dec.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_max_trivial",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4e25e4137da187681125aee125ed76c646d75254e914e5a610454f0dab1bdbf2",
        "warmup_time": -1
    },
    "index_object.Range.time_min": {
        "code": "class Range:\n    def time_min(self):\n        self.idx_dec.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_min",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5d8be4d1e9900d49eb6d2838b94ceaf7b5b6044f15d46b44772fd09d2ed706ed",
        "warmup_time": -1
    },
    "index_object.Range.time_min_trivial": {
        "code": "class Range:\n    def time_min_trivial(self):\n        self.idx_inc.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_min_trivial",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9406fe8e0431d861ebb9af746fdd854868498b66f1a43f0b7184b8a5955f901b",
        "warmup_time": -1
    },
    "index_object.Range.time_sort_values_asc": {
        "code": "class Range:\n    def time_sort_values_asc(self):\n        self.idx_inc.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_sort_values_asc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ad0ef7f510dcd8d00149b95616b19281a15359db8f2989bf9b4db306fdf0153f",
        "warmup_time": -1
    },
    "index_object.Range.time_sort_values_des": {
        "code": "class Range:\n    def time_sort_values_des(self):\n        self.idx_inc.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_sort_values_des",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c7ce6ea7bb8b8649240594fbbc1a612d9d42aa3b0e41c90f92cfb40283cbbd45",
        "warmup_time": -1
    },
    "index_object.SetDisjoint.time_datetime_difference_disjoint": {
        "code": "class SetDisjoint:\n    def time_datetime_difference_disjoint(self):\n        self.datetime_left.difference(self.datetime_right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetDisjoint:\n    def setup(self):\n        N = 10**5\n        B = N + 20000\n        self.datetime_left = DatetimeIndex(range(N))\n        self.datetime_right = DatetimeIndex(range(N, B))",
        "min_run_count": 2,
        "name": "index_object.SetDisjoint.time_datetime_difference_disjoint",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5f314bb98034f50776d52507597278df13b4f23a7942559fc0dedf93d1c11c62",
        "warmup_time": -1
    },
    "index_object.SetOperations.time_operation": {
        "code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method):\n        N = 10**5\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n        date_str_left = Index(dates_left.strftime(fmt))\n        int_left = Index(np.arange(N))\n        ea_int_left = Index(np.arange(N), dtype=\"Int64\")\n        str_left = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n    \n        data = {\n            \"datetime\": dates_left,\n            \"date_string\": date_str_left,\n            \"int\": int_left,\n            \"strings\": str_left,\n            \"ea_int\": ea_int_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": idx, \"right\": idx[:-1]} for k, idx in data.items()}\n    \n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]",
        "min_run_count": 2,
        "name": "index_object.SetOperations.time_operation",
        "number": 0,
        "param_names": [
            "index_structure",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'monotonic'",
                "'non_monotonic'"
            ],
            [
                "'datetime'",
                "'date_string'",
                "'int'",
                "'strings'",
                "'ea_int'"
            ],
            [
                "'intersection'",
                "'union'",
                "'symmetric_difference'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "705854d266f8227ee3d9b1eebe268d69ac27a014c6ad4691945dfab9b8c3707b",
        "warmup_time": -1
    },
    "index_object.UnionWithDuplicates.time_union_with_duplicates": {
        "code": "class UnionWithDuplicates:\n    def time_union_with_duplicates(self):\n        self.left.union(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass UnionWithDuplicates:\n    def setup(self):\n        self.left = Index(np.repeat(np.arange(1000), 100))\n        self.right = Index(np.tile(np.arange(500, 1500), 50))",
        "min_run_count": 2,
        "name": "index_object.UnionWithDuplicates.time_union_with_duplicates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0420e720a40b09b5a83ef4ace67c704a238d521a86a8cb00c673aae12cfa2f25",
        "warmup_time": -1
    },
    "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index": {
        "code": "class AssignTimeseriesIndex:\n    def time_frame_assign_timeseries_index(self):\n        self.df[\"date\"] = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AssignTimeseriesIndex:\n    def setup(self):\n        N = 100000\n        idx = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        self.df = DataFrame(np.random.randn(N, 1), columns=[\"A\"], index=idx)",
        "min_run_count": 2,
        "name": "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8a46e2b72c84ebbe38a56cb3270fe056a22bae89403a8b5abbba563b26d08524",
        "warmup_time": -1
    },
    "indexing.Block.time_test": {
        "code": "class Block:\n    def time_test(self):\n        start = datetime(2010, 5, 1)\n        end = datetime(2010, 9, 1)\n        self.df.loc[start:end, :] = True\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Block:\n    def setup(self):\n        self.df = DataFrame(\n            False,\n            columns=np.arange(500).astype(str),\n            index=date_range(\"2010-01-01\", \"2011-01-01\"),\n        )",
        "min_run_count": 2,
        "name": "indexing.Block.time_test",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "39e6c3768a47acba71f7629130e05fa40727ceee91cea7b9615069e0d7ff1970",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_get_indexer_list": {
        "code": "class CategoricalIndexIndexing:\n    def time_get_indexer_list(self, index):\n        self.data_unique.get_indexer(self.cat_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_get_indexer_list",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "62150e3781f883d8f6823c45067fcac0fefeb8ec685a47ce8057bed4cbaf3de7",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_get_loc_scalar": {
        "code": "class CategoricalIndexIndexing:\n    def time_get_loc_scalar(self, index):\n        self.data.get_loc(self.cat_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_get_loc_scalar",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f37f9a77340871ef67cae5bac921473a106ea7e1c707babd9a5d708a28df0d9a",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_bool_array": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_bool_array",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b4c1625b9c78f360819094fa2e243d9c3671eccf5396bd00cc7d4298824b370d",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_list": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_list(self, index):\n        self.data[self.int_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_list",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "25f5a440360e857bbf13b393292f058291a0fe0e335aa56339d4690c25ac147c",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_list_like": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.int_scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_list_like",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d616c85b999476b17108e8f7e22f95a195640eb4a2d59226df18c1f7eb5fbc26",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_scalar": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_scalar(self, index):\n        self.data[self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a18201ebf2cfad696d0e413b9cbc8eb4884b1f5b7447ca8f974fe3f765766278",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_slice": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_slice(self, index):\n        self.data[: self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_slice",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4c7a1c61821c96671e21fd7ce147081487558bee846c82a1db1d2a696acb4761",
        "warmup_time": -1
    },
    "indexing.ChainIndexing.time_chained_indexing": {
        "code": "class ChainIndexing:\n    def time_chained_indexing(self, mode):\n        df = self.df\n        N = self.N\n        with warnings.catch_warnings(record=True):\n            with option_context(\"mode.chained_assignment\", mode):\n                df2 = df[df.A > N // 2]\n                df2[\"C\"] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ChainIndexing:\n    def setup(self, mode):\n        self.N = 1000000\n        self.df = DataFrame({\"A\": np.arange(self.N), \"B\": \"foo\"})",
        "min_run_count": 2,
        "name": "indexing.ChainIndexing.time_chained_indexing",
        "number": 0,
        "param_names": [
            "mode"
        ],
        "params": [
            [
                "None",
                "'warn'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "16258f12b7c725f7ffc21ffed9c69bd9751f02f6a459f86e81c20750c1fc1bba",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_bool_indexer": {
        "code": "class DataFrameNumericIndexing:\n    def time_bool_indexer(self, index, index_structure):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_bool_indexer",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5b49ac8c1fc01d2dc2c19c3edcf588116fa02ee673f47dde99584eb435361fed",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_iloc": {
        "code": "class DataFrameNumericIndexing:\n    def time_iloc(self, index, index_structure):\n        self.df.iloc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_iloc",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d4f1ee902bd3f0617b7fe7bfbca605d0c34d424476e2ea162e220ee701e530eb",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_iloc_dups": {
        "code": "class DataFrameNumericIndexing:\n    def time_iloc_dups(self, index, index_structure):\n        self.df_dup.iloc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_iloc_dups",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4390803cba45b26841ac1b3f27cffcaed921e6083822e3d13e9eff994ee542e5",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_loc": {
        "code": "class DataFrameNumericIndexing:\n    def time_loc(self, index, index_structure):\n        self.df.loc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_loc",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a85621866c240f052375710c72ffe0cc190d797923084092e4984bff4240dfdf",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_loc_dups": {
        "code": "class DataFrameNumericIndexing:\n    def time_loc_dups(self, index, index_structure):\n        self.df_dup.loc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_loc_dups",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9789412267c4eba4099218c01b54dc8d5055978255c8cae7cd1d3f96cf362b7e",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_at": {
        "code": "class DataFrameStringIndexing:\n    def time_at(self):\n        self.df.at[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_at",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "04739f5bfcf96a2f809bfa8f746b3114f7e77b97abc35344668e4ca4a11170d4",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_at_setitem": {
        "code": "class DataFrameStringIndexing:\n    def time_at_setitem(self):\n        self.df.at[self.idx_scalar, self.col_scalar] = 0.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_at_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "16329486e02da43d62eec0a291532ad60f0896602155cbceaedcad8754660605",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_boolean_rows": {
        "code": "class DataFrameStringIndexing:\n    def time_boolean_rows(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_boolean_rows",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8c68634926f34e2c9bc0f70108b33cfe3e2b04a295ea8cd25fc43f47be736790",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_boolean_rows_boolean": {
        "code": "class DataFrameStringIndexing:\n    def time_boolean_rows_boolean(self):\n        self.df[self.boolean_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_boolean_rows_boolean",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6dab0adc8de5d2f64428f7448f101efc6b11cbcc807586ed900490d1d9afb74d",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_boolean_rows_object": {
        "code": "class DataFrameStringIndexing:\n    def time_boolean_rows_object(self):\n        self.df[self.bool_obj_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_boolean_rows_object",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "17f00e8889b2275c34fb7afa8d331fedfd9d5e12704117ffc4055d512bd2bd60",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_getitem_scalar": {
        "code": "class DataFrameStringIndexing:\n    def time_getitem_scalar(self):\n        self.df[self.col_scalar][self.idx_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fcea3e53ee2d996215560d161151b94b0177c7b2d2cbbc4580f324f6dc2de27a",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_loc": {
        "code": "class DataFrameStringIndexing:\n    def time_loc(self):\n        self.df.loc[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "12b067d7b3c3ffe25275292b557ba18517ad4d2c5b6e1b41fdfb018f4889d00c",
        "warmup_time": -1
    },
    "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz": {
        "code": "class DatetimeIndexIndexing:\n    def time_get_indexer_mismatched_tz(self):\n        # reached via e.g.\n        #  ser = Series(range(len(dti)), index=dti)\n        #  ser[dti2]\n        self.dti.get_indexer(self.dti2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexIndexing:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        dti2 = dti.tz_convert(\"UTC\")\n        self.dti = dti\n        self.dti2 = dti2",
        "min_run_count": 2,
        "name": "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c9cf20755eb4a51e544f3173086738738b06c2840acdc00a8c905a951594ce03",
        "warmup_time": -1
    },
    "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int": {
        "code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_int(self):\n        self.df_int_col[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))",
        "min_run_count": 2,
        "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8516566e6a549f1f7c5a48623aa1378d299f882af8c200a8ab04eb7d321f0a23",
        "warmup_time": -1
    },
    "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label": {
        "code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_label(self):\n        self.df_string_col[\"A\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))",
        "min_run_count": 2,
        "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a03a82b5117e7c2d6cccfe8ac22ef652a2ac9b039e27f15814a7bfab97c94f00",
        "warmup_time": -1
    },
    "indexing.IndexSingleRow.time_iloc_row": {
        "code": "class IndexSingleRow:\n    def time_iloc_row(self, unique_cols):\n        self.df.iloc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10**7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df",
        "min_run_count": 2,
        "name": "indexing.IndexSingleRow.time_iloc_row",
        "number": 0,
        "param_names": [
            "unique_cols"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4e20d2ce44a18740b78a7eae0eab3b3352a211486335db125fa22f685c9c5c68",
        "warmup_time": -1
    },
    "indexing.IndexSingleRow.time_loc_row": {
        "code": "class IndexSingleRow:\n    def time_loc_row(self, unique_cols):\n        self.df.loc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10**7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df",
        "min_run_count": 2,
        "name": "indexing.IndexSingleRow.time_loc_row",
        "number": 0,
        "param_names": [
            "unique_cols"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b1ae71b2de36f0424ee21d6b377c7e4370496ce8ed29f92ce82786280ff4c9db",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_assign_list_like_with_setitem": {
        "code": "class InsertColumns:\n    def time_assign_list_like_with_setitem(self):\n        self.df[list(range(100))] = np.random.randn(self.N, 100)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_assign_list_like_with_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3bb24f36b40d94be98724ac3ffea9a7afbc390d394fa5fa9475cc77a13ffdf7b",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_assign_list_of_columns_concat": {
        "code": "class InsertColumns:\n    def time_assign_list_of_columns_concat(self):\n        df = DataFrame(np.random.randn(self.N, 100))\n        concat([self.df, df], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_assign_list_of_columns_concat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "41cef472b41bd56488365882e9724052692d13ec0abf67f3fa395e44af3a045d",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_assign_with_setitem": {
        "code": "class InsertColumns:\n    def time_assign_with_setitem(self):\n        for i in range(100):\n            self.df[i] = np.random.randn(self.N)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_assign_with_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "594d490a7116f20753d8366d82e417220b8035ce74080b41de66a9f64d7b2abd",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_insert": {
        "code": "class InsertColumns:\n    def time_insert(self):\n        for i in range(100):\n            self.df.insert(0, i, np.random.randn(self.N), allow_duplicates=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_insert",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0021e91e2211b243fded9954bae458921f73a3e5ded206d0817555b44c945c0d",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_insert_middle": {
        "code": "class InsertColumns:\n    def time_insert_middle(self):\n        # same as time_insert but inserting to a middle column rather than\n        #  front or back (which have fast-paths)\n        for i in range(100):\n            self.df2.insert(\n                1, \"colname\", np.random.randn(self.N), allow_duplicates=True\n            )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_insert_middle",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c08ac878c8c7f19edcae9cddb8525e726ef5328f5fb06d9932ca3e83158e4a7d",
        "warmup_time": -1
    },
    "indexing.IntervalIndexing.time_getitem_list": {
        "code": "class IntervalIndexing:\n    def time_getitem_list(self, monotonic):\n        monotonic[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic",
        "min_run_count": 2,
        "name": "indexing.IntervalIndexing.time_getitem_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:324",
        "type": "time",
        "unit": "seconds",
        "version": "ae80a330a1a4becae8c369fe9bcb0c8f430beb2d8ac3986f5e2f82490c50e071",
        "warmup_time": -1
    },
    "indexing.IntervalIndexing.time_getitem_scalar": {
        "code": "class IntervalIndexing:\n    def time_getitem_scalar(self, monotonic):\n        monotonic[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic",
        "min_run_count": 2,
        "name": "indexing.IntervalIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:324",
        "type": "time",
        "unit": "seconds",
        "version": "f160eaae3bf3bcbcc3fd20357b12c28670839282da6644be0e8024f97b21204b",
        "warmup_time": -1
    },
    "indexing.IntervalIndexing.time_loc_list": {
        "code": "class IntervalIndexing:\n    def time_loc_list(self, monotonic):\n        monotonic.loc[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic",
        "min_run_count": 2,
        "name": "indexing.IntervalIndexing.time_loc_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:324",
        "type": "time",
        "unit": "seconds",
        "version": "634735f3995a5c9be2542706652ca9d8a024f91ded9a8e3ec8653b176bb9c556",
        "warmup_time": -1
    },
    "indexing.IntervalIndexing.time_loc_scalar": {
        "code": "class IntervalIndexing:\n    def time_loc_scalar(self, monotonic):\n        monotonic.loc[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic",
        "min_run_count": 2,
        "name": "indexing.IntervalIndexing.time_loc_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:324",
        "type": "time",
        "unit": "seconds",
        "version": "9682c17d993a421023a33cdfbf1ae6a67d4f2b1a8a9eb98fb60445f56f4d892e",
        "warmup_time": -1
    },
    "indexing.MethodLookup.time_lookup_iloc": {
        "code": "class MethodLookup:\n    def time_lookup_iloc(self, s):\n        s.iloc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s",
        "min_run_count": 2,
        "name": "indexing.MethodLookup.time_lookup_iloc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:418",
        "type": "time",
        "unit": "seconds",
        "version": "de130c1315ebaff60daa5132a0ffba11a1513d688c4d7465c4f0b75fa3b40d4d",
        "warmup_time": -1
    },
    "indexing.MethodLookup.time_lookup_loc": {
        "code": "class MethodLookup:\n    def time_lookup_loc(self, s):\n        s.loc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s",
        "min_run_count": 2,
        "name": "indexing.MethodLookup.time_lookup_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:418",
        "type": "time",
        "unit": "seconds",
        "version": "8f3e9ba1fa6ae32795b77d4fb0a2cb3a36108a494ac5a33197076f41a75cee6c",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_all_bool_indexers": {
        "code": "class MultiIndexing:\n    def time_loc_all_bool_indexers(self, unique_levels):\n        target = tuple([self.tgt_bool_indexer] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_all_bool_indexers",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1771918b3fe0b5cbe067324593f312813f66ac1576a3387207feb5abfb7ca806",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_all_lists": {
        "code": "class MultiIndexing:\n    def time_loc_all_lists(self, unique_levels):\n        target = tuple([self.tgt_list] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_all_lists",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "472ab8a43bc8d905a0c7bfecd2190e954a7da13e4e29ddbaf54d1ffa9c50a846",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_all_null_slices": {
        "code": "class MultiIndexing:\n    def time_loc_all_null_slices(self, unique_levels):\n        target = tuple([self.tgt_null_slice] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_all_null_slices",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee13de44701c0630572b0428b6d08740c41bc7278df47aae6f015bed57f20896",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_all_scalars": {
        "code": "class MultiIndexing:\n    def time_loc_all_scalars(self, unique_levels):\n        target = tuple([self.tgt_scalar] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_all_scalars",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "52fba5b8883c06b2ad277a711b4ac49603c38321be1afb8a2daf975deff153af",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_all_slices": {
        "code": "class MultiIndexing:\n    def time_loc_all_slices(self, unique_levels):\n        target = tuple([self.tgt_slice] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_all_slices",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7ee6845e7a946179e2f28eb51291bf1e8dc5aa663346c5e70b7db58cf6a415d4",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_multiindex": {
        "code": "class MultiIndexing:\n    def time_loc_multiindex(self, unique_levels):\n        target = self.df.index[::10]\n        self.df.loc[target]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_multiindex",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "845e85441994edf43d432790182cf5f3f1c8a8d11260d19322d4f9c26e9ea82e",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_null_slice_plus_slice": {
        "code": "class MultiIndexing:\n    def time_loc_null_slice_plus_slice(self, unique_levels):\n        target = (self.tgt_null_slice, self.tgt_slice)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_null_slice_plus_slice",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f8a8667e507761ed75e543d5d59a9b99abf35fbbd88506af79bba513db537b1d",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_partial_key_bool_indexer": {
        "code": "class MultiIndexing:\n    def time_loc_partial_key_bool_indexer(self, unique_levels):\n        self.df.loc[self.tgt_bool_indexer, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_partial_key_bool_indexer",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f4163b15e26adc988dcb7d895e5ced6f1fa85495a29d44c6f1df7010fff0d379",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_partial_key_list": {
        "code": "class MultiIndexing:\n    def time_loc_partial_key_list(self, unique_levels):\n        self.df.loc[self.tgt_list, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_partial_key_list",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3d998427658ce79d9730202287dfc27f39d7b70b94481fc82cc28c58bb10fc2c",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_partial_key_null_slice": {
        "code": "class MultiIndexing:\n    def time_loc_partial_key_null_slice(self, unique_levels):\n        self.df.loc[self.tgt_null_slice, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_partial_key_null_slice",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "777e2da95dafebe327dcbfc63277290e5760e3bb51661ddfe6a5fd3c7e0702bc",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_partial_key_scalar": {
        "code": "class MultiIndexing:\n    def time_loc_partial_key_scalar(self, unique_levels):\n        self.df.loc[self.tgt_scalar, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_partial_key_scalar",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7fff81ab0ee84cd8d0d1cbb857a086f21277e9956a9dd836bbe17b4070bf4188",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_partial_key_slice": {
        "code": "class MultiIndexing:\n    def time_loc_partial_key_slice(self, unique_levels):\n        self.df.loc[self.tgt_slice, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_partial_key_slice",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7e493377f1a856eeb73c21aae1208537b26a4a29edb1afaa8ac89e4ffa29ef49",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_loc_slice_plus_null_slice": {
        "code": "class MultiIndexing:\n    def time_loc_slice_plus_null_slice(self, unique_levels):\n        target = (self.tgt_slice, self.tgt_null_slice)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_loc_slice_plus_null_slice",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e35e95d2686e9edb9c298e881d73f80b937d8cc77b9c363ce78a9e6f079157f9",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_xs_full_key": {
        "code": "class MultiIndexing:\n    def time_xs_full_key(self, unique_levels):\n        target = tuple([self.tgt_scalar] * self.nlevels)\n        self.df.xs(target)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_xs_full_key",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d9bbac09a6803b7e0d554f99cfbfa0517a1d7320e6a6af606bce52ec78fe89d5",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_xs_level_0": {
        "code": "class MultiIndexing:\n    def time_xs_level_0(self, unique_levels):\n        target = self.tgt_scalar\n        self.df.xs(target, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_xs_level_0",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "daaf4beb33874670dbba4df791aff72a906678fd1058938bc990e56cd7b733e3",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_xs_level_1": {
        "code": "class MultiIndexing:\n    def time_xs_level_1(self, unique_levels):\n        target = self.tgt_scalar\n        self.df.xs(target, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_xs_level_1",
        "number": 0,
        "param_names": [
            "unique_levels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "464f6f9822548adbb0a5afc6fd74b0fa4a5077d6215ac2a85daf48a6454b74b8",
        "warmup_time": -1
    },
    "indexing.NonNumericSeriesIndexing.time_getitem_label_slice": {
        "code": "class NonNumericSeriesIndexing:\n    def time_getitem_label_slice(self, index, index_structure):\n        self.s[: self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]",
        "min_run_count": 2,
        "name": "indexing.NonNumericSeriesIndexing.time_getitem_label_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "'string'",
                "'datetime'",
                "'period'"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b7149a98ec037ac1cf628a59eae2af60f74f9e88aa8a8184591977e3c6053734",
        "warmup_time": -1
    },
    "indexing.NonNumericSeriesIndexing.time_getitem_list_like": {
        "code": "class NonNumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.s[[self.lbl]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]",
        "min_run_count": 2,
        "name": "indexing.NonNumericSeriesIndexing.time_getitem_list_like",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "'string'",
                "'datetime'",
                "'period'"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6a98622cf697e3e9ee3a5279589dc8280e8ed223e48a847e90691ad95248b8fe",
        "warmup_time": -1
    },
    "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice": {
        "code": "class NonNumericSeriesIndexing:\n    def time_getitem_pos_slice(self, index, index_structure):\n        self.s[:80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]",
        "min_run_count": 2,
        "name": "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "'string'",
                "'datetime'",
                "'period'"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "06c57330892af61624a8f99c03e8af71fe978ac9049882d56369cf5f4b0ab7a7",
        "warmup_time": -1
    },
    "indexing.NonNumericSeriesIndexing.time_getitem_scalar": {
        "code": "class NonNumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.s[self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]",
        "min_run_count": 2,
        "name": "indexing.NonNumericSeriesIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "'string'",
                "'datetime'",
                "'period'"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9eff631ecc5e93c0bc45f0d7cfa28a9241c82461e4e1af909e9e0f1bcae15268",
        "warmup_time": -1
    },
    "indexing.NumericMaskedIndexing.time_get_indexer": {
        "code": "class NumericMaskedIndexing:\n    def time_get_indexer(self, dtype, monotonic):\n        self.data.get_indexer(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericMaskedIndexing:\n    def setup(self, dtype, monotonic):\n        indices = {\n            True: Index(self.monotonic_list, dtype=dtype),\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\n                Index([NA], dtype=dtype)\n            ),\n        }\n        self.data = indices[monotonic]\n        self.indexer = np.arange(300, 1_000)\n        self.data_dups = self.data.append(self.data)",
        "min_run_count": 2,
        "name": "indexing.NumericMaskedIndexing.time_get_indexer",
        "number": 0,
        "param_names": [
            "dtype",
            "monotonic"
        ],
        "params": [
            [
                "'Int64'",
                "'UInt64'",
                "'Float64'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c9f9a8ac9f8595fa973302687b629db6bf6b9924be4c3431f56d1b61c68570d2",
        "warmup_time": -1
    },
    "indexing.NumericMaskedIndexing.time_get_indexer_dups": {
        "code": "class NumericMaskedIndexing:\n    def time_get_indexer_dups(self, dtype, monotonic):\n        self.data.get_indexer_for(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericMaskedIndexing:\n    def setup(self, dtype, monotonic):\n        indices = {\n            True: Index(self.monotonic_list, dtype=dtype),\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\n                Index([NA], dtype=dtype)\n            ),\n        }\n        self.data = indices[monotonic]\n        self.indexer = np.arange(300, 1_000)\n        self.data_dups = self.data.append(self.data)",
        "min_run_count": 2,
        "name": "indexing.NumericMaskedIndexing.time_get_indexer_dups",
        "number": 0,
        "param_names": [
            "dtype",
            "monotonic"
        ],
        "params": [
            [
                "'Int64'",
                "'UInt64'",
                "'Float64'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "650c0af5a8f5231315bb45ae613c0b6e4fe1a990510b7c6ef5cb41e20818e616",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_array": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_array(self, index, index_structure):\n        self.data[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_array",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f8dbc1486bd95bff70285ace102a5d9ae45c39e61501c81985e19c24fef1d788",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_list_like": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.data[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_list_like",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "767f017c9055f888f75b6eed2e15a080b0b64319d1095620556c015c88fa110d",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_lists": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_lists(self, index, index_structure):\n        self.data[self.array_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_lists",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "443e55142dfd34591a735feb3d4d744e6958acb9018b753424bb95601e47a666",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_scalar": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.data[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "73c063a362862485753efeb9a6fbc07336e18a6c35add26bec792086df47b674",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_slice": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_slice(self, index, index_structure):\n        self.data[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_slice",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "53dd251b95b13c6d4735cc1d1ad7f926e4ec0328748779a56fa1c63f4fa359a0",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_iloc_array": {
        "code": "class NumericSeriesIndexing:\n    def time_iloc_array(self, index, index_structure):\n        self.data.iloc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_iloc_array",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7ca4d36d48a371195da509750de2d5dbb5fe15f466c419bd88a3d832c7339921",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_iloc_list_like": {
        "code": "class NumericSeriesIndexing:\n    def time_iloc_list_like(self, index, index_structure):\n        self.data.iloc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_iloc_list_like",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e6eb0977e121dbf9c0f8fed57bba4cbd0712e219c303813a323edfbeb879ca5f",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_iloc_scalar": {
        "code": "class NumericSeriesIndexing:\n    def time_iloc_scalar(self, index, index_structure):\n        self.data.iloc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_iloc_scalar",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d5a3df9b91de4f27357390975b96e77f6fe4ed9eced3a16044211134bc38617b",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_iloc_slice": {
        "code": "class NumericSeriesIndexing:\n    def time_iloc_slice(self, index, index_structure):\n        self.data.iloc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_iloc_slice",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6dd75593c3e3cf6040fc6b6152cae16559fec377ae607105dc5867d7257d6e6b",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_loc_array": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_array(self, index, index_structure):\n        self.data.loc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_loc_array",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3165bdce66ae50b67ee74bf5b720ddc68ab182ec7445bc812e1c0a6282bdf773",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_loc_list_like": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_list_like(self, index, index_structure):\n        self.data.loc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_loc_list_like",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9bd41a8e0e77f49c1815e6441bfed382f1642a7ffd8d470af8ae822095871ce7",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_loc_scalar": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_scalar(self, index, index_structure):\n        self.data.loc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_loc_scalar",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ca036299851e1902e2e167658690aabd8b3c4a23c4565717eaed87565bac7725",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_loc_slice": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, index_structure):\n        self.data.loc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_loc_slice",
        "number": 0,
        "param_names": [
            "dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float64'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7ec9524466f40bb446af6342c1220299a782e5c6c08e8a074782d963360ff732",
        "warmup_time": -1
    },
    "indexing.Setitem.time_setitem": {
        "code": "class Setitem:\n    def time_setitem(self):\n        self.df[100] = 100\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Setitem:\n    def setup(self):\n        N = 500_000\n        cols = 500\n        self.df = DataFrame(np.random.rand(N, cols))",
        "min_run_count": 2,
        "name": "indexing.Setitem.time_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "05f726f7641992ec4777d8bd735c1ae3ec9b5046bec013ae0c155fe1b3e37560",
        "warmup_time": -1
    },
    "indexing.Setitem.time_setitem_list": {
        "code": "class Setitem:\n    def time_setitem_list(self):\n        self.df[[100, 200, 300]] = 100\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Setitem:\n    def setup(self):\n        N = 500_000\n        cols = 500\n        self.df = DataFrame(np.random.rand(N, cols))",
        "min_run_count": 2,
        "name": "indexing.Setitem.time_setitem_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6ae63a2e6c513edbdfdf8c6e2acfeca129311e22230ada6b94c26bda50916b2b",
        "warmup_time": -1
    },
    "indexing.SetitemObjectDtype.time_setitem_object_dtype": {
        "code": "class SetitemObjectDtype:\n    def time_setitem_object_dtype(self):\n        self.df.loc[0, 1] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetitemObjectDtype:\n    def setup(self):\n        N = 1000\n        cols = 500\n        self.df = DataFrame(index=range(N), columns=range(cols), dtype=object)",
        "min_run_count": 2,
        "name": "indexing.SetitemObjectDtype.time_setitem_object_dtype",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8097d4d139957ec4def40f768092a69c123eb5734fd79de749c28d017fcf96d8",
        "warmup_time": -1
    },
    "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_sorted": {
        "code": "class SortedAndUnsortedDatetimeIndexLoc:\n    def time_loc_sorted(self):\n        self.df_sort.loc[\"2016-6-11\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortedAndUnsortedDatetimeIndexLoc:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        index = np.array(dti)\n    \n        unsorted_index = index.copy()\n        unsorted_index[10] = unsorted_index[20]\n    \n        self.df_unsorted = DataFrame(index=unsorted_index, data={\"a\": 1})\n        self.df_sort = DataFrame(index=index, data={\"a\": 1})",
        "min_run_count": 2,
        "name": "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_sorted",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0f65be8fdfcef229110b3366c9eeec8b227559f9db6dbbae3de7e915928496c4",
        "warmup_time": -1
    },
    "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_unsorted": {
        "code": "class SortedAndUnsortedDatetimeIndexLoc:\n    def time_loc_unsorted(self):\n        self.df_unsorted.loc[\"2016-6-11\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortedAndUnsortedDatetimeIndexLoc:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        index = np.array(dti)\n    \n        unsorted_index = index.copy()\n        unsorted_index[10] = unsorted_index[20]\n    \n        self.df_unsorted = DataFrame(index=unsorted_index, data={\"a\": 1})\n        self.df_sort = DataFrame(index=index, data={\"a\": 1})",
        "min_run_count": 2,
        "name": "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_unsorted",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7f7406b54217c050b92bb548cd77d9e99371a9102aed4a513cc83b2677d7dd3d",
        "warmup_time": -1
    },
    "indexing.Take.time_take": {
        "code": "class Take:\n    def time_take(self, index):\n        self.s.take(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": Index(np.arange(N), dtype=np.int64),\n            \"datetime\": date_range(\"2011-01-01\", freq=\"s\", periods=N),\n        }\n        index = indexes[index]\n        self.s = Series(np.random.rand(N), index=index)\n        self.indexer = np.random.randint(0, N, size=N)",
        "min_run_count": 2,
        "name": "indexing.Take.time_take",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "aaab1dd97f72161e6764c891742376656b295e9c0af44239f220454e583034c4",
        "warmup_time": -1
    },
    "indexing_engines.MaskedNumericEngineIndexing.time_get_loc": {
        "code": "class MaskedNumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n        dtype = dtype.lower()\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.zeros(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n    \n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n            mask[-1] = True\n    \n        self.data = engine(BaseMaskedArray(arr, mask))\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]",
        "min_run_count": 2,
        "name": "indexing_engines.MaskedNumericEngineIndexing.time_get_loc",
        "number": 0,
        "param_names": [
            "engine_and_dtype",
            "index_type",
            "unique",
            "N"
        ],
        "params": [
            [
                "(<class 'pandas._libs.index.MaskedInt64Engine'>, 'Int64')",
                "(<class 'pandas._libs.index.MaskedInt32Engine'>, 'Int32')",
                "(<class 'pandas._libs.index.MaskedInt16Engine'>, 'Int16')",
                "(<class 'pandas._libs.index.MaskedInt8Engine'>, 'Int8')",
                "(<class 'pandas._libs.index.MaskedUInt64Engine'>, 'UInt64')",
                "(<class 'pandas._libs.index.MaskedUInt32Engine'>, 'UInt32')",
                "(<class 'pandas._libs.index.MaskedUInt8Engine'>, 'UInt8')",
                "(<class 'pandas._libs.index.MaskedFloat64Engine'>, 'Float64')",
                "(<class 'pandas._libs.index.MaskedFloat32Engine'>, 'Float32')"
            ],
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ],
            [
                "True",
                "False"
            ],
            [
                "100000",
                "2000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7c394755b12d2c3e21c69c1654a1096049d5ff48d44e9fa5e68c13a5edd9a2de",
        "warmup_time": -1
    },
    "indexing_engines.MaskedNumericEngineIndexing.time_get_loc_near_middle": {
        "code": "class MaskedNumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n        dtype = dtype.lower()\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.zeros(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n    \n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n            mask[-1] = True\n    \n        self.data = engine(BaseMaskedArray(arr, mask))\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]",
        "min_run_count": 2,
        "name": "indexing_engines.MaskedNumericEngineIndexing.time_get_loc_near_middle",
        "number": 0,
        "param_names": [
            "engine_and_dtype",
            "index_type",
            "unique",
            "N"
        ],
        "params": [
            [
                "(<class 'pandas._libs.index.MaskedInt64Engine'>, 'Int64')",
                "(<class 'pandas._libs.index.MaskedInt32Engine'>, 'Int32')",
                "(<class 'pandas._libs.index.MaskedInt16Engine'>, 'Int16')",
                "(<class 'pandas._libs.index.MaskedInt8Engine'>, 'Int8')",
                "(<class 'pandas._libs.index.MaskedUInt64Engine'>, 'UInt64')",
                "(<class 'pandas._libs.index.MaskedUInt32Engine'>, 'UInt32')",
                "(<class 'pandas._libs.index.MaskedUInt8Engine'>, 'UInt8')",
                "(<class 'pandas._libs.index.MaskedFloat64Engine'>, 'Float64')",
                "(<class 'pandas._libs.index.MaskedFloat32Engine'>, 'Float32')"
            ],
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ],
            [
                "True",
                "False"
            ],
            [
                "100000",
                "2000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "33a4604e2edf65feda97d75cabe7a94bc517e629c63acaf5c3a788c199e7eff6",
        "warmup_time": -1
    },
    "indexing_engines.NumericEngineIndexing.time_get_loc": {
        "code": "class NumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n    \n        self.data = engine(arr)\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]",
        "min_run_count": 2,
        "name": "indexing_engines.NumericEngineIndexing.time_get_loc",
        "number": 0,
        "param_names": [
            "engine_and_dtype",
            "index_type",
            "unique",
            "N"
        ],
        "params": [
            [
                "(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)",
                "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)",
                "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)",
                "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)",
                "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)",
                "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)",
                "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)",
                "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)",
                "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"
            ],
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ],
            [
                "True",
                "False"
            ],
            [
                "100000",
                "2000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "65b3d11b3c6faf12c8e905404b7d91d9b5495adad1b0e3d7af303b94c66d754d",
        "warmup_time": -1
    },
    "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle": {
        "code": "class NumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n    \n        self.data = engine(arr)\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]",
        "min_run_count": 2,
        "name": "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle",
        "number": 0,
        "param_names": [
            "engine_and_dtype",
            "index_type",
            "unique",
            "N"
        ],
        "params": [
            [
                "(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)",
                "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)",
                "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)",
                "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)",
                "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)",
                "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)",
                "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)",
                "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)",
                "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"
            ],
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ],
            [
                "True",
                "False"
            ],
            [
                "100000",
                "2000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "beaa25ddfea801a7e7b25d2d14e6fa0d37145eb2280a06ed4fdc06bbf2b9dc37",
        "warmup_time": -1
    },
    "indexing_engines.ObjectEngineIndexing.time_get_loc": {
        "code": "class ObjectEngineIndexing:\n    def time_get_loc(self, index_type):\n        self.data.get_loc(\"b\")\n\n    def setup(self, index_type):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=object),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=object),\n            \"non_monotonic\": np.array(list(\"abc\") * N, dtype=object),\n        }[index_type]\n    \n        self.data = libindex.ObjectEngine(arr)\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(\"b\")",
        "min_run_count": 2,
        "name": "indexing_engines.ObjectEngineIndexing.time_get_loc",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d2f16137376532b74997179666987b5cf12d74dd819aeeae3a8b339bd1faf320",
        "warmup_time": -1
    },
    "inference.MaybeConvertNumeric.time_convert": {
        "code": "class MaybeConvertNumeric:\n    def time_convert(self, data):\n        lib.maybe_convert_numeric(data, set(), coerce_numeric=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertNumeric:\n    def setup_cache(self):\n        N = 10**6\n        arr = np.repeat([2**63], N) + np.arange(N).astype(\"uint64\")\n        data = arr.astype(object)\n        data[1::2] = arr[1::2].astype(str)\n        data[-1] = -1\n        return data",
        "min_run_count": 2,
        "name": "inference.MaybeConvertNumeric.time_convert",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "inference:80",
        "type": "time",
        "unit": "seconds",
        "version": "cf27dbc37431d8df629b71882573a765fb8244c558a5874dc6c8d279f80c581e",
        "warmup_time": -1
    },
    "inference.MaybeConvertObjects.time_maybe_convert_objects": {
        "code": "class MaybeConvertObjects:\n    def time_maybe_convert_objects(self):\n        lib.maybe_convert_objects(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertObjects:\n    def setup(self):\n        N = 10**5\n    \n        data = list(range(N))\n        data[0] = NaT\n        data = np.array(data)\n        self.data = data",
        "min_run_count": 2,
        "name": "inference.MaybeConvertObjects.time_maybe_convert_objects",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5e7742ec3e74701df6d7944b29f2a86f87a571e7c29cdd82373fbc1264620fcf",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_dup_seconds_and_unit": {
        "code": "class ToDatetimeCache:\n    def time_dup_seconds_and_unit(self, cache):\n        to_datetime(self.dup_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_dup_seconds_and_unit",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "115495d011e90c1e84334a047f0989bfb9edee09d9a3180f0c98d9d55a4f5d9e",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_dup_string_dates": {
        "code": "class ToDatetimeCache:\n    def time_dup_string_dates(self, cache):\n        to_datetime(self.dup_string_dates, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_dup_string_dates",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "98daac9ccb43e22cad7edf108a8f9ef3f7dfbf2eb8deb23ea7df594845b8af4c",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_dup_string_dates_and_format": {
        "code": "class ToDatetimeCache:\n    def time_dup_string_dates_and_format(self, cache):\n        to_datetime(self.dup_string_dates, format=\"%Y-%m-%d\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_dup_string_dates_and_format",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee70077e5420259875c0f2299f011187d7baaef6f1cdeb4826b8ef8b1552dbce",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_dup_string_tzoffset_dates": {
        "code": "class ToDatetimeCache:\n    def time_dup_string_tzoffset_dates(self, cache):\n        to_datetime(self.dup_string_with_tz, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_dup_string_tzoffset_dates",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9e31f01ac2515ecaf953530ced77a145692dd110a116641738e36e284fe36dd6",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_unique_seconds_and_unit": {
        "code": "class ToDatetimeCache:\n    def time_unique_seconds_and_unit(self, cache):\n        to_datetime(self.unique_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_unique_seconds_and_unit",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0cd72e287b8884f32a7696a5bae419aa06c002232f3f3e5644000bec0a231d7c",
        "warmup_time": -1
    },
    "inference.ToDatetimeCacheSmallCount.time_unique_date_strings": {
        "code": "class ToDatetimeCacheSmallCount:\n    def time_unique_date_strings(self, cache, count):\n        to_datetime(self.unique_date_strings, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCacheSmallCount:\n    def setup(self, cache, count):\n        rng = date_range(start=\"1/1/1971\", periods=count)\n        self.unique_date_strings = rng.strftime(\"%Y-%m-%d\").tolist()",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCacheSmallCount.time_unique_date_strings",
        "number": 0,
        "param_names": [
            "cache",
            "count"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "50",
                "500",
                "5000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a56323da170a0fe1ab82a8aa298f38bf720a11efd9c5e53816e754fbfa0d2c10",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_different_offset_to_utc": {
        "code": "class ToDatetimeFormat:\n    def time_different_offset_to_utc(self):\n        to_datetime(self.diff_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_different_offset_to_utc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1134fb9d2267ce314aafafd3994e3faf459b0ffb6f88a729c01ab4ea6bb44302",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_exact": {
        "code": "class ToDatetimeFormat:\n    def time_exact(self):\n        to_datetime(self.s2, format=\"%d%b%y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_exact",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "76d9d38bf86802c26b9548453bc209c70d50d02a2d30f7ae0469155f0576cb0a",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_no_exact": {
        "code": "class ToDatetimeFormat:\n    def time_no_exact(self):\n        to_datetime(self.s, format=\"%d%b%y\", exact=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_no_exact",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1cbd72079d4edb0010f0b4016b0fd8ef613e37fb9f6c47a4de28327121902b19",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_same_offset": {
        "code": "class ToDatetimeFormat:\n    def time_same_offset(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_same_offset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "081651f9c7ef04560ccff0b7e01f00e729a8f50007024b8be6ae5df6d8252682",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_same_offset_to_utc": {
        "code": "class ToDatetimeFormat:\n    def time_same_offset_to_utc(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_same_offset_to_utc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "19b041862541f6a61d1616096316f0f2de3452b56a3bf5c720c671b4f0bad85f",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormatQuarters.time_infer_quarter": {
        "code": "class ToDatetimeFormatQuarters:\n    def time_infer_quarter(self):\n        to_datetime(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormatQuarters:\n    def setup(self):\n        self.s = Series([\"2Q2005\", \"2Q05\", \"2005Q1\", \"05Q1\"] * 10000)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormatQuarters.time_infer_quarter",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "87bb6a74eb91c588ca3c6a25551ece61b8b7585eb61f04410973d650e0964120",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_nanosec_float64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_float64(self):\n        to_datetime(self.ts_nanosec_float, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_float64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2a6fbb3b51b828848e8d7f73b076d8fae1161c6e4d53f48a8c4524fb4bd1820e",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_nanosec_int64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_int64(self):\n        to_datetime(self.ts_nanosec, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_int64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8970f8a6a15aef3813dcea5bb9bf3a7c39853f92d88c59907ac2830fd16daef2",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_uint64(self):\n        to_datetime(self.ts_nanosec_uint, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "55b37560ce70ea683ab6134ede09ee43de470162b68416ec0ef8b0f469e90e97",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_sec_float64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_sec_float64(self):\n        to_datetime(self.ts_sec_float, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_sec_float64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "412960192629b47bdb51536bd1acc465c6644d94331ec0b060809f15f2270d21",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_sec_int64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_sec_int64(self):\n        to_datetime(self.ts_sec, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_sec_int64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "723bef42790ad2535ae6772086a189690bbc81c0dc720a9ae78f79b14541e1ed",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_sec_uint64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_sec_uint64(self):\n        to_datetime(self.ts_sec_uint, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_sec_uint64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ca17f492874efa6d87297d7a5eb649d9b0235ba934649a093f70ea48bc399454",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601(self):\n        to_datetime(self.strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c01e071dec3afc28fb8a6bcd6b0d157e5a0fb6281c3ae6da7ee509aa2dfe980a",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_format": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_format(self):\n        to_datetime(self.strings, format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_format",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bed05451c81f560e10f4add4bbd244599ac8758951990f8804a6c0e8ecde2f59",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_format_no_sep": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_format_no_sep(self):\n        to_datetime(self.strings_nosep, format=\"%Y%m%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_format_no_sep",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "97f94b8084cbb68f27ace40b4638b64544d81de4239a98b0ea7a5171624c9547",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_infer_zero_tz_fromat(self):\n        # GH 41047\n        to_datetime(self.strings_zero_tz)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "09c70549ea4de0f71bbbc97d084cd8ba946f2497635d0d05907a074e9e1c6c33",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_nosep": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_nosep(self):\n        to_datetime(self.strings_nosep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_nosep",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "30412f207bfd54b6590f2cdb46e9d487f1c49b618946150f4befc00b60adfa74",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_tz_spaceformat(self):\n        to_datetime(self.strings_tz_space)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4c99d43165a9bb12c372d05ec434c5809826524a4733adfa440a3308cc4d8325",
        "warmup_time": -1
    },
    "inference.ToDatetimeNONISO8601.time_different_offset": {
        "code": "class ToDatetimeNONISO8601:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset, utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half",
        "min_run_count": 2,
        "name": "inference.ToDatetimeNONISO8601.time_different_offset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c4d2dac26604bd44f4fbe5d20e10cfe4e33ee4e0caf00f554cd8ac8bd0b01544",
        "warmup_time": -1
    },
    "inference.ToDatetimeNONISO8601.time_same_offset": {
        "code": "class ToDatetimeNONISO8601:\n    def time_same_offset(self):\n        to_datetime(self.same_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half",
        "min_run_count": 2,
        "name": "inference.ToDatetimeNONISO8601.time_same_offset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f4cfe5cc89ed121e911be978f375ccb3976e7f6b8bc0e40ffd649e75abf676dc",
        "warmup_time": -1
    },
    "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD": {
        "code": "class ToDatetimeYYYYMMDD:\n    def time_format_YYYYMMDD(self):\n        to_datetime(self.stringsD, format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeYYYYMMDD:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=10000, freq=\"D\")\n        self.stringsD = Series(rng.strftime(\"%Y%m%d\"))",
        "min_run_count": 2,
        "name": "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1231af2c8acd673f7622a4a5cda34d3f69371a14c6d712e970653093e409349a",
        "warmup_time": -1
    },
    "inference.ToNumeric.time_from_float": {
        "code": "class ToNumeric:\n    def time_from_float(self):\n        to_numeric(self.float, errors=\"coerce\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))",
        "min_run_count": 2,
        "name": "inference.ToNumeric.time_from_float",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9d75d9dac86525757a5986d2c2dee84dba189d19de4e669b52b14d80836074ed",
        "warmup_time": -1
    },
    "inference.ToNumeric.time_from_numeric_str": {
        "code": "class ToNumeric:\n    def time_from_numeric_str(self):\n        to_numeric(self.numstr, errors=\"coerce\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))",
        "min_run_count": 2,
        "name": "inference.ToNumeric.time_from_numeric_str",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b0102b1d044bac37afcd31c72237a09f674c1507572f573689182f5a8741c57a",
        "warmup_time": -1
    },
    "inference.ToNumeric.time_from_str": {
        "code": "class ToNumeric:\n    def time_from_str(self):\n        to_numeric(self.str, errors=\"coerce\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))",
        "min_run_count": 2,
        "name": "inference.ToNumeric.time_from_str",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "94e2154cf6f33f78190c75601c38cc6b42e2c4147b864e5142b57a9b140c7165",
        "warmup_time": -1
    },
    "inference.ToNumericDowncast.time_downcast": {
        "code": "class ToNumericDowncast:\n    def time_downcast(self, dtype, downcast):\n        to_numeric(self.data, downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumericDowncast:\n    def setup(self, dtype, downcast):\n        self.data = self.data_dict[dtype]",
        "min_run_count": 2,
        "name": "inference.ToNumericDowncast.time_downcast",
        "number": 0,
        "param_names": [
            "dtype",
            "downcast"
        ],
        "params": [
            [
                "'string-float'",
                "'string-int'",
                "'string-nint'",
                "'datetime64'",
                "'int-list'",
                "'int32'"
            ],
            [
                "None",
                "'integer'",
                "'signed'",
                "'unsigned'",
                "'float'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0c056f48d7870e4188d6e5d83b2fae5d416f447632d4ee4e9e8c1ccec4b933bc",
        "warmup_time": -1
    },
    "inference.ToTimedelta.time_convert_int": {
        "code": "class ToTimedelta:\n    def time_convert_int(self):\n        to_timedelta(self.ints, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")",
        "min_run_count": 2,
        "name": "inference.ToTimedelta.time_convert_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e3d32b170c7865f14153be4d1dfe4cedbbfa407716af9b931a20cbf2be09aa76",
        "warmup_time": -1
    },
    "inference.ToTimedelta.time_convert_string_days": {
        "code": "class ToTimedelta:\n    def time_convert_string_days(self):\n        to_timedelta(self.str_days)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")",
        "min_run_count": 2,
        "name": "inference.ToTimedelta.time_convert_string_days",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b10b9c32557f6894a8d5cdad6099b33d92453d78580ed6ac9bce54eeda6ac731",
        "warmup_time": -1
    },
    "inference.ToTimedelta.time_convert_string_seconds": {
        "code": "class ToTimedelta:\n    def time_convert_string_seconds(self):\n        to_timedelta(self.str_seconds)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")",
        "min_run_count": 2,
        "name": "inference.ToTimedelta.time_convert_string_seconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ab0555d598557f0386f6743a49658aed686a61742a1a10086b99506a9dc533ba",
        "warmup_time": -1
    },
    "inference.ToTimedeltaErrors.time_convert": {
        "code": "class ToTimedeltaErrors:\n    def time_convert(self):\n        to_timedelta(self.arr, errors=\"coerce\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedeltaErrors:\n    def setup(self):\n        ints = np.random.randint(0, 60, size=10000)\n        self.arr = [f\"{i} days\" for i in ints]\n        self.arr[-1] = \"apple\"",
        "min_run_count": 2,
        "name": "inference.ToTimedeltaErrors.time_convert",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8939aa39071f3beefd6e45525ee345620bdf5dee832181f748ff4078ed239fe1",
        "warmup_time": -1
    },
    "io.csv.ParseDateComparison.time_read_csv_dayfirst": {
        "code": "class ParseDateComparison:\n    def time_read_csv_dayfirst(self, cache_dates):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                sep=\",\",\n                header=None,\n                names=[\"Date\"],\n                parse_dates=[\"Date\"],\n                cache_dates=cache_dates,\n                dayfirst=True,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ParseDateComparison.time_read_csv_dayfirst",
        "number": 0,
        "param_names": [
            "cache_dates"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b531fbcabfa9f50a40159c707fc3c7f6e7b08d581c7b1d7a345041defb16e66f",
        "warmup_time": -1
    },
    "io.csv.ParseDateComparison.time_to_datetime_dayfirst": {
        "code": "class ParseDateComparison:\n    def time_to_datetime_dayfirst(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ParseDateComparison.time_to_datetime_dayfirst",
        "number": 0,
        "param_names": [
            "cache_dates"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "50d96a36fe567c997d3c1a6fbd696fe9705f2ea698a08554aa84d41cd77fcd4d",
        "warmup_time": -1
    },
    "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY": {
        "code": "class ParseDateComparison:\n    def time_to_datetime_format_DD_MM_YYYY(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, format=\"%d-%m-%Y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY",
        "number": 0,
        "param_names": [
            "cache_dates"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "22583c40b98481bf789be587a51186ee7ff145dc4fb7e8e302872d06333449c9",
        "warmup_time": -1
    },
    "io.csv.ReadCSVCParserLowMemory.peakmem_over_2gb_input": {
        "code": "class ReadCSVCParserLowMemory:\n    def peakmem_over_2gb_input(self):\n        read_csv(self.csv, engine=\"c\", low_memory=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCParserLowMemory:\n    def setup(self):\n        self.csv = StringIO(\n            \"strings\\n\" + \"\\n\".join([\"x\" * (1 << 20) for _ in range(2100)])\n        )",
        "name": "io.csv.ReadCSVCParserLowMemory.peakmem_over_2gb_input",
        "param_names": [],
        "params": [],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "a48446a53498bc61ad769b708252358aea4b14b242699d3724820c38150f87ab"
    },
    "io.csv.ReadCSVCachedParseDates.time_read_csv_cached": {
        "code": "class ReadCSVCachedParseDates:\n    def time_read_csv_cached(self, do_cache, engine):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                engine=engine,\n                header=None,\n                parse_dates=[0],\n                cache_dates=do_cache,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCachedParseDates:\n    def setup(self, do_cache, engine):\n        data = (\"\\n\".join([f\"10/{year}\" for year in range(2000, 2100)]) + \"\\n\") * 10\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVCachedParseDates.time_read_csv_cached",
        "number": 0,
        "param_names": [
            "do_cache",
            "engine"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bd18017d7e35c75b5b8e7641eba13970add0683431db08d765c8d0c218e4a37d",
        "warmup_time": -1
    },
    "io.csv.ReadCSVCategorical.time_convert_direct": {
        "code": "class ReadCSVCategorical:\n    def time_convert_direct(self, engine):\n        read_csv(self.fname, engine=engine, dtype=\"category\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVCategorical.time_convert_direct",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b2e9577b100c6272d45c9326e6ae5cc423be2a61cded554dcded5c3f443ab3d3",
        "warmup_time": -1
    },
    "io.csv.ReadCSVCategorical.time_convert_post": {
        "code": "class ReadCSVCategorical:\n    def time_convert_post(self, engine):\n        read_csv(self.fname, engine=engine).apply(Categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVCategorical.time_convert_post",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b7f42a0fff0e3f819147a800861b2f3c3bfe6ed2893ab8f978bbc88396a2df45",
        "warmup_time": -1
    },
    "io.csv.ReadCSVComment.time_comment": {
        "code": "class ReadCSVComment:\n    def time_comment(self, engine):\n        read_csv(\n            self.data(self.StringIO_input), comment=\"#\", header=None, names=list(\"abc\")\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVComment:\n    def setup(self, engine):\n        data = [\"A,B,C\"] + ([\"1,2,3 # comment\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVComment.time_comment",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a90bbb38eb91ba9eeed032776bd52d7fd80b20ac0f6bc97853a821d08e98cf4b",
        "warmup_time": -1
    },
    "io.csv.ReadCSVConcatDatetime.time_read_csv": {
        "code": "class ReadCSVConcatDatetime:\n    def time_read_csv(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=50000, freq=\"s\")\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(self.iso8601).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVConcatDatetime.time_read_csv",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e9dddefec004c49888fad8124ac5f7f21e37497376bb8d3366b4c79d8aadebb6",
        "warmup_time": -1
    },
    "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv": {
        "code": "class ReadCSVConcatDatetimeBadDateValue:\n    def time_read_csv(self, bad_date_value):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\", \"bar\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetimeBadDateValue:\n    def setup(self, bad_date_value):\n        self.StringIO_input = StringIO((f\"{bad_date_value},\\n\") * 50000)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv",
        "number": 0,
        "param_names": [
            "bad_date_value"
        ],
        "params": [
            [
                "'nan'",
                "'0'",
                "''"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bbf5c349092a736709a8ab77f99aac07e8537b14babc5371d15b985c262ba233",
        "warmup_time": -1
    },
    "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv": {
        "code": "class ReadCSVDInferDatetimeFormat:\n    def time_read_csv(self, format):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDInferDatetimeFormat:\n    def setup(self, format):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        formats = {\n            None: None,\n            \"custom\": \"%m/%d/%Y %H:%M:%S.%f\",\n            \"iso8601\": \"%Y-%m-%d %H:%M:%S\",\n            \"ymd\": \"%Y%m%d\",\n        }\n        dt_format = formats[format]\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(dt_format).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv",
        "number": 0,
        "param_names": [
            "format"
        ],
        "params": [
            [
                "None",
                "'custom'",
                "'iso8601'",
                "'ymd'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "24fbc7cd7577a0d332b069a46fd6569ee2f6763c413b3881ae61d2f2076a8a2e",
        "warmup_time": -1
    },
    "io.csv.ReadCSVDatePyarrowEngine.time_read_csv_index_col": {
        "code": "class ReadCSVDatePyarrowEngine:\n    def time_read_csv_index_col(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            parse_dates=[\"a\"],\n            engine=\"pyarrow\",\n            dtype_backend=\"pyarrow\",\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDatePyarrowEngine:\n    def setup(self):\n        count_elem = 100_000\n        data = \"a\\n\" + \"2019-12-31\\n\" * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVDatePyarrowEngine.time_read_csv_index_col",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ab535d209bd4b1a968a990f24391747a6fe7684b99cbd8d3ed50c2ca9869b133",
        "warmup_time": -1
    },
    "io.csv.ReadCSVEngine.peakmem_read_csv": {
        "code": "class ReadCSVEngine:\n    def peakmem_read_csv(self, engine):\n        read_csv(self.data(self.BytesIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))",
        "name": "io.csv.ReadCSVEngine.peakmem_read_csv",
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'",
                "'pyarrow'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "85d9dcbcd51f8538733f7a37f3f653c6eafe85a442cd76faccd8832554af70c6"
    },
    "io.csv.ReadCSVEngine.time_read_bytescsv": {
        "code": "class ReadCSVEngine:\n    def time_read_bytescsv(self, engine):\n        read_csv(self.data(self.BytesIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVEngine.time_read_bytescsv",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'",
                "'pyarrow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c55db1629ca6d2b9c2cc35edb1684bf28f0a642354365378b739990b2beb3b36",
        "warmup_time": -1
    },
    "io.csv.ReadCSVEngine.time_read_stringcsv": {
        "code": "class ReadCSVEngine:\n    def time_read_stringcsv(self, engine):\n        read_csv(self.data(self.StringIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVEngine.time_read_stringcsv",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'",
                "'pyarrow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bcd2541e7d01564732b9ee7d1a6eb25bc0640eba5345d2109c242f2887344d0b",
        "warmup_time": -1
    },
    "io.csv.ReadCSVFloatPrecision.time_read_csv": {
        "code": "class ReadCSVFloatPrecision:\n    def time_read_csv(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            names=list(\"abc\"),\n            float_precision=float_precision,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}{{}}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVFloatPrecision.time_read_csv",
        "number": 0,
        "param_names": [
            "sep",
            "decimal",
            "float_precision"
        ],
        "params": [
            [
                "','",
                "';'"
            ],
            [
                "'.'",
                "'_'"
            ],
            [
                "None",
                "'high'",
                "'round_trip'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "663280822afc0347b49d14d5e3295794e4e85cd460cf06e6afe197b7a034a74d",
        "warmup_time": -1
    },
    "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine": {
        "code": "class ReadCSVFloatPrecision:\n    def time_read_csv_python_engine(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            engine=\"python\",\n            float_precision=None,\n            names=list(\"abc\"),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}{{}}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine",
        "number": 0,
        "param_names": [
            "sep",
            "decimal",
            "float_precision"
        ],
        "params": [
            [
                "','",
                "';'"
            ],
            [
                "'.'",
                "'_'"
            ],
            [
                "None",
                "'high'",
                "'round_trip'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8904e1f9bcabd952d3ac2b41f754258e2e24205b0106b3bde4ba9fe99d668d64",
        "warmup_time": -1
    },
    "io.csv.ReadCSVIndexCol.time_read_csv_index_col": {
        "code": "class ReadCSVIndexCol:\n    def time_read_csv_index_col(self):\n        read_csv(self.data(self.StringIO_input), index_col=\"a\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVIndexCol:\n    def setup(self):\n        count_elem = 100_000\n        data = \"a,b\\n\" + \"1,2\\n\" * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVIndexCol.time_read_csv_index_col",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3e032e9f81b1221965b2e243ded96c0c63c65763cd3a0f1cd55e498a0728243e",
        "warmup_time": -1
    },
    "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8": {
        "code": "class ReadCSVMemMapUTF8:\n    def time_read_memmapped_utf8(self):\n        read_csv(self.fname, header=None, memory_map=True, encoding=\"utf-8\", engine=\"c\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemMapUTF8:\n    def setup(self):\n        lines = []\n        line_length = 128\n        start_char = \" \"\n        end_char = \"\\U00010080\"\n        # This for loop creates a list of 128-char strings\n        # consisting of consecutive Unicode chars\n        for lnum in range(ord(start_char), ord(end_char), line_length):\n            line = \"\".join([chr(c) for c in range(lnum, lnum + 0x80)]) + \"\\n\"\n            try:\n                line.encode(\"utf-8\")\n            except UnicodeEncodeError:\n                # Some 16-bit words are not valid Unicode chars and must be skipped\n                continue\n            lines.append(line)\n        df = DataFrame(lines)\n        df = concat([df for n in range(100)], ignore_index=True)\n        df.to_csv(self.fname, index=False, header=False, encoding=\"utf-8\")",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8",
        "number": 5,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "28f7fd520f718e3d43c75304bfe758d8db2e0e48f9ecbcc93c96af3d09bb34c5",
        "warmup_time": -1
    },
    "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks": {
        "code": "class ReadCSVMemoryGrowth:\n    def mem_parser_chunks(self, engine):\n        # see gh-24805.\n        result = read_csv(self.fname, chunksize=self.chunksize, engine=engine)\n    \n        for _ in result:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemoryGrowth:\n    def setup(self, engine):\n        with open(self.fname, \"w\", encoding=\"utf-8\") as f:\n            for i in range(self.num_rows):\n                f.write(f\"{i}\\n\")",
        "name": "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks",
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "type": "memory",
        "unit": "bytes",
        "version": "387998c7983127f8fd0c8355a485887a7bbb6b50be4b44fb222cf04d96bd4298"
    },
    "io.csv.ReadCSVParseDates.time_baseline": {
        "code": "class ReadCSVParseDates:\n    def time_baseline(self, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            parse_dates=[1],\n            names=list(string.digits[:9]),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self, engine):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVParseDates.time_baseline",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "221a4700fd1f02faac09f891ec2ff4bf841f4f8838d4912b40bd070ce1747d0d",
        "warmup_time": -1
    },
    "io.csv.ReadCSVParseSpecialDate.time_read_special_date": {
        "code": "class ReadCSVParseSpecialDate:\n    def time_read_special_date(self, value, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            names=[\"Date\"],\n            parse_dates=[\"Date\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseSpecialDate:\n    def setup(self, value, engine):\n        count_elem = 10000\n        data = self.objects[value] * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVParseSpecialDate.time_read_special_date",
        "number": 0,
        "param_names": [
            "value",
            "engine"
        ],
        "params": [
            [
                "'mY'",
                "'mdY'",
                "'hm'"
            ],
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4adfa495cb5b837ceef161540601f8b0378f4433acbcd79ec36d1936f32b0276",
        "warmup_time": -1
    },
    "io.csv.ReadCSVSkipRows.time_skipprows": {
        "code": "class ReadCSVSkipRows:\n    def time_skipprows(self, skiprows, engine):\n        read_csv(self.fname, skiprows=skiprows, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVSkipRows:\n    def setup(self, skiprows, engine):\n        N = 20000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        df = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        df.to_csv(self.fname)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVSkipRows.time_skipprows",
        "number": 0,
        "param_names": [
            "skiprows",
            "engine"
        ],
        "params": [
            [
                "None",
                "10000"
            ],
            [
                "'c'",
                "'python'",
                "'pyarrow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fbe9957f14169d7708d3647b72449031d3ce2d6804cdb3dd942f15ce72a7fb63",
        "warmup_time": -1
    },
    "io.csv.ReadCSVThousands.time_thousands": {
        "code": "class ReadCSVThousands:\n    def time_thousands(self, sep, thousands, engine):\n        read_csv(self.fname, sep=sep, thousands=thousands, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVThousands:\n    def setup(self, sep, thousands, engine):\n        N = 10000\n        K = 8\n        data = np.random.randn(N, K) * np.random.randint(100, 10000, (N, K))\n        df = DataFrame(data)\n        if thousands is not None:\n            fmt = f\":{thousands}\"\n            fmt = \"{\" + fmt + \"}\"\n            df = df.map(lambda x: fmt.format(x))\n        df.to_csv(self.fname, sep=sep)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVThousands.time_thousands",
        "number": 0,
        "param_names": [
            "sep",
            "thousands",
            "engine"
        ],
        "params": [
            [
                "','",
                "'|'"
            ],
            [
                "None",
                "','"
            ],
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "28174298e72aa540f2c967d0ae4c27033f3635114bea61298cf59ac2e8364ef5",
        "warmup_time": -1
    },
    "io.csv.ReadUint64Integers.time_read_uint64": {
        "code": "class ReadUint64Integers:\n    def time_read_uint64(self):\n        read_csv(self.data(self.data1), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadUint64Integers.time_read_uint64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d4d93b300cdd080ede9b4b6103d9f29b7d9a87955c39dab1b41661f3b1836158",
        "warmup_time": -1
    },
    "io.csv.ReadUint64Integers.time_read_uint64_na_values": {
        "code": "class ReadUint64Integers:\n    def time_read_uint64_na_values(self):\n        read_csv(\n            self.data(self.data1), header=None, names=[\"foo\"], na_values=self.na_values\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadUint64Integers.time_read_uint64_na_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "36be6bf3e25ad59106e12794881da1b2cb92dfed243163b4c6802ee873fff567",
        "warmup_time": -1
    },
    "io.csv.ReadUint64Integers.time_read_uint64_neg_values": {
        "code": "class ReadUint64Integers:\n    def time_read_uint64_neg_values(self):\n        read_csv(self.data(self.data2), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadUint64Integers.time_read_uint64_neg_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2ff84e494ccdcd98ac1f99314c9865a5af568a2a806ace6dd69261d3ff23bd17",
        "warmup_time": -1
    },
    "io.csv.ToCSV.time_frame": {
        "code": "class ToCSV:\n    def time_frame(self, kind):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSV:\n    def setup(self, kind):\n        wide_frame = DataFrame(np.random.randn(3000, 30))\n        long_frame = DataFrame(\n            {\n                \"A\": np.arange(50000),\n                \"B\": np.arange(50000) + 1.0,\n                \"C\": np.arange(50000) + 2.0,\n                \"D\": np.arange(50000) + 3.0,\n            }\n        )\n        mixed_frame = DataFrame(\n            {\n                \"float\": np.random.randn(5000),\n                \"int\": np.random.randn(5000).astype(int),\n                \"bool\": (np.arange(5000) % 2) == 0,\n                \"datetime\": date_range(\"2001\", freq=\"s\", periods=5000),\n                \"object\": [\"foo\"] * 5000,\n            }\n        )\n        mixed_frame.loc[30:500, \"float\"] = np.nan\n        data = {\"wide\": wide_frame, \"long\": long_frame, \"mixed\": mixed_frame}\n        self.df = data[kind]",
        "min_run_count": 2,
        "name": "io.csv.ToCSV.time_frame",
        "number": 0,
        "param_names": [
            "kind"
        ],
        "params": [
            [
                "'wide'",
                "'long'",
                "'mixed'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b207acadf1f9b5992775d04050e8e1c95f5b672a69adc5ea1bb47fac8c558b49",
        "warmup_time": -1
    },
    "io.csv.ToCSVDatetime.time_frame_date_formatting": {
        "code": "class ToCSVDatetime:\n    def time_frame_date_formatting(self):\n        self.data.to_csv(self.fname, date_format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        self.data = DataFrame(rng, index=rng)",
        "min_run_count": 2,
        "name": "io.csv.ToCSVDatetime.time_frame_date_formatting",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "48aec9f413466587de05eec973105aa3ca66fba9830fc6165228f306cfa384d0",
        "warmup_time": -1
    },
    "io.csv.ToCSVDatetimeBig.time_frame": {
        "code": "class ToCSVDatetimeBig:\n    def time_frame(self, nobs):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeBig:\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "io.csv.ToCSVDatetimeBig.time_frame",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "fa395b3a3f41934aecbec3ec06ce6f479c37e6f98c7e1bae1bc958330e6dcfdb",
        "warmup_time": -1
    },
    "io.csv.ToCSVDatetimeIndex.time_frame_date_formatting_index": {
        "code": "class ToCSVDatetimeIndex:\n    def time_frame_date_formatting_index(self):\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeIndex:\n    def setup(self):\n        rng = date_range(\"2000\", periods=100_000, freq=\"s\")\n        self.data = DataFrame({\"a\": 1}, index=rng)",
        "min_run_count": 2,
        "name": "io.csv.ToCSVDatetimeIndex.time_frame_date_formatting_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "be53e0ea21b907c9caf3497a41461ca870f2b3189772b5c4ed6008a199faff36",
        "warmup_time": -1
    },
    "io.csv.ToCSVDatetimeIndex.time_frame_date_no_format_index": {
        "code": "class ToCSVDatetimeIndex:\n    def time_frame_date_no_format_index(self):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeIndex:\n    def setup(self):\n        rng = date_range(\"2000\", periods=100_000, freq=\"s\")\n        self.data = DataFrame({\"a\": 1}, index=rng)",
        "min_run_count": 2,
        "name": "io.csv.ToCSVDatetimeIndex.time_frame_date_no_format_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a29d8f3cec0c25a7cbfc00d1da20a757fd4c53994cb8622eb1ebfd0e0cb2d5ba",
        "warmup_time": -1
    },
    "io.csv.ToCSVIndexes.time_head_of_multiindex": {
        "code": "class ToCSVIndexes:\n    def time_head_of_multiindex(self):\n        self.df_custom_index_then_head.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )",
        "min_run_count": 2,
        "name": "io.csv.ToCSVIndexes.time_head_of_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b19bd98ca4e016f0e4a61cb075ab765fe428f49a7a406dd786bf37617833558c",
        "warmup_time": -1
    },
    "io.csv.ToCSVIndexes.time_multiindex": {
        "code": "class ToCSVIndexes:\n    def time_multiindex(self):\n        self.df_head_then_custom_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )",
        "min_run_count": 2,
        "name": "io.csv.ToCSVIndexes.time_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e6c356ab53559b97134b83598c7406d7849f7d72f0cd33999f3ed3a1388ae70b",
        "warmup_time": -1
    },
    "io.csv.ToCSVIndexes.time_standard_index": {
        "code": "class ToCSVIndexes:\n    def time_standard_index(self):\n        self.df_standard_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )",
        "min_run_count": 2,
        "name": "io.csv.ToCSVIndexes.time_standard_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4d8e112a392acdd1a4bdd4008abb8a96e5e23ac65da30366feda0363459f118b",
        "warmup_time": -1
    },
    "io.csv.ToCSVMultiIndexUnusedLevels.time_full_frame": {
        "code": "class ToCSVMultiIndexUnusedLevels:\n    def time_full_frame(self):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]",
        "min_run_count": 2,
        "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_full_frame",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "724d348ca5334e593a849378524d8ed762f78bff3cdf32b12389521b5d4296d6",
        "warmup_time": -1
    },
    "io.csv.ToCSVMultiIndexUnusedLevels.time_single_index_frame": {
        "code": "class ToCSVMultiIndexUnusedLevels:\n    def time_single_index_frame(self):\n        self.df_single_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]",
        "min_run_count": 2,
        "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_single_index_frame",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fddcb69899294d5fe6894ce1add6d4d9dd6b6c889218886482b796f7df3f0718",
        "warmup_time": -1
    },
    "io.csv.ToCSVMultiIndexUnusedLevels.time_sliced_frame": {
        "code": "class ToCSVMultiIndexUnusedLevels:\n    def time_sliced_frame(self):\n        self.df_unused_levels.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]",
        "min_run_count": 2,
        "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_sliced_frame",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c52b3c8ffc9d375d7d7fe89c76149484b884cdab2db3b786aa976b2a571dc669",
        "warmup_time": -1
    },
    "io.csv.ToCSVPeriod.time_frame_period_formatting": {
        "code": "class ToCSVPeriod:\n    def time_frame_period_formatting(self, nobs, freq):\n        # Nb: `date_format` is not actually taken into account here today, so the\n        # performance is currently identical to `time_frame_period_formatting_default`\n        # above. This timer is therefore expected to degrade when GH#51621 is fixed.\n        # (Remove this comment when GH#51621 is fixed.)\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d___%H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "io.csv.ToCSVPeriod.time_frame_period_formatting",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5170753217ef6733879fd3238ebf2cc66780345d552f0cd80797bc50fbfa8f9a",
        "warmup_time": -1
    },
    "io.csv.ToCSVPeriod.time_frame_period_formatting_default": {
        "code": "class ToCSVPeriod:\n    def time_frame_period_formatting_default(self, nobs, freq):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "io.csv.ToCSVPeriod.time_frame_period_formatting_default",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "97fe0df229e93c48eb91efabbb13c673ea37727315d159564845c312e2b6d0bb",
        "warmup_time": -1
    },
    "io.csv.ToCSVPeriod.time_frame_period_formatting_default_explicit": {
        "code": "class ToCSVPeriod:\n    def time_frame_period_formatting_default_explicit(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=self.default_fmt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "io.csv.ToCSVPeriod.time_frame_period_formatting_default_explicit",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "70a4e40c81c34918091a014201d45867a489c6949e7de705876a37f9a70981f7",
        "warmup_time": -1
    },
    "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index": {
        "code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d___%H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0331c31f8b48949b743fcd0aaae50203e37d79f16702b6c3e627c8c8f72d4a7d",
        "warmup_time": -1
    },
    "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default": {
        "code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index_default(self, nobs, freq):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "deb79b68a5a3d0c5dee09ca8f3e00032d4cdbe53e595d7a4633bae09e0998e4e",
        "warmup_time": -1
    },
    "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default_explicit": {
        "code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index_default_explicit(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=self.default_fmt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default_explicit",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "438b06aa750f7ccc6158ee25ad424220362457cc9ea8d2413071ae2a3570c671",
        "warmup_time": -1
    },
    "io.excel.ReadExcel.time_read_excel": {
        "code": "class ReadExcel:\n    def time_read_excel(self, engine):\n        if engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()",
        "min_run_count": 2,
        "name": "io.excel.ReadExcel.time_read_excel",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'openpyxl'",
                "'odf'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.excel:85",
        "type": "time",
        "unit": "seconds",
        "version": "5b4c727b29b6c7a2c1a6679ecdebdf57f4082a33d80b1b263e51a694d738c7f8",
        "warmup_time": -1
    },
    "io.excel.ReadExcelNRows.time_read_excel": {
        "code": "class ReadExcelNRows:\n    def time_read_excel(self, engine):\n        if engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine, nrows=10)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()",
        "min_run_count": 2,
        "name": "io.excel.ReadExcelNRows.time_read_excel",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'openpyxl'",
                "'odf'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.excel:85",
        "type": "time",
        "unit": "seconds",
        "version": "3e5f8dfb13ec7132e6defe6d8e37342d4d227165982cfc87986a70725225b237",
        "warmup_time": -1
    },
    "io.excel.WriteExcel.time_write_excel": {
        "code": "class WriteExcel:\n    def time_write_excel(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        with ExcelWriter(bio, engine=engine) as writer:\n            self.df.to_excel(writer, sheet_name=\"Sheet1\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcel:\n    def setup(self, engine):\n        self.df = _generate_dataframe()",
        "min_run_count": 2,
        "name": "io.excel.WriteExcel.time_write_excel",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'openpyxl'",
                "'xlsxwriter'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7578b2403493bd3778db1aadd2c8d24328372b68145f847a4e479265ddccd155",
        "warmup_time": -1
    },
    "io.excel.WriteExcelStyled.time_write_excel_style": {
        "code": "class WriteExcelStyled:\n    def time_write_excel_style(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        with ExcelWriter(bio, engine=engine) as writer:\n            df_style = self.df.style\n            df_style.map(lambda x: \"border: red 1px solid;\")\n            df_style.map(lambda x: \"color: blue\")\n            df_style.map(lambda x: \"border-color: green black\", subset=[\"float1\"])\n            df_style.to_excel(writer, sheet_name=\"Sheet1\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcelStyled:\n    def setup(self, engine):\n        self.df = _generate_dataframe()",
        "min_run_count": 2,
        "name": "io.excel.WriteExcelStyled.time_write_excel_style",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'openpyxl'",
                "'xlsxwriter'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "35f39ed22d0a5c540ef5e9f7b05a346a1e0d747b934181b07307d760f10dca5c",
        "warmup_time": -1
    },
    "io.hdf.HDF.peakmem_read_hdf": {
        "code": "class HDF:\n    def peakmem_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, key=\"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, key=\"df1\", format=format)",
        "name": "io.hdf.HDF.peakmem_read_hdf",
        "param_names": [
            "format"
        ],
        "params": [
            [
                "'table'",
                "'fixed'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "aaaba56d83f41d2e23cac92e27feaad11f59b9fa6d3f769aca477dde545c7932"
    },
    "io.hdf.HDF.time_read_hdf": {
        "code": "class HDF:\n    def time_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, key=\"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, key=\"df1\", format=format)",
        "min_run_count": 2,
        "name": "io.hdf.HDF.time_read_hdf",
        "number": 0,
        "param_names": [
            "format"
        ],
        "params": [
            [
                "'table'",
                "'fixed'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3e0703c9fab38fa828e5d37a9fb080d2e463bee144fc5317f25738e6bc003f7b",
        "warmup_time": -1
    },
    "io.hdf.HDF.time_write_hdf": {
        "code": "class HDF:\n    def time_write_hdf(self, format):\n        self.df.to_hdf(self.fname, key=\"df\", format=format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, key=\"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, key=\"df1\", format=format)",
        "min_run_count": 2,
        "name": "io.hdf.HDF.time_write_hdf",
        "number": 0,
        "param_names": [
            "format"
        ],
        "params": [
            [
                "'table'",
                "'fixed'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b081f5fb51c8d13a4691214bd0372806f6a9605fb3b5fbd69d0e571e8ae80444",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_query_store_table": {
        "code": "class HDFStoreDataFrame:\n    def time_query_store_table(self):\n        self.store.select(\"table\", where=\"index > self.start and index < self.stop\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_query_store_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "40b2068f3fa64a0e6a20da79476d70035884e866d3b4994f9da2e7828cd555c2",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_query_store_table_wide": {
        "code": "class HDFStoreDataFrame:\n    def time_query_store_table_wide(self):\n        self.store.select(\n            \"table_wide\", where=\"index > self.start_wide and index < self.stop_wide\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_query_store_table_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "205842891832cc3189d2d8c107fb32a32951b545c2567df596beea6814ece721",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store(self):\n        self.store.get(\"fixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b81c7b37b744fb0fe641d2b6d817db00b609a32efd08df6d7d7071fdae8ba8a0",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store_mixed": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store_mixed(self):\n        self.store.get(\"fixed_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "80585e918467a2bc34f9d22dfec4aea16e3ca27199eb3eada198f0a8d01db954",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store_table": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store_table(self):\n        self.store.select(\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a0b2d2c3b5db0383751a7133216ac82e5c8e2f2460d14a9743250eeca3476216",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store_table_mixed(self):\n        self.store.select(\"table_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "654b809e344f0e10c8a3baac21f45bab7ad0ee525970e4f37cc667bf431c09a9",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store_table_wide": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store_table_wide(self):\n        self.store.select(\"table_wide\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "68e77ec6a80f61239b61938e5edcde665dcb40aabeecd31c67093d3e89dc0224",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_store_info": {
        "code": "class HDFStoreDataFrame:\n    def time_store_info(self):\n        self.store.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_store_info",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "49715b28d77dba64c85fec14ce3fe1d467fb262c9f60bdb37036c71df679a8dc",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_store_repr": {
        "code": "class HDFStoreDataFrame:\n    def time_store_repr(self):\n        repr(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_store_repr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "56bf271ad7094e3cd93786522fded365bab13a2eb8463232c31dd7d346f35024",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_store_str": {
        "code": "class HDFStoreDataFrame:\n    def time_store_str(self):\n        str(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_store_str",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d579449dfe09044c2900a1f5cbeaf78ea5bbedab0e10f8949912bc68b36591f0",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store(self):\n        self.store.put(\"fixed_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee8346e909168ac76078a6746c4bb841bbd325a8e9a633a593ba4e3be629591b",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_mixed": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_mixed(self):\n        self.store.put(\"fixed_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d9a86e316a21f2f06f6a5510d44c49901d77f3ff3e328dc05884b09657635842",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_table": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_table(self):\n        self.store.append(\"table_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d47058fa561771efea619eea183eab7a6d5b7802df94c96d7e940bb000111118",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_table_dc": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_table_dc(self):\n        self.store.append(\"table_dc_write\", self.df_dc, data_columns=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_dc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3835d70e0f39619d661465373c95f90fdcb126a771138196ed2761ef7b7a8bcd",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_table_mixed(self):\n        self.store.append(\"table_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cfc399c3925c502380baf60452f942cc9fccdc9f9fe9a3d13c6bc9f9bc06b710",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_table_wide": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_table_wide(self):\n        self.store.append(\"table_wide_write\", self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d4ab189fff466312714744b38e13c09f0a3eb767a53878d0309b322701e5ab04",
        "warmup_time": -1
    },
    "io.json.NormalizeJSON.time_normalize_json": {
        "code": "class NormalizeJSON:\n    def time_normalize_json(self, orient, frame):\n        json_normalize(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NormalizeJSON:\n    def setup(self, orient, frame):\n        data = {\n            \"hello\": [\"thisisatest\", 999898, \"mixed types\"],\n            \"nest1\": {\"nest2\": {\"nest3\": \"nest3_value\", \"nest3_int\": 3445}},\n            \"nest1_list\": {\"nest2\": [\"blah\", 32423, 546456.876, 92030234]},\n            \"hello2\": \"string\",\n        }\n        self.data = [data for i in range(10000)]",
        "min_run_count": 2,
        "name": "io.json.NormalizeJSON.time_normalize_json",
        "number": 0,
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "318fc7d7f7bff26fc7a49a190be4dc0e2690469149e9fda19e3a8074d89cde6c",
        "warmup_time": -1
    },
    "io.json.ReadJSON.time_read_json": {
        "code": "class ReadJSON:\n    def time_read_json(self, orient, index):\n        read_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSON:\n    def setup(self, orient, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=orient)",
        "min_run_count": 2,
        "name": "io.json.ReadJSON.time_read_json",
        "number": 0,
        "param_names": [
            "orient",
            "index"
        ],
        "params": [
            [
                "'split'",
                "'index'",
                "'records'"
            ],
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "060ff02601813d99dcb85d35f2248cc6d5ee446b65bd53e44b8047fbff44c093",
        "warmup_time": -1
    },
    "io.json.ReadJSONLines.peakmem_read_json_lines": {
        "code": "class ReadJSONLines:\n    def peakmem_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "name": "io.json.ReadJSONLines.peakmem_read_json_lines",
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "453a39b717c84b10924b6c7381d2d4ac3ca4b6b34daf8038481adc4c63b37684"
    },
    "io.json.ReadJSONLines.peakmem_read_json_lines_concat": {
        "code": "class ReadJSONLines:\n    def peakmem_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "name": "io.json.ReadJSONLines.peakmem_read_json_lines_concat",
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "8ae93d7aa059d6ca9dbd26187d6b3782176449620b47b2e321dd8f4d891393f3"
    },
    "io.json.ReadJSONLines.peakmem_read_json_lines_nrows": {
        "code": "class ReadJSONLines:\n    def peakmem_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=15000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "name": "io.json.ReadJSONLines.peakmem_read_json_lines_nrows",
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "ac250f3377bcd575593ac2b371b4c45a47c3ba22cf6904c83289edccf77211ae"
    },
    "io.json.ReadJSONLines.time_read_json_lines": {
        "code": "class ReadJSONLines:\n    def time_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "min_run_count": 2,
        "name": "io.json.ReadJSONLines.time_read_json_lines",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "279f192d538915c094d4ea8ba8b0fd1ef396291dafe6751c31424148be445ad6",
        "warmup_time": -1
    },
    "io.json.ReadJSONLines.time_read_json_lines_concat": {
        "code": "class ReadJSONLines:\n    def time_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "min_run_count": 2,
        "name": "io.json.ReadJSONLines.time_read_json_lines_concat",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "777bcd588c46f7ee722bd31443ac6db78bd8e01de64a0d7e4a09b0f778b1319f",
        "warmup_time": -1
    },
    "io.json.ReadJSONLines.time_read_json_lines_nrows": {
        "code": "class ReadJSONLines:\n    def time_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=25000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "min_run_count": 2,
        "name": "io.json.ReadJSONLines.time_read_json_lines_nrows",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7f3ac492e006023c74a0a50408cf85b315c2115bbd11ea92acc78c6cc2af2385",
        "warmup_time": -1
    },
    "io.json.ToJSON.peakmem_to_json": {
        "code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "name": "io.json.ToJSON.peakmem_to_json",
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "87eb3ebd846df1b3f04989da149647f27085e365975bb82ce1a093db9bac8f5b"
    },
    "io.json.ToJSON.time_to_json": {
        "code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSON.time_to_json",
        "number": 0,
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9c17efa9080b8d5102c0beaef576f498ed86d1fe6e4fba86df65a39335f72728",
        "warmup_time": -1
    },
    "io.json.ToJSONISO.time_iso_format": {
        "code": "class ToJSONISO:\n    def time_iso_format(self, orient):\n        self.df.to_json(orient=orient, date_format=\"iso\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONISO:\n    def setup(self, orient):\n        N = 10**5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        self.df = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONISO.time_iso_format",
        "number": 0,
        "param_names": [
            "orient"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "de31091c8c9695232ad7a580672fe1150d42e0e74f06119dbe4a85b76c1e6c4a",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_delta_int_tstamp_lines": {
        "code": "class ToJSONLines:\n    def time_delta_int_tstamp_lines(self):\n        self.df_td_int_ts.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_delta_int_tstamp_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7a68f6c940cbfe5b7a9d9027dbcf1d2f2156232603726e0c67f7c89c756638fa",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_float_int_lines": {
        "code": "class ToJSONLines:\n    def time_float_int_lines(self):\n        self.df_int_floats.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_float_int_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e13146fb82a5dad2ab3bd80cf8af40ebd2cd8d8cbae32a4d4ec10a5dfe13d0ec",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_float_int_str_lines": {
        "code": "class ToJSONLines:\n    def time_float_int_str_lines(self):\n        self.df_int_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_float_int_str_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1517c8c4bbfff332b785506b826f50dcfad142f899a967b7afafdc636cd64789",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_float_longint_str_lines": {
        "code": "class ToJSONLines:\n    def time_float_longint_str_lines(self):\n        self.df_longint_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_float_longint_str_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5a0cc00815b32129927ef8c2875f9c5597779d59ef8b197ab9020ad5aea6df17",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_floats_with_dt_index_lines": {
        "code": "class ToJSONLines:\n    def time_floats_with_dt_index_lines(self):\n        self.df_date_idx.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_floats_with_dt_index_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2414d07086e041907667e8b1ba53fa8258be5e0ae02f44cba6c71675e8e82d90",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_floats_with_int_idex_lines": {
        "code": "class ToJSONLines:\n    def time_floats_with_int_idex_lines(self):\n        self.df.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_floats_with_int_idex_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1a872bf1a0dbe4c6dacf8368bd57159ad9f6e13729f234362d97480564486430",
        "warmup_time": -1
    },
    "io.json.ToJSONMem.peakmem_float": {
        "code": "class ToJSONMem:\n    def peakmem_float(self, frames):\n        df = frames[\"float\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames",
        "name": "io.json.ToJSONMem.peakmem_float",
        "param_names": [],
        "params": [],
        "setup_cache_key": "io.json:289",
        "type": "peakmemory",
        "unit": "bytes",
        "version": "00ee9841b98283beeb453d7dfd4cd72008d10a2028768798140f0ad54c56b581"
    },
    "io.json.ToJSONMem.peakmem_int": {
        "code": "class ToJSONMem:\n    def peakmem_int(self, frames):\n        df = frames[\"int\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames",
        "name": "io.json.ToJSONMem.peakmem_int",
        "param_names": [],
        "params": [],
        "setup_cache_key": "io.json:289",
        "type": "peakmemory",
        "unit": "bytes",
        "version": "a0f0fbfe022c1f66c3bb2fb28d8e1a6ecea8488a0a4252439e9a1cb94f397c3e"
    },
    "io.json.ToJSONMem.peakmem_time": {
        "code": "class ToJSONMem:\n    def peakmem_time(self, frames):\n        df = frames[\"datetime\"]\n        for _ in range(10_000):\n            df.to_json(orient=\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames",
        "name": "io.json.ToJSONMem.peakmem_time",
        "param_names": [],
        "params": [],
        "setup_cache_key": "io.json:289",
        "type": "peakmemory",
        "unit": "bytes",
        "version": "2260dc5c098f332173c0b87ea1e18f2c50b70b762d04871af1f0c6186d9cfb2f"
    },
    "io.json.ToJSONWide.peakmem_to_json": {
        "code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide",
        "name": "io.json.ToJSONWide.peakmem_to_json",
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f179e468594888d4ad11b82d624fc4c3925d4831054986c7642b6a7938e395d8"
    },
    "io.json.ToJSONWide.peakmem_to_json_wide": {
        "code": "class ToJSONWide:\n    def peakmem_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide",
        "name": "io.json.ToJSONWide.peakmem_to_json_wide",
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "350c040ee03cb09b3b2af80aacdb6f89f0b64fb12027e7abfcecf1754316da0d"
    },
    "io.json.ToJSONWide.time_to_json": {
        "code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide",
        "min_run_count": 2,
        "name": "io.json.ToJSONWide.time_to_json",
        "number": 0,
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3efe5275ae2f37aaa5320e63422ce5b375719e691728af347d4018c67aef213a",
        "warmup_time": -1
    },
    "io.json.ToJSONWide.time_to_json_wide": {
        "code": "class ToJSONWide:\n    def time_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide",
        "min_run_count": 2,
        "name": "io.json.ToJSONWide.time_to_json_wide",
        "number": 0,
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "aae5665173eb24e14595380fcf07cfeeab21783b5862479ee4e358e042ba6c38",
        "warmup_time": -1
    },
    "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes": {
        "code": "class DoesStringLookLikeDatetime:\n    def time_check_datetimes(self, value):\n        for obj in self.objects:\n            _does_string_look_like_datetime(obj)\n\n    def setup(self, value):\n        self.objects = [value] * 1000000",
        "min_run_count": 2,
        "name": "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes",
        "number": 0,
        "param_names": [
            "value"
        ],
        "params": [
            [
                "'2Q2005'",
                "'0.0'",
                "'10000'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a023015f4dc4ff2fbfce3252f6fd4b6c28970e462a5e405f7c2febd9b2256de7",
        "warmup_time": -1
    },
    "io.pickle.Pickle.peakmem_read_pickle": {
        "code": "class Pickle:\n    def peakmem_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)",
        "name": "io.pickle.Pickle.peakmem_read_pickle",
        "param_names": [],
        "params": [],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "4f88c24f38210faf3621a5f3c8a3f69477ec21a24d2ddc6be2c8470c01aa40e3"
    },
    "io.pickle.Pickle.peakmem_write_pickle": {
        "code": "class Pickle:\n    def peakmem_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)",
        "name": "io.pickle.Pickle.peakmem_write_pickle",
        "param_names": [],
        "params": [],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "d6e455195b782b35e91ceac2d611911bb32493f8c4d4487fc4c4e31f0f4e0ceb"
    },
    "io.pickle.Pickle.time_read_pickle": {
        "code": "class Pickle:\n    def time_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)",
        "min_run_count": 2,
        "name": "io.pickle.Pickle.time_read_pickle",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b91906f3a4f0e0fc6d0e7c75087708710c17306f6261154037cce4d579f9a168",
        "warmup_time": -1
    },
    "io.pickle.Pickle.time_write_pickle": {
        "code": "class Pickle:\n    def time_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)",
        "min_run_count": 2,
        "name": "io.pickle.Pickle.time_write_pickle",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "197a465e7ef1ae675a5470d939c4e2ce2d4f98b1f7d774e82a579024a5626166",
        "warmup_time": -1
    },
    "io.sas.SAS.time_read_sas7bdat": {
        "code": "class SAS:\n    def time_read_sas7bdat(self):\n        read_sas(ROOT / \"test1.sas7bdat\")",
        "min_run_count": 2,
        "name": "io.sas.SAS.time_read_sas7bdat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "90750b4b8570b3ae59cde41f15ee1b854b9ab5ce81313090b40ed33623373ac0",
        "warmup_time": -1
    },
    "io.sas.SAS.time_read_sas7bdat_2": {
        "code": "class SAS:\n    def time_read_sas7bdat_2(self):\n        next(read_sas(ROOT / \"0x00controlbyte.sas7bdat.bz2\", chunksize=11000))",
        "min_run_count": 2,
        "name": "io.sas.SAS.time_read_sas7bdat_2",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6634a822c4810085a951c2a037c4c61eeb579b792626fe9e9258ee6c42746e28",
        "warmup_time": -1
    },
    "io.sas.SAS.time_read_sas7bdat_2_chunked": {
        "code": "class SAS:\n    def time_read_sas7bdat_2_chunked(self):\n        for i, _ in enumerate(\n            read_sas(ROOT / \"0x00controlbyte.sas7bdat.bz2\", chunksize=1000)\n        ):\n            if i == 10:\n                break",
        "min_run_count": 2,
        "name": "io.sas.SAS.time_read_sas7bdat_2_chunked",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d10bf08f751bef710fda95bf4064e7efe3c337d520294711968c04867570b2e1",
        "warmup_time": -1
    },
    "io.sas.SAS.time_read_xpt": {
        "code": "class SAS:\n    def time_read_xpt(self):\n        read_sas(ROOT / \"paxraw_d_short.xpt\")",
        "min_run_count": 2,
        "name": "io.sas.SAS.time_read_xpt",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e400235073dafa325dfdd6e6eda51419eff1337191b1178a5f5ab43af9d3bb9a",
        "warmup_time": -1
    },
    "io.sql.ReadSQLTable.time_read_sql_table_all": {
        "code": "class ReadSQLTable:\n    def time_read_sql_table_all(self):\n        read_sql_table(self.table_name, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.ReadSQLTable.time_read_sql_table_all",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8805189ad353a53259e1140e68baa586a0df8cd9d72c69b5a8cb9423e2338323",
        "warmup_time": -1
    },
    "io.sql.ReadSQLTable.time_read_sql_table_parse_dates": {
        "code": "class ReadSQLTable:\n    def time_read_sql_table_parse_dates(self):\n        read_sql_table(\n            self.table_name,\n            self.con,\n            columns=[\"datetime_string\"],\n            parse_dates=[\"datetime_string\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.ReadSQLTable.time_read_sql_table_parse_dates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "dd4c0ad3318162e5578f5184117e902602f575122eb690a13703523fafe2ebd4",
        "warmup_time": -1
    },
    "io.sql.ReadSQLTableDtypes.time_read_sql_table_column": {
        "code": "class ReadSQLTableDtypes:\n    def time_read_sql_table_column(self, dtype):\n        read_sql_table(self.table_name, self.con, columns=[dtype])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTableDtypes:\n    def setup(self, dtype):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.ReadSQLTableDtypes.time_read_sql_table_column",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'float_with_nan'",
                "'string'",
                "'bool'",
                "'int'",
                "'date'",
                "'time'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3715243646c52bd93b31afb5ade91a7fb8659472bee04546210dcbfc423b0e34",
        "warmup_time": -1
    },
    "io.sql.SQL.time_read_sql_query": {
        "code": "class SQL:\n    def time_read_sql_query(self, connection):\n        read_sql_query(self.query_all, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.SQL.time_read_sql_query",
        "number": 0,
        "param_names": [
            "connection"
        ],
        "params": [
            [
                "'sqlalchemy'",
                "'sqlite'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6e9c468300eee3818a1fdb1388194e0442416d67fe7b467ea3551de7b486cec8",
        "warmup_time": -1
    },
    "io.sql.SQL.time_to_sql_dataframe": {
        "code": "class SQL:\n    def time_to_sql_dataframe(self, connection):\n        self.df.to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.SQL.time_to_sql_dataframe",
        "number": 0,
        "param_names": [
            "connection"
        ],
        "params": [
            [
                "'sqlalchemy'",
                "'sqlite'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e83de9885c2f942c647a56d72031c18606ffbee73b7ee38d1dc227d2b1f69cda",
        "warmup_time": -1
    },
    "io.sql.WriteSQLDtypes.time_read_sql_query_select_column": {
        "code": "class WriteSQLDtypes:\n    def time_read_sql_query_select_column(self, connection, dtype):\n        read_sql_query(self.query_col, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.WriteSQLDtypes.time_read_sql_query_select_column",
        "number": 0,
        "param_names": [
            "connection",
            "dtype"
        ],
        "params": [
            [
                "'sqlalchemy'",
                "'sqlite'"
            ],
            [
                "'float'",
                "'float_with_nan'",
                "'string'",
                "'bool'",
                "'int'",
                "'date'",
                "'time'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6a6d2a3f39d33e0506f5c087cd7c7a253eaacac063a5aa53e54f846897e5c243",
        "warmup_time": -1
    },
    "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column": {
        "code": "class WriteSQLDtypes:\n    def time_to_sql_dataframe_column(self, connection, dtype):\n        self.df[[dtype]].to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column",
        "number": 0,
        "param_names": [
            "connection",
            "dtype"
        ],
        "params": [
            [
                "'sqlalchemy'",
                "'sqlite'"
            ],
            [
                "'float'",
                "'float_with_nan'",
                "'string'",
                "'bool'",
                "'int'",
                "'date'",
                "'time'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1ef8f5f1c2e6e522fda7b7be0b4b74a02379fca208bdedc44c04133a3168ee4d",
        "warmup_time": -1
    },
    "io.stata.Stata.time_read_stata": {
        "code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(self.N)], dtype=object)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)",
        "min_run_count": 2,
        "name": "io.stata.Stata.time_read_stata",
        "number": 0,
        "param_names": [
            "convert_dates"
        ],
        "params": [
            [
                "'tc'",
                "'td'",
                "'tm'",
                "'tw'",
                "'th'",
                "'tq'",
                "'ty'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "373dd72e429ef636629454da90e787c31ecff5cea8dd978c7f0a2d01b864b846",
        "warmup_time": -1
    },
    "io.stata.Stata.time_write_stata": {
        "code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(self.N)], dtype=object)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)",
        "min_run_count": 2,
        "name": "io.stata.Stata.time_write_stata",
        "number": 0,
        "param_names": [
            "convert_dates"
        ],
        "params": [
            [
                "'tc'",
                "'td'",
                "'tm'",
                "'tw'",
                "'th'",
                "'tq'",
                "'ty'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fecc2ef1a45be678d915bdc0d91dfe1927166b223d0f0fb6ff194407d6cdeb18",
        "warmup_time": -1
    },
    "io.stata.StataMissing.time_read_stata": {
        "code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)",
        "min_run_count": 2,
        "name": "io.stata.StataMissing.time_read_stata",
        "number": 0,
        "param_names": [
            "convert_dates"
        ],
        "params": [
            [
                "'tc'",
                "'td'",
                "'tm'",
                "'tw'",
                "'th'",
                "'tq'",
                "'ty'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b28404f018d5ce3e6f6e9f4f573bfc333203130ac26b6ad0a55ab363d4091d56",
        "warmup_time": -1
    },
    "io.stata.StataMissing.time_write_stata": {
        "code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)",
        "min_run_count": 2,
        "name": "io.stata.StataMissing.time_write_stata",
        "number": 0,
        "param_names": [
            "convert_dates"
        ],
        "params": [
            [
                "'tc'",
                "'td'",
                "'tm'",
                "'tw'",
                "'th'",
                "'tq'",
                "'ty'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "12dd8e544d5d5dc0ff5c73373ffa7a2338cc235fc3829df79060f21c721b21c1",
        "warmup_time": -1
    },
    "io.style.Render.peakmem_apply_format_hide_render": {
        "code": "class Render:\n    def peakmem_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_apply_format_hide_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "24efee29e9f4259b3dc32b50ebebd07120a2cc59672b5f07aaf694b3350ffc33"
    },
    "io.style.Render.peakmem_apply_render": {
        "code": "class Render:\n    def peakmem_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_apply_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f1291d9b0cee2ed29164614c2827a58907e0943d031efe0a1f700dd7bb3ea1ef"
    },
    "io.style.Render.peakmem_classes_render": {
        "code": "class Render:\n    def peakmem_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_classes_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "1d74d0ee63b8ddbcb67f37a2c6260ebe84c54ec1d2650db12d284630efa672c9"
    },
    "io.style.Render.peakmem_format_render": {
        "code": "class Render:\n    def peakmem_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_format_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "2d2ae2b598964ca4ec2ce6befed05ff0ed2c8833539c314cbc42c2a006d9abcf"
    },
    "io.style.Render.peakmem_tooltips_render": {
        "code": "class Render:\n    def peakmem_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_tooltips_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f3165d89bad8a5256ce768ec97faaca1dc322cc15dfc6cce5c8f629872c4b625"
    },
    "io.style.Render.time_apply_format_hide_render": {
        "code": "class Render:\n    def time_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_apply_format_hide_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4624b648242dbd72367816b07786b7bb20dec67fcf4d8b269046640a281b891b",
        "warmup_time": -1
    },
    "io.style.Render.time_apply_render": {
        "code": "class Render:\n    def time_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_apply_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b7713a928f5b63249a63e44399f6d18a893bff35ae8541e666af0885aec0a166",
        "warmup_time": -1
    },
    "io.style.Render.time_classes_render": {
        "code": "class Render:\n    def time_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_classes_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e385c7e77a27a0e29b3941e7cf3c0727f5f83d8b6279cd9500e63fb1f630d7d5",
        "warmup_time": -1
    },
    "io.style.Render.time_format_render": {
        "code": "class Render:\n    def time_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_format_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2fe7b97954d549aadb2eb134d3d09b8c1334a640488b36869090ed4c430365ed",
        "warmup_time": -1
    },
    "io.style.Render.time_tooltips_render": {
        "code": "class Render:\n    def time_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_tooltips_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bf6a27f9959b331a6f71cda4f842f4ceb8df92624979f2a522fe57cc98a5e34d",
        "warmup_time": -1
    },
    "join_merge.Align.time_series_align_int64_index": {
        "code": "class Align:\n    def time_series_align_int64_index(self):\n        self.ts1 + self.ts2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)",
        "min_run_count": 2,
        "name": "join_merge.Align.time_series_align_int64_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "59ba8b3aa681ebdec8f5b793e2c2d9f7edd0cc1306163877b74d2788ac7102c0",
        "warmup_time": -1
    },
    "join_merge.Align.time_series_align_left_monotonic": {
        "code": "class Align:\n    def time_series_align_left_monotonic(self):\n        self.ts1.align(self.ts2, join=\"left\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)",
        "min_run_count": 2,
        "name": "join_merge.Align.time_series_align_left_monotonic",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1c381483982c07fac3b6c437f2f740ae055cad4035d9a2bdf325a4acfe440e76",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_empty_left": {
        "code": "class Concat:\n    def time_concat_empty_left(self, axis):\n        concat(self.empty_left, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_empty_left",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c24f8d889c69b6fddab68477db7feb9bdd64d0bfc8a437af267480d6244476bc",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_empty_right": {
        "code": "class Concat:\n    def time_concat_empty_right(self, axis):\n        concat(self.empty_right, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_empty_right",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "50a67de8903652dc050970bc82dc1e728dd0803fb2d35b1eefd98d1b5771497b",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_mixed_ndims": {
        "code": "class Concat:\n    def time_concat_mixed_ndims(self, axis):\n        concat(self.mixed_ndims, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_mixed_ndims",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c9ed31fc560eb4af434e4a5f9c1c3f4661613c9c160b2335cbe6555ce327feac",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_series": {
        "code": "class Concat:\n    def time_concat_series(self, axis):\n        concat(self.series, axis=axis, sort=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_series",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bf170cabb255499f965da712f65e57cd5f3a050cf5c35d2069e104851dd6e5a0",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_small_frames": {
        "code": "class Concat:\n    def time_concat_small_frames(self, axis):\n        concat(self.small_frames, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_small_frames",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "470adfb2d6977cd7074d1f42533fea5a4d223b74619f161758021c6161815779",
        "warmup_time": -1
    },
    "join_merge.ConcatDataFrames.time_c_ordered": {
        "code": "class ConcatDataFrames:\n    def time_c_ordered(self, axis, ignore_index):\n        concat(self.frame_c, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20",
        "min_run_count": 2,
        "name": "join_merge.ConcatDataFrames.time_c_ordered",
        "number": 0,
        "param_names": [
            "axis",
            "ignore_index"
        ],
        "params": [
            [
                "0",
                "1"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a747cecacb0f57e2d282f77dbc9ba6108bb55d137dcb4cdef4d0cb94bd2ef909",
        "warmup_time": -1
    },
    "join_merge.ConcatDataFrames.time_f_ordered": {
        "code": "class ConcatDataFrames:\n    def time_f_ordered(self, axis, ignore_index):\n        concat(self.frame_f, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20",
        "min_run_count": 2,
        "name": "join_merge.ConcatDataFrames.time_f_ordered",
        "number": 0,
        "param_names": [
            "axis",
            "ignore_index"
        ],
        "params": [
            [
                "0",
                "1"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4ae3b6dda3a99cfd094de14c2550530e69a1ede87ff9911c02706ef1acf501eb",
        "warmup_time": -1
    },
    "join_merge.ConcatIndexDtype.time_concat_series": {
        "code": "class ConcatIndexDtype:\n    def time_concat_series(self, dtype, structure, axis, sort):\n        concat(self.series, axis=axis, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatIndexDtype:\n    def setup(self, dtype, structure, axis, sort):\n        N = 10_000\n        if dtype == \"datetime64[ns]\":\n            vals = date_range(\"1970-01-01\", periods=N)\n        elif dtype in (\"int64\", \"Int64\", \"int64[pyarrow]\"):\n            vals = np.arange(N, dtype=np.int64)\n        elif dtype in (\"string[python]\", \"string[pyarrow]\"):\n            vals = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        else:\n            raise NotImplementedError\n    \n        idx = Index(vals, dtype=dtype)\n    \n        if structure == \"monotonic\":\n            idx = idx.sort_values()\n        elif structure == \"non_monotonic\":\n            idx = idx[::-1]\n        elif structure == \"has_na\":\n            if not idx._can_hold_na:\n                raise NotImplementedError\n            idx = Index([None], dtype=dtype).append(idx)\n        else:\n            raise NotImplementedError\n    \n        self.series = [Series(i, idx[:-i]) for i in range(1, 6)]",
        "min_run_count": 2,
        "name": "join_merge.ConcatIndexDtype.time_concat_series",
        "number": 0,
        "param_names": [
            "dtype",
            "structure",
            "axis",
            "sort"
        ],
        "params": [
            [
                "'datetime64[ns]'",
                "'int64'",
                "'Int64'",
                "'int64[pyarrow]'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "'monotonic'",
                "'non_monotonic'",
                "'has_na'"
            ],
            [
                "0",
                "1"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3f0be47c3aec82696fed8b66f103fb17e1c8ade9f27aed2205614c881c60a48a",
        "warmup_time": -1
    },
    "join_merge.I8Merge.time_i8merge": {
        "code": "class I8Merge:\n    def time_i8merge(self, how):\n        merge(self.left, self.right, how=how)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass I8Merge:\n    def setup(self, how):\n        low, high, n = -1000, 1000, 10**6\n        self.left = DataFrame(\n            np.random.randint(low, high, (n, 7)), columns=list(\"ABCDEFG\")\n        )\n        self.left[\"left\"] = self.left.sum(axis=1)\n        self.right = self.left.sample(frac=1).rename({\"left\": \"right\"}, axis=1)\n        self.right = self.right.reset_index(drop=True)\n        self.right[\"right\"] *= -1",
        "min_run_count": 2,
        "name": "join_merge.I8Merge.time_i8merge",
        "number": 0,
        "param_names": [
            "how"
        ],
        "params": [
            [
                "'inner'",
                "'outer'",
                "'left'",
                "'right'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d4abb49d5f599a151d5e78dad2990f16fe5bf60710912a404da24856006a297a",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframe_index_multi": {
        "code": "class Join:\n    def time_join_dataframe_index_multi(self, sort):\n        self.df.join(self.df_multi, on=[\"key1\", \"key2\"], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframe_index_multi",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4333bf6cde7671e71926340c558300735ccf5294d204d4e0c4c81a51d019eb1c",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort": {
        "code": "class Join:\n    def time_join_dataframe_index_shuffle_key_bigger_sort(self, sort):\n        self.df_shuf.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c4db5e399d8b3f5fe10c825360367198fb61e0ea906c2842d56ec531c4cd5f97",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframe_index_single_key_bigger": {
        "code": "class Join:\n    def time_join_dataframe_index_single_key_bigger(self, sort):\n        self.df.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframe_index_single_key_bigger",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c91255828f8625e649458aaa81a177dd077c288fe7beb2a8349f154536f30000",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframe_index_single_key_small": {
        "code": "class Join:\n    def time_join_dataframe_index_single_key_small(self, sort):\n        self.df.join(self.df_key1, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframe_index_single_key_small",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "eec67ca32224c312bdba6f34b701b8fcea4192407ff25bca0a093889a2c86f01",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframes_cross": {
        "code": "class Join:\n    def time_join_dataframes_cross(self, sort):\n        self.df.loc[:2000].join(self.df_key1, how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframes_cross",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3a48d807904c7c932eb0f8012602129fcf2c528ffbf8a19bb5af2fa0084b6b29",
        "warmup_time": -1
    },
    "join_merge.JoinEmpty.time_inner_join_left_empty": {
        "code": "class JoinEmpty:\n    def time_inner_join_left_empty(self):\n        self.df_empty.join(self.df, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinEmpty:\n    def setup(self):\n        N = 100_000\n        self.df = DataFrame({\"A\": np.arange(N)})\n        self.df_empty = DataFrame(columns=[\"B\", \"C\"], dtype=\"int64\")",
        "min_run_count": 2,
        "name": "join_merge.JoinEmpty.time_inner_join_left_empty",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bfdd1b4564785774724d06a1078e1417803a55bc67f678a1cdd417a1aedc2f04",
        "warmup_time": -1
    },
    "join_merge.JoinEmpty.time_inner_join_right_empty": {
        "code": "class JoinEmpty:\n    def time_inner_join_right_empty(self):\n        self.df.join(self.df_empty, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinEmpty:\n    def setup(self):\n        N = 100_000\n        self.df = DataFrame({\"A\": np.arange(N)})\n        self.df_empty = DataFrame(columns=[\"B\", \"C\"], dtype=\"int64\")",
        "min_run_count": 2,
        "name": "join_merge.JoinEmpty.time_inner_join_right_empty",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "dcfe17741af364f20337e68e1210e4775f3da625571f7a163b7a94dd7ba6ab00",
        "warmup_time": -1
    },
    "join_merge.JoinIndex.time_left_outer_join_index": {
        "code": "class JoinIndex:\n    def time_left_outer_join_index(self):\n        self.left.join(self.right, on=\"jim\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinIndex:\n    def setup(self):\n        N = 5000\n        self.left = DataFrame(\n            np.random.randint(1, N / 50, (N, 2)), columns=[\"jim\", \"joe\"]\n        )\n        self.right = DataFrame(\n            np.random.randint(1, N / 50, (N, 2)), columns=[\"jolie\", \"jolia\"]\n        ).set_index(\"jolie\")",
        "min_run_count": 2,
        "name": "join_merge.JoinIndex.time_left_outer_join_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1745a459c7417d954ba2b1543c89580f2da4fae87754d704488eb8a230577907",
        "warmup_time": -1
    },
    "join_merge.JoinMultiindexSubset.time_join_multiindex_subset": {
        "code": "class JoinMultiindexSubset:\n    def time_join_multiindex_subset(self):\n        self.left.join(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinMultiindexSubset:\n    def setup(self):\n        N = 100_000\n        mi1 = MultiIndex.from_arrays([np.arange(N)] * 4, names=[\"a\", \"b\", \"c\", \"d\"])\n        mi2 = MultiIndex.from_arrays([np.arange(N)] * 2, names=[\"a\", \"b\"])\n        self.left = DataFrame({\"col1\": 1}, index=mi1)\n        self.right = DataFrame({\"col2\": 2}, index=mi2)",
        "min_run_count": 2,
        "name": "join_merge.JoinMultiindexSubset.time_join_multiindex_subset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "27bf46b67e61ae20d7d34733a62c67fd8dd46b37dcd0a578e046d57b6c6a5751",
        "warmup_time": -1
    },
    "join_merge.JoinNonUnique.time_join_non_unique_equal": {
        "code": "class JoinNonUnique:\n    def time_join_non_unique_equal(self):\n        self.fracofday * self.temp\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinNonUnique:\n    def setup(self):\n        date_index = date_range(\"01-Jan-2013\", \"23-Jan-2013\", freq=\"min\")\n        daily_dates = date_index.to_period(\"D\").to_timestamp(\"s\", \"s\")\n        self.fracofday = date_index.values - daily_dates.values\n        self.fracofday = self.fracofday.astype(\"timedelta64[ns]\")\n        self.fracofday = self.fracofday.astype(np.float64) / 86_400_000_000_000\n        self.fracofday = Series(self.fracofday, daily_dates)\n        index = date_range(date_index.min(), date_index.max(), freq=\"D\")\n        self.temp = Series(1.0, index)[self.fracofday.index]",
        "min_run_count": 2,
        "name": "join_merge.JoinNonUnique.time_join_non_unique_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0e34c149af187b7f4eaa9c905928f5605dabce492f1114f9878a83fcfa4be311",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_2intkey": {
        "code": "class Merge:\n    def time_merge_2intkey(self, sort):\n        merge(self.left, self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_2intkey",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "02c985ca0f91e858a760146877c62a3ce45e8e49ad16d9cf150e01a8e45d60f8",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_dataframe_empty_left": {
        "code": "class Merge:\n    def time_merge_dataframe_empty_left(self, sort):\n        merge(self.left.iloc[:0], self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_dataframe_empty_left",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5385d6eda16a400f6398618dc87406e053b44c3237148b4a88ee3af3bd997e7e",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_dataframe_empty_right": {
        "code": "class Merge:\n    def time_merge_dataframe_empty_right(self, sort):\n        merge(self.left, self.right.iloc[:0], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_dataframe_empty_right",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1c458073428462f9afadf4c68a397a523995779eb31f4ba9dfa01d7b1c86853d",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_dataframe_integer_2key": {
        "code": "class Merge:\n    def time_merge_dataframe_integer_2key(self, sort):\n        merge(self.df, self.df3, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_dataframe_integer_2key",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "82965bb5c88367b7ca51c2841a96d09f5e13ef409582a2df03886b979a391141",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_dataframe_integer_key": {
        "code": "class Merge:\n    def time_merge_dataframe_integer_key(self, sort):\n        merge(self.df, self.df2, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_dataframe_integer_key",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2de11a2e31283d7107f028ba38e3768119a8b6727421ad035d81d7523bc31df5",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_dataframes_cross": {
        "code": "class Merge:\n    def time_merge_dataframes_cross(self, sort):\n        merge(self.left.loc[:2000], self.right.loc[:2000], how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_dataframes_cross",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "16ca5aa7ee0537da110abb59b4c2c6890937b10500617006e027f576afa9bf99",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_by_int": {
        "code": "class MergeAsof:\n    def time_by_int(self, direction, tolerance):\n        merge_asof(\n            self.df1c,\n            self.df2c,\n            on=\"time\",\n            by=\"key2\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_by_int",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9388814b37a8f7c3e8196e0e5e974f1114e5d09931e00ac3f102f86743babca9",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_by_object": {
        "code": "class MergeAsof:\n    def time_by_object(self, direction, tolerance):\n        merge_asof(\n            self.df1b,\n            self.df2b,\n            on=\"time\",\n            by=\"key\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_by_object",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "164ee691bc50a6d10e4f62c99daae4dce68786d7b02f5bd35af7bf33191d0405",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_multiby": {
        "code": "class MergeAsof:\n    def time_multiby(self, direction, tolerance):\n        merge_asof(\n            self.df1e,\n            self.df2e,\n            on=\"time\",\n            by=[\"key\", \"key2\"],\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_multiby",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "464ed78df4c5a78bcd7350edc12851af5dd87d18c63ed889b0ee80e806eed6a1",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_on_int": {
        "code": "class MergeAsof:\n    def time_on_int(self, direction, tolerance):\n        merge_asof(\n            self.df1a, self.df2a, on=\"time\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_on_int",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a0ba76e01b99515f8c84950f1a4683fb1e2b601110a25798072287f3d1574ca1",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_on_int32": {
        "code": "class MergeAsof:\n    def time_on_int32(self, direction, tolerance):\n        merge_asof(\n            self.df1d, self.df2d, on=\"time32\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_on_int32",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5c26b3578593ec04d313f1cbf97df60936516fb7691a67ad03f78d68554fa57f",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_on_uint64": {
        "code": "class MergeAsof:\n    def time_on_uint64(self, direction, tolerance):\n        merge_asof(\n            self.df1f, self.df2f, on=\"timeu64\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_on_uint64",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "272c9034f60d2e7af35cd9d80009bb4f6d2ed987924efec03f83106e40c406be",
        "warmup_time": -1
    },
    "join_merge.MergeCategoricals.time_merge_cat": {
        "code": "class MergeCategoricals:\n    def time_merge_cat(self):\n        merge(self.left_cat, self.right_cat, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")",
        "min_run_count": 2,
        "name": "join_merge.MergeCategoricals.time_merge_cat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "00a33d8aa98005ee74e2a9419efbcba37da5a72412cf5677491a0d7e883e16ac",
        "warmup_time": -1
    },
    "join_merge.MergeCategoricals.time_merge_object": {
        "code": "class MergeCategoricals:\n    def time_merge_object(self):\n        merge(self.left_object, self.right_object, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")",
        "min_run_count": 2,
        "name": "join_merge.MergeCategoricals.time_merge_object",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "77cf8c07c705b35dc8457937294233b8bb0eefee79f670c7293bc9c2381afe22",
        "warmup_time": -1
    },
    "join_merge.MergeCategoricals.time_merge_on_cat_col": {
        "code": "class MergeCategoricals:\n    def time_merge_on_cat_col(self):\n        merge(self.left_cat_col, self.right_cat_col, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")",
        "min_run_count": 2,
        "name": "join_merge.MergeCategoricals.time_merge_on_cat_col",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "332c136f45e9500d990f645254420649a7483fe922cc1518686320b47d002d4d",
        "warmup_time": -1
    },
    "join_merge.MergeCategoricals.time_merge_on_cat_idx": {
        "code": "class MergeCategoricals:\n    def time_merge_on_cat_idx(self):\n        merge(self.left_cat_idx, self.right_cat_idx, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")",
        "min_run_count": 2,
        "name": "join_merge.MergeCategoricals.time_merge_on_cat_idx",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fa95749bee211b87d0765b6dd09a6130d3f28acb1b0d329273458f1ffba8efd8",
        "warmup_time": -1
    },
    "join_merge.MergeDatetime.time_merge": {
        "code": "class MergeDatetime:\n    def time_merge(self, units, tz, monotonic):\n        merge(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeDatetime:\n    def setup(self, units, tz, monotonic):\n        unit_left, unit_right = units\n        N = 10_000\n        keys = Series(date_range(\"2012-01-01\", freq=\"min\", periods=N, tz=tz))\n        self.left = DataFrame(\n            {\n                \"key\": keys.sample(N * 10, replace=True).dt.as_unit(unit_left),\n                \"value1\": np.random.randn(N * 10),\n            }\n        )\n        self.right = DataFrame(\n            {\n                \"key\": keys[:8000].dt.as_unit(unit_right),\n                \"value2\": np.random.randn(8000),\n            }\n        )\n        if monotonic:\n            self.left = self.left.sort_values(\"key\")\n            self.right = self.right.sort_values(\"key\")",
        "min_run_count": 2,
        "name": "join_merge.MergeDatetime.time_merge",
        "number": 0,
        "param_names": [
            "units",
            "tz",
            "monotonic"
        ],
        "params": [
            [
                "('ns', 'ns')",
                "('ms', 'ms')",
                "('ns', 'ms')"
            ],
            [
                "None",
                "'Europe/Brussels'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7fefbf78c16bc3a08818771113e2d29c712563606490a20e5d16660d9870a115",
        "warmup_time": -1
    },
    "join_merge.MergeEA.time_merge": {
        "code": "class MergeEA:\n    def time_merge(self, dtype, monotonic):\n        merge(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeEA:\n    def setup(self, dtype, monotonic):\n        N = 10_000\n        indices = np.arange(1, N)\n        key = np.tile(indices[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": Series(key, dtype=dtype), \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": Series(indices[2000:], dtype=dtype),\n                \"value2\": np.random.randn(7999),\n            }\n        )\n        if monotonic:\n            self.left = self.left.sort_values(\"key\")\n            self.right = self.right.sort_values(\"key\")",
        "min_run_count": 2,
        "name": "join_merge.MergeEA.time_merge",
        "number": 0,
        "param_names": [
            "dtype",
            "monotonic"
        ],
        "params": [
            [
                "'Int64'",
                "'Int32'",
                "'Int16'",
                "'UInt64'",
                "'UInt32'",
                "'UInt16'",
                "'Float64'",
                "'Float32'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f0e5552415c5bc8cd8e34955cf48492cb0932495123062d6282b85ea95868817",
        "warmup_time": -1
    },
    "join_merge.MergeMultiIndex.time_merge_sorted_multiindex": {
        "code": "class MergeMultiIndex:\n    def time_merge_sorted_multiindex(self, dtypes, how):\n        # copy to avoid MultiIndex._values caching\n        df1 = self.df1.copy()\n        df2 = self.df2.copy()\n        merge(df1, df2, how=how, left_index=True, right_index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeMultiIndex:\n    def setup(self, dtypes, how):\n        n = 100_000\n        offset = 50_000\n        mi1 = MultiIndex.from_arrays(\n            [\n                array(np.arange(n), dtype=dtypes[0]),\n                array(np.arange(n), dtype=dtypes[1]),\n            ]\n        )\n        mi2 = MultiIndex.from_arrays(\n            [\n                array(np.arange(offset, n + offset), dtype=dtypes[0]),\n                array(np.arange(offset, n + offset), dtype=dtypes[1]),\n            ]\n        )\n        self.df1 = DataFrame({\"col1\": 1}, index=mi1)\n        self.df2 = DataFrame({\"col2\": 2}, index=mi2)",
        "min_run_count": 2,
        "name": "join_merge.MergeMultiIndex.time_merge_sorted_multiindex",
        "number": 0,
        "param_names": [
            "dtypes",
            "how"
        ],
        "params": [
            [
                "('int64', 'int64')",
                "('datetime64[ns]', 'int64')",
                "('Int64', 'Int64')"
            ],
            [
                "'left'",
                "'right'",
                "'inner'",
                "'outer'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "87d6032a44f31143b8c18c1f04684f8a2aa12fbf908500d9bb17310283004aa3",
        "warmup_time": -1
    },
    "join_merge.MergeOrdered.time_merge_ordered": {
        "code": "class MergeOrdered:\n    def time_merge_ordered(self):\n        merge_ordered(self.left, self.right, on=\"key\", left_by=\"group\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeOrdered:\n    def setup(self):\n        groups = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        self.left = DataFrame(\n            {\n                \"group\": groups.repeat(5000),\n                \"key\": np.tile(np.arange(0, 10000, 2), 10),\n                \"lvalue\": np.random.randn(50000),\n            }\n        )\n        self.right = DataFrame(\n            {\"key\": np.arange(10000), \"rvalue\": np.random.randn(10000)}\n        )",
        "min_run_count": 2,
        "name": "join_merge.MergeOrdered.time_merge_ordered",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d15295cd5ee465cbd2aaa4c0bfe30d6feba058e0379020f3360c6857fd4a6781",
        "warmup_time": -1
    },
    "join_merge.UniqueMerge.time_unique_merge": {
        "code": "class UniqueMerge:\n    def time_unique_merge(self, unique_elements):\n        merge(self.left, self.right, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass UniqueMerge:\n    def setup(self, unique_elements):\n        N = 1_000_000\n        self.left = DataFrame({\"a\": np.random.randint(1, unique_elements, (N,))})\n        self.right = DataFrame({\"a\": np.random.randint(1, unique_elements, (N,))})\n        uniques = self.right.a.drop_duplicates()\n        self.right[\"a\"] = concat(\n            [uniques, Series(np.arange(0, -(N - len(uniques)), -1))], ignore_index=True\n        )",
        "min_run_count": 2,
        "name": "join_merge.UniqueMerge.time_unique_merge",
        "number": 0,
        "param_names": [
            "unique_elements"
        ],
        "params": [
            [
                "4000000",
                "1000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "581e60a84032b51ebdf5071b2cbe5b27a5b4a5db94d2966a6145b815b235c390",
        "warmup_time": -1
    },
    "libs.CacheReadonly.time_cache_readonly": {
        "code": "class CacheReadonly:\n    def time_cache_readonly(self):\n        self.obj.prop\n\n    def setup(self):\n        class Foo:\n            @cache_readonly\n            def prop(self):\n                return 5\n    \n        self.obj = Foo()",
        "min_run_count": 2,
        "name": "libs.CacheReadonly.time_cache_readonly",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0c1cb69a185e93f75c8a4df1942cf6b4e0cf583d0eb2f7e80d1df4e75305b788",
        "warmup_time": -1
    },
    "libs.FastZip.time_lib_fast_zip": {
        "code": "class FastZip:\n    def time_lib_fast_zip(self):\n        lib.fast_zip(self.col_array_list)\n\n    def setup(self):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        col_array = np.vstack([key1, key2, np.random.randn(N * K)])\n        col_array2 = col_array.copy()\n        col_array2[:, :10000] = np.nan\n        self.col_array_list = list(col_array)",
        "min_run_count": 2,
        "name": "libs.FastZip.time_lib_fast_zip",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "91a51ca613db8362ac81df82eb2a907dd705058cd702a87ce9542e1b208d187e",
        "warmup_time": -1
    },
    "libs.InferDtype.time_infer_dtype": {
        "code": "class InferDtype:\n    def time_infer_dtype(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=False)",
        "min_run_count": 2,
        "name": "libs.InferDtype.time_infer_dtype",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'np-object'",
                "'py-object'",
                "'np-null'",
                "'py-null'",
                "'np-int'",
                "'np-floating'",
                "'empty'",
                "'bytes'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "125f86966c05a7552f7d61e8833a505c865982149242f645b314a569f9830a3e",
        "warmup_time": -1
    },
    "libs.InferDtype.time_infer_dtype_skipna": {
        "code": "class InferDtype:\n    def time_infer_dtype_skipna(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=True)",
        "min_run_count": 2,
        "name": "libs.InferDtype.time_infer_dtype_skipna",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'np-object'",
                "'py-object'",
                "'np-null'",
                "'py-null'",
                "'np-int'",
                "'np-floating'",
                "'empty'",
                "'bytes'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "92424cbc247a56269a3db019273c9b16434c61cd8f83fd7210ea2168ac4e31e0",
        "warmup_time": -1
    },
    "libs.ScalarListLike.time_is_list_like": {
        "code": "class ScalarListLike:\n    def time_is_list_like(self, param):\n        is_list_like(param)",
        "min_run_count": 2,
        "name": "libs.ScalarListLike.time_is_list_like",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "0",
                "1.0",
                "(1+2j)",
                "True",
                "'foo'",
                "b'bar'",
                "None",
                "numpy.datetime64('1970-01-01T00:00:00.000000123')",
                "numpy.timedelta64(123,'ns')",
                "NaT",
                "<NA>",
                "array('123', dtype='<U3')",
                "array([1, 2, 3])",
                "{0: 1}",
                "{1, 2, 3}",
                "[1, 2, 3]",
                "(1, 2, 3)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f12c7f398bcc1c4a71e6dbe7b8aec6631a2565dd2a614a6f834dee7e64388bf8",
        "warmup_time": -1
    },
    "libs.ScalarListLike.time_is_scalar": {
        "code": "class ScalarListLike:\n    def time_is_scalar(self, param):\n        is_scalar(param)",
        "min_run_count": 2,
        "name": "libs.ScalarListLike.time_is_scalar",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "0",
                "1.0",
                "(1+2j)",
                "True",
                "'foo'",
                "b'bar'",
                "None",
                "numpy.datetime64('1970-01-01T00:00:00.000000123')",
                "numpy.timedelta64(123,'ns')",
                "NaT",
                "<NA>",
                "array('123', dtype='<U3')",
                "array([1, 2, 3])",
                "{0: 1}",
                "{1, 2, 3}",
                "[1, 2, 3]",
                "(1, 2, 3)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ec357011e1e42690c47ad59e42ea37c1b167ef442f92e787301c3ef26d40a34d",
        "warmup_time": -1
    },
    "multiindex_object.Append.time_append": {
        "code": "class Append:\n    def time_append(self, dtype):\n        self.left.append(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self, dtype):\n        N1 = 1000\n        N2 = 500\n        left_level1 = range(N1)\n        right_level1 = range(N1, N1 + N1)\n    \n        if dtype == \"datetime64[ns]\":\n            level2 = date_range(start=\"2000-01-01\", periods=N2)\n        elif dtype == \"int64\":\n            level2 = range(N2)\n        elif dtype == \"string\":\n            level2 = Index([f\"i-{i}\" for i in range(N2)], dtype=object)\n        else:\n            raise NotImplementedError\n    \n        self.left = MultiIndex.from_product([left_level1, level2])\n        self.right = MultiIndex.from_product([right_level1, level2])",
        "min_run_count": 2,
        "name": "multiindex_object.Append.time_append",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns]'",
                "'int64'",
                "'string'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "76fd9f729ee3cd6d46110db9ab4c9d1c758cc7e3341892fdeda30d892e6c82ae",
        "warmup_time": -1
    },
    "multiindex_object.CategoricalLevel.time_categorical_level": {
        "code": "class CategoricalLevel:\n    def time_categorical_level(self):\n        self.df.set_index([\"a\", \"b\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalLevel:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.arange(1_000_000, dtype=np.int32),\n                \"b\": np.arange(1_000_000, dtype=np.int64),\n                \"c\": np.arange(1_000_000, dtype=float),\n            }\n        ).astype({\"a\": \"category\", \"b\": \"category\"})",
        "min_run_count": 2,
        "name": "multiindex_object.CategoricalLevel.time_categorical_level",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "95746db84674b4c2c4a999d967e65da698fe749fb6a989c5cfa92e4a34dfe20f",
        "warmup_time": -1
    },
    "multiindex_object.Difference.time_difference": {
        "code": "class Difference:\n    def time_difference(self, dtype):\n        self.left.difference(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Difference:\n    def setup(self, dtype):\n        N = 10**4 * 2\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Series(range(N // 1000), dtype=\"Int64\")\n        level2[0] = NA\n        ea_int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"ea_int\": ea_int_left,\n            \"string\": str_left,\n        }\n    \n        data = {k: {\"left\": mi, \"right\": mi[:5]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]",
        "min_run_count": 2,
        "name": "multiindex_object.Difference.time_difference",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime'",
                "'int'",
                "'string'",
                "'ea_int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0168a00ca95fba1c258cd54bdc3faf908f061cbf0a054c35404c75be0273497f",
        "warmup_time": -1
    },
    "multiindex_object.Duplicated.time_duplicated": {
        "code": "class Duplicated:\n    def time_duplicated(self):\n        self.mi.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n, k = 200, 5000\n        levels = [\n            np.arange(n),\n            Index([f\"i-{i}\" for i in range(n)], dtype=object).values,\n            1000 + np.arange(n),\n        ]\n        codes = [np.random.choice(n, (k * n)) for lev in levels]\n        self.mi = MultiIndex(levels=levels, codes=codes)",
        "min_run_count": 2,
        "name": "multiindex_object.Duplicated.time_duplicated",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a38c9fead000e3b6fd3c54f7de782d3ba37dd31161e8fdd82c58194ae7324c22",
        "warmup_time": -1
    },
    "multiindex_object.Duplicates.time_remove_unused_levels": {
        "code": "class Duplicates:\n    def time_remove_unused_levels(self):\n        self.mi_unused_levels.remove_unused_levels()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicates:\n    def setup(self):\n        size = 65536\n        arrays = [np.random.randint(0, 8192, size), np.random.randint(0, 1024, size)]\n        mask = np.random.rand(size) < 0.1\n        self.mi_unused_levels = MultiIndex.from_arrays(arrays)\n        self.mi_unused_levels = self.mi_unused_levels[mask]",
        "min_run_count": 2,
        "name": "multiindex_object.Duplicates.time_remove_unused_levels",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "858a4d9728167fda18b01dd248d011becaf52569cc3789ebc23781748020a547",
        "warmup_time": -1
    },
    "multiindex_object.Equals.time_equals_deepcopy": {
        "code": "class Equals:\n    def time_equals_deepcopy(self):\n        self.mi.equals(self.mi_deepcopy)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        self.mi = MultiIndex.from_product(\n            [\n                date_range(\"2000-01-01\", periods=1000),\n                RangeIndex(1000),\n            ]\n        )\n        self.mi_deepcopy = self.mi.copy(deep=True)\n        self.idx_non_object = RangeIndex(1)",
        "min_run_count": 2,
        "name": "multiindex_object.Equals.time_equals_deepcopy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3c8ee7ba225f03d3cf9c2afce902b41bea67d5d6a541fe7074939ee82f3f7cf6",
        "warmup_time": -1
    },
    "multiindex_object.Equals.time_equals_non_object_index": {
        "code": "class Equals:\n    def time_equals_non_object_index(self):\n        self.mi.equals(self.idx_non_object)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        self.mi = MultiIndex.from_product(\n            [\n                date_range(\"2000-01-01\", periods=1000),\n                RangeIndex(1000),\n            ]\n        )\n        self.mi_deepcopy = self.mi.copy(deep=True)\n        self.idx_non_object = RangeIndex(1)",
        "min_run_count": 2,
        "name": "multiindex_object.Equals.time_equals_non_object_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "90c7f091d490800450f501a3c2b4c17889809056c889ada043abc9c6fcaad06b",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_large_get_loc": {
        "code": "class GetLoc:\n    def time_large_get_loc(self):\n        self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_large_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "dd084286aabcc048d0407dfacebe59f29ed1f976d92d013a0a10f35ba2e96bdb",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_large_get_loc_warm": {
        "code": "class GetLoc:\n    def time_large_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_large_get_loc_warm",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "137653619e4d1b432e07d94aa7a9cf46441e320de449aa65f5129efc13888912",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_med_get_loc": {
        "code": "class GetLoc:\n    def time_med_get_loc(self):\n        self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_med_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b783d9cb5dbdc6787a0879e0f8c0862c4014d5ea0611abb97c342d46f77826e1",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_med_get_loc_warm": {
        "code": "class GetLoc:\n    def time_med_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_med_get_loc_warm",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "50ea4f6a67d9f88227e60e668996edef05b7564987506a1145e7b2c23a2ccb41",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_small_get_loc_warm": {
        "code": "class GetLoc:\n    def time_small_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_small_get_loc_warm",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fe1c2475d50cac160a619e2371fc123f6053a4346c2f4d01018f499d4cfec4e7",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_string_get_loc": {
        "code": "class GetLoc:\n    def time_string_get_loc(self):\n        self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_string_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e96912b143865fa80131f906e8f63d1f3c40b3d142b8571de3b1b9615adf1801",
        "warmup_time": -1
    },
    "multiindex_object.GetLocs.time_large_get_locs": {
        "code": "class GetLocs:\n    def time_large_get_locs(self):\n        self.mi_large.get_locs([999, 19, \"Z\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLocs.time_large_get_locs",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f6945fa307f8737f7231a2a44181eb523a78c225bc91dbcb18e3b75194dfc5bc",
        "warmup_time": -1
    },
    "multiindex_object.GetLocs.time_med_get_locs": {
        "code": "class GetLocs:\n    def time_med_get_locs(self):\n        self.mi_med.get_locs([999, 9, \"A\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLocs.time_med_get_locs",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cf1640cb0f946d097ff83e7740951339843061148884ca31b8394c7abfa2c016",
        "warmup_time": -1
    },
    "multiindex_object.GetLocs.time_small_get_locs": {
        "code": "class GetLocs:\n    def time_small_get_locs(self):\n        self.mi_small.get_locs([99, \"A\", \"A\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLocs.time_small_get_locs",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e20e0ac51b10b4dd999beefc7d99e3da94d32206cbb5cad3f13e2f9f110c765e",
        "warmup_time": -1
    },
    "multiindex_object.Integer.time_get_indexer": {
        "code": "class Integer:\n    def time_get_indexer(self):\n        self.mi_int.get_indexer(self.obj_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.Integer.time_get_indexer",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fbdc58718b979f87ea6a8c82f9bc10f0b1ebc5fb70ea385528f54cff5edb41e7",
        "warmup_time": -1
    },
    "multiindex_object.Integer.time_get_indexer_and_backfill": {
        "code": "class Integer:\n    def time_get_indexer_and_backfill(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"backfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.Integer.time_get_indexer_and_backfill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f3a337ce0bc68b9b181e2f10744c48edfc0aea4481ed3ae1d3daf65dc1c9d53b",
        "warmup_time": -1
    },
    "multiindex_object.Integer.time_get_indexer_and_pad": {
        "code": "class Integer:\n    def time_get_indexer_and_pad(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"pad\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.Integer.time_get_indexer_and_pad",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee2af65e57a49d84022609e04c926f032e6e248514ffaccf6af4a25038d13f78",
        "warmup_time": -1
    },
    "multiindex_object.Integer.time_is_monotonic": {
        "code": "class Integer:\n    def time_is_monotonic(self):\n        self.mi_int.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.Integer.time_is_monotonic",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fe8e8d89536abf16fb7a6ef01595817776ab712a6865435f65f407568be53b2b",
        "warmup_time": -1
    },
    "multiindex_object.Isin.time_isin_large": {
        "code": "class Isin:\n    def time_isin_large(self, dtype):\n        self.midx.isin(self.values_large)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_midx = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_midx,\n            \"int\": int_midx,\n            \"string\": str_midx,\n        }\n    \n        self.midx = data[dtype]\n        self.values_small = self.midx[:100]\n        self.values_large = self.midx[100:]",
        "min_run_count": 2,
        "name": "multiindex_object.Isin.time_isin_large",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'string'",
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7d85e0708b91ce1073f3eb5be362351b5419529c28ad4c98794a4fea4adf8773",
        "warmup_time": -1
    },
    "multiindex_object.Isin.time_isin_small": {
        "code": "class Isin:\n    def time_isin_small(self, dtype):\n        self.midx.isin(self.values_small)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_midx = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_midx,\n            \"int\": int_midx,\n            \"string\": str_midx,\n        }\n    \n        self.midx = data[dtype]\n        self.values_small = self.midx[:100]\n        self.values_large = self.midx[100:]",
        "min_run_count": 2,
        "name": "multiindex_object.Isin.time_isin_small",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'string'",
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6c13190c2ec3169da4f76b0363e486cf173c635d7bb1edba8daec0a6a089f193",
        "warmup_time": -1
    },
    "multiindex_object.Putmask.time_putmask": {
        "code": "class Putmask:\n    def time_putmask(self):\n        self.midx.putmask(self.mask, self.midx_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Putmask:\n    def setup(self):\n        N = 10**5\n        level1 = range(1_000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        self.midx = MultiIndex.from_product([level1, level2])\n    \n        level1 = range(1_000, 2_000)\n        self.midx_values = MultiIndex.from_product([level1, level2])\n    \n        level2 = date_range(start=\"1/1/2010\", periods=N // 1000)\n        self.midx_values_different = MultiIndex.from_product([level1, level2])\n        self.mask = np.array([True, False] * (N // 2))",
        "min_run_count": 2,
        "name": "multiindex_object.Putmask.time_putmask",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "50b446c4932ddf04ca8086ddae7020ac3b1392556c9a5ec0bceee4a3471b774c",
        "warmup_time": -1
    },
    "multiindex_object.Putmask.time_putmask_all_different": {
        "code": "class Putmask:\n    def time_putmask_all_different(self):\n        self.midx.putmask(self.mask, self.midx_values_different)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Putmask:\n    def setup(self):\n        N = 10**5\n        level1 = range(1_000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        self.midx = MultiIndex.from_product([level1, level2])\n    \n        level1 = range(1_000, 2_000)\n        self.midx_values = MultiIndex.from_product([level1, level2])\n    \n        level2 = date_range(start=\"1/1/2010\", periods=N // 1000)\n        self.midx_values_different = MultiIndex.from_product([level1, level2])\n        self.mask = np.array([True, False] * (N // 2))",
        "min_run_count": 2,
        "name": "multiindex_object.Putmask.time_putmask_all_different",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "df38cba739c0876f17aa511e01ea4c5d6ae937fab90a3c6ba526fe149c270ac5",
        "warmup_time": -1
    },
    "multiindex_object.SetOperations.time_operation": {
        "code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method, sort):\n        getattr(self.left, method)(self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method, sort):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        ea_int_left = MultiIndex.from_product([level1, Series(level2, dtype=\"Int64\")])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"string\": str_left,\n            \"ea_int\": ea_int_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": mi, \"right\": mi[:-1]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]",
        "min_run_count": 2,
        "name": "multiindex_object.SetOperations.time_operation",
        "number": 0,
        "param_names": [
            "index_structure",
            "dtype",
            "method",
            "sort"
        ],
        "params": [
            [
                "'monotonic'",
                "'non_monotonic'"
            ],
            [
                "'datetime'",
                "'int'",
                "'string'",
                "'ea_int'"
            ],
            [
                "'intersection'",
                "'union'",
                "'symmetric_difference'"
            ],
            [
                "False",
                "None"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "dc16c7e3877db2721ec17de5cc8eb031f00bbf400e50f5f1e1565c4c64ba78aa",
        "warmup_time": -1
    },
    "multiindex_object.SortValues.time_sort_values": {
        "code": "class SortValues:\n    def time_sort_values(self, dtype):\n        self.mi.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, dtype):\n        a = array(np.tile(np.arange(100), 1000), dtype=dtype)\n        b = array(np.tile(np.arange(1000), 100), dtype=dtype)\n        self.mi = MultiIndex.from_arrays([a, b])",
        "min_run_count": 2,
        "name": "multiindex_object.SortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'Int64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "eb98215f2130dc70e3c3979ccb2442480cccf2a7f1fe46dabae490de9fa669ce",
        "warmup_time": -1
    },
    "multiindex_object.Sortlevel.time_sortlevel_int64": {
        "code": "class Sortlevel:\n    def time_sortlevel_int64(self):\n        self.mi_int.sortlevel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))",
        "min_run_count": 2,
        "name": "multiindex_object.Sortlevel.time_sortlevel_int64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a8b2951c7f045b903e0cd3abcea3295e405768580e65c267316e5d7993c375e4",
        "warmup_time": -1
    },
    "multiindex_object.Sortlevel.time_sortlevel_one": {
        "code": "class Sortlevel:\n    def time_sortlevel_one(self):\n        self.mi.sortlevel(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))",
        "min_run_count": 2,
        "name": "multiindex_object.Sortlevel.time_sortlevel_one",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "17b98983847e3899dd3aecd51f007b8eee9219cafba180bcd18d23a273f074e4",
        "warmup_time": -1
    },
    "multiindex_object.Sortlevel.time_sortlevel_zero": {
        "code": "class Sortlevel:\n    def time_sortlevel_zero(self):\n        self.mi.sortlevel(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))",
        "min_run_count": 2,
        "name": "multiindex_object.Sortlevel.time_sortlevel_zero",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1f7d209d70d9ce641fdba817c8598ab8212457073e4f1218e5ecec974b8af00b",
        "warmup_time": -1
    },
    "multiindex_object.Unique.time_unique": {
        "code": "class Unique:\n    def time_unique(self, dtype_val):\n        self.midx.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unique:\n    def setup(self, dtype_val):\n        level = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(1_000_000)),\n            dtype=dtype_val[0],\n        )\n        self.midx = MultiIndex.from_arrays([level, level])\n    \n        level_dups = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(500_000)) * 2,\n            dtype=dtype_val[0],\n        )\n    \n        self.midx_dups = MultiIndex.from_arrays([level_dups, level_dups])",
        "min_run_count": 2,
        "name": "multiindex_object.Unique.time_unique",
        "number": 0,
        "param_names": [
            "dtype_val"
        ],
        "params": [
            [
                "('Int64', <NA>)",
                "('int64', 0)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "92002a61c3c2deb0be986b18be58b6f290334692a0ddda344728454264d8c69f",
        "warmup_time": -1
    },
    "multiindex_object.Unique.time_unique_dups": {
        "code": "class Unique:\n    def time_unique_dups(self, dtype_val):\n        self.midx_dups.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unique:\n    def setup(self, dtype_val):\n        level = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(1_000_000)),\n            dtype=dtype_val[0],\n        )\n        self.midx = MultiIndex.from_arrays([level, level])\n    \n        level_dups = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(500_000)) * 2,\n            dtype=dtype_val[0],\n        )\n    \n        self.midx_dups = MultiIndex.from_arrays([level_dups, level_dups])",
        "min_run_count": 2,
        "name": "multiindex_object.Unique.time_unique_dups",
        "number": 0,
        "param_names": [
            "dtype_val"
        ],
        "params": [
            [
                "('Int64', <NA>)",
                "('int64', 0)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e7f6ae2612b4e61ab7e9b6ec0fa03d09c37653dcccd19cf141ea041ff0d0eec7",
        "warmup_time": -1
    },
    "multiindex_object.Values.time_datetime_level_values_copy": {
        "code": "class Values:\n    def time_datetime_level_values_copy(self, mi):\n        mi.copy().values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi",
        "min_run_count": 2,
        "name": "multiindex_object.Values.time_datetime_level_values_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "multiindex_object:197",
        "type": "time",
        "unit": "seconds",
        "version": "63e7a47c0b022503f19576c75633ea3ca8a93ecce618be6e102892f9bd42dc33",
        "warmup_time": -1
    },
    "multiindex_object.Values.time_datetime_level_values_sliced": {
        "code": "class Values:\n    def time_datetime_level_values_sliced(self, mi):\n        mi[:10].values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi",
        "min_run_count": 2,
        "name": "multiindex_object.Values.time_datetime_level_values_sliced",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "multiindex_object:197",
        "type": "time",
        "unit": "seconds",
        "version": "6cfa5ee6916e13b58f6d108ca083f0ce269ffc3682b201c7fb24a2c4f82119bf",
        "warmup_time": -1
    },
    "package.TimeImport.time_import": {
        "code": "class TimeImport:\n    def time_import(self):\n        # on py37+ we the \"-X importtime\" usage gives us a more precise\n        #  measurement of the import time we actually care about,\n        #  without the subprocess or interpreter overhead\n        cmd = [sys.executable, \"-X\", \"importtime\", \"-c\", \"import pandas as pd\"]\n        p = subprocess.run(cmd, stderr=subprocess.PIPE, check=True)\n    \n        line = p.stderr.splitlines()[-1]\n        field = line.split(b\"|\")[-2].strip()\n        total = int(field)  # microseconds\n        return total",
        "min_run_count": 2,
        "name": "package.TimeImport.time_import",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "83a56070bd7dda7f68a557d63e6b32341f956e6303d5820f6f5f3cfd62ac924b",
        "warmup_time": -1
    },
    "period.Algorithms.time_drop_duplicates": {
        "code": "class Algorithms:\n    def time_drop_duplicates(self, typ):\n        self.vector.drop_duplicates()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)",
        "min_run_count": 2,
        "name": "period.Algorithms.time_drop_duplicates",
        "number": 0,
        "param_names": [
            "typ"
        ],
        "params": [
            [
                "'index'",
                "'series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5ed71a0e29ea9fe94acdf37fe778becc6a166703e59fe06b43693190e73c358c",
        "warmup_time": -1
    },
    "period.Algorithms.time_value_counts": {
        "code": "class Algorithms:\n    def time_value_counts(self, typ):\n        self.vector.value_counts()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)",
        "min_run_count": 2,
        "name": "period.Algorithms.time_value_counts",
        "number": 0,
        "param_names": [
            "typ"
        ],
        "params": [
            [
                "'index'",
                "'series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7aaad3304a09d800100a2dc5f7da82c36953722c7da6aca2ca4c2e446a3badc8",
        "warmup_time": -1
    },
    "period.DataFramePeriodColumn.time_set_index": {
        "code": "class DataFramePeriodColumn:\n    def time_set_index(self):\n        # GH#21582 limited by comparisons of Period objects\n        self.df[\"col2\"] = self.rng\n        self.df.set_index(\"col2\", append=True)\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"s\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))",
        "min_run_count": 2,
        "name": "period.DataFramePeriodColumn.time_set_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "575f1539efb942f285e06bed12d6e468229977eb8dfe5637e627fc97f98d5c0a",
        "warmup_time": -1
    },
    "period.DataFramePeriodColumn.time_setitem_period_column": {
        "code": "class DataFramePeriodColumn:\n    def time_setitem_period_column(self):\n        self.df[\"col\"] = self.rng\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"s\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))",
        "min_run_count": 2,
        "name": "period.DataFramePeriodColumn.time_setitem_period_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "da793a842fd7c5e41b19f604fed3ece4f2373f1946c06c9733baad3cc9ae9168",
        "warmup_time": -1
    },
    "period.Indexing.time_align": {
        "code": "class Indexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_align",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7ba91f5b4184a97b1e578ce06acd5823a15ef927984c534ef97a97209494f3e9",
        "warmup_time": -1
    },
    "period.Indexing.time_get_loc": {
        "code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.period)\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "16c0233f1354d0efad7e0568b42faab3ceda761dbe321e610db062449c038b2b",
        "warmup_time": -1
    },
    "period.Indexing.time_intersection": {
        "code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_intersection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e473ad8ce23861754e1a2322452188035f32546b5106e9c354504575f161c9dc",
        "warmup_time": -1
    },
    "period.Indexing.time_series_loc": {
        "code": "class Indexing:\n    def time_series_loc(self):\n        self.series.loc[self.period]\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_series_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "051bdec8fea0886aa445b372b56bf9dc434ca870d0168882015b967bb1545aa4",
        "warmup_time": -1
    },
    "period.Indexing.time_shallow_copy": {
        "code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_shallow_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ec340ef909e8666710788924d6a879a98eceecf319ce9ddaa3afaef7f7c6a891",
        "warmup_time": -1
    },
    "period.Indexing.time_unique": {
        "code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_unique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c4ce9c886be5dcc91f24921a741cee9552a169c54f69f0ec4893b19145ca6cda",
        "warmup_time": -1
    },
    "period.PeriodIndexConstructor.time_from_date_range": {
        "code": "class PeriodIndexConstructor:\n    def time_from_date_range(self, freq, is_offset):\n        PeriodIndex(self.rng, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "period.PeriodIndexConstructor.time_from_date_range",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "90341c890b6fd853e93fe5ad5a5d9935048545a0c2bf70da9324aca627215961",
        "warmup_time": -1
    },
    "period.PeriodIndexConstructor.time_from_ints": {
        "code": "class PeriodIndexConstructor:\n    def time_from_ints(self, freq, is_offset):\n        PeriodIndex(self.ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "period.PeriodIndexConstructor.time_from_ints",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "40e20dbe294496152b0cab99ad8277ec6836602167d363e0c665de9915971d7d",
        "warmup_time": -1
    },
    "period.PeriodIndexConstructor.time_from_ints_daily": {
        "code": "class PeriodIndexConstructor:\n    def time_from_ints_daily(self, freq, is_offset):\n        PeriodIndex(self.daily_ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "period.PeriodIndexConstructor.time_from_ints_daily",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7ec1c957be1d06e33b08c4eb1a645648cba0172013a8b73a1e8c8d8f8e5725a8",
        "warmup_time": -1
    },
    "period.PeriodIndexConstructor.time_from_pydatetime": {
        "code": "class PeriodIndexConstructor:\n    def time_from_pydatetime(self, freq, is_offset):\n        PeriodIndex(self.rng2, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "period.PeriodIndexConstructor.time_from_pydatetime",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2e9a86e7434b9d0777e5ccc8fc9165eaf99b3ae701c88bb9a2f2bfbb3a8742c1",
        "warmup_time": -1
    },
    "plotting.BackendLoading.time_get_plot_backend": {
        "code": "class BackendLoading:\n    def time_get_plot_backend(self):\n        # finds the first my_ep_backend\n        _get_plot_backend(\"my_ep_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        mod = importlib.util.module_from_spec(\n            importlib.machinery.ModuleSpec(\"pandas_dummy_backend\", None)\n        )\n        mod.plot = lambda *args, **kwargs: 1\n    \n        with contextlib.ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {\"pandas_dummy_backend\": mod})\n            )\n            tmp_path = pathlib.Path(stack.enter_context(tempfile.TemporaryDirectory()))\n    \n            sys.path.insert(0, os.fsdecode(tmp_path))\n            stack.callback(sys.path.remove, os.fsdecode(tmp_path))\n    \n            dist_info = tmp_path / \"my_backend-0.0.0.dist-info\"\n            dist_info.mkdir()\n            (dist_info / \"entry_points.txt\").write_bytes(\n                b\"[pandas_plotting_backends]\\n\"\n                b\"my_ep_backend = pandas_dummy_backend\\n\"\n                b\"my_ep_backend0 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend1 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend2 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend3 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend4 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend5 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend6 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend7 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend8 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend9 = pandas_dummy_backend\\n\"\n            )\n            self.stack = stack.pop_all()",
        "min_run_count": 2,
        "name": "plotting.BackendLoading.time_get_plot_backend",
        "number": 1,
        "param_names": [],
        "params": [],
        "repeat": 1,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "275ed8f1d87eb6e40f19e678ae4e0130a88ef153363ae407c9576044f4455591",
        "warmup_time": 0
    },
    "plotting.BackendLoading.time_get_plot_backend_fallback": {
        "code": "class BackendLoading:\n    def time_get_plot_backend_fallback(self):\n        # iterates through all the my_ep_backend[0-9] before falling back\n        # to importlib.import_module\n        _get_plot_backend(\"pandas_dummy_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        mod = importlib.util.module_from_spec(\n            importlib.machinery.ModuleSpec(\"pandas_dummy_backend\", None)\n        )\n        mod.plot = lambda *args, **kwargs: 1\n    \n        with contextlib.ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {\"pandas_dummy_backend\": mod})\n            )\n            tmp_path = pathlib.Path(stack.enter_context(tempfile.TemporaryDirectory()))\n    \n            sys.path.insert(0, os.fsdecode(tmp_path))\n            stack.callback(sys.path.remove, os.fsdecode(tmp_path))\n    \n            dist_info = tmp_path / \"my_backend-0.0.0.dist-info\"\n            dist_info.mkdir()\n            (dist_info / \"entry_points.txt\").write_bytes(\n                b\"[pandas_plotting_backends]\\n\"\n                b\"my_ep_backend = pandas_dummy_backend\\n\"\n                b\"my_ep_backend0 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend1 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend2 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend3 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend4 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend5 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend6 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend7 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend8 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend9 = pandas_dummy_backend\\n\"\n            )\n            self.stack = stack.pop_all()",
        "min_run_count": 2,
        "name": "plotting.BackendLoading.time_get_plot_backend_fallback",
        "number": 1,
        "param_names": [],
        "params": [],
        "repeat": 1,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5910845eb9f1e056392eea6799696858a13e4b42bcc4462d896f69e4c4e69fdc",
        "warmup_time": 0
    },
    "plotting.FramePlotting.time_frame_plot": {
        "code": "class FramePlotting:\n    def time_frame_plot(self, kind):\n        self.df.plot(x=\"x\", y=\"y\", kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FramePlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\", \"scatter\", \"hexbin\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.x = Series(np.random.randn(n))\n        self.y = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.x = self.x.abs()\n            self.y = self.y.abs()\n        self.df = DataFrame({\"x\": self.x, \"y\": self.y})",
        "min_run_count": 2,
        "name": "plotting.FramePlotting.time_frame_plot",
        "number": 0,
        "param_names": [
            "kind"
        ],
        "params": [
            [
                "'line'",
                "'bar'",
                "'area'",
                "'barh'",
                "'hist'",
                "'kde'",
                "'pie'",
                "'scatter'",
                "'hexbin'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d6c19f0e6ee8994eb981863b029fa07bc3dc6e28ca77fd1947a32124682e279a",
        "warmup_time": -1
    },
    "plotting.Misc.time_plot_andrews_curves": {
        "code": "class Misc:\n    def time_plot_andrews_curves(self):\n        andrews_curves(self.df, \"Name\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Misc:\n    def setup(self):\n        N = 500\n        M = 10\n        self.df = DataFrame(np.random.randn(N, M))\n        self.df[\"Name\"] = [\"A\"] * N",
        "min_run_count": 2,
        "name": "plotting.Misc.time_plot_andrews_curves",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c5cdb631131db0763b96053825ebc29d36564b7efc93174553deebff526d0e51",
        "warmup_time": -1
    },
    "plotting.SeriesPlotting.time_series_plot": {
        "code": "class SeriesPlotting:\n    def time_series_plot(self, kind):\n        self.s.plot(kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesPlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.s = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.s = self.s.abs()",
        "min_run_count": 2,
        "name": "plotting.SeriesPlotting.time_series_plot",
        "number": 0,
        "param_names": [
            "kind"
        ],
        "params": [
            [
                "'line'",
                "'bar'",
                "'area'",
                "'barh'",
                "'hist'",
                "'kde'",
                "'pie'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "160ab68dd1bbcfdc4cb7ac7c745857d954d7b49e2140f072e93341253436ffb2",
        "warmup_time": -1
    },
    "plotting.TimeseriesPlotting.time_plot_irregular": {
        "code": "class TimeseriesPlotting:\n    def time_plot_irregular(self):\n        self.df2.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )",
        "min_run_count": 2,
        "name": "plotting.TimeseriesPlotting.time_plot_irregular",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "eebbebf937fc740e9be07af175a3643c600ac60a98e1f1606d1ed7150b2966b0",
        "warmup_time": -1
    },
    "plotting.TimeseriesPlotting.time_plot_regular": {
        "code": "class TimeseriesPlotting:\n    def time_plot_regular(self):\n        self.df.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )",
        "min_run_count": 2,
        "name": "plotting.TimeseriesPlotting.time_plot_regular",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c3871908c149bdf0cd9d3c7cdce5ed7bd993762db8bacec201061775ac030be2",
        "warmup_time": -1
    },
    "plotting.TimeseriesPlotting.time_plot_regular_compat": {
        "code": "class TimeseriesPlotting:\n    def time_plot_regular_compat(self):\n        self.df.plot(x_compat=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )",
        "min_run_count": 2,
        "name": "plotting.TimeseriesPlotting.time_plot_regular_compat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6b83eb693399183277a784aee0704171f06e4913b66ddd6bddde0dcc2fb427ff",
        "warmup_time": -1
    },
    "plotting.TimeseriesPlotting.time_plot_table": {
        "code": "class TimeseriesPlotting:\n    def time_plot_table(self):\n        self.df.plot(table=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )",
        "min_run_count": 2,
        "name": "plotting.TimeseriesPlotting.time_plot_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2c526eb7965a6c381c8aa22565224994f1cbd2c378f4a0aa87af283821f76da3",
        "warmup_time": -1
    },
    "reindex.Align.time_align_series_irregular_string": {
        "code": "class Align:\n    def time_align_series_irregular_string(self):\n        self.x + self.y\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        n = 50000\n        indices = Index([f\"i-{i}\" for i in range(n)], dtype=object)\n        subsample_size = 40000\n        self.x = Series(np.random.randn(n), indices)\n        self.y = Series(\n            np.random.randn(subsample_size),\n            index=np.random.choice(indices, subsample_size, replace=False),\n        )",
        "min_run_count": 2,
        "name": "reindex.Align.time_align_series_irregular_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "99535222ff12826c671cd482a3e3dce8a1feb88c9e23e1a204057e24eff7019a",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_frame_drop_dups": {
        "code": "class DropDuplicates:\n    def time_frame_drop_dups(self, inplace):\n        self.df.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_frame_drop_dups",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9e3407f683cc7f16fac045b6c3c7aa89bb7ab9c2f86d11a22aa26844cdfc8bd8",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_frame_drop_dups_bool": {
        "code": "class DropDuplicates:\n    def time_frame_drop_dups_bool(self, inplace):\n        self.df_bool.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_frame_drop_dups_bool",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ff1fe38fe30683f1f77e7f0d500e80fdc6a7c481f9529f0faceacb438bf8acf3",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_frame_drop_dups_int": {
        "code": "class DropDuplicates:\n    def time_frame_drop_dups_int(self, inplace):\n        self.df_int.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_frame_drop_dups_int",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "219d98c5c189760cab8a4753d551329b822cec481ba3587429a5918348833430",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_frame_drop_dups_na": {
        "code": "class DropDuplicates:\n    def time_frame_drop_dups_na(self, inplace):\n        self.df_nan.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_frame_drop_dups_na",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6645f4d4309d703c15aee91e0cccb7387dddfe3a50a13a8ee231b2e8598539f0",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_series_drop_dups_int": {
        "code": "class DropDuplicates:\n    def time_series_drop_dups_int(self, inplace):\n        self.s.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_series_drop_dups_int",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0d5f8b5b9a0532b4bf319dbe2d7ccb87052976d4333850a3eaf137b4d9b23e5d",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_series_drop_dups_string": {
        "code": "class DropDuplicates:\n    def time_series_drop_dups_string(self, inplace):\n        self.s_str.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_series_drop_dups_string",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0c0a1fb01f308c8f6dfbb4593af90cb7d596b775640ebe908d4556cc6e00938c",
        "warmup_time": -1
    },
    "reindex.LevelAlign.time_align_level": {
        "code": "class LevelAlign:\n    def time_align_level(self):\n        self.df.align(self.df_level, level=1, copy=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])",
        "min_run_count": 2,
        "name": "reindex.LevelAlign.time_align_level",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cced19c77cf2154fcd7f760f955314b571a4c552f1c3dda834b08449c39cf96a",
        "warmup_time": -1
    },
    "reindex.LevelAlign.time_reindex_level": {
        "code": "class LevelAlign:\n    def time_reindex_level(self):\n        self.df_level.reindex(self.index, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])",
        "min_run_count": 2,
        "name": "reindex.LevelAlign.time_reindex_level",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9c4e829ee0f877d248f2dca88a52830e615dd62d42be7dc5b046cd79771b41d2",
        "warmup_time": -1
    },
    "reindex.Reindex.time_reindex_columns": {
        "code": "class Reindex:\n    def time_reindex_columns(self):\n        self.df2.reindex(columns=self.df.columns[1:5])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()",
        "min_run_count": 2,
        "name": "reindex.Reindex.time_reindex_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "00a301c16f6c5bce541f67b2a6f047a8d90ab2341ce70509821a6cfb1c0d38df",
        "warmup_time": -1
    },
    "reindex.Reindex.time_reindex_dates": {
        "code": "class Reindex:\n    def time_reindex_dates(self):\n        self.df.reindex(self.rng_subset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()",
        "min_run_count": 2,
        "name": "reindex.Reindex.time_reindex_dates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d8bf7e54481378634e8e80cc8c0c55d1700f313f036d19ab3de1dca31e190f66",
        "warmup_time": -1
    },
    "reindex.Reindex.time_reindex_multiindex_no_cache": {
        "code": "class Reindex:\n    def time_reindex_multiindex_no_cache(self):\n        # Copy to avoid MultiIndex._values getting cached\n        self.s.reindex(self.s_subset_no_cache.index.copy())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()",
        "min_run_count": 2,
        "name": "reindex.Reindex.time_reindex_multiindex_no_cache",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a87224c6ab473aaa760c5bef29410e56f6234562f30eaa05cd52c79d7ee74f25",
        "warmup_time": -1
    },
    "reindex.Reindex.time_reindex_multiindex_no_cache_dates": {
        "code": "class Reindex:\n    def time_reindex_multiindex_no_cache_dates(self):\n        # Copy to avoid MultiIndex._values getting cached\n        self.s2_subset.reindex(self.s2.index.copy())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()",
        "min_run_count": 2,
        "name": "reindex.Reindex.time_reindex_multiindex_no_cache_dates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "34d18834462d53c009ef308fc30cfadd3c904d729da717f68d96a14ef887073a",
        "warmup_time": -1
    },
    "reindex.Reindex.time_reindex_multiindex_with_cache": {
        "code": "class Reindex:\n    def time_reindex_multiindex_with_cache(self):\n        # MultiIndex._values gets cached\n        self.s.reindex(self.s_subset.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()",
        "min_run_count": 2,
        "name": "reindex.Reindex.time_reindex_multiindex_with_cache",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fcee94dfdbc0f691c1052335d9fe83cbb8a3adf26ff91b6a60701a0f2b512526",
        "warmup_time": -1
    },
    "reindex.ReindexMethod.time_reindex_method": {
        "code": "class ReindexMethod:\n    def time_reindex_method(self, method, constructor):\n        self.ts.reindex(self.idx, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReindexMethod:\n    def setup(self, method, constructor):\n        N = 100000\n        self.idx = constructor(\"1/1/2000\", periods=N, freq=\"1min\")\n        self.ts = Series(np.random.randn(N), index=self.idx)[::2]",
        "min_run_count": 2,
        "name": "reindex.ReindexMethod.time_reindex_method",
        "number": 0,
        "param_names": [
            "method",
            "constructor"
        ],
        "params": [
            [
                "'pad'",
                "'backfill'"
            ],
            [
                "<function date_range>",
                "<function period_range>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "52e66df756313fc255334a8a0cb3c1dbaf796d0b655126ff3c140d0a2207a3bc",
        "warmup_time": -1
    },
    "replace.Convert.time_replace": {
        "code": "class Convert:\n    def time_replace(self, constructor, replace_data):\n        self.data.replace(self.to_replace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Convert:\n    def setup(self, constructor, replace_data):\n        N = 10**3\n        data = {\n            \"Series\": pd.Series(np.random.randint(N, size=N)),\n            \"DataFrame\": pd.DataFrame(\n                {\"A\": np.random.randint(N, size=N), \"B\": np.random.randint(N, size=N)}\n            ),\n        }\n        self.to_replace = {i: getattr(pd, replace_data) for i in range(N)}\n        self.data = data[constructor]",
        "min_run_count": 2,
        "name": "replace.Convert.time_replace",
        "number": 0,
        "param_names": [
            "constructor",
            "replace_data"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "'Timestamp'",
                "'Timedelta'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a744fa5ba9e82cf960d86890e5316fd597568f0134b134ef39e6a068d4a6fcaa",
        "warmup_time": -1
    },
    "replace.FillNa.time_fillna": {
        "code": "class FillNa:\n    def time_fillna(self, inplace):\n        self.ts.fillna(0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)",
        "min_run_count": 2,
        "name": "replace.FillNa.time_fillna",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0b76c4847fb4ab0037ada56a69ae0191854beb20a29f7c1fdb937679f1a20cfa",
        "warmup_time": -1
    },
    "replace.FillNa.time_replace": {
        "code": "class FillNa:\n    def time_replace(self, inplace):\n        self.ts.replace(np.nan, 0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)",
        "min_run_count": 2,
        "name": "replace.FillNa.time_replace",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ce112dec862dc388710999d0a5afaf6410c6e73eb37747f783c8f0f031390817",
        "warmup_time": -1
    },
    "replace.ReplaceDict.time_replace_series": {
        "code": "class ReplaceDict:\n    def time_replace_series(self, inplace):\n        self.s.replace(self.to_rep, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceDict:\n    def setup(self, inplace):\n        N = 10**5\n        start_value = 10**5\n        self.to_rep = dict(enumerate(np.arange(N) + start_value))\n        self.s = pd.Series(np.random.randint(N, size=10**3))",
        "min_run_count": 2,
        "name": "replace.ReplaceDict.time_replace_series",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8597d90cda40f0b788096a546f8abbf5caa952c6eea9f9e47eb8d4ce2d3c1aa2",
        "warmup_time": -1
    },
    "replace.ReplaceList.time_replace_list": {
        "code": "class ReplaceList:\n    def time_replace_list(self, inplace):\n        self.df.replace([np.inf, -np.inf], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(10**7))",
        "min_run_count": 2,
        "name": "replace.ReplaceList.time_replace_list",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "959eed35fcb7e64cf2b5aec83263f040060cf5f6bbbff9dcbc719a20863b5eac",
        "warmup_time": -1
    },
    "replace.ReplaceList.time_replace_list_one_match": {
        "code": "class ReplaceList:\n    def time_replace_list_one_match(self, inplace):\n        # the 1 can be held in self._df.blocks[0], while the inf and -inf can't\n        self.df.replace([np.inf, -np.inf, 1], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(10**7))",
        "min_run_count": 2,
        "name": "replace.ReplaceList.time_replace_list_one_match",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6d505bdc8d7c3ba7390852b2bee3c44fcb2c810e807722f5dbc7bbf9e5969c02",
        "warmup_time": -1
    },
    "reshape.Crosstab.time_crosstab": {
        "code": "class Crosstab:\n    def time_crosstab(self):\n        pd.crosstab(self.vec1, self.vec2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)",
        "min_run_count": 2,
        "name": "reshape.Crosstab.time_crosstab",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9111a9ad9a258688c45ba6a0c05b7b226f360b676432ed650b695e5397fde93e",
        "warmup_time": -1
    },
    "reshape.Crosstab.time_crosstab_normalize": {
        "code": "class Crosstab:\n    def time_crosstab_normalize(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)",
        "min_run_count": 2,
        "name": "reshape.Crosstab.time_crosstab_normalize",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5aca65001068430d0914d98785bddb8561273e9c8aa15b387c7dd93043ebf568",
        "warmup_time": -1
    },
    "reshape.Crosstab.time_crosstab_normalize_margins": {
        "code": "class Crosstab:\n    def time_crosstab_normalize_margins(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True, margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)",
        "min_run_count": 2,
        "name": "reshape.Crosstab.time_crosstab_normalize_margins",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4c136fc000722c789e91a8ae69e2c658c5bedd669b2178c0fc2a1f4f2b42727b",
        "warmup_time": -1
    },
    "reshape.Crosstab.time_crosstab_values": {
        "code": "class Crosstab:\n    def time_crosstab_values(self):\n        pd.crosstab(self.vec1, self.vec2, values=self.ind1, aggfunc=\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)",
        "min_run_count": 2,
        "name": "reshape.Crosstab.time_crosstab_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3b4ec27deb69daa12d4b65e15cc4b7b2edcc88df3a066962121c333f57a3423e",
        "warmup_time": -1
    },
    "reshape.Cut.peakmem_cut_interval": {
        "code": "class Cut:\n    def peakmem_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "name": "reshape.Cut.peakmem_cut_interval",
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "4a50cdb22148145d78b66b3246a5d917de2b2b2c2a79baab6c336150c6028996"
    },
    "reshape.Cut.time_cut_datetime": {
        "code": "class Cut:\n    def time_cut_datetime(self, bins):\n        pd.cut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_datetime",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "58412e44ffc063ce05ec9eabf6599316b54c12e85398a5cd91280e5f2eaec7de",
        "warmup_time": -1
    },
    "reshape.Cut.time_cut_float": {
        "code": "class Cut:\n    def time_cut_float(self, bins):\n        pd.cut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_float",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "85096ca698be2f3208680d4f35d7aeded90a2e9795781508cbc5dfdf35e7e36b",
        "warmup_time": -1
    },
    "reshape.Cut.time_cut_int": {
        "code": "class Cut:\n    def time_cut_int(self, bins):\n        pd.cut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_int",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e8b43cd5e06cec8978579ef14b528be88fb90d1577ba5cc34c0c00559616d982",
        "warmup_time": -1
    },
    "reshape.Cut.time_cut_interval": {
        "code": "class Cut:\n    def time_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_interval",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "379c2ec4450e760810c91f3626fdd11aad35e5d872d5b8912a9db3362f42e133",
        "warmup_time": -1
    },
    "reshape.Cut.time_cut_timedelta": {
        "code": "class Cut:\n    def time_cut_timedelta(self, bins):\n        pd.cut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_timedelta",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "758ab752e664d48441ccb021304bc8e71171846cee22a64b2e72be3351f00447",
        "warmup_time": -1
    },
    "reshape.Cut.time_qcut_datetime": {
        "code": "class Cut:\n    def time_qcut_datetime(self, bins):\n        pd.qcut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_qcut_datetime",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d04a2db349c29907a75caab0e3a9c580e577e50262df736e1650eb96f77d134d",
        "warmup_time": -1
    },
    "reshape.Cut.time_qcut_float": {
        "code": "class Cut:\n    def time_qcut_float(self, bins):\n        pd.qcut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_qcut_float",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0482097ddcc850236edbae620fd920d073c84d385fe332eaefbfb40041f64df2",
        "warmup_time": -1
    },
    "reshape.Cut.time_qcut_int": {
        "code": "class Cut:\n    def time_qcut_int(self, bins):\n        pd.qcut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_qcut_int",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "83d5a7e00e70a8e2dae57a0f38abad70d2db20c1bc5fe39c202f1d94ba5f6360",
        "warmup_time": -1
    },
    "reshape.Cut.time_qcut_timedelta": {
        "code": "class Cut:\n    def time_qcut_timedelta(self, bins):\n        pd.qcut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_qcut_timedelta",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ce5e325613d980c2c58926140ecd066ba1caa5ff13d1f13c4b028bf98cb83b0f",
        "warmup_time": -1
    },
    "reshape.Explode.time_explode": {
        "code": "class Explode:\n    def time_explode(self, n_rows, max_list_length):\n        self.series.explode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Explode:\n    def setup(self, n_rows, max_list_length):\n        data = [np.arange(np.random.randint(max_list_length)) for _ in range(n_rows)]\n        self.series = pd.Series(data)",
        "min_run_count": 2,
        "name": "reshape.Explode.time_explode",
        "number": 0,
        "param_names": [
            "n_rows",
            "max_list_length"
        ],
        "params": [
            [
                "100",
                "1000",
                "10000"
            ],
            [
                "3",
                "5",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1e8e8da03418f2a12d85f80f073278296ec8c8f9e43fc8bcc690b704c5f258de",
        "warmup_time": -1
    },
    "reshape.GetDummies.time_get_dummies_1d": {
        "code": "class GetDummies:\n    def time_get_dummies_1d(self):\n        pd.get_dummies(self.s, sparse=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s",
        "min_run_count": 2,
        "name": "reshape.GetDummies.time_get_dummies_1d",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f6981c8b44fbd13f60eff496356529e393625318426d340155a55ed3d7ffb4ee",
        "warmup_time": -1
    },
    "reshape.GetDummies.time_get_dummies_1d_sparse": {
        "code": "class GetDummies:\n    def time_get_dummies_1d_sparse(self):\n        pd.get_dummies(self.s, sparse=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s",
        "min_run_count": 2,
        "name": "reshape.GetDummies.time_get_dummies_1d_sparse",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f4b85a94bf96350e6ae89b0267fcb36cf05e306063a0915e425fc9e5a1a4467e",
        "warmup_time": -1
    },
    "reshape.Melt.time_melt_dataframe": {
        "code": "class Melt:\n    def time_melt_dataframe(self, dtype):\n        melt(self.df, id_vars=[\"id1\", \"id2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Melt:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(100_000, 3), columns=[\"A\", \"B\", \"C\"], dtype=dtype\n        )\n        self.df[\"id1\"] = pd.Series(np.random.randint(0, 10, 10000))\n        self.df[\"id2\"] = pd.Series(np.random.randint(100, 1000, 10000))",
        "min_run_count": 2,
        "name": "reshape.Melt.time_melt_dataframe",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float64'",
                "'Float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "22a1727a0e67859dc0ec65b547a3d44f8c9725863c959eba27153fb0d8f66d4c",
        "warmup_time": -1
    },
    "reshape.Pivot.time_reshape_pivot_time_series": {
        "code": "class Pivot:\n    def time_reshape_pivot_time_series(self):\n        self.df.pivot(index=\"date\", columns=\"variable\", values=\"value\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pivot:\n    def setup(self):\n        N = 10000\n        index = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        data = {\n            \"value\": np.random.randn(N * 50),\n            \"variable\": np.arange(50).repeat(N),\n            \"date\": np.tile(index.values, 50),\n        }\n        self.df = DataFrame(data)",
        "min_run_count": 2,
        "name": "reshape.Pivot.time_reshape_pivot_time_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7466faab8bdadd61fa94c30f9a91cca68cb993c7d0bcf34c64f2b9a31994d7b8",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table": {
        "code": "class PivotTable:\n    def time_pivot_table(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "03f1827427df23f7923b9d2b4ff8790a8896570fbbccf7ccd79cda77f3b29fb6",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_agg": {
        "code": "class PivotTable:\n    def time_pivot_table_agg(self):\n        self.df.pivot_table(\n            index=\"key1\", columns=[\"key2\", \"key3\"], aggfunc=[\"sum\", \"mean\"]\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_agg",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e31596884db26ad8a96fbca432b50937254b59d0e4139cefbc2d930b6835d13b",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_categorical": {
        "code": "class PivotTable:\n    def time_pivot_table_categorical(self):\n        self.df2.pivot_table(\n            index=\"col1\", values=\"col3\", columns=\"col2\", aggfunc=\"sum\", fill_value=0\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_categorical",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d8d0ae28f6fb18e72ed98a04ed6ec36ca77902bf4ebba37acf33e7df0fd6ca21",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_categorical_observed": {
        "code": "class PivotTable:\n    def time_pivot_table_categorical_observed(self):\n        self.df2.pivot_table(\n            index=\"col1\",\n            values=\"col3\",\n            columns=\"col2\",\n            aggfunc=\"sum\",\n            fill_value=0,\n            observed=True,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_categorical_observed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "06e19f29bad0004311d0422c04884a94e54d725e383443b1c5476d40e62a64df",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_margins": {
        "code": "class PivotTable:\n    def time_pivot_table_margins(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_margins",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0afefd1f2578cc7e47b9f9ef6791eac3f77b8ec807c5725b2ef687d228c99241",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_margins_only_column": {
        "code": "class PivotTable:\n    def time_pivot_table_margins_only_column(self):\n        self.df.pivot_table(columns=[\"key1\", \"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_margins_only_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "21e105d206932a8572d6c9e47758f4bc5a6ee77cb384c346e1d145fd2bb9bbfe",
        "warmup_time": -1
    },
    "reshape.ReshapeExtensionDtype.time_stack": {
        "code": "class ReshapeExtensionDtype:\n    def time_stack(self, dtype):\n        self.df.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeExtensionDtype.time_stack",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns, US/Pacific]'",
                "'Period[s]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "71f50c1837c91a2ab25587dc3675ead2ce4cc6662b0442f0b8aabc7677405330",
        "warmup_time": -1
    },
    "reshape.ReshapeExtensionDtype.time_transpose": {
        "code": "class ReshapeExtensionDtype:\n    def time_transpose(self, dtype):\n        self.df.T\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeExtensionDtype.time_transpose",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns, US/Pacific]'",
                "'Period[s]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "de98fb88e477fc5bd7f6b256e4a9b735100ef3450027db1f429fee20265ecde3",
        "warmup_time": -1
    },
    "reshape.ReshapeExtensionDtype.time_unstack_fast": {
        "code": "class ReshapeExtensionDtype:\n    def time_unstack_fast(self, dtype):\n        # last level -> doesn't have to make copies\n        self.ser.unstack(\"bar\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeExtensionDtype.time_unstack_fast",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns, US/Pacific]'",
                "'Period[s]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bfb452390fbd0c8f64654a5fa654ae3cba890d1d7668880d51f418f1c2ea0059",
        "warmup_time": -1
    },
    "reshape.ReshapeExtensionDtype.time_unstack_slow": {
        "code": "class ReshapeExtensionDtype:\n    def time_unstack_slow(self, dtype):\n        # first level -> must make copies\n        self.ser.unstack(\"foo\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeExtensionDtype.time_unstack_slow",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns, US/Pacific]'",
                "'Period[s]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "19cf929eb6cc86687d322f9c25207cd480041be2aafd11fe37cf4815e5be49c8",
        "warmup_time": -1
    },
    "reshape.ReshapeMaskedArrayDtype.time_stack": {
        "code": "class ReshapeExtensionDtype:\n    def time_stack(self, dtype):\n        self.df.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeMaskedArrayDtype.time_stack",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'Int64'",
                "'Float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1eeaeec84de4310b0b92095ad52b62f6c1ec17563f5cc993db36df1fc9f1bc86",
        "warmup_time": -1
    },
    "reshape.ReshapeMaskedArrayDtype.time_transpose": {
        "code": "class ReshapeExtensionDtype:\n    def time_transpose(self, dtype):\n        self.df.T\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeMaskedArrayDtype.time_transpose",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'Int64'",
                "'Float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bb124b2b5f9cfebdc4507a7ef8c75f1112caf5fa34c040451cb2ef3ad5f0040e",
        "warmup_time": -1
    },
    "reshape.ReshapeMaskedArrayDtype.time_unstack_fast": {
        "code": "class ReshapeExtensionDtype:\n    def time_unstack_fast(self, dtype):\n        # last level -> doesn't have to make copies\n        self.ser.unstack(\"bar\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeMaskedArrayDtype.time_unstack_fast",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'Int64'",
                "'Float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a267ffdd7317e4df0f6a83ebde82619df89c2a8e4737cf4d9563453b9b18ddc0",
        "warmup_time": -1
    },
    "reshape.ReshapeMaskedArrayDtype.time_unstack_slow": {
        "code": "class ReshapeExtensionDtype:\n    def time_unstack_slow(self, dtype):\n        # first level -> must make copies\n        self.ser.unstack(\"foo\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeMaskedArrayDtype.time_unstack_slow",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'Int64'",
                "'Float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e11dd322f7d3a2fa04944bb0e94c949b1f27eb0b27cef49390542c77bc015bc9",
        "warmup_time": -1
    },
    "reshape.SimpleReshape.time_stack": {
        "code": "class SimpleReshape:\n    def time_stack(self):\n        self.udf.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)",
        "min_run_count": 2,
        "name": "reshape.SimpleReshape.time_stack",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a6d770036abb815e9c3a58b1e211a9731ce733599757aa8153db703496818011",
        "warmup_time": -1
    },
    "reshape.SimpleReshape.time_unstack": {
        "code": "class SimpleReshape:\n    def time_unstack(self):\n        self.df.unstack(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)",
        "min_run_count": 2,
        "name": "reshape.SimpleReshape.time_unstack",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee883fcccbd0ef7d6c8bb60b550c2de5d2bc5b98458113c63b9f23a2f652e873",
        "warmup_time": -1
    },
    "reshape.SparseIndex.time_unstack": {
        "code": "class SparseIndex:\n    def time_unstack(self):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseIndex:\n    def setup(self):\n        NUM_ROWS = 1000\n        self.df = DataFrame(\n            {\n                \"A\": np.random.randint(50, size=NUM_ROWS),\n                \"B\": np.random.randint(50, size=NUM_ROWS),\n                \"C\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"D\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"E\": np.random.randint(10, size=NUM_ROWS),\n                \"F\": np.random.randn(NUM_ROWS),\n            }\n        )\n        self.df = self.df.set_index([\"A\", \"B\", \"C\", \"D\", \"E\"])",
        "min_run_count": 2,
        "name": "reshape.SparseIndex.time_unstack",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "41381253268a24b9d6ee1f0c20e6602a24860a05d0e483f11a992776103b51be",
        "warmup_time": -1
    },
    "reshape.Unstack.time_full_product": {
        "code": "class Unstack:\n    def time_full_product(self, dtype):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(dict(enumerate(values)), index, columns)\n    \n        self.df2 = self.df.iloc[:-1]",
        "min_run_count": 2,
        "name": "reshape.Unstack.time_full_product",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'int'",
                "'category'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b28492d9054e9dc56a19db0f8cd8638ff873d22ea2faeb49de210add68896584",
        "warmup_time": -1
    },
    "reshape.Unstack.time_without_last_row": {
        "code": "class Unstack:\n    def time_without_last_row(self, dtype):\n        self.df2.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(dict(enumerate(values)), index, columns)\n    \n        self.df2 = self.df.iloc[:-1]",
        "min_run_count": 2,
        "name": "reshape.Unstack.time_without_last_row",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'int'",
                "'category'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0c546381b8ec02b2e96bf78f998f4f2a191ac77f0045346909d25e8b88f3e1e1",
        "warmup_time": -1
    },
    "reshape.WideToLong.time_wide_to_long_big": {
        "code": "class WideToLong:\n    def time_wide_to_long_big(self):\n        wide_to_long(self.df, self.letters, i=\"id\", j=\"year\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WideToLong:\n    def setup(self):\n        nyrs = 20\n        nidvars = 20\n        N = 5000\n        self.letters = list(\"ABCD\")\n        yrvars = [\n            letter + str(num)\n            for letter, num in product(self.letters, range(1, nyrs + 1))\n        ]\n        columns = [str(i) for i in range(nidvars)] + yrvars\n        self.df = DataFrame(np.random.randn(N, nidvars + len(yrvars)), columns=columns)\n        self.df[\"id\"] = self.df.index",
        "min_run_count": 2,
        "name": "reshape.WideToLong.time_wide_to_long_big",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "38b6ee0820735de02ad64b598a14cbe298769f714808e915411fde11e73f8598",
        "warmup_time": -1
    },
    "rolling.Apply.time_rolling": {
        "code": "class Apply:\n    def time_rolling(self, constructor, window, dtype, function, raw):\n        self.roll.apply(function, raw=raw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, constructor, window, dtype, function, raw):\n        N = 10**3\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)",
        "min_run_count": 2,
        "name": "rolling.Apply.time_rolling",
        "number": 0,
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "function",
            "raw"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "3",
                "300"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "<built-in function sum>",
                "<function sum>",
                "<function Apply.<lambda>>"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "871accb43f689bd0f04df4d9d50bb65a4d3403027f3ff0b5e49789cf4cf80a70",
        "warmup_time": -1
    },
    "rolling.EWMMethods.time_ewm": {
        "code": "class EWMMethods:\n    def time_ewm(self, constructor, kwargs_method, dtype):\n        getattr(self.ewm, self.method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass EWMMethods:\n    def setup(self, constructor, kwargs_method, dtype):\n        N = 10**5\n        kwargs, method = kwargs_method\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.method = method\n        self.ewm = getattr(pd, constructor)(arr).ewm(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.EWMMethods.time_ewm",
        "number": 0,
        "param_names": [
            "constructor",
            "kwargs_method",
            "dtype"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "({'halflife': 10}, 'mean')",
                "({'halflife': 10}, 'std')",
                "({'halflife': 1000}, 'mean')",
                "({'halflife': 1000}, 'std')",
                "({'halflife': '1 Day', 'times': DatetimeIndex(['1900-01-01 00:00:00', '1900-01-01 00:00:23',\n               '1900-01-01 00:00:46', '1900-01-01 00:01:09',\n               '1900-01-01 00:01:32', '1900-01-01 00:01:55',\n               '1900-01-01 00:02:18', '1900-01-01 00:02:41',\n               '1900-01-01 00:03:04', '1900-01-01 00:03:27',\n               ...\n               '1900-01-27 14:49:30', '1900-01-27 14:49:53',\n               '1900-01-27 14:50:16', '1900-01-27 14:50:39',\n               '1900-01-27 14:51:02', '1900-01-27 14:51:25',\n               '1900-01-27 14:51:48', '1900-01-27 14:52:11',\n               '1900-01-27 14:52:34', '1900-01-27 14:52:57'],\n              dtype='datetime64[ns]', length=100000, freq='23s')}, 'mean')"
            ],
            [
                "'int'",
                "'float'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "44cf214a28e488cb440a036e0178da2f3f3ea426055c4f0952f4fdedbd55eff8",
        "warmup_time": -1
    },
    "rolling.ForwardWindowMethods.peakmem_rolling": {
        "code": "class ForwardWindowMethods:\n    def peakmem_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)",
        "name": "rolling.ForwardWindowMethods.peakmem_rolling",
        "param_names": [
            "constructor",
            "window_size",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "10",
                "1000"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'kurt'",
                "'sum'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "9ac3a0bf8c769f331e8cd492fdbc30f03ab699681211d932253349936b2ec964"
    },
    "rolling.ForwardWindowMethods.time_rolling": {
        "code": "class ForwardWindowMethods:\n    def time_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)",
        "min_run_count": 2,
        "name": "rolling.ForwardWindowMethods.time_rolling",
        "number": 0,
        "param_names": [
            "constructor",
            "window_size",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "10",
                "1000"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'kurt'",
                "'sum'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6dfc98201296ab54c1be4d985a80b8f835a8c4b225f3719c6869e418405eac45",
        "warmup_time": -1
    },
    "rolling.Groupby.time_method": {
        "code": "class Groupby:\n    def time_method(self, method, window_kwargs):\n        getattr(self.groupby_window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groupby:\n    def setup(self, method, window_kwargs):\n        N = 1000\n        window, kwargs = window_kwargs\n        df = pd.DataFrame(\n            {\n                \"A\": [str(i) for i in range(N)] * 10,\n                \"B\": list(range(N)) * 10,\n            }\n        )\n        if isinstance(kwargs.get(\"window\", None), str):\n            df.index = pd.date_range(start=\"1900-01-01\", freq=\"1min\", periods=N * 10)\n        self.groupby_window = getattr(df.groupby(\"A\"), window)(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.Groupby.time_method",
        "number": 0,
        "param_names": [
            "param1",
            "param2"
        ],
        "params": [
            [
                "'sum' (0)",
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'kurt'",
                "'sum' (1)"
            ],
            [
                "('rolling', {'window': 2})",
                "('rolling', {'window': '30s'})",
                "('expanding', {})"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1f0550f768119c2d4aa887f71e8c464ca76822e8f39b17def026e6701ff98501",
        "warmup_time": -1
    },
    "rolling.GroupbyEWM.time_groupby_method": {
        "code": "class GroupbyEWM:\n    def time_groupby_method(self, method):\n        getattr(self.gb_ewm, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWM:\n    def setup(self, method):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)",
        "min_run_count": 2,
        "name": "rolling.GroupbyEWM.time_groupby_method",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'var'",
                "'std'",
                "'cov'",
                "'corr'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ad6a51326eb042f1ee88615e2048d6bc92adf02dfecb26d43ba24834f3c61150",
        "warmup_time": -1
    },
    "rolling.GroupbyEWMEngine.time_groupby_mean": {
        "code": "class GroupbyEWMEngine:\n    def time_groupby_mean(self, engine):\n        self.gb_ewm.mean(engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWMEngine:\n    def setup(self, engine):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)",
        "min_run_count": 2,
        "name": "rolling.GroupbyEWMEngine.time_groupby_mean",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'cython'",
                "'numba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d69e116193dcb411ee111f0a146b8d596d2d73236f686eb16ef4e9221bd2bd52",
        "warmup_time": -1
    },
    "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation": {
        "code": "class GroupbyLargeGroups:\n    def time_rolling_multiindex_creation(self):\n        self.df.groupby(\"A\").rolling(3).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyLargeGroups:\n    def setup(self):\n        N = 100000\n        self.df = pd.DataFrame({\"A\": [1, 2] * (N // 2), \"B\": np.random.randn(N)})",
        "min_run_count": 2,
        "name": "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "31a34a6b020d62e4c7b595aeb804a131f135c1fd1497365577c3bbf2fe7c511c",
        "warmup_time": -1
    },
    "rolling.Methods.peakmem_method": {
        "code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10**5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)",
        "name": "rolling.Methods.peakmem_method",
        "param_names": [
            "constructor",
            "window_kwargs",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "('rolling', {'window': 10})",
                "('rolling', {'window': 1000})",
                "('expanding', {})"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'std'",
                "'count'",
                "'skew'",
                "'kurt'",
                "'sum'",
                "'sem'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "0c01a9273a20049fc5dfd09ead608a5e199977644711bc856c0dbaf525d6d0d5"
    },
    "rolling.Methods.time_method": {
        "code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10**5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.Methods.time_method",
        "number": 0,
        "param_names": [
            "constructor",
            "window_kwargs",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "('rolling', {'window': 10})",
                "('rolling', {'window': 1000})",
                "('expanding', {})"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'std'",
                "'count'",
                "'skew'",
                "'kurt'",
                "'sum'",
                "'sem'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5402683efd6d1e8b4bab7594be55921fa6334cec6319e73a3f3660d99df1a7a5",
        "warmup_time": -1
    },
    "rolling.Pairwise.time_groupby": {
        "code": "class Pairwise:\n    def time_groupby(self, kwargs_window, method, pairwise):\n        getattr(self.window_group, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10**4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.Pairwise.time_groupby",
        "number": 0,
        "param_names": [
            "window_kwargs",
            "method",
            "pairwise"
        ],
        "params": [
            [
                "({'window': 10}, 'rolling')",
                "({'window': 1000}, 'rolling')",
                "({}, 'expanding')"
            ],
            [
                "'corr'",
                "'cov'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f1e4be4e4d441bdc8b2cebdbc678ae970eb20874fa682bb1ca41352d98a0a23e",
        "warmup_time": -1
    },
    "rolling.Pairwise.time_pairwise": {
        "code": "class Pairwise:\n    def time_pairwise(self, kwargs_window, method, pairwise):\n        getattr(self.window, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10**4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.Pairwise.time_pairwise",
        "number": 0,
        "param_names": [
            "window_kwargs",
            "method",
            "pairwise"
        ],
        "params": [
            [
                "({'window': 10}, 'rolling')",
                "({'window': 1000}, 'rolling')",
                "({}, 'expanding')"
            ],
            [
                "'corr'",
                "'cov'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "315ccdf22c0f4d21fa6ee729bdd8f21c51913704006fbcdfc1f4e2500d816ef3",
        "warmup_time": -1
    },
    "rolling.PeakMemFixedWindowMinMax.peakmem_fixed": {
        "code": "class PeakMemFixedWindowMinMax:\n    def peakmem_fixed(self, operation):\n        for x in range(5):\n            getattr(self.roll, operation)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PeakMemFixedWindowMinMax:\n    def setup(self, operation):\n        N = 10**6\n        arr = np.random.random(N)\n        self.roll = pd.Series(arr).rolling(2)",
        "name": "rolling.PeakMemFixedWindowMinMax.peakmem_fixed",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'min'",
                "'max'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "b9767f691709345094cdfdc4984bb728c9e78389a22aa1bae02462af8dd67ec2"
    },
    "rolling.Quantile.time_quantile": {
        "code": "class Quantile:\n    def time_quantile(self, constructor, window, dtype, percentile, interpolation):\n        self.roll.quantile(percentile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, constructor, window, dtype, percentile, interpolation):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)",
        "min_run_count": 2,
        "name": "rolling.Quantile.time_quantile",
        "number": 0,
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "percentile",
            "param5"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "10",
                "1000"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "0",
                "0.5",
                "1"
            ],
            [
                "'linear'",
                "'nearest'",
                "'lower'",
                "'higher'",
                "'midpoint'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f94389cbc4b3cca82ab4db4970a4acd0daa3c0fbf9cc3f230a6b7d69e841bc4f",
        "warmup_time": -1
    },
    "rolling.Rank.time_rank": {
        "code": "class Rank:\n    def time_rank(self, constructor, window, dtype, percentile, ascending, method):\n        self.roll.rank(pct=percentile, ascending=ascending, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, window, dtype, percentile, ascending, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)",
        "min_run_count": 2,
        "name": "rolling.Rank.time_rank",
        "number": 0,
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "percentile",
            "ascending",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "10",
                "1000"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "True",
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'min'",
                "'max'",
                "'average'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f02fd2586b260b9f5ab15f641e1279b2d47c07b805c6059cdf5f0e5f424a5b6c",
        "warmup_time": -1
    },
    "rolling.TableMethod.time_apply": {
        "code": "class TableMethod:\n    def time_apply(self, method):\n        self.df.rolling(2, method=method).apply(\n            table_method_func, raw=True, engine=\"numba\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))",
        "min_run_count": 2,
        "name": "rolling.TableMethod.time_apply",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'single'",
                "'table'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "30880eb453b9d41a953d95fc25ba24088b0a48b94ab49ea12406e4abc0b976ac",
        "warmup_time": -1
    },
    "rolling.TableMethod.time_ewm_mean": {
        "code": "class TableMethod:\n    def time_ewm_mean(self, method):\n        self.df.ewm(1, method=method).mean(engine=\"numba\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))",
        "min_run_count": 2,
        "name": "rolling.TableMethod.time_ewm_mean",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'single'",
                "'table'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "446dcdc251bda1381a3cf943305e8a6a22ea15ca4513ec2dc7454a8692ab99ad",
        "warmup_time": -1
    },
    "rolling.VariableWindowMethods.peakmem_method": {
        "code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)",
        "name": "rolling.VariableWindowMethods.peakmem_method",
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "'50s'",
                "'1h'",
                "'1d'"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'std'",
                "'count'",
                "'skew'",
                "'kurt'",
                "'sum'",
                "'sem'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "7b52c11d6e1b242c90ddaa78b88fb15e12a3676d5faf98af9807087e0243c3e8"
    },
    "rolling.VariableWindowMethods.time_method": {
        "code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)",
        "min_run_count": 2,
        "name": "rolling.VariableWindowMethods.time_method",
        "number": 0,
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "'50s'",
                "'1h'",
                "'1d'"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'std'",
                "'count'",
                "'skew'",
                "'kurt'",
                "'sum'",
                "'sem'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f5b8129df64b00950a4dbfbcf89e760f149ee8ffb5df1d544c0b87cceb86c41b",
        "warmup_time": -1
    },
    "series_methods.All.time_all": {
        "code": "class All:\n    def time_all(self, N, case, dtype):\n        self.s.all()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass All:\n    def setup(self, N, case, dtype):\n        val = case != \"fast\"\n        self.s = Series([val] * N, dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.All.time_all",
        "number": 0,
        "param_names": [
            "N",
            "case",
            "dtype"
        ],
        "params": [
            [
                "1000",
                "1000000"
            ],
            [
                "'fast'",
                "'slow'"
            ],
            [
                "'bool'",
                "'boolean'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "45f86547ce03394cb299551fd376fc8a763de3a613d475e1b9b2e71852b8c4f9",
        "warmup_time": -1
    },
    "series_methods.Any.time_any": {
        "code": "class Any:\n    def time_any(self, N, case, dtype):\n        self.s.any()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Any:\n    def setup(self, N, case, dtype):\n        val = case == \"fast\"\n        self.s = Series([val] * N, dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.Any.time_any",
        "number": 0,
        "param_names": [
            "N",
            "case",
            "dtype"
        ],
        "params": [
            [
                "1000",
                "1000000"
            ],
            [
                "'fast'",
                "'slow'"
            ],
            [
                "'bool'",
                "'boolean'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2e53bbc75704910ed273c169cc5a41b3037436503911ac1dd4fa9a62a7261c44",
        "warmup_time": -1
    },
    "series_methods.Clip.time_clip": {
        "code": "class Clip:\n    def time_clip(self, n):\n        self.s.clip(0, 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, n):\n        self.s = Series(np.random.randn(n))",
        "min_run_count": 2,
        "name": "series_methods.Clip.time_clip",
        "number": 0,
        "param_names": [
            "n"
        ],
        "params": [
            [
                "50",
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8179a96510fbe69a1326ac0c3cdb1466db7b5719d20b59a243564362d9b56a4a",
        "warmup_time": -1
    },
    "series_methods.ClipDt.time_clip": {
        "code": "class ClipDt:\n    def time_clip(self):\n        self.s.clip(upper=self.clipper_dt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ClipDt:\n    def setup(self):\n        dr = date_range(\"20220101\", periods=100_000, freq=\"s\", tz=\"UTC\")\n        self.clipper_dt = dr[0:1_000].repeat(100)\n        self.s = Series(dr)",
        "min_run_count": 2,
        "name": "series_methods.ClipDt.time_clip",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5e24ee89ae59664da88494ca3070b3c7d1a6c1fe48429471f94661dbff272408",
        "warmup_time": -1
    },
    "series_methods.Dir.time_dir_strings": {
        "code": "class Dir:\n    def time_dir_strings(self):\n        dir(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dir:\n    def setup(self):\n        self.s = Series(index=Index([f\"i-{i}\" for i in range(10000)], dtype=object))",
        "min_run_count": 2,
        "name": "series_methods.Dir.time_dir_strings",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7d61c7dcd41b858046d7576d5e7a6ab11653a5972d6c06e62c3537f02301c81e",
        "warmup_time": -1
    },
    "series_methods.Dropna.time_dropna": {
        "code": "class Dropna:\n    def time_dropna(self, dtype):\n        self.s.dropna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, dtype):\n        N = 10**6\n        data = {\n            \"int\": np.random.randint(1, 10, N),\n            \"datetime\": date_range(\"2000-01-01\", freq=\"s\", periods=N),\n        }\n        self.s = Series(data[dtype])\n        if dtype == \"datetime\":\n            self.s[np.random.randint(1, N, 100)] = NaT",
        "min_run_count": 2,
        "name": "series_methods.Dropna.time_dropna",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d04113f96c3ce4c734ec801a839150033050d2312e0df5c6763e3e5093c05792",
        "warmup_time": -1
    },
    "series_methods.Fillna.time_bfill": {
        "code": "class Fillna:\n    def time_bfill(self, dtype):\n        self.ser.bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value",
        "min_run_count": 2,
        "name": "series_methods.Fillna.time_bfill",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns]'",
                "'float32'",
                "'float64'",
                "'Float64'",
                "'Int64'",
                "'int64[pyarrow]'",
                "'string'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "956fc00ef50dc099cc2bf7e02378c6f7503e72c339b42237bafe8c85c2981f61",
        "warmup_time": -1
    },
    "series_methods.Fillna.time_ffill": {
        "code": "class Fillna:\n    def time_ffill(self, dtype):\n        self.ser.ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value",
        "min_run_count": 2,
        "name": "series_methods.Fillna.time_ffill",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns]'",
                "'float32'",
                "'float64'",
                "'Float64'",
                "'Int64'",
                "'int64[pyarrow]'",
                "'string'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e625516727ac9a43cf480c4279e94bf2cd7ed62ea4a68ac86fe8c6e10fc4ef81",
        "warmup_time": -1
    },
    "series_methods.Fillna.time_fillna": {
        "code": "class Fillna:\n    def time_fillna(self, dtype):\n        self.ser.fillna(value=self.fill_value)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value",
        "min_run_count": 2,
        "name": "series_methods.Fillna.time_fillna",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns]'",
                "'float32'",
                "'float64'",
                "'Float64'",
                "'Int64'",
                "'int64[pyarrow]'",
                "'string'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "02aebbbe16436923ebd160a95e13d6289dd497f1890f5fca503fa6150f330da5",
        "warmup_time": -1
    },
    "series_methods.Iter.time_iter": {
        "code": "class Iter:\n    def time_iter(self, dtype):\n        for v in self.s:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iter:\n    def setup(self, dtype):\n        N = 10**5\n        if dtype in [\"bool\", \"boolean\"]:\n            data = np.repeat([True, False], N // 2)\n        elif dtype in [\"int64\", \"Int64\"]:\n            data = np.arange(N)\n        elif dtype in [\"float64\", \"Float64\"]:\n            data = np.random.randn(N)\n        elif dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(data, dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.Iter.time_iter",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'bool'",
                "'boolean'",
                "'int64'",
                "'Int64'",
                "'float64'",
                "'Float64'",
                "'datetime64[ns]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8d4391387859c36e6cb82fe13b7d67993a73ba3541e8bc6e6e2c3d8c28a11a42",
        "warmup_time": -1
    },
    "series_methods.Map.time_map": {
        "code": "class Map:\n    def time_map(self, mapper, dtype, na_action):\n        self.s.map(self.map_data, na_action=na_action)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Map:\n    def setup(self, mapper, dtype, na_action):\n        map_size = 1000\n        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\n    \n        # construct mapper\n        if mapper == \"Series\":\n            self.map_data = map_data\n        elif mapper == \"dict\":\n            self.map_data = map_data.to_dict()\n        elif mapper == \"lambda\":\n            map_dict = map_data.to_dict()\n            self.map_data = lambda x: map_dict[x]\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.Map.time_map",
        "number": 0,
        "param_names": [
            "mapper",
            "dtype",
            "na_action"
        ],
        "params": [
            [
                "'dict'",
                "'Series'",
                "'lambda'"
            ],
            [
                "'object'",
                "'category'",
                "'int'"
            ],
            [
                "None",
                "'ignore'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "823a6d9b510f81584335c722e2cf02561c44811ceea86875d37e212bfb7e71ad",
        "warmup_time": -1
    },
    "series_methods.Mode.time_mode": {
        "code": "class Mode:\n    def time_mode(self, N, dtype):\n        self.s.mode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Mode:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)",
        "min_run_count": 2,
        "name": "series_methods.Mode.time_mode",
        "number": 0,
        "param_names": [
            "N",
            "dtype"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ],
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "293b41b446df29f5e77e19b14540c5af87a0168e4710d64dbb12037435ef4202",
        "warmup_time": -1
    },
    "series_methods.ModeObjectDropNAFalse.time_mode": {
        "code": "class ModeObjectDropNAFalse:\n    def time_mode(self, N):\n        self.s.mode(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ModeObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")",
        "min_run_count": 2,
        "name": "series_methods.ModeObjectDropNAFalse.time_mode",
        "number": 0,
        "param_names": [
            "N"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e2488dac5c2fdbcfe29cc7e9e32e32b33227ebda39debbcf7e35dbc59aea3f4a",
        "warmup_time": -1
    },
    "series_methods.NSort.time_nlargest": {
        "code": "class NSort:\n    def time_nlargest(self, keep):\n        self.s.nlargest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))",
        "min_run_count": 2,
        "name": "series_methods.NSort.time_nlargest",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b2d7318a10dc119adee969b91b3e8224c14af04542e29aea061c0c549cfbe264",
        "warmup_time": -1
    },
    "series_methods.NSort.time_nsmallest": {
        "code": "class NSort:\n    def time_nsmallest(self, keep):\n        self.s.nsmallest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))",
        "min_run_count": 2,
        "name": "series_methods.NSort.time_nsmallest",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8b1f411ecb151ecb227a739c4be77e69ccde5647917c3adb93dca8fbcae978e1",
        "warmup_time": -1
    },
    "series_methods.NanOps.time_func": {
        "code": "class NanOps:\n    def time_func(self, func, N, dtype):\n        self.func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NanOps:\n    def setup(self, func, N, dtype):\n        if func == \"argmax\" and dtype in {\"Int64\", \"boolean\"}:\n            # Skip argmax for nullable int since this doesn't work yet (GH-24382)\n            raise NotImplementedError\n        self.s = Series(np.ones(N), dtype=dtype)\n        self.func = getattr(self.s, func)",
        "min_run_count": 2,
        "name": "series_methods.NanOps.time_func",
        "number": 0,
        "param_names": [
            "func",
            "N",
            "dtype"
        ],
        "params": [
            [
                "'var'",
                "'mean'",
                "'median'",
                "'max'",
                "'min'",
                "'sum'",
                "'std'",
                "'sem'",
                "'argmax'",
                "'skew'",
                "'kurt'",
                "'prod'"
            ],
            [
                "1000",
                "1000000"
            ],
            [
                "'int8'",
                "'int32'",
                "'int64'",
                "'float64'",
                "'Int64'",
                "'boolean'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4e7a30930490c8c97bb09a4b0301621652f43531dbe206b758cd0b8a25cde577",
        "warmup_time": -1
    },
    "series_methods.Rank.time_rank": {
        "code": "class Rank:\n    def time_rank(self, dtype):\n        self.s.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(0, 1000, size=100000), dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.Rank.time_rank",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cf912b236884d1fded0314151a2a53dce2cf23529a155f2103666ee9d002bff7",
        "warmup_time": -1
    },
    "series_methods.Replace.peakmem_replace_dict": {
        "code": "class Replace:\n    def peakmem_replace_dict(self, num_to_replace):\n        self.ser.replace(self.replace_dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))",
        "name": "series_methods.Replace.peakmem_replace_dict",
        "param_names": [
            "num_to_replace"
        ],
        "params": [
            [
                "100",
                "1000"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "82dfd71ffd244c5b1205af03154e4e4547227fe2551d07660db4b7656efdac03"
    },
    "series_methods.Replace.peakmem_replace_list": {
        "code": "class Replace:\n    def peakmem_replace_list(self, num_to_replace):\n        self.ser.replace(self.to_replace_list, self.values_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))",
        "name": "series_methods.Replace.peakmem_replace_list",
        "param_names": [
            "num_to_replace"
        ],
        "params": [
            [
                "100",
                "1000"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "11d050f21303f90f57bfaf0eef0535a9459a8ef82e29053f7e1a7090ef4b226c"
    },
    "series_methods.Replace.time_replace_dict": {
        "code": "class Replace:\n    def time_replace_dict(self, num_to_replace):\n        self.ser.replace(self.replace_dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))",
        "min_run_count": 2,
        "name": "series_methods.Replace.time_replace_dict",
        "number": 0,
        "param_names": [
            "num_to_replace"
        ],
        "params": [
            [
                "100",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "61cb7f463d734dcaf1edbd292af75ede0994c5b2aed3311d7807aac689771d2d",
        "warmup_time": -1
    },
    "series_methods.Replace.time_replace_list": {
        "code": "class Replace:\n    def time_replace_list(self, num_to_replace):\n        self.ser.replace(self.to_replace_list, self.values_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))",
        "min_run_count": 2,
        "name": "series_methods.Replace.time_replace_list",
        "number": 0,
        "param_names": [
            "num_to_replace"
        ],
        "params": [
            [
                "100",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bb772d4b5c8a9a6917a2f3b97f69478c55a246981d6e2350802c926011741b0a",
        "warmup_time": -1
    },
    "series_methods.SearchSorted.time_searchsorted": {
        "code": "class SearchSorted:\n    def time_searchsorted(self, dtype):\n        key = \"2\" if dtype == \"str\" else 2\n        self.s.searchsorted(key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self, dtype):\n        N = 10**5\n        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\n        self.s = Series(data)",
        "min_run_count": 2,
        "name": "series_methods.SearchSorted.time_searchsorted",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "'float16'",
                "'float32'",
                "'float64'",
                "'str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "323b35cab3b64f29d4f839af05bd6b12ad82170fc35bfee718e2e9d52b7fd61e",
        "warmup_time": -1
    },
    "series_methods.SeriesConstructor.time_constructor_dict": {
        "code": "class SeriesConstructor:\n    def time_constructor_dict(self):\n        Series(data=self.data, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])",
        "min_run_count": 2,
        "name": "series_methods.SeriesConstructor.time_constructor_dict",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e71f5d93471f71f757d994db2550ae233bb7f18e13e21aca22dafa53f833fb4e",
        "warmup_time": -1
    },
    "series_methods.SeriesConstructor.time_constructor_no_data": {
        "code": "class SeriesConstructor:\n    def time_constructor_no_data(self):\n        Series(data=None, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])",
        "min_run_count": 2,
        "name": "series_methods.SeriesConstructor.time_constructor_no_data",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c55e26955fd47febad07ecd223347b24a08ae3454ba16023ad6bb73ec4aaf43a",
        "warmup_time": -1
    },
    "series_methods.SeriesGetattr.time_series_datetimeindex_repr": {
        "code": "class SeriesGetattr:\n    def time_series_datetimeindex_repr(self):\n        getattr(self.s, \"a\", None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesGetattr:\n    def setup(self):\n        self.s = Series(1, index=date_range(\"2012-01-01\", freq=\"s\", periods=10**6))",
        "min_run_count": 2,
        "name": "series_methods.SeriesGetattr.time_series_datetimeindex_repr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a1c5e293ae62939d93cd88e2ea4047f3f42f8c318db822e2539805b7e16b72a7",
        "warmup_time": -1
    },
    "series_methods.ToFrame.time_to_frame": {
        "code": "class ToFrame:\n    def time_to_frame(self, dtype, name):\n        self.ser.to_frame(name)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToFrame:\n    def setup(self, dtype, name):\n        arr = np.arange(10**5)\n        ser = Series(arr, dtype=dtype)\n        self.ser = ser",
        "min_run_count": 2,
        "name": "series_methods.ToFrame.time_to_frame",
        "number": 0,
        "param_names": [
            "dtype",
            "name"
        ],
        "params": [
            [
                "'int64'",
                "'datetime64[ns]'",
                "'category'",
                "'Int64'"
            ],
            [
                "None",
                "'foo'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9837bd38099b9a8813a9b22a59b46e9e9afd7614361947eb24b302192b97eb20",
        "warmup_time": -1
    },
    "series_methods.ToNumpy.time_to_numpy": {
        "code": "class ToNumpy:\n    def time_to_numpy(self):\n        self.ser.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )",
        "min_run_count": 2,
        "name": "series_methods.ToNumpy.time_to_numpy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0ffdc5fb3536043b1cc8a7e1f7f402cf3fe4a601504d03eef9003017585b1037",
        "warmup_time": -1
    },
    "series_methods.ToNumpy.time_to_numpy_copy": {
        "code": "class ToNumpy:\n    def time_to_numpy_copy(self):\n        self.ser.to_numpy(copy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )",
        "min_run_count": 2,
        "name": "series_methods.ToNumpy.time_to_numpy_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d702db82db43d7f93cd41a3786618d602a7938313ff783cfc0a836026c2997dd",
        "warmup_time": -1
    },
    "series_methods.ToNumpy.time_to_numpy_double_copy": {
        "code": "class ToNumpy:\n    def time_to_numpy_double_copy(self):\n        self.ser.to_numpy(dtype=\"float64\", copy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )",
        "min_run_count": 2,
        "name": "series_methods.ToNumpy.time_to_numpy_double_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5ef7c18c63ba7e87e2f511e1b4eb1466a36198dbd621bc47d2c7ac5cde81682d",
        "warmup_time": -1
    },
    "series_methods.ToNumpy.time_to_numpy_float_with_nan": {
        "code": "class ToNumpy:\n    def time_to_numpy_float_with_nan(self):\n        self.ser.to_numpy(dtype=\"float64\", na_value=np.nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )",
        "min_run_count": 2,
        "name": "series_methods.ToNumpy.time_to_numpy_float_with_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d62d4317f22ebf4486d4d6a4902963ccadd2a4c3a1ef2dd8cf1e8e4413545f18",
        "warmup_time": -1
    },
    "series_methods.ValueCounts.time_value_counts": {
        "code": "class ValueCounts:\n    def time_value_counts(self, N, dtype):\n        self.s.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)",
        "min_run_count": 2,
        "name": "series_methods.ValueCounts.time_value_counts",
        "number": 0,
        "param_names": [
            "N",
            "dtype"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ],
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1f5bd690b4a0f777032140a9e0c26ed03c57e4402268b2e8a64b3e1a88d4ee63",
        "warmup_time": -1
    },
    "series_methods.ValueCountsEA.time_value_counts": {
        "code": "class ValueCountsEA:\n    def time_value_counts(self, N, dropna):\n        self.s.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsEA:\n    def setup(self, N, dropna):\n        self.s = Series(np.random.randint(0, N, size=10 * N), dtype=\"Int64\")\n        self.s.loc[1] = NA",
        "min_run_count": 2,
        "name": "series_methods.ValueCountsEA.time_value_counts",
        "number": 0,
        "param_names": [
            "N",
            "dropna"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b1c2f96329a2881dd15f3586facaa30e4405bf239449cae6534cde266ed71cd4",
        "warmup_time": -1
    },
    "series_methods.ValueCountsObjectDropNAFalse.time_value_counts": {
        "code": "class ValueCountsObjectDropNAFalse:\n    def time_value_counts(self, N):\n        self.s.value_counts(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")",
        "min_run_count": 2,
        "name": "series_methods.ValueCountsObjectDropNAFalse.time_value_counts",
        "number": 0,
        "param_names": [
            "N"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a95ddcf5298c1d0d3e53729949f04ee80696bd4b75829dc18ba02781f93d57eb",
        "warmup_time": -1
    },
    "sparse.Arithmetic.time_add": {
        "code": "class Arithmetic:\n    def time_add(self, dense_proportion, fill_value):\n        self.array1 + self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Arithmetic.time_add",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "de0c48747f8d85c11b89324f25d19e454599ce8ea41d8a20d4ad622ee0df72f2",
        "warmup_time": -1
    },
    "sparse.Arithmetic.time_divide": {
        "code": "class Arithmetic:\n    def time_divide(self, dense_proportion, fill_value):\n        self.array1 / self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Arithmetic.time_divide",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3144ab0a952cbf5c353d0326f3901df201f82d17b53a4384714904cb31a1d650",
        "warmup_time": -1
    },
    "sparse.Arithmetic.time_intersect": {
        "code": "class Arithmetic:\n    def time_intersect(self, dense_proportion, fill_value):\n        self.array1.sp_index.intersect(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Arithmetic.time_intersect",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7ac983ea31ec4919e8b0a02237314df70f5fc22fccdc3f2873c848da78bf7bf1",
        "warmup_time": -1
    },
    "sparse.Arithmetic.time_make_union": {
        "code": "class Arithmetic:\n    def time_make_union(self, dense_proportion, fill_value):\n        self.array1.sp_index.make_union(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Arithmetic.time_make_union",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "024b326e3d80e2aa19a052c3e01a3a543974a28c12de2b047b91eb1b4a166106",
        "warmup_time": -1
    },
    "sparse.ArithmeticBlock.time_addition": {
        "code": "class ArithmeticBlock:\n    def time_addition(self, fill_value):\n        self.arr1 + self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )",
        "min_run_count": 2,
        "name": "sparse.ArithmeticBlock.time_addition",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "nan",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "23ca7b349bf4efc6f2264729829fecf63394a0b3c46d61c3f2259d925bb9fc8f",
        "warmup_time": -1
    },
    "sparse.ArithmeticBlock.time_division": {
        "code": "class ArithmeticBlock:\n    def time_division(self, fill_value):\n        self.arr1 / self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )",
        "min_run_count": 2,
        "name": "sparse.ArithmeticBlock.time_division",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "nan",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "642210e7c27c272426725acf65d9abba4f9ef4960d2f195e11b7a83598035d72",
        "warmup_time": -1
    },
    "sparse.ArithmeticBlock.time_intersect": {
        "code": "class ArithmeticBlock:\n    def time_intersect(self, fill_value):\n        self.arr2.sp_index.intersect(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )",
        "min_run_count": 2,
        "name": "sparse.ArithmeticBlock.time_intersect",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "nan",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "163f2bc776313f35b5c130a63fa439494f45003c8ed9ad3fbf8d319b3d47d43f",
        "warmup_time": -1
    },
    "sparse.ArithmeticBlock.time_make_union": {
        "code": "class ArithmeticBlock:\n    def time_make_union(self, fill_value):\n        self.arr1.sp_index.make_union(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )",
        "min_run_count": 2,
        "name": "sparse.ArithmeticBlock.time_make_union",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "nan",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7d3b3e09ca0bfcd7880498366bd319799da49101f951ebee8cac1a364a829ace",
        "warmup_time": -1
    },
    "sparse.FromCoo.time_sparse_series_from_coo": {
        "code": "class FromCoo:\n    def time_sparse_series_from_coo(self):\n        Series.sparse.from_coo(self.matrix)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromCoo:\n    def setup(self):\n        self.matrix = scipy.sparse.coo_matrix(\n            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\n        )",
        "min_run_count": 2,
        "name": "sparse.FromCoo.time_sparse_series_from_coo",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "195924096fa77c5284cc4c2886c3e4e1ec58441bb83c1afe52ee2d94f9987a1a",
        "warmup_time": -1
    },
    "sparse.GetItem.time_integer_indexing": {
        "code": "class GetItem:\n    def time_integer_indexing(self):\n        self.sp_arr[78]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)",
        "min_run_count": 2,
        "name": "sparse.GetItem.time_integer_indexing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "33a91e68a6e5a68dc11115130afb1282d75e72c695768deefdefa5cd05f90191",
        "warmup_time": -1
    },
    "sparse.GetItem.time_slice": {
        "code": "class GetItem:\n    def time_slice(self):\n        self.sp_arr[1:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)",
        "min_run_count": 2,
        "name": "sparse.GetItem.time_slice",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b5ccb973e1258c02d5f387766bf0fea6895662936594235434c58e2ab78122e6",
        "warmup_time": -1
    },
    "sparse.GetItemMask.time_mask": {
        "code": "class GetItemMask:\n    def time_mask(self, fill_value):\n        self.sp_arr[self.sp_b_arr]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemMask:\n    def setup(self, fill_value):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)\n        b_arr = np.full(shape=N, fill_value=fill_value, dtype=np.bool_)\n        fv_inds = np.unique(\n            np.random.randint(low=0, high=N - 1, size=int(N * d), dtype=np.int32)\n        )\n        b_arr[fv_inds] = True if pd.isna(fill_value) else not fill_value\n        self.sp_b_arr = SparseArray(b_arr, dtype=np.bool_, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.GetItemMask.time_mask",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "True",
                "False",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "faec0e7113d63984cae0b03f7857c1d88a455a72fd5f1dd15f082e047f8139c2",
        "warmup_time": -1
    },
    "sparse.MinMax.time_min_max": {
        "code": "class MinMax:\n    def time_min_max(self, func, fill_value):\n        getattr(self.sp_arr, func)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MinMax:\n    def setup(self, func, fill_value):\n        N = 1_000_000\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.MinMax.time_min_max",
        "number": 0,
        "param_names": [
            "func",
            "fill_value"
        ],
        "params": [
            [
                "'min'",
                "'max'"
            ],
            [
                "0.0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5666067aa9bdd3647031cbff0f601ab81231b8c4dc791adc44067a9f361d169a",
        "warmup_time": -1
    },
    "sparse.SparseArrayConstructor.time_sparse_array": {
        "code": "class SparseArrayConstructor:\n    def time_sparse_array(self, dense_proportion, fill_value, dtype):\n        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseArrayConstructor:\n    def setup(self, dense_proportion, fill_value, dtype):\n        N = 10**6\n        self.array = make_array(N, dense_proportion, fill_value, dtype)",
        "min_run_count": 2,
        "name": "sparse.SparseArrayConstructor.time_sparse_array",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value",
            "dtype"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ],
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.float64'>",
                "<class 'object'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e55fb75aef7adab66fc35b1f00e5d38f4c21a7465625d0a1cce5873ce8096110",
        "warmup_time": -1
    },
    "sparse.SparseDataFrameConstructor.time_from_scipy": {
        "code": "class SparseDataFrameConstructor:\n    def time_from_scipy(self):\n        pd.DataFrame.sparse.from_spmatrix(self.sparse)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.sparse = scipy.sparse.rand(N, N, 0.005)",
        "min_run_count": 2,
        "name": "sparse.SparseDataFrameConstructor.time_from_scipy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "177d56dfb0c583f7adb94c9adb8e996066558bf79bf5c7600620c4d85eac136f",
        "warmup_time": -1
    },
    "sparse.SparseSeriesToFrame.time_series_to_frame": {
        "code": "class SparseSeriesToFrame:\n    def time_series_to_frame(self):\n        pd.DataFrame(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseSeriesToFrame:\n    def setup(self):\n        K = 50\n        N = 50001\n        rng = date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        self.series = {}\n        for i in range(1, K):\n            data = np.random.randn(N)[:-i]\n            idx = rng[:-i]\n            data[100:] = np.nan\n            self.series[i] = Series(SparseArray(data), index=idx)",
        "min_run_count": 2,
        "name": "sparse.SparseSeriesToFrame.time_series_to_frame",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f2c3253236bf887dec28449ec4523175e3527457017bb55c9b937e6cd0911d3f",
        "warmup_time": -1
    },
    "sparse.Take.time_take": {
        "code": "class Take:\n    def time_take(self, indices, allow_fill):\n        self.sp_arr.take(indices, allow_fill=allow_fill)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, indices, allow_fill):\n        N = 1_000_000\n        fill_value = 0.0\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Take.time_take",
        "number": 0,
        "param_names": [
            "indices",
            "allow_fill"
        ],
        "params": [
            [
                "array([0])",
                "array([    0,     1,     2, ..., 99997, 99998, 99999])",
                "array([-1, -1, -1, ..., -1, -1, -1])"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "de40b85a6b156eead56c80f2a8a02564cec85e5cda7f49c947f0385fc4552dbb",
        "warmup_time": -1
    },
    "sparse.ToCoo.time_sparse_series_to_coo": {
        "code": "class ToCoo:\n    def time_sparse_series_to_coo(self, sort_labels):\n        self.ss_mult_lvl.sparse.to_coo(\n            row_levels=[0, 1], column_levels=[2, 3], sort_labels=sort_labels\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")",
        "min_run_count": 2,
        "name": "sparse.ToCoo.time_sparse_series_to_coo",
        "number": 0,
        "param_names": [
            "sort_labels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "30ca6ac73768cb7fe0d759bfd836f6ccc90dbdfcd666842cfe90d333c4063300",
        "warmup_time": -1
    },
    "sparse.ToCoo.time_sparse_series_to_coo_single_level": {
        "code": "class ToCoo:\n    def time_sparse_series_to_coo_single_level(self, sort_labels):\n        self.ss_two_lvl.sparse.to_coo(sort_labels=sort_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")",
        "min_run_count": 2,
        "name": "sparse.ToCoo.time_sparse_series_to_coo_single_level",
        "number": 0,
        "param_names": [
            "sort_labels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9f146457117b9ef50ec361711446aad79f7c706f074b3b9d901b5536c47680c0",
        "warmup_time": -1
    },
    "sparse.ToCooFrame.time_to_coo": {
        "code": "class ToCooFrame:\n    def time_to_coo(self):\n        self.df.sparse.to_coo()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCooFrame:\n    def setup(self):\n        N = 10000\n        k = 10\n        arr = np.zeros((N, k), dtype=float)\n        arr[0, 0] = 3.0\n        arr[12, 7] = -1.0\n        arr[0, 9] = 11.2\n        self.df = pd.DataFrame(arr, dtype=pd.SparseDtype(\"float\", fill_value=0.0))",
        "min_run_count": 2,
        "name": "sparse.ToCooFrame.time_to_coo",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "aa52b43e43b97a10066b7eb8a13b85c06203c3660e6293bf051b23418b51d48a",
        "warmup_time": -1
    },
    "stat_ops.Correlation.peakmem_corr_wide": {
        "code": "class Correlation:\n    def peakmem_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "name": "stat_ops.Correlation.peakmem_corr_wide",
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "3ee8f436749f1f2d1f0a071b811c2fa8f22e5b7bfa05919d0449957533179b9a"
    },
    "stat_ops.Correlation.time_corr": {
        "code": "class Correlation:\n    def time_corr(self, method):\n        self.df.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corr",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "985b3d9669fc0dfe69164a9a3e932c4cab6585326d0af33ff34da7dcfcc72ecd",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corr_series": {
        "code": "class Correlation:\n    def time_corr_series(self, method):\n        self.s.corr(self.s2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corr_series",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "15f8a4d1a6ad3002de031f6c6188e46257f89004dd83e0efb0133cda90ddfa33",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corr_wide": {
        "code": "class Correlation:\n    def time_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corr_wide",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "54637cc9be24613ba7ed8eb9724167b189a287c89fc91fcc80840fa02444d657",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corr_wide_nans": {
        "code": "class Correlation:\n    def time_corr_wide_nans(self, method):\n        self.df_wide_nans.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corr_wide_nans",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "07c00330d5c6a030d9e77e6aaec677ed606490cdf7f574cf00748a8a8d00c6b9",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corrwith_cols": {
        "code": "class Correlation:\n    def time_corrwith_cols(self, method):\n        self.df.corrwith(self.df2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corrwith_cols",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5d0002de6d691b52406c99ef171a6bef8d6f9569a32c8223c1544b748f1cee3f",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corrwith_rows": {
        "code": "class Correlation:\n    def time_corrwith_rows(self, method):\n        self.df.corrwith(self.df2, axis=1, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corrwith_rows",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "537c1ca1a5384e46898eef91e2a713efab1b5f27bece96d73baa8c1084a319eb",
        "warmup_time": -1
    },
    "stat_ops.Covariance.time_cov_series": {
        "code": "class Covariance:\n    def time_cov_series(self):\n        self.s.cov(self.s2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Covariance:\n    def setup(self):\n        self.s = pd.Series(np.random.randn(100000))\n        self.s2 = pd.Series(np.random.randn(100000))",
        "min_run_count": 2,
        "name": "stat_ops.Covariance.time_cov_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5127b263e3a6473e609cbc77952bf516e224e61656efd15280caf5a2bd93ac5f",
        "warmup_time": -1
    },
    "stat_ops.FrameMixedDtypesOps.time_op": {
        "code": "class FrameMixedDtypesOps:\n    def time_op(self, op, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMixedDtypesOps:\n    def setup(self, op, axis):\n        if op in (\"sum\", \"skew\", \"kurt\", \"prod\", \"sem\", \"var\") or (\n            (op, axis)\n            in (\n                (\"mean\", 1),\n                (\"mean\", None),\n                (\"median\", 1),\n                (\"median\", None),\n                (\"std\", 1),\n                (\"std\", None),\n            )\n        ):\n            # Skipping cases where datetime aggregations are not implemented\n            raise NotImplementedError\n    \n        N = 1_000_000\n        df = pd.DataFrame(\n            {\n                \"f\": np.random.normal(0.0, 1.0, N),\n                \"i\": np.random.randint(0, N, N),\n                \"ts\": pd.date_range(start=\"1/1/2000\", periods=N, freq=\"h\"),\n            }\n        )\n    \n        self.df_func = getattr(df, op)",
        "min_run_count": 2,
        "name": "stat_ops.FrameMixedDtypesOps.time_op",
        "number": 0,
        "param_names": [
            "op",
            "axis"
        ],
        "params": [
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'prod'",
                "'sem'",
                "'var'"
            ],
            [
                "0",
                "1",
                "None"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "83f19b7e8442fd23c184fef4e499a97eb4a4b610ca5e20691dff8b1724a3058e",
        "warmup_time": -1
    },
    "stat_ops.FrameMultiIndexOps.time_op": {
        "code": "class FrameMultiIndexOps:\n    def time_op(self, op):\n        self.df_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMultiIndexOps:\n    def setup(self, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        df = pd.DataFrame(np.random.randn(len(index), 4), index=index)\n        self.df_func = getattr(df, op)",
        "min_run_count": 2,
        "name": "stat_ops.FrameMultiIndexOps.time_op",
        "number": 0,
        "param_names": [
            "op"
        ],
        "params": [
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'prod'",
                "'sem'",
                "'var'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "13a0374ca338a8b54f1bd16d1ffe134ba780a1d942f5be7ac191ba76b2be4f8f",
        "warmup_time": -1
    },
    "stat_ops.FrameOps.time_op": {
        "code": "class FrameOps:\n    def time_op(self, op, dtype, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameOps:\n    def setup(self, op, dtype, axis):\n        values = np.random.randn(100000, 4)\n        if dtype == \"Int64\":\n            values = values.astype(int)\n        df = pd.DataFrame(values).astype(dtype)\n        self.df_func = getattr(df, op)",
        "min_run_count": 2,
        "name": "stat_ops.FrameOps.time_op",
        "number": 0,
        "param_names": [
            "op",
            "dtype",
            "axis"
        ],
        "params": [
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'prod'",
                "'sem'",
                "'var'"
            ],
            [
                "'float'",
                "'int'",
                "'Int64'"
            ],
            [
                "0",
                "1",
                "None"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b07391c064482d2f0ffb065b28ce25a0cc9d57d9d0281a2d85490c669a986f7e",
        "warmup_time": -1
    },
    "stat_ops.Rank.time_average_old": {
        "code": "class Rank:\n    def time_average_old(self, constructor, pct):\n        self.data.rank(pct=pct) / len(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)",
        "min_run_count": 2,
        "name": "stat_ops.Rank.time_average_old",
        "number": 0,
        "param_names": [
            "constructor",
            "pct"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "82f64cd32e871ed31fd99deb14e611ab16a04df9a99cf92bf1e12863d0d82bda",
        "warmup_time": -1
    },
    "stat_ops.Rank.time_rank": {
        "code": "class Rank:\n    def time_rank(self, constructor, pct):\n        self.data.rank(pct=pct)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)",
        "min_run_count": 2,
        "name": "stat_ops.Rank.time_rank",
        "number": 0,
        "param_names": [
            "constructor",
            "pct"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f8b083c6f46cf347224b1f03549284db11f310cb7e3936a705627eddfeb01142",
        "warmup_time": -1
    },
    "stat_ops.SeriesMultiIndexOps.time_op": {
        "code": "class SeriesMultiIndexOps:\n    def time_op(self, op):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesMultiIndexOps:\n    def setup(self, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        s = pd.Series(np.random.randn(len(index)), index=index)\n        self.s_func = getattr(s, op)",
        "min_run_count": 2,
        "name": "stat_ops.SeriesMultiIndexOps.time_op",
        "number": 0,
        "param_names": [
            "op"
        ],
        "params": [
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'prod'",
                "'sem'",
                "'var'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fafe7c22ddf1ddd0aa6871d8d9537041f3e037adacdc1794d69166a0bfc9dbaa",
        "warmup_time": -1
    },
    "stat_ops.SeriesOps.time_op": {
        "code": "class SeriesOps:\n    def time_op(self, op, dtype):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesOps:\n    def setup(self, op, dtype):\n        s = pd.Series(np.random.randn(100000)).astype(dtype)\n        self.s_func = getattr(s, op)",
        "min_run_count": 2,
        "name": "stat_ops.SeriesOps.time_op",
        "number": 0,
        "param_names": [
            "op",
            "dtype"
        ],
        "params": [
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'prod'",
                "'sem'",
                "'var'"
            ],
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "32cfffab59594606bcaccdcd64c3521e5ffec20c0dcf9b1c864e4d0a6dc41bd4",
        "warmup_time": -1
    },
    "strftime.BusinessHourStrftime.time_frame_offset_repr": {
        "code": "class BusinessHourStrftime:\n    def time_frame_offset_repr(self, nobs):\n        self.data[\"off\"].apply(repr)\n\n    def setup(self, nobs):\n        self.data = pd.DataFrame(\n            {\n                \"off\": [offsets.BusinessHour()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.BusinessHourStrftime.time_frame_offset_repr",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "a46e69099d417d6960551a9c61f7218c1c698b1a064f46cb71253c6e94b54baf",
        "warmup_time": -1
    },
    "strftime.BusinessHourStrftime.time_frame_offset_str": {
        "code": "class BusinessHourStrftime:\n    def time_frame_offset_str(self, nobs):\n        self.data[\"off\"].apply(str)\n\n    def setup(self, nobs):\n        self.data = pd.DataFrame(\n            {\n                \"off\": [offsets.BusinessHour()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.BusinessHourStrftime.time_frame_offset_str",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "c6bd6a7c9015f044c74ec8ada5991b59b8e6811009465b189b2998771710e66c",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_date_formatting_custom": {
        "code": "class DatetimeStrftime:\n    def time_frame_date_formatting_custom(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=\"%Y---%m---%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_date_formatting_custom",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "d8c2ef0e234003004a808414432827b34b1314aec0c69a9322be2df115c12c28",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_date_formatting_default": {
        "code": "class DatetimeStrftime:\n    def time_frame_date_formatting_default(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_date_formatting_default",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "4d7dbcd663f6d27bf3c01012b2b750c048d3b893fbae2f63b59de0ff09ba544f",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_date_formatting_default_explicit": {
        "code": "class DatetimeStrftime:\n    def time_frame_date_formatting_default_explicit(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=\"%Y-%m-%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_date_formatting_default_explicit",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "413c43d2510bbf20e866c514a93a3d2f808f687f6cbf2c2d7fcb586332b29878",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_date_to_str": {
        "code": "class DatetimeStrftime:\n    def time_frame_date_to_str(self, nobs):\n        self.data[\"d\"].astype(str)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_date_to_str",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "054e08eca2d4a8767e953c76bde4ff267409bb5703360cece151bbe66a333160",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_datetime_formatting_custom": {
        "code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_custom(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d --- %H:%M:%S\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_custom",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "45f78787f94eb5bc3a07ef4de1615aeb63966f4bc0323e6efd09f5e1a4466fc2",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_datetime_formatting_default": {
        "code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "fa3e5c135498e5597fee3a7b0be426c176f10b8619cbee4f27ac55f095e64407",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit": {
        "code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_explicit(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "ec080e75b9842b184e4d1ffec10e5499756d68b597c0665dd44b755de1e5d72c",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit_date_only": {
        "code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_explicit_date_only(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit_date_only",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "2d5a4bbcd37dd7efc7834d4fe604fa054058f030eaac3f245f2eed5c2a384df6",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_with_float": {
        "code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_with_float(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S.%f\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_with_float",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "c3d5e3fc1b3d0590232afef2ae418ff61154bc7d430b0475e7e70cdf7dcc4723",
        "warmup_time": -1
    },
    "strftime.DatetimeStrftime.time_frame_datetime_to_str": {
        "code": "class DatetimeStrftime:\n    def time_frame_datetime_to_str(self, nobs):\n        self.data[\"dt\"].astype(str)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )",
        "min_run_count": 2,
        "name": "strftime.DatetimeStrftime.time_frame_datetime_to_str",
        "number": 0,
        "param_names": [
            "nobs"
        ],
        "params": [
            [
                "1000",
                "10000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "5a4c4ba96a951bbfd2b09497a9dfe6a72abfa1eac880c8f2d90e19c7bed5b98b",
        "warmup_time": -1
    },
    "strftime.PeriodStrftime.time_frame_period_formatting_custom": {
        "code": "class PeriodStrftime:\n    def time_frame_period_formatting_custom(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%d --- %H:%M:%S\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "strftime.PeriodStrftime.time_frame_period_formatting_custom",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "16999601594a1d9cd57cfa7155f55be9da4b04ddd986430761e938fe4138d5ff",
        "warmup_time": -1
    },
    "strftime.PeriodStrftime.time_frame_period_formatting_default": {
        "code": "class PeriodStrftime:\n    def time_frame_period_formatting_default(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "strftime.PeriodStrftime.time_frame_period_formatting_default",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "9043ba2fbb552e444f04b49a0bad1382d6e7d4e1f55d150b30bd5117704ca1a9",
        "warmup_time": -1
    },
    "strftime.PeriodStrftime.time_frame_period_formatting_default_explicit": {
        "code": "class PeriodStrftime:\n    def time_frame_period_formatting_default_explicit(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=self.default_fmt)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "strftime.PeriodStrftime.time_frame_period_formatting_default_explicit",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "b18eda1cc34ea4b3062f32befb43ba338a0f37eb1ffae5221f65db35f7c86c2e",
        "warmup_time": -1
    },
    "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_Z": {
        "code": "class PeriodStrftime:\n    def time_frame_period_formatting_iso8601_strftime_Z(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%dT%H:%M:%SZ\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_Z",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "f5de27264273a2cee140307660efbe5e2f798fdf298074c308d5029ca9c58d76",
        "warmup_time": -1
    },
    "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_offset": {
        "code": "class PeriodStrftime:\n    def time_frame_period_formatting_iso8601_strftime_offset(self, nobs, freq):\n        \"\"\"Not optimized yet as %z is not supported by `convert_strftime_format`\"\"\"\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%dT%H:%M:%S%z\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_offset",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "5ba896f46eb860aff2aef5027c2302bd7b1b7eb8ec9d264467a11db4f4ffafe4",
        "warmup_time": -1
    },
    "strftime.PeriodStrftime.time_frame_period_to_str": {
        "code": "class PeriodStrftime:\n    def time_frame_period_to_str(self, nobs, freq):\n        self.data[\"p\"].astype(str)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"",
        "min_run_count": 2,
        "name": "strftime.PeriodStrftime.time_frame_period_to_str",
        "number": 0,
        "param_names": [
            "nobs",
            "freq"
        ],
        "params": [
            [
                "1000",
                "10000"
            ],
            [
                "'D'",
                "'h'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "1cdd45d58644445828a73b51075c943c00e4d5d0665144898cc6f8b8ffc16e19",
        "warmup_time": -1
    },
    "strings.Cat.time_cat": {
        "code": "class Cat:\n    def time_cat(self, other_cols, sep, na_rep, na_frac):\n        # before the concatenation (one caller + other_cols columns), the total\n        # expected fraction of rows containing any NaN is:\n        # reduce(lambda t, _: t + (1 - t) * na_frac, range(other_cols + 1), 0)\n        # for other_cols=3 and na_frac=0.15, this works out to ~48%\n        self.s.str.cat(others=self.others, sep=sep, na_rep=na_rep)\n\n    def setup(self, other_cols, sep, na_rep, na_frac):\n        N = 10**5\n        mask_gen = lambda: np.random.choice([True, False], N, p=[1 - na_frac, na_frac])\n        self.s = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object)).where(\n            mask_gen()\n        )\n        if other_cols == 0:\n            # str.cat self-concatenates only for others=None\n            self.others = None\n        else:\n            self.others = DataFrame(\n                {\n                    i: Index([f\"i-{i}\" for i in range(N)], dtype=object).where(\n                        mask_gen()\n                    )\n                    for i in range(other_cols)\n                }\n            )",
        "min_run_count": 2,
        "name": "strings.Cat.time_cat",
        "number": 0,
        "param_names": [
            "other_cols",
            "sep",
            "na_rep",
            "na_frac"
        ],
        "params": [
            [
                "0",
                "3"
            ],
            [
                "None",
                "','"
            ],
            [
                "None",
                "'-'"
            ],
            [
                "0.0",
                "0.001",
                "0.15"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b52f18e7cc25692faed0025e10bc3626a9ae604f84505b3a27457ae00fed759a",
        "warmup_time": -1
    },
    "strings.Construction.peakmem_construction": {
        "code": "class Construction:\n    def peakmem_construction(self, pd_type, dtype):\n        self.pd_mapping[pd_type](self.arr, dtype=dtype)\n\n    def setup(self, pd_type, dtype):\n        series_arr = np.array(\n            [str(i) * 10 for i in range(100_000)], dtype=self.dtype_mapping[dtype]\n        )\n        if pd_type == \"series\":\n            self.arr = series_arr\n        elif pd_type == \"frame\":\n            self.arr = series_arr.reshape((50_000, 2)).copy()\n        elif pd_type == \"categorical_series\":\n            # GH37371. Testing construction of string series/frames from ExtensionArrays\n            self.arr = Categorical(series_arr)",
        "name": "strings.Construction.peakmem_construction",
        "param_names": [
            "pd_type",
            "dtype"
        ],
        "params": [
            [
                "'series'",
                "'frame'",
                "'categorical_series'"
            ],
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "388fe5a8cc42f895e1448afe8c9ef9f4345e9cdb97befbfa8ec7e38f4ff97a1d"
    },
    "strings.Construction.time_construction": {
        "code": "class Construction:\n    def time_construction(self, pd_type, dtype):\n        self.pd_mapping[pd_type](self.arr, dtype=dtype)\n\n    def setup(self, pd_type, dtype):\n        series_arr = np.array(\n            [str(i) * 10 for i in range(100_000)], dtype=self.dtype_mapping[dtype]\n        )\n        if pd_type == \"series\":\n            self.arr = series_arr\n        elif pd_type == \"frame\":\n            self.arr = series_arr.reshape((50_000, 2)).copy()\n        elif pd_type == \"categorical_series\":\n            # GH37371. Testing construction of string series/frames from ExtensionArrays\n            self.arr = Categorical(series_arr)",
        "min_run_count": 2,
        "name": "strings.Construction.time_construction",
        "number": 0,
        "param_names": [
            "pd_type",
            "dtype"
        ],
        "params": [
            [
                "'series'",
                "'frame'",
                "'categorical_series'"
            ],
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c957bf7cd41d3cf91aba30f7a6a9da9ebfdb15a91e538ec7f97aca263e832104",
        "warmup_time": -1
    },
    "strings.Contains.time_contains": {
        "code": "class Contains:\n    def time_contains(self, dtype, regex):\n        self.s.str.contains(\"A\", regex=regex)\n\n    def setup(self, dtype, regex):\n        super().setup(dtype)",
        "min_run_count": 2,
        "name": "strings.Contains.time_contains",
        "number": 0,
        "param_names": [
            "dtype",
            "regex"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "059d755b738e508f2767456a3bcb5561731b1d7d8ac1ad2e92fddc4828e30270",
        "warmup_time": -1
    },
    "strings.Dummies.time_get_dummies": {
        "code": "class Dummies:\n    def time_get_dummies(self, dtype):\n        self.s.str.get_dummies(\"|\")\n\n    def setup(self, dtype):\n        super().setup(dtype)\n        N = len(self.s) // 5\n        self.s = self.s[:N].str.join(\"|\")",
        "min_run_count": 2,
        "name": "strings.Dummies.time_get_dummies",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3636a8f3b31beca3d40035add6c3a6c089964df164eebcdad0b37494708ed25d",
        "warmup_time": -1
    },
    "strings.Encode.time_encode_decode": {
        "code": "class Encode:\n    def time_encode_decode(self):\n        self.ser.str.encode(\"utf-8\").str.decode(\"utf-8\")\n\n    def setup(self):\n        self.ser = Series(Index([f\"i-{i}\" for i in range(10_000)], dtype=object))",
        "min_run_count": 2,
        "name": "strings.Encode.time_encode_decode",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "98f6dd64fcea519c34e03c7f29d78170688c0d7b9dd676aac55e4f511c3f8f4c",
        "warmup_time": -1
    },
    "strings.Extract.time_extract_single_group": {
        "code": "class Extract:\n    def time_extract_single_group(self, dtype, expand):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)",
        "min_run_count": 2,
        "name": "strings.Extract.time_extract_single_group",
        "number": 0,
        "param_names": [
            "dtype",
            "expand"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4a4c5c7bdd1645c137d0f4bcafc4eb9b92be955e5bb27fd6fe7994d2466c32e7",
        "warmup_time": -1
    },
    "strings.Iter.time_iter": {
        "code": "class Iter:\n    def time_iter(self, dtype):\n        for i in self.s:\n            pass\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Iter.time_iter",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "99048e2de430528987ca96a33415109d24b1dd34d4cb676f4b231d2b9aff3b8b",
        "warmup_time": -1
    },
    "strings.Methods.time_center": {
        "code": "class Methods:\n    def time_center(self, dtype):\n        self.s.str.center(100)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_center",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "dfabd2c2c8e80cf9db6124aac4d32c245e22cc4575b5511d68c85b74670ae71f",
        "warmup_time": -1
    },
    "strings.Methods.time_count": {
        "code": "class Methods:\n    def time_count(self, dtype):\n        self.s.str.count(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_count",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c5f611f3836ad7c1eba5910a47f2878bab4a45394f8b8509f1a697be4b228a84",
        "warmup_time": -1
    },
    "strings.Methods.time_endswith": {
        "code": "class Methods:\n    def time_endswith(self, dtype):\n        self.s.str.endswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_endswith",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f9197c560ddedfee42d2f56aa147f186c719a1252e2510055356947eb1493611",
        "warmup_time": -1
    },
    "strings.Methods.time_extract": {
        "code": "class Methods:\n    def time_extract(self, dtype):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A(\\\\w*)\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_extract",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "98472f6dea453c2b4940a283b32acb0b6016ddfad19469cc8a584c4c227bfef1",
        "warmup_time": -1
    },
    "strings.Methods.time_find": {
        "code": "class Methods:\n    def time_find(self, dtype):\n        self.s.str.find(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_find",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "044081b6b2c59961aa6e9e4da5c63fc29009575ded9293310b6ea51e8ca6fe83",
        "warmup_time": -1
    },
    "strings.Methods.time_findall": {
        "code": "class Methods:\n    def time_findall(self, dtype):\n        self.s.str.findall(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_findall",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d61679b2c211f5b801bfbd27f0a53c99409504239b2992449684331a4be39572",
        "warmup_time": -1
    },
    "strings.Methods.time_fullmatch": {
        "code": "class Methods:\n    def time_fullmatch(self, dtype):\n        self.s.str.fullmatch(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_fullmatch",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e35eec9cf8a46f0139c766632d91d276dc10a435699f63602829b85e082c4da0",
        "warmup_time": -1
    },
    "strings.Methods.time_get": {
        "code": "class Methods:\n    def time_get(self, dtype):\n        self.s.str.get(0)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_get",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bffc7305f03c22402d92a8d667aca1c6902341d79bba2c207702c4aac008896d",
        "warmup_time": -1
    },
    "strings.Methods.time_isalnum": {
        "code": "class Methods:\n    def time_isalnum(self, dtype):\n        self.s.str.isalnum()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_isalnum",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "350d7a1e593e25179b2573f0e18b9a6e6cb2c055e4c9ee2feda18b3451b61cc0",
        "warmup_time": -1
    },
    "strings.Methods.time_isalpha": {
        "code": "class Methods:\n    def time_isalpha(self, dtype):\n        self.s.str.isalpha()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_isalpha",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f61025f688fe65e123f289d71a146cf295cb2f743069c8ce97d40b25e8864728",
        "warmup_time": -1
    },
    "strings.Methods.time_isdecimal": {
        "code": "class Methods:\n    def time_isdecimal(self, dtype):\n        self.s.str.isdecimal()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_isdecimal",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "742859be99c9ee213dbe9bea515f5e0189276d4e227d063af08f7449cd8147a7",
        "warmup_time": -1
    },
    "strings.Methods.time_isdigit": {
        "code": "class Methods:\n    def time_isdigit(self, dtype):\n        self.s.str.isdigit()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_isdigit",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8e1a851ddb833d51dc5a70c3cf221399e7ac360c3572450e3df2a0870eccc6df",
        "warmup_time": -1
    },
    "strings.Methods.time_islower": {
        "code": "class Methods:\n    def time_islower(self, dtype):\n        self.s.str.islower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_islower",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2cd6ca8660528de5f67d097c83a8306d2d637abda2721b1ab0e05b4b7088f100",
        "warmup_time": -1
    },
    "strings.Methods.time_isnumeric": {
        "code": "class Methods:\n    def time_isnumeric(self, dtype):\n        self.s.str.isnumeric()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_isnumeric",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "93209b1b18f1417cbdc050726a9174b9fb76d43563303242b4f7617e3a94036b",
        "warmup_time": -1
    },
    "strings.Methods.time_isspace": {
        "code": "class Methods:\n    def time_isspace(self, dtype):\n        self.s.str.isspace()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_isspace",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a9ba8663a43748c749f7e5b13fa37c790716199afa48b66e114a0660a68f4b41",
        "warmup_time": -1
    },
    "strings.Methods.time_istitle": {
        "code": "class Methods:\n    def time_istitle(self, dtype):\n        self.s.str.istitle()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_istitle",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9d616462e52f19dd8270a6f747143737102c4056aa528613b839c29dfe751f67",
        "warmup_time": -1
    },
    "strings.Methods.time_isupper": {
        "code": "class Methods:\n    def time_isupper(self, dtype):\n        self.s.str.isupper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_isupper",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b4f3172ccc98adcd21201b75f29adbe4f30202e5307f6e52cf62df633c7663c1",
        "warmup_time": -1
    },
    "strings.Methods.time_join": {
        "code": "class Methods:\n    def time_join(self, dtype):\n        self.s.str.join(\" \")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_join",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "31e2bb80662edda7fba2732e3104d5e16bf85f26bcd65f83ddce2db39d042e02",
        "warmup_time": -1
    },
    "strings.Methods.time_len": {
        "code": "class Methods:\n    def time_len(self, dtype):\n        self.s.str.len()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_len",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "15831f1f1fc1053f7d40396a1e8f06de2b9ce7d36a77263935795618fcf26473",
        "warmup_time": -1
    },
    "strings.Methods.time_lower": {
        "code": "class Methods:\n    def time_lower(self, dtype):\n        self.s.str.lower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_lower",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2e0f8ba78ce20a15b2246f9e313459303cec518989e54b52c665208ef6e69070",
        "warmup_time": -1
    },
    "strings.Methods.time_lstrip": {
        "code": "class Methods:\n    def time_lstrip(self, dtype):\n        self.s.str.lstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_lstrip",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9c3141587e7b7809c1de02ebace59cd44a0cd5013b5383c14d95d70df242f699",
        "warmup_time": -1
    },
    "strings.Methods.time_match": {
        "code": "class Methods:\n    def time_match(self, dtype):\n        self.s.str.match(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_match",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1875a652c9e9a2e4a398a590828e6977bba7a8e30f58c2a582c125f1b2287cec",
        "warmup_time": -1
    },
    "strings.Methods.time_normalize": {
        "code": "class Methods:\n    def time_normalize(self, dtype):\n        self.s.str.normalize(\"NFC\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_normalize",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0029f0976f6b3cdafe05ce21172d6b1733929dcf148531c35b5e9daf472c7b14",
        "warmup_time": -1
    },
    "strings.Methods.time_pad": {
        "code": "class Methods:\n    def time_pad(self, dtype):\n        self.s.str.pad(100, side=\"both\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_pad",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d2eb769aa07b3f253dcc0bafb6f7965322f8d510b09bdc57c905eadb28b7467f",
        "warmup_time": -1
    },
    "strings.Methods.time_partition": {
        "code": "class Methods:\n    def time_partition(self, dtype):\n        self.s.str.partition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_partition",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4a17da39f63b92446009df4fe223405c2062b6e02e4ad0b75f6f589a447d43b6",
        "warmup_time": -1
    },
    "strings.Methods.time_replace": {
        "code": "class Methods:\n    def time_replace(self, dtype):\n        self.s.str.replace(\"A\", \"\\x01\\x01\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_replace",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "86c5eb08ad17d3743614bdfafdccc89241f8a0dd7135d96e623688603bb9aeb9",
        "warmup_time": -1
    },
    "strings.Methods.time_rfind": {
        "code": "class Methods:\n    def time_rfind(self, dtype):\n        self.s.str.rfind(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_rfind",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bff18b026560620448f6d9277e349128f6089973cedef619640ae1c024bf8c9b",
        "warmup_time": -1
    },
    "strings.Methods.time_rpartition": {
        "code": "class Methods:\n    def time_rpartition(self, dtype):\n        self.s.str.rpartition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_rpartition",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "78fc7a482d33a89264eef3b15a11469b223b2129733dae9074d636311e2cbdd6",
        "warmup_time": -1
    },
    "strings.Methods.time_rstrip": {
        "code": "class Methods:\n    def time_rstrip(self, dtype):\n        self.s.str.rstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_rstrip",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "eda693ad14adab58cbce9e55efdaf6c2c46080dfc584c1ae93d306b125aa953f",
        "warmup_time": -1
    },
    "strings.Methods.time_slice": {
        "code": "class Methods:\n    def time_slice(self, dtype):\n        self.s.str.slice(5, 15, 2)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_slice",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "533b86a28e89ae89262a20e75cb22c9cf750b8c7e9c0fa09683d784ee0e03357",
        "warmup_time": -1
    },
    "strings.Methods.time_startswith": {
        "code": "class Methods:\n    def time_startswith(self, dtype):\n        self.s.str.startswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_startswith",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5c00f04f17e556c9ba519e01d190b425d603977100265c6fa3fd7bec0f12c92c",
        "warmup_time": -1
    },
    "strings.Methods.time_strip": {
        "code": "class Methods:\n    def time_strip(self, dtype):\n        self.s.str.strip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_strip",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a1d6a533499233d62a84e1f56f3b98f8319d9dff982c01f5a9599f2a1411f149",
        "warmup_time": -1
    },
    "strings.Methods.time_title": {
        "code": "class Methods:\n    def time_title(self, dtype):\n        self.s.str.title()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_title",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fbfb0a2b913b93aa6344ba9b6c28d74680889c1b1714a1518fca0b905d0f6459",
        "warmup_time": -1
    },
    "strings.Methods.time_translate": {
        "code": "class Methods:\n    def time_translate(self, dtype):\n        self.s.str.translate({\"A\": \"\\x01\\x01\"})\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_translate",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0ae15fa8fa4067f6f432f63d971644c286ebdee520d5edd17c9a448356c28f3a",
        "warmup_time": -1
    },
    "strings.Methods.time_upper": {
        "code": "class Methods:\n    def time_upper(self, dtype):\n        self.s.str.upper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_upper",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7d79a2ac0817c85a6d5426ad30a0ced267a4c2477d924bd909ae9c9f1af896a5",
        "warmup_time": -1
    },
    "strings.Methods.time_wrap": {
        "code": "class Methods:\n    def time_wrap(self, dtype):\n        self.s.str.wrap(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_wrap",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8118c3a07bfcff1b6eb842caef841ba5c8c0b85d21537b1d23fb01388a201035",
        "warmup_time": -1
    },
    "strings.Methods.time_zfill": {
        "code": "class Methods:\n    def time_zfill(self, dtype):\n        self.s.str.zfill(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err",
        "min_run_count": 2,
        "name": "strings.Methods.time_zfill",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "89c50187e9898c6f7920175d3b698c14fef65ffc54c731c8c049e82081ab4851",
        "warmup_time": -1
    },
    "strings.Repeat.time_repeat": {
        "code": "class Repeat:\n    def time_repeat(self, repeats):\n        self.s.str.repeat(self.values)\n\n    def setup(self, repeats):\n        N = 10**5\n        self.s = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        repeat = {\"int\": 1, \"array\": np.random.randint(1, 3, N)}\n        self.values = repeat[repeats]",
        "min_run_count": 2,
        "name": "strings.Repeat.time_repeat",
        "number": 0,
        "param_names": [
            "repeats"
        ],
        "params": [
            [
                "'int'",
                "'array'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1020d0debc1446a71cfda9efe059407dc390e74d806d2783566fdba4e7d1de98",
        "warmup_time": -1
    },
    "strings.Slice.time_vector_slice": {
        "code": "class Slice:\n    def time_vector_slice(self):\n        # GH 2602\n        self.s.str[:5]\n\n    def setup(self):\n        self.s = Series([\"abcdefg\", np.nan] * 500000)",
        "min_run_count": 2,
        "name": "strings.Slice.time_vector_slice",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "aaf1ec9c90cc2539c76cae9af1c26b6b5ffb1d0311ec7d6dafe7d228d106ef86",
        "warmup_time": -1
    },
    "strings.Split.time_rsplit": {
        "code": "class Split:\n    def time_rsplit(self, dtype, expand):\n        self.s.str.rsplit(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")",
        "min_run_count": 2,
        "name": "strings.Split.time_rsplit",
        "number": 0,
        "param_names": [
            "dtype",
            "expand"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c748bf724293b4083adf3d91ce7a5255043bddcd7ecaba38777cac47767ad1f0",
        "warmup_time": -1
    },
    "strings.Split.time_split": {
        "code": "class Split:\n    def time_split(self, dtype, expand):\n        self.s.str.split(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")",
        "min_run_count": 2,
        "name": "strings.Split.time_split",
        "number": 0,
        "param_names": [
            "dtype",
            "expand"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "abecb3cbc4195a6fedc3bc41353ecd447d36060b1cd5e43944cda06edfa8a2e6",
        "warmup_time": -1
    },
    "strings.StringArrayConstruction.peakmem_stringarray_construction": {
        "code": "class StringArrayConstruction:\n    def peakmem_stringarray_construction(self):\n        StringArray(self.series_arr)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])",
        "name": "strings.StringArrayConstruction.peakmem_stringarray_construction",
        "param_names": [],
        "params": [],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "1644a62bd4fef4c7214ab6a613fb523651eb795bdc0eca8bafc1bceb6af4bc8d"
    },
    "strings.StringArrayConstruction.time_string_array_construction": {
        "code": "class StringArrayConstruction:\n    def time_string_array_construction(self):\n        StringArray(self.series_arr)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])",
        "min_run_count": 2,
        "name": "strings.StringArrayConstruction.time_string_array_construction",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4ded60d6eacf6b7203c61d538380497e0dd86ed15910c739819f0c18299357a4",
        "warmup_time": -1
    },
    "strings.StringArrayConstruction.time_string_array_with_nan_construction": {
        "code": "class StringArrayConstruction:\n    def time_string_array_with_nan_construction(self):\n        StringArray(self.series_arr_nan)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])",
        "min_run_count": 2,
        "name": "strings.StringArrayConstruction.time_string_array_with_nan_construction",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c7ef4a3758ceb79e8124d016a878c5be0d6bf37399e516da63b10e21cb3fc1d5",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_dt_accessor": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor(self, series):\n        series.dt\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_dt_accessor",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "type": "time",
        "unit": "seconds",
        "version": "56ad9655f66a0485943ce9ca9547af9c97e48f5b12779c60896c3147c5422526",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_timedelta_days": {
        "code": "class DatetimeAccessor:\n    def time_timedelta_days(self, series):\n        series.dt.days\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_timedelta_days",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "type": "time",
        "unit": "seconds",
        "version": "06c603c515e826893772c4d64fe4de8ff76367d3c422060262604d4917fbec03",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_timedelta_microseconds": {
        "code": "class DatetimeAccessor:\n    def time_timedelta_microseconds(self, series):\n        series.dt.microseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_timedelta_microseconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "type": "time",
        "unit": "seconds",
        "version": "6504e61d63ba227783a76d2cab32c1d791b1af813406a8c384fc386ca60b1898",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_timedelta_nanoseconds": {
        "code": "class DatetimeAccessor:\n    def time_timedelta_nanoseconds(self, series):\n        series.dt.nanoseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_timedelta_nanoseconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "type": "time",
        "unit": "seconds",
        "version": "c1cc39aec7c93cb50ced4bf81ec26506de8bfddaaee6968142c0c018f91e296a",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_timedelta_seconds": {
        "code": "class DatetimeAccessor:\n    def time_timedelta_seconds(self, series):\n        series.dt.seconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_timedelta_seconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "type": "time",
        "unit": "seconds",
        "version": "0514e9978f000e47c609125255de6d9536aed804334d426a9222e1347183702d",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_align": {
        "code": "class TimedeltaIndexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_align",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f5833d39497fb06bb05cac21fd9feeebace738d8e1cb626bea9fb0bbd86049ce",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_get_loc": {
        "code": "class TimedeltaIndexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.timedelta)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "25e9df433acdb6dcf3c1df99f789a41f9c774fba04d175a24c5b8688dad9a7f3",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_intersection": {
        "code": "class TimedeltaIndexing:\n    def time_intersection(self):\n        self.index.intersection(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_intersection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c3f027dc76eb6a9ef0eff1bc06dd59ee562b54fbdb029d2a6a6c4865601424c1",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_series_loc": {
        "code": "class TimedeltaIndexing:\n    def time_series_loc(self):\n        self.series.loc[self.timedelta]\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_series_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5902b5b4b32fc27d85bee9808b6014b1f9664e7f28f444e498a7d04083c92e05",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_shallow_copy": {
        "code": "class TimedeltaIndexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_shallow_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fae422a896cb1cff9173dd94eb799be107e0957d5845004660eed3d30e0540ba",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_union": {
        "code": "class TimedeltaIndexing:\n    def time_union(self):\n        self.index.union(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_union",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "266034126c423f3e411bf2195dc68cd983b6a181466b383df54ba9341232ad71",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_unique": {
        "code": "class TimedeltaIndexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_unique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "17ea4667001a64a4f9df8c9594ca120a6491a18edd28102cd5712c88535ac416",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof": {
        "code": "class AsOf:\n    def time_asof(self, constructor):\n        self.ts.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "37bd4ce5386fd0b7c34272d255acd943468380376dc1ee5dd9dea070fb806805",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof_nan": {
        "code": "class AsOf:\n    def time_asof_nan(self, constructor):\n        self.ts2.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof_nan",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "501dd990a898123eb091528ad6846c32abada27e5834f83a86729b32c4a0bcde",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof_nan_single": {
        "code": "class AsOf:\n    def time_asof_nan_single(self, constructor):\n        self.ts3.asof(self.date_last)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof_nan_single",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5607d6a56f2adf8c34116da998623d2111a97c21c45c0d1287f625a3ecda0055",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof_single": {
        "code": "class AsOf:\n    def time_asof_single(self, constructor):\n        self.ts.asof(self.date)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof_single",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "afe0b338280acc8cfed3251b3ee2abf5e165c63fe746d8032f062675bf9021ac",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof_single_early": {
        "code": "class AsOf:\n    def time_asof_single_early(self, constructor):\n        self.ts.asof(self.date_early)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof_single_early",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2ce4002d656f7b5513c14e1e36605c59ff9c7a0c53ce76a87dc70c83c7052b1c",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor(self, tz):\n        self.series.dt\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c4654d6ecec4d6eb77017231cdf50af038043ea4902f77696dfe07ccf474acbd",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_date": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_date(self, tz):\n        self.series.dt.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_date",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "094be7aa69f4d56549e49c066b297e49081304a97ea4b4099a49b4dc4bd7a42b",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_day_name": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_day_name(self, tz):\n        self.series.dt.day_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_day_name",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "df76b5c41131ea1ca919a20e8df2e83bba306d899e8870b93f5d9384ce80faa1",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_month_name": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_month_name(self, tz):\n        self.series.dt.month_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_month_name",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9b5673999481df055b0f075354fdf3e35bd5b1607adbe41ebe9f93f1ade8fbc4",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_normalize": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_normalize(self, tz):\n        self.series.dt.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_normalize",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f72f5ac1e6051cfb422cd5c2e7d24d223f12e59d0e999c03edad788b7a625078",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_time": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_time(self, tz):\n        self.series.dt.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_time",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7f9eb32f2fbf8aee4af73e69833ddc753487025f72b66b7880110bb5a972edc1",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_year": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_year(self, tz):\n        self.series.dt.year\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_year",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cc33ec3abfe516cac3685bdca04c77540a7b773f1f8ac33dbbea439353070373",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_add_timedelta": {
        "code": "class DatetimeIndex:\n    def time_add_timedelta(self, index_type):\n        self.index + timedelta(minutes=2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_add_timedelta",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1298590f12ff60438ee82782f6cb66df435c77f26bd8a574d98fed569ca2b127",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_get": {
        "code": "class DatetimeIndex:\n    def time_get(self, index_type):\n        self.index[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_get",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "89ec08b759e4b4b38fd3b04ca3b8c07579d2e76e771ddabc2dbf2e086be1206f",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_is_dates_only": {
        "code": "class DatetimeIndex:\n    def time_is_dates_only(self, index_type):\n        self.index._is_dates_only\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_is_dates_only",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "05d01dfb62d23729c918fb360748b143555963b32f4cf61cb539a8bc05ca358b",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_normalize": {
        "code": "class DatetimeIndex:\n    def time_normalize(self, index_type):\n        self.index.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_normalize",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ca5039cfd4ea100f42b401e5adc4fec5a27a4727e781e20af9e2cf6f74b07b68",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_timeseries_is_month_start": {
        "code": "class DatetimeIndex:\n    def time_timeseries_is_month_start(self, index_type):\n        self.index.is_month_start\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_timeseries_is_month_start",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "eff9b3be0946643635ef49382acfb8e570bda84292d1296f9f6e6213393d8f8e",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_to_date": {
        "code": "class DatetimeIndex:\n    def time_to_date(self, index_type):\n        self.index.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_to_date",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "dd2bebb8b3ed2ab476d0ef8661ecd7c8def6d4efbbed55849357f7781a3b0be8",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_to_pydatetime": {
        "code": "class DatetimeIndex:\n    def time_to_pydatetime(self, index_type):\n        self.index.to_pydatetime()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_to_pydatetime",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "54fb10c75741cf7897f5ac51da9f1c369bf503d921df5ed999155a06d9f669e7",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_to_time": {
        "code": "class DatetimeIndex:\n    def time_to_time(self, index_type):\n        self.index.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_to_time",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7c6798dd8a6859a5f62025b29470444fb1ffe43cfcb4a5738ba6c40619392699",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_unique": {
        "code": "class DatetimeIndex:\n    def time_unique(self, index_type):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_unique",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4a214dbb167f02d37caab9b8ba6fe10cb4acf8cb9588840b79e7f693da0f4095",
        "warmup_time": -1
    },
    "timeseries.InferFreq.time_infer_freq": {
        "code": "class InferFreq:\n    def time_infer_freq(self, freq):\n        infer_freq(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InferFreq:\n    def setup(self, freq):\n        if freq is None:\n            self.idx = date_range(start=\"1/1/1700\", freq=\"D\", periods=10000)\n            self.idx._data._freq = None\n        else:\n            self.idx = date_range(start=\"1/1/1700\", freq=freq, periods=10000)",
        "min_run_count": 2,
        "name": "timeseries.InferFreq.time_infer_freq",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "None",
                "'D'",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "52f02044de50a1a68041e7526ab41b12d85500472c7652ce485fa54cfe87ecc0",
        "warmup_time": -1
    },
    "timeseries.Iteration.time_iter": {
        "code": "class Iteration:\n    def time_iter(self, time_index):\n        for _ in self.idx:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"min\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"min\", periods=N)\n        self.exit = 10000",
        "min_run_count": 2,
        "name": "timeseries.Iteration.time_iter",
        "number": 0,
        "param_names": [
            "time_index"
        ],
        "params": [
            [
                "<function date_range>",
                "<function period_range>",
                "<function timedelta_range>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "7462a5f79cb42d4bd08d938457631a39d3b1fe203fef2eaca6dd612ccf0956a7",
        "warmup_time": -1
    },
    "timeseries.Iteration.time_iter_preexit": {
        "code": "class Iteration:\n    def time_iter_preexit(self, time_index):\n        for i, _ in enumerate(self.idx):\n            if i > self.exit:\n                break\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"min\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"min\", periods=N)\n        self.exit = 10000",
        "min_run_count": 2,
        "name": "timeseries.Iteration.time_iter_preexit",
        "number": 0,
        "param_names": [
            "time_index"
        ],
        "params": [
            [
                "<function date_range>",
                "<function period_range>",
                "<function timedelta_range>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8c6848d29bdf8fb903dbbb06fcb0a6ef5405d6f4d2d02679fb20236f69ff6070",
        "warmup_time": -1
    },
    "timeseries.Lookup.time_lookup_and_cleanup": {
        "code": "class Lookup:\n    def time_lookup_and_cleanup(self):\n        self.ts[self.lookup_val]\n        self.ts.index._cleanup()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        N = 1500000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.ts = Series(1, index=rng)\n        self.lookup_val = rng[N // 2]",
        "min_run_count": 2,
        "name": "timeseries.Lookup.time_lookup_and_cleanup",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "622243e3fbc3f77c3a07df1366425577e34f93696a149766f75e2f67ebbdfbfe",
        "warmup_time": -1
    },
    "timeseries.ResampleDataFrame.time_method": {
        "code": "class ResampleDataFrame:\n    def time_method(self, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDataFrame:\n    def setup(self, method):\n        rng = date_range(start=\"20130101\", periods=100000, freq=\"50ms\")\n        df = DataFrame(np.random.randn(100000, 2), index=rng)\n        self.resample = getattr(df.resample(\"1s\"), method)",
        "min_run_count": 2,
        "name": "timeseries.ResampleDataFrame.time_method",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'max'",
                "'mean'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a4fb6ef3ce886b50c0e792fa873de3cd9aee12fb92d9f2952dd99045ea9ca6d4",
        "warmup_time": -1
    },
    "timeseries.ResampleDatetetime64.time_resample": {
        "code": "class ResampleDatetetime64:\n    def time_resample(self):\n        self.dt_ts.resample(\"1s\").last()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDatetetime64:\n    def setup(self):\n        rng3 = date_range(\n            start=\"2000-01-01 00:00:00\", end=\"2000-01-01 10:00:00\", freq=\"555000us\"\n        )\n        self.dt_ts = Series(5, rng3, dtype=\"datetime64[ns]\")",
        "min_run_count": 2,
        "name": "timeseries.ResampleDatetetime64.time_resample",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0983037197a0d6923106eac1e156d4ea4fbaeb06a934c6d00f4af0240931e319",
        "warmup_time": -1
    },
    "timeseries.ResampleSeries.time_resample": {
        "code": "class ResampleSeries:\n    def time_resample(self, index, freq, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleSeries:\n    def setup(self, index, freq, method):\n        indexes = {\n            \"period\": period_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"min\"),\n            \"datetime\": date_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"min\"),\n        }\n        idx = indexes[index]\n        ts = Series(np.random.randn(len(idx)), index=idx)\n        self.resample = getattr(ts.resample(freq), method)",
        "min_run_count": 2,
        "name": "timeseries.ResampleSeries.time_resample",
        "number": 0,
        "param_names": [
            "index",
            "freq",
            "method"
        ],
        "params": [
            [
                "'period'",
                "'datetime'"
            ],
            [
                "'5min'",
                "'1D'"
            ],
            [
                "'mean'",
                "'ohlc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "55b0e708ae03f83acfe58adc721a2552d94d0f4c55f29b01731e881a672a4338",
        "warmup_time": -1
    },
    "timeseries.ResetIndex.time_reset_datetimeindex": {
        "code": "class ResetIndex:\n    def time_reset_datetimeindex(self, tz):\n        self.df.reset_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResetIndex:\n    def setup(self, tz):\n        idx = date_range(start=\"1/1/2000\", periods=1000, freq=\"h\", tz=tz)\n        self.df = DataFrame(np.random.randn(1000, 2), index=idx)",
        "min_run_count": 2,
        "name": "timeseries.ResetIndex.time_reset_datetimeindex",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "69f268ece46afbbdef1c2696b72b004a1ea89cb77eef5125c1ef70576c922b24",
        "warmup_time": -1
    },
    "timeseries.SortIndex.time_get_slice": {
        "code": "class SortIndex:\n    def time_get_slice(self, monotonic):\n        self.s[:10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)",
        "min_run_count": 2,
        "name": "timeseries.SortIndex.time_get_slice",
        "number": 0,
        "param_names": [
            "monotonic"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0a9e9e75d9711805af9e2bd23525b886c146db147bda183e7c62c68212a7d2af",
        "warmup_time": -1
    },
    "timeseries.SortIndex.time_sort_index": {
        "code": "class SortIndex:\n    def time_sort_index(self, monotonic):\n        self.s.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)",
        "min_run_count": 2,
        "name": "timeseries.SortIndex.time_sort_index",
        "number": 0,
        "param_names": [
            "monotonic"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4e3d97e97d12382b09d20e93cc00244951e5d85c15eb06dd5e57dc55c553db37",
        "warmup_time": -1
    },
    "timeseries.TimeDatetimeConverter.time_convert": {
        "code": "class TimeDatetimeConverter:\n    def time_convert(self):\n        DatetimeConverter.convert(self.rng, None, None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeDatetimeConverter:\n    def setup(self):\n        N = 100000\n        self.rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")",
        "min_run_count": 2,
        "name": "timeseries.TimeDatetimeConverter.time_convert",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "79f58665e747b6d28bf6b6a355cb6518597a5b4f0bb838b47ca93e0e6e7d19b7",
        "warmup_time": -1
    },
    "timeseries.TzLocalize.time_infer_dst": {
        "code": "class TzLocalize:\n    def time_infer_dst(self, tz):\n        self.index.tz_localize(tz, ambiguous=\"infer\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TzLocalize:\n    def setup(self, tz):\n        dst_rng = date_range(\n            start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n        )\n        self.index = date_range(start=\"10/29/2000\", end=\"10/29/2000 00:59:59\", freq=\"s\")\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(\n            date_range(start=\"10/29/2000 2:00:00\", end=\"10/29/2000 3:00:00\", freq=\"s\")\n        )",
        "min_run_count": 2,
        "name": "timeseries.TzLocalize.time_infer_dst",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ed09ad3f4f73b8252ef5fb6874b8019d0077dae5d4ef1828a52519d880aef55b",
        "warmup_time": -1
    },
    "tslibs.fields.TimeGetDateField.time_get_date_field": {
        "code": "class TimeGetDateField:\n    def time_get_date_field(self, size, field):\n        get_date_field(self.i8data, field)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeGetDateField:\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.fields.TimeGetDateField.time_get_date_field",
        "number": 0,
        "param_names": [
            "size",
            "field"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "'Y'",
                "'M'",
                "'D'",
                "'h'",
                "'m'",
                "'s'",
                "'us'",
                "'ns'",
                "'doy'",
                "'dow'",
                "'woy'",
                "'q'",
                "'dim'",
                "'is_leap_year'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fa11fee9605cb60559821a23f251696b5ee45b9cf0483c05fc58ee3da8954228",
        "warmup_time": -1
    },
    "tslibs.fields.TimeGetStartEndField.time_get_start_end_field": {
        "code": "class TimeGetStartEndField:\n    def time_get_start_end_field(self, size, side, period, freqstr, month_kw):\n        get_start_end_field(self.i8data, self.attrname, freqstr, month_kw=month_kw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeGetStartEndField:\n    def setup(self, size, side, period, freqstr, month_kw):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n    \n        self.attrname = f\"is_{period}_{side}\"",
        "min_run_count": 2,
        "name": "tslibs.fields.TimeGetStartEndField.time_get_start_end_field",
        "number": 0,
        "param_names": [
            "size",
            "side",
            "period",
            "freqstr",
            "month_kw"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "'start'",
                "'end'"
            ],
            [
                "'month'",
                "'quarter'",
                "'year'"
            ],
            [
                "'B'",
                "None",
                "'QS'"
            ],
            [
                "12",
                "3",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fa79a0f2cad977700429fcc398c6e468de4851429f899f1fd3468f6f3445b488",
        "warmup_time": -1
    },
    "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field": {
        "code": "class TimeGetTimedeltaField:\n    def time_get_timedelta_field(self, size, field):\n        get_timedelta_field(self.i8data, field)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeGetTimedeltaField:\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n        arr = np.random.randint(-86400 * 1_000_000_000, 0, size=size, dtype=\"i8\")\n        self.i8data_negative = arr",
        "min_run_count": 2,
        "name": "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field",
        "number": 0,
        "param_names": [
            "size",
            "field"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "'seconds'",
                "'microseconds'",
                "'nanoseconds'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2062d9b02d31b3cccc19774c8b4ffe829394496dd2967d6865382a6815150bd8",
        "warmup_time": -1
    },
    "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field_negative_td": {
        "code": "class TimeGetTimedeltaField:\n    def time_get_timedelta_field_negative_td(self, size, field):\n        get_timedelta_field(self.i8data_negative, field)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeGetTimedeltaField:\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n        arr = np.random.randint(-86400 * 1_000_000_000, 0, size=size, dtype=\"i8\")\n        self.i8data_negative = arr",
        "min_run_count": 2,
        "name": "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field_negative_td",
        "number": 0,
        "param_names": [
            "size",
            "field"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "'seconds'",
                "'microseconds'",
                "'nanoseconds'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3214622052a495d757444a8caec211b0f78d5a29b9c47d223ce19cec7b3db21a",
        "warmup_time": -1
    },
    "tslibs.normalize.Normalize.time_is_date_array_normalized": {
        "code": "class Normalize:\n    def time_is_date_array_normalized(self, size, tz):\n        # TODO: cases with different levels of short-circuiting\n        # 10 i.e. NPY_FR_ns\n        is_date_array_normalized(self.i8data, tz, 10)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "tslibs.normalize.Normalize.time_is_date_array_normalized",
        "number": 0,
        "param_names": [
            "size",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8a0062a64c2f0559eaee437a8eeefbae5c75e27db5faf86541286085b875a6d2",
        "warmup_time": -1
    },
    "tslibs.normalize.Normalize.time_normalize_i8_timestamps": {
        "code": "class Normalize:\n    def time_normalize_i8_timestamps(self, size, tz):\n        # 10 i.e. NPY_FR_ns\n        normalize_i8_timestamps(self.i8data, tz, 10)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "tslibs.normalize.Normalize.time_normalize_i8_timestamps",
        "number": 0,
        "param_names": [
            "size",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "90e93c0bf30f84159194f95da549370de993eadd2b9924b3bc6dc1d0ac05889e",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_add": {
        "code": "class OffestDatetimeArithmetic:\n    def time_add(self, offset):\n        self.date + offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "bfb2ef7f8d94ebf443a43ab768a426b24846a01bcb9e60873cfca5ac9d84acbb",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_add_10": {
        "code": "class OffestDatetimeArithmetic:\n    def time_add_10(self, offset):\n        self.date + (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_10",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "412f51bfc037b5b10f23387d475123e2c8ebd62a69e6a5692a07f7924f5149ac",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_add_np_dt64": {
        "code": "class OffestDatetimeArithmetic:\n    def time_add_np_dt64(self, offset):\n        offset + self.dt64\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_np_dt64",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1165522291f90bef9f0aa75d6407828206ad6efc49a2b7023f47fdfd998851fa",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_subtract": {
        "code": "class OffestDatetimeArithmetic:\n    def time_subtract(self, offset):\n        self.date - offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "775bbe2574e947fdebb23ba6451a8510d68d5dfaf0e0813a6967a39209d770fc",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10": {
        "code": "class OffestDatetimeArithmetic:\n    def time_subtract_10(self, offset):\n        self.date - (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f0a5bf6590a5f4e89c95b4b22ecc27ec52e4cb03e8255cef5009879bb71dbc69",
        "warmup_time": -1
    },
    "tslibs.offsets.OnOffset.time_on_offset": {
        "code": "class OnOffset:\n    def time_on_offset(self, offset):\n        for date in self.dates:\n            offset.is_on_offset(date)\n\n    def setup(self, offset):\n        self.dates = [\n            datetime(2016, m, d)\n            for m in [10, 11, 12]\n            for d in [1, 2, 3, 28, 29, 30, 31]\n            if not (m == 11 and d == 31)\n        ]",
        "min_run_count": 2,
        "name": "tslibs.offsets.OnOffset.time_on_offset",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ae5cbac53a07afd70222f6a228bac6518d5df75e369f5e8450db66831ba8afa2",
        "warmup_time": -1
    },
    "tslibs.period.PeriodConstructor.time_period_constructor": {
        "code": "class PeriodConstructor:\n    def time_period_constructor(self, freq, is_offset):\n        Period(\"2012-06-01\", freq=freq)\n\n    def setup(self, freq, is_offset):\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodConstructor.time_period_constructor",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d98fc24ec3bee7645af5de9f3e7af5e28f028c74e4785bda4ceb36f1d46a671d",
        "warmup_time": -1
    },
    "tslibs.period.PeriodProperties.time_property": {
        "code": "class PeriodProperties:\n    def time_property(self, freq, attr):\n        getattr(self.per, attr)\n\n    def setup(self, freq, attr):\n        self.per = Period(\"2012-06-01\", freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodProperties.time_property",
        "number": 0,
        "param_names": [
            "freq",
            "attr"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ],
            [
                "'year'",
                "'month'",
                "'day'",
                "'hour'",
                "'minute'",
                "'second'",
                "'is_leap_year'",
                "'quarter'",
                "'qyear'",
                "'week'",
                "'daysinmonth'",
                "'dayofweek'",
                "'dayofyear'",
                "'start_time'",
                "'end_time'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6c0fa44f9b9f197537446c79ae6f7ce95ab1d18e2e68b5acb2a96103c097f4c6",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_asfreq": {
        "code": "class PeriodUnaryMethods:\n    def time_asfreq(self, freq):\n        self.per.asfreq(\"Y\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_asfreq",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f7636fac37be75ac435c3f2c26c70c768d8d6ac6a2f2ec4147c53e28bd84e016",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_now": {
        "code": "class PeriodUnaryMethods:\n    def time_now(self, freq):\n        self.per.now(freq)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_now",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ca497c2d273dcef636fd17b5cea2c596ea5d0e00aeb08e468f29db99e141026b",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_repr": {
        "code": "class PeriodUnaryMethods:\n    def time_repr(self, freq):\n        repr(self.per)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_repr",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "61db62d1d01fccdc5715ddf23d9ee8a51342bcf44f53ef99823dc6c5c23ccd95",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_str": {
        "code": "class PeriodUnaryMethods:\n    def time_str(self, freq):\n        str(self.per)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_str",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8d0bcff5d02fdbae27d445ee63fb0f76ca46a7b3470124eb29f12fb7d2e8fe92",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_strftime_custom": {
        "code": "class PeriodUnaryMethods:\n    def time_strftime_custom(self, freq):\n        self.per.strftime(\"%b. %d, %Y was a %A\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_strftime_custom",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6c1e84f9e7ff08f4aa2690c6ffd1b1031f1c278b0054d9070885809726493eb5",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_strftime_default": {
        "code": "class PeriodUnaryMethods:\n    def time_strftime_default(self, freq):\n        self.per.strftime(None)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_strftime_default",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a72f29d38796a94ca930f1af6cc6420afa2c6a70670e067a947c4b6a5240d08b",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_strftime_default_explicit": {
        "code": "class PeriodUnaryMethods:\n    def time_strftime_default_explicit(self, freq):\n        self.per.strftime(self.default_fmt)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_strftime_default_explicit",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "68d6b14934e4f96084f7276c1f9cb2ca0f3cec4f1132c94b1347849287da909f",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_to_timestamp": {
        "code": "class PeriodUnaryMethods:\n    def time_to_timestamp(self, freq):\n        self.per.to_timestamp()\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_to_timestamp",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "622b732f215b2fcad912dbef729ddb69296d8e499bf7c12df2048003b7253980",
        "warmup_time": -1
    },
    "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr": {
        "code": "class TimeDT64ArrToPeriodArr:\n    def time_dt64arr_to_periodarr(self, size, freq, tz):\n        dt64arr_to_periodarr(self.i8values, freq, tz)\n\n    def setup(self, size, freq, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        # we pick 2**55 because smaller values end up returning\n        # -1 from npy_datetimestruct_to_datetime with NPY_FR_Y frequency\n        # this artificially slows down functions since -1 is also the\n        # error sentinel\n        arr = np.arange(2**55, 2**55 + 10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr",
        "min_run_count": 2,
        "name": "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr",
        "number": 0,
        "param_names": [
            "size",
            "freq",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "1000",
                "1011",
                "2000",
                "2011",
                "3000",
                "4000",
                "4006",
                "5000",
                "6000",
                "7000",
                "8000",
                "9000",
                "10000",
                "11000",
                "12000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ae34f49e649e17a7c1cd4e91306253105adec71ba2612a4c890005782d8339c6",
        "warmup_time": -1
    },
    "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr": {
        "code": "class TimePeriodArrToDT64Arr:\n    def time_periodarray_to_dt64arr(self, size, freq):\n        periodarr_to_dt64arr(self.i8values, freq)\n\n    def setup(self, size, freq):\n        arr = np.arange(10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr",
        "min_run_count": 2,
        "name": "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr",
        "number": 0,
        "param_names": [
            "size",
            "freq"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "1000",
                "1011",
                "2000",
                "2011",
                "3000",
                "4000",
                "4006",
                "5000",
                "6000",
                "7000",
                "8000",
                "9000",
                "10000",
                "11000",
                "12000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "780a003a3675ffce34b1163502be5f0eb10d3e9c8e10d3a8f2ce56387e643da2",
        "warmup_time": -1
    },
    "tslibs.resolution.TimeResolution.time_get_resolution": {
        "code": "class TimeResolution:\n    def time_get_resolution(self, unit, size, tz):\n        get_resolution(self.i8data, tz)\n\n    def setup(self, unit, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        arr = arr.view(f\"M8[{unit}]\").astype(\"M8[ns]\").view(\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.resolution.TimeResolution.time_get_resolution",
        "number": 0,
        "param_names": [
            "unit",
            "size",
            "tz"
        ],
        "params": [
            [
                "'D'",
                "'h'",
                "'m'",
                "'s'",
                "'us'",
                "'ns'"
            ],
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "31259509175475d91c89e0d7ed2c1aeb7f584c1ef106af6b79c15883759acb97",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_components": {
        "code": "class TimedeltaConstructor:\n    def time_from_components(self):\n        Timedelta(\n            days=1,\n            hours=2,\n            minutes=3,\n            seconds=4,\n            milliseconds=5,\n            microseconds=6,\n            nanoseconds=7,\n        )\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_components",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "976de79734124e410aadd9f6fdb589658515fb75c3456c6c5003df04e31495c8",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta": {
        "code": "class TimedeltaConstructor:\n    def time_from_datetime_timedelta(self):\n        Timedelta(self.dttimedelta)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3326b70bfe99c2a6a044540b5db8b882ec1b999993fff273029767c5717f11db",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_int": {
        "code": "class TimedeltaConstructor:\n    def time_from_int(self):\n        Timedelta(123456789)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ebc3b0e00ba7cba6a0d3e95134a6f1c56543605b5c4f0337fd76a0b846078e4d",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format": {
        "code": "class TimedeltaConstructor:\n    def time_from_iso_format(self):\n        Timedelta(\"P4DT12H30M5S\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a16446c3495768b14e84c7b2e947bdfbb1fb7558e73cd969d79d2fddd94f4961",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_missing": {
        "code": "class TimedeltaConstructor:\n    def time_from_missing(self):\n        Timedelta(\"nat\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_missing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee87e86713ff7adca408473446c87ca651516e45b5a7c43b9142fead580aad84",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta": {
        "code": "class TimedeltaConstructor:\n    def time_from_np_timedelta(self):\n        Timedelta(self.nptimedelta64)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a8fe79df54c66d13d34089a76ce37bd86f35e6da129e6de26dd0235934789c8c",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta": {
        "code": "class TimedeltaConstructor:\n    def time_from_pd_timedelta(self):\n        Timedelta(self.td)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "831bac3969b78367fedc8c945ad8667ac98baab3994380c2c72b8a30c1516c50",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_string": {
        "code": "class TimedeltaConstructor:\n    def time_from_string(self):\n        Timedelta(\"1 days\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8da4af162b193652f720feee641b52568c67cc80c2eef6d146965283fb04bc8d",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_unit": {
        "code": "class TimedeltaConstructor:\n    def time_from_unit(self):\n        Timedelta(1, unit=\"D\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_unit",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "847323667685ed5b43d8b14581d093b940ce61c95df2d08c156c1da8cd993cd5",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaProperties.time_timedelta_days": {
        "code": "class TimedeltaProperties:\n    def time_timedelta_days(self, td):\n        td.days\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_days",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "tslibs.timedelta:56",
        "type": "time",
        "unit": "seconds",
        "version": "027721dc928a0aac947e4eb804535d4414cc57804449f21a50097455e1eb34cc",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds": {
        "code": "class TimedeltaProperties:\n    def time_timedelta_microseconds(self, td):\n        td.microseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "tslibs.timedelta:56",
        "type": "time",
        "unit": "seconds",
        "version": "1c88f64d84fd4aa67383bda6396ed221e9b5a7fb816a7ff3ab0788a108b0c6c8",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds": {
        "code": "class TimedeltaProperties:\n    def time_timedelta_nanoseconds(self, td):\n        td.nanoseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "tslibs.timedelta:56",
        "type": "time",
        "unit": "seconds",
        "version": "458eb6a15687e81995044a9cf3b9938fdf6724c379b347d74c6fcb101204008b",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds": {
        "code": "class TimedeltaProperties:\n    def time_timedelta_seconds(self, td):\n        td.seconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "tslibs.timedelta:56",
        "type": "time",
        "unit": "seconds",
        "version": "16d230d4bbe759fe887153a89399d0eb5eebbf999155cbe9ec2fdfef09305b0c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst": {
        "code": "class TimestampAcrossDst:\n    def time_replace_across_dst(self):\n        self.ts2.replace(tzinfo=self.tzinfo)\n\n    def setup(self):\n        dt = datetime(2016, 3, 27, 1, fold=0)\n        self.tzinfo = dt.astimezone(zoneinfo.ZoneInfo(\"Europe/Berlin\")).tzinfo\n        self.ts2 = Timestamp(dt)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d6e90f7d3f0abfe1f318015d95176bae16b3feb28afb05377278fa7d790089f0",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware": {
        "code": "class TimestampConstruction:\n    def time_from_datetime_aware(self):\n        Timestamp(self.dttime_aware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8a030bf8ec780cb4dc5e1625c8d736c9b81c2ff243e43d42f464f567e813d6e0",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware": {
        "code": "class TimestampConstruction:\n    def time_from_datetime_unaware(self):\n        Timestamp(self.dttime_unaware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "983c9adb7fdbba5a99bd19eb8252ca74c5dcb49c1a1cf758774b62e84f2a87f3",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64": {
        "code": "class TimestampConstruction:\n    def time_from_npdatetime64(self):\n        Timestamp(self.npdatetime64)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f1f26896f458efeef6da817aad5e1d4c30bc86b09d6ee0a8783fae7daf0443bf",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp": {
        "code": "class TimestampConstruction:\n    def time_from_pd_timestamp(self):\n        Timestamp(self.ts)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1c4fe914accb797d939c2c07e58cd473c68a7c8ac0027fb851219b69f5c2bed7",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_fromordinal": {
        "code": "class TimestampConstruction:\n    def time_fromordinal(self):\n        Timestamp.fromordinal(730120)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_fromordinal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "96b6e5064dce0499a6d4a0df4e3756e57651147b2bec00bd32a6cb5be90bd004",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_fromtimestamp": {
        "code": "class TimestampConstruction:\n    def time_fromtimestamp(self):\n        Timestamp.fromtimestamp(1515448538)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_fromtimestamp",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b3cb82296c78e7efb2c13f66d8221e5c7d13e42556333ed6bbbaf1df30f1e15d",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_dateutil": {
        "code": "class TimestampConstruction:\n    def time_parse_dateutil(self):\n        Timestamp(\"2017/08/25 08:16:14 AM\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_dateutil",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1b5e36ee973fd194d8b45f0e49c40d1b5ac8583640d7eee6ccf3378b8ae6a17e",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz": {
        "code": "class TimestampConstruction:\n    def time_parse_iso8601_no_tz(self):\n        Timestamp(\"2017-08-25 08:16:14\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e6370f5829a555c736196554bfab166d8886eb68763439e09b2cb5e22751db78",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz": {
        "code": "class TimestampConstruction:\n    def time_parse_iso8601_tz(self):\n        Timestamp(\"2017-08-25 08:16:14-0500\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1a1617ee722913b3a4942920b0e70ccb25c8e7a4dee81a6fae1a74ad0024045c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_now": {
        "code": "class TimestampConstruction:\n    def time_parse_now(self):\n        Timestamp(\"now\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_now",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e6772d97c449c0d7504f5f31da90d9ac3ec9724dcf9209895c3f2146f5c604b8",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_today": {
        "code": "class TimestampConstruction:\n    def time_parse_today(self):\n        Timestamp(\"today\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_today",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "08f0014d4ce59fd183e8d40386f2aa20ac9c28f5f9883a147e94c6d8c51d507c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_ceil": {
        "code": "class TimestampOps:\n    def time_ceil(self, tz):\n        self.ts.ceil(\"5min\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_ceil",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "baf73e231e602f7995c8b34f3b99e8b6c695160889ca1f755f19fd2c8b6e776e",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_floor": {
        "code": "class TimestampOps:\n    def time_floor(self, tz):\n        self.ts.floor(\"5min\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_floor",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ad9343f6d07a8c951d0913deffcfa58ae1e8dd7f188610392b097ce3ca19e11b",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_normalize": {
        "code": "class TimestampOps:\n    def time_normalize(self, tz):\n        self.ts.normalize()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_normalize",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f7688ade61af780f34bdb840481260073c8bfb88a7504a06758c91f033fb951d",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_replace_None": {
        "code": "class TimestampOps:\n    def time_replace_None(self, tz):\n        self.ts.replace(tzinfo=None)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_replace_None",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "395164d585e187bf1f2ecd1f965a26fe6f63a204fb26eb6daf8c2544e7895f5f",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_replace_tz": {
        "code": "class TimestampOps:\n    def time_replace_tz(self, tz):\n        self.ts.replace(tzinfo=zoneinfo.ZoneInfo(\"US/Eastern\"))\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_replace_tz",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fce499c8af56c528f3342003a6a8b10ce5c348bb960f1508673fe58b3360e009",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_to_julian_date": {
        "code": "class TimestampOps:\n    def time_to_julian_date(self, tz):\n        self.ts.to_julian_date()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_to_julian_date",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b986ab53361d72e7f0d0ea59b3584f48d6d6fc4994e87be9157f503231f22e70",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_to_pydatetime": {
        "code": "class TimestampOps:\n    def time_to_pydatetime(self, tz):\n        self.ts.to_pydatetime()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_to_pydatetime",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1db879395196c84d3fd8f358a23b86aaef86f45475d0f83716f8a546e489a627",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_tz_convert": {
        "code": "class TimestampOps:\n    def time_tz_convert(self, tz):\n        if self.ts.tz is not None:\n            self.ts.tz_convert(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_tz_convert",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "43ec3d5f390c7c62a00c06c942395078df2cc729fd8f92a4b0276815f342896d",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_tz_localize": {
        "code": "class TimestampOps:\n    def time_tz_localize(self, tz):\n        if self.ts.tz is None:\n            self.ts.tz_localize(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_tz_localize",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0ed9c18cc2666c8a010ac46b26f73181d886d5bad76c5a2e012111741777d94c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_dayofweek": {
        "code": "class TimestampProperties:\n    def time_dayofweek(self, tz):\n        self.ts.dayofweek\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_dayofweek",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e29f2f9d5602cdd3653692a09582476ebfd93e83ef6498019842c6cf6b8ec80a",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_dayofyear": {
        "code": "class TimestampProperties:\n    def time_dayofyear(self, tz):\n        self.ts.dayofyear\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_dayofyear",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "ee2f40845ecc6394591ee911396fc80479a217eeabf14738f0a9b516b7709a70",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_days_in_month": {
        "code": "class TimestampProperties:\n    def time_days_in_month(self, tz):\n        self.ts.days_in_month\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_days_in_month",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "17752b2964de1c685127ffa838ee3c5e3b0e2a8a63461dff3cba393207ee472e",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_leap_year": {
        "code": "class TimestampProperties:\n    def time_is_leap_year(self, tz):\n        self.ts.is_leap_year\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_leap_year",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e38d3b3704a4721bdc9af6bde865107faa0b6a19cceb1afc4db2be6abebcd5ef",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_month_end": {
        "code": "class TimestampProperties:\n    def time_is_month_end(self, tz):\n        self.ts.is_month_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_month_end",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "30c8d2e4ef76effa485342decbfb5349b1b96926523713ba746a85a9b4fc0819",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_month_start": {
        "code": "class TimestampProperties:\n    def time_is_month_start(self, tz):\n        self.ts.is_month_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_month_start",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0c562c955215c96790f0242b5ba277157e69be2c739e9e95472aa6dd0416d299",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_quarter_end": {
        "code": "class TimestampProperties:\n    def time_is_quarter_end(self, tz):\n        self.ts.is_quarter_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_end",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "03313e5f8997f2a2420815b1bcafdef5fcda6334d1bd7ef80f122b59e7403ebe",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_quarter_start": {
        "code": "class TimestampProperties:\n    def time_is_quarter_start(self, tz):\n        self.ts.is_quarter_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_start",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "280e8892418c358b39acbba39be3acbd1c294f244e50db4c4ebb0c364fadad1d",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_year_end": {
        "code": "class TimestampProperties:\n    def time_is_year_end(self, tz):\n        self.ts.is_year_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_year_end",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "eb42a1cc4fe4177b738115226d04b4e2536031f7159767c9709bbb7556c64831",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_year_start": {
        "code": "class TimestampProperties:\n    def time_is_year_start(self, tz):\n        self.ts.is_year_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_year_start",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5db3d7d1a89f3a35fe2a867c9046efedb39a0d8d9295b0880d0182689cb78a94",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_microsecond": {
        "code": "class TimestampProperties:\n    def time_microsecond(self, tz):\n        self.ts.microsecond\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_microsecond",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "657d803a947bd2ee87ff6e4f5fb74034cac717ea6c7234a95be94a19f3a9d926",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_month_name": {
        "code": "class TimestampProperties:\n    def time_month_name(self, tz):\n        self.ts.month_name()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_month_name",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "601bf8fc4cd6762f48b99ed3cf7cc263fd851d65febdfa88735ffb31ed02e55d",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_quarter": {
        "code": "class TimestampProperties:\n    def time_quarter(self, tz):\n        self.ts.quarter\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_quarter",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f822d240b6aab8f16f5cb4b0b15eb282a11540a85c12eb391cbf3adcd0dea0dd",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_tz": {
        "code": "class TimestampProperties:\n    def time_tz(self, tz):\n        self.ts.tz\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_tz",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c7f2fb57fa5899b99e67eed5aed5efb470cddf82e1f2a8f1c6472ba40e5ea021",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_week": {
        "code": "class TimestampProperties:\n    def time_week(self, tz):\n        self.ts.week\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_week",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cf7c5eef5480fb665a78f4c97bb9d21ac5d4a0141c4b107f915bcef238c4ceca",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_weekday_name": {
        "code": "class TimestampProperties:\n    def time_weekday_name(self, tz):\n        self.ts.day_name()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_weekday_name",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "72364a32ce479df795dde42a507109f4f6ff8450ba4212e2469d7c7c09785e31",
        "warmup_time": -1
    },
    "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime": {
        "code": "class TimeIntsToPydatetime:\n    def time_ints_to_pydatetime(self, box, size, tz):\n        ints_to_pydatetime(self.i8data, tz, box=box)\n\n    def setup(self, box, size, tz):\n        if box == \"date\" and tz is not None:\n            # tz is ignored, so avoid running redundant benchmarks\n            raise NotImplementedError  # skip benchmark\n        if size == 10**6 and tz is _tzs[-1]:\n            # This is cumbersomely-slow, so skip to trim runtime\n            raise NotImplementedError  # skip benchmark\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime",
        "number": 0,
        "param_names": [
            "box",
            "size",
            "tz"
        ],
        "params": [
            [
                "'time'",
                "'date'",
                "'datetime'",
                "'timestamp'"
            ],
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cc992ad9ce5601940faa38dd855be6b5df8a12c763443caf43906b262537aa5b",
        "warmup_time": -1
    },
    "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc": {
        "code": "class TimeTZConvert:\n    def time_tz_convert_from_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data, tz=tz)\n        #  dti.tz_localize(None)\n        if old_sig:\n            tz_convert_from_utc(self.i8data, timezone.utc, tz)\n        else:\n            tz_convert_from_utc(self.i8data, tz)\n\n    def setup(self, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc",
        "number": 0,
        "param_names": [
            "size",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "28c2d29c5fd5c54e8236ad66f2944a2805df7b88c82e32ff0d372b1f466cbe12",
        "warmup_time": -1
    },
    "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc": {
        "code": "class TimeTZConvert:\n    def time_tz_localize_to_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data)\n        #  dti.tz_localize(tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n        tz_localize_to_utc(self.i8data, tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n\n    def setup(self, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc",
        "number": 0,
        "param_names": [
            "size",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "zoneinfo.ZoneInfo(key='US/Pacific')",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3bcf7f94df95f8ab82da03b954dc9d477df030167d67f9ead7d5549deb4025d2",
        "warmup_time": -1
    },
    "version": 2
}