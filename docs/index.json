{"project": "pandas", "project_url": "https://pandas.pydata.org/", "show_commit_url": "https://github.com/pandas-dev/pandas/commit/", "hash_length": 8, "revision_to_hash": {"288": "4906ee79d730f77be02ec586ec7f66c95a0433da", "862": "9e406c50b77949433ed8f7fd094fd30b5421a35e", "874": "645d61131ad5acf768fff906a25e9e34b53efb92", "926": "cdc607c8ebd05419c0c446298a89814eac817459", "933": "ba1ff88c95b081741eb28c8630aaa6b0423900e0", "981": "35c6b68facf00788e9092d1fcedd53acbf99be89", "1029": "a8b14798fe18050e486845b26370d4899f46a8b3", "1084": "a0aa6a96d8a2456523d9f407d3f9f936f24dd7c8", "1185": "8f79f7c6e01874bbf7f3b9bc38af01551c90121e", "1194": "da3e95da95e1e07acc535b8e734b9b80a0972609", "1342": "010a620da89e5babc137b924dd1f632b4f6e6fee", "1440": "d5fbdcc26520d1c92b5dd73bb6e9a9902756ad16", "1632": "2ca93a17ed4609960f0ee3b8704b8b2edca1db5b", "1812": "06f608182ecd516abcd140531c65e07b30293eb0", "2072": "13f5db0ac0ba5a30d64866cdbd02b9985efa6303", "2077": "abc59ab02622560f226dd32bd068857053bc96d0", "2196": "776d80c2145ce4a4df1cf5c9ad21140b09df671d", "2247": "483ca398bd20ae42dd1a9d12f972634b384d560b", "2358": "4117b4fde3ffbc74a48b01f3a28f1f76b2db05fd", "2539": "9d0949396a8533d9fb9b0a6d0fb90a9f0ac16b23", "2555": "dfd7447e47562a941bb355af51c475823520f9e3", "3074": "5b98fdfeae2ef42d78242c4cca1e0959b9c710db", "3262": "fde270b20861fbf36d3063d504fb299d0b58695b", "3266": "a1d768829015796d16486cbc1e99020348901e25", "3344": "1c08383fc3cf24d503ae221c5d31b93899da6473", "3360": "5f5df2aa34f027d3fc83abb19cf7840ababd4557", "3361": "5d90f7d0e7e9bb53e55fdb7b70f972aa502004ed", "3393": "c91f6d1f62d02a65af78651f61f8db9a62c58b1b", "3412": "a901af2cdfe411d6aa9f9b1f6fa3223738f3e514", "3418": "f5a1bc9cda068f724d2de2ddc0da8ac2c518095b", "3494": "1c24700c3ba74419988e74319fd46e1f937c1f4d", "3551": "4e95b311bbf320d7b88edd6f8ce17194e48b8145", "3557": "23fa6f8b3d1f823dbafb64dc52e5a96fefe9236c", "3912": "e1b6e44bed02f47f59bf2d71c836f42f6e130dea", "3955": "6d9bd5a6374f1d6b4c18d3d53fc0413c82a16b49", "4026": "b5956fdc123b0208cf36fafc1b80a9671c66efbb", "4249": "2d576ee9b9337210a8c85f11e48177db42ecd57f", "4289": "9867f8af6e20cd2248626548f9b3f9a66b57789c", "4723": "78ce0ce8baef9c66bbee77083c0d12a47d5e294f", "4816": "1751bae723d336904bca81945097b3b700b11801", "5022": "31ecaa9d06f71b5d652d15441cf6b2dcc6f7e640", "5767": "258c7e3c5ec5dca7bec32308925b94267fbcff61", "5863": "f9eea308611152f1f7bb89981380fa5d85685f48", "6664": "b96ab6bddd5f2e84bd88a0659c4d98154819cffc", "6794": "8c0a34f15f8a87def3f7ad6ebdac052de44669f2", "7983": "16052e501adc3dedec3bf8cf65a7ea24300de1b1", "8139": "a5410ed841759badae2c3fe4cc71335c9dd6ad92", "8234": "db18d443dc0eac6454b864e179579619493899dc", "8327": "48c005ea761adcaf6b76a84aa94da0d35db8c6d6", "8680": "d10a658673b7d2c2e7a346461c9a4bfc5233d7e1", "9617": "76f6cf0050025ec5a6187e17957ea9a158cc2d56", "9713": "da0f7ae362bb0ee747c3c5c141327d1d8ba161bc", "10140": "d839555f5e080a981ce5faf89b4df7dfe0924541", "10501": "12248ffc942acf3a224922495102462c6999c804", "10793": "8dfbe09c1443334fc3036465712195a36c773f4b", "10853": "017adeaa4b70d63fe6c788db457dc9d31562f4d6", "10956": "d8ab3415373ea42713c096a97c3d9ed5c9cb82ee", "11042": "f1b270fcf5d505eebe4bf964f0541d6a43c3560e", "11188": "18ea1d856d45c87fe18a41d1a267ede46e10880e", "11528": "9e859f40c1651b38f9528aaccd211b1706cf317e", "11564": "c91bdbadfdbf9f60879ead8dd86bd1e72ca18ccf", "11906": "ca9eefc3c4733f368c054e33537ff18384114b43", "12077": "06832891870119984c6a5404bc7f7a471f43b99c", "12091": "6b1055c765c488e6fb411eed452abf75ff8df4bb", "12722": "9687145e06aed545c14630460d24a9693c9a0b39", "12860": "071cffd63e4b99362c68a5e2d472b629618c50a1", "12889": "fe48704835323c140846d1bde5e1387aa0cac3d4", "13158": "6c30cbecf8e5ae610f2a37ba821116bd9f77044d", "13520": "9259a56c600f6ea247a9c58c00af017790fe5e21", "13611": "e5ed87b33ab6cd9dade10df945bc5d7452310b7d", "13622": "e462ece64b7cb12fe7cad6e085f62f3bfe9785c6", "13832": "87b0f4dc1e91571cc4dd933b7cb181b99606ad20", "14278": "497a3bcbf6a1f97a9596278f78b9883b50a4c66f", "14326": "b97dbd01e49f54ae6fa8df382d6f6e4c771d2bc0", "14431": "27b783986230a3d044d045604b72a51acd13b7be", "14702": "825876ca7ee8ac7bea463925399c083d5f190b3e", "15296": "19fc8dac68e088126ffd132dc322dbf8a163ec69", "15353": "2002da33b0a755fcf7ef64b2c87ca4252f0e7df0", "15361": "a31c96d34d00dc757908b564dc93991e867d83e2", "15367": "e346c663cf76186c22f4d3b703461b1b60db280f", "15368": "e5134306bd47db9f6d0f125d2cafd0b8a789e065", "15570": "2814061730893bc8122caa4e01197c699da352e6", "15682": "3a7f956c30528736beaae5784f509a76d892e229", "16091": "c277cd76416d4e930b1f05da873b9eaf101139da", "16137": "81372093f1fdc0c07e4b45ba0f47b0360fabd405", "16138": "fc1e50733ea4c372f4c9eb3a53bf35e102d5d215", "16588": "7bb204a05fee20c3c825e7da39ccaf39fbeb8ca5", "16690": "fae79204e2b60ac1ff2b2309352ffb5d9382a017", "16717": "a00154dcfe5057cb3fd86653172e74b6893e337d", "17526": "44ccca1f3c27795322b979cf6e5dbd49422b5173", "17528": "b02c69ac7309ccf63a17471b25475bf0c0ebe3c3", "17585": "3147a86e1b20571766b488a8444c74cef29729ad", "17586": "2eb5a67999552d60f7a2a9e1922549d5417d714f", "17742": "1a23779f09abc6ebf908d66ee88b973b767e2e3c", "17912": "9b0f560a73d11b2fa72c48d7fd16126b5137f349", "17939": "edb71fda022c6a155717e7a25679040ee0476639", "18114": "0409521665bd436a10aea7e06336066bf07ff057", "19270": "fdc4db25a9988a7b595a3756760d05a6c177123d", "19350": "83eb2428ceb6257042173582f3f436c2c887aa69", "19351": "0c4113fa0906273007cc12a4bcadff85d943dc84", "19432": "1700680381bdbfbc1abe9774f96881801b24d6ca", "19667": "cb00deb94500205fcb27a33cc1d0df79a9727f8b", "20326": "2efb60717bda9fc64344c5f6647d58564930808e", "20419": "d1accd032b648c9affd6dce1f81feb9c99422483", "20420": "d48306e77c0a708e0ee33a2aa1da7e267df52ef6", "20693": "171c71611886aab8549a8620c5b0071a129ad685", "21092": "0efc71b53f019c6c5a8da7a38e08646ca75c17d9", "21228": "62a87bf4a2af02a8d3bc271ad26e5994292b8e6a", "22233": "d3f08566a80239a18a813ebda9a2ebb0368b1dc5", "22234": "b7fcb545a1a298817cd7d9f8940f19992d1202d2", "22534": "fd9ceb9dce3d62d8a9caa6ba7c127b512939452e", "22696": "29d6b0232aab9576afa896ff5bab0b994760495a", "23181": "7485dbe6fcdab3fe2e5a23534ba00767d50374d8", "23268": "3adf3340453d6704d4a2cb47058214cc697a7d29", "24127": "1ce1c3c1ef9894bf1ba79805f37514291f52a9da", "24334": "b687cd4d9e520666a956a60849568a98dd00c672", "24589": "bfac13628394ac7317bb94833319bd6bf87603af", "24599": "d9fff2792bf16178d4e450fe7384244e50635733", "24600": "d1b1faa3f68dad6163000784c34a66b8f6c227e1", "24766": "f2ca0a2665b2d169c97de87b8e778dbed86aea07", "24985": "2a7d3326dee660824a8433ffd01065f8ac37f7d6", "25335": "db08276bc116c438d3fdee492026f8223584c477", "25721": "67a3d4241ab84419856b84fc3ebc9abcbe66c6b3", "26254": "b5958ee1999e9aead1938c0bba2b674378807b3d", "26272": "7688d3cfebb7227c978cb386145c0d4924209efc", "26273": "0f587028e42d5444e2f0edbc0b4c889af16eae26", "26505": "3e89b4c4b1580aa890023fc550774e63d499da25", "26843": "9d598a5e1eee26df95b3910e3f2934890d062caa", "27074": "7d32926db8f7541c356066dcadabf854487738de", "27322": "f2c8480af2f25efdbd803218b9d87980f416563e", "27733": "2cb96529396d93b46abab7bbc73a208e708c642e", "28346": "3765b2099e6e2cb4d180edbb354045ae09a40269", "28347": "cff206be208c61146c0aead51ffacb5a15b4e31d", "28355": "2dd9e9ba9009a40191c0c0b96262fa3939d609f0", "28488": "7c48ff4409c622c582c56a5702373f726de08e96", "28580": "f00ed8f47020034e752baf0250483053340971b0", "28765": "c7f7443c1bad8262358114d5e88cd9c8a308e8aa", "28950": "5f648bf1706dd75a9ca0d29f26eadfbb595fe52b", "29202": "73c68257545b5f8530b7044f56647bd2db92e2ba", "29485": "945c9ed766a61c7d2c0a7cbb251b6edebf9cb7d5", "29966": "66e3805b8cabe977f40c05259cc3fcf7ead5687d", "30178": "d023ba755322e09b95fd954bbdc43f5be224688e", "30179": "7a4a85a0f76c81f8d03d5603baf626a9a068a655", "30387": "bb1f651536508cdfef8550f93ace7849b00046ee", "30635": "06d230151e6f18fdb8139d09abf539867a8cd481", "30959": "4bfe3d07b4858144c219b9346329027024102ab6", "31382": "e8093ba372f9adfe79439d90fe74b0b5b6dea9d6", "31772": "224458ee25d92ccdf289d1ae2741d178df4f323e", "31773": "573e7eaffd801ee5bd1f7685697b51eef5b8ed85", "31825": "ca60aab7340d9989d9428e11a51467658190bb6b", "31984": "87cfe4e38bafe7300a6003a1d18bd80f3f77c763", "32259": "91111fd99898d9dcaa6bf6bedb662db4108da6e6", "32630": "8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7", "33222": "2e218d10984e9919f0296931d92ea851c6a6faf5", "33589": "1a2e300170efc08cb509a0b4ff6248f8d55ae777", "33590": "09c6351374ca45ab621f448d0d7d160f0becbd76", "33911": "c2a7f1ae753737e589617ebaaff673070036d653", "34111": "478d340667831908b5b4bf09a2787a11a14560c9", "34390": "37ea63d540fd27274cad6585082c91b1283f963d", "34664": "965ceca9fd796940050d6fc817707bba1c4f9bff", "34934": "0f437949513225922d851e9581723d82120684a6", "35294": "1b2d39cbfc3db9520e0f5455a4eb3da0f569fa0f", "35295": "49ca01ba9023b677f2b2d1c42e99f45595258b74", "35491": "ba1cccd19da778f0c3a7d6a885685da16a072870", "35668": "e86ed377639948c64c429059127bcf5b359ab6be", "35914": "a60ad39b4a9febdea9a59d602dad44b1538b0ea5", "36024": "2a953cf80b77e4348bf50ed724f8abc0d814d9dd", "36334": "a671b5a8bf5dd13fb19f0e88edc679bc9e15c673", "36457": "dc37a6d035474c25932d805cfe50a47b04916a83", "36458": "d4c8d82b52045f49a0bb1d762968918a06886ae9", "36666": "f538741432edf55c6b9fb5d0d496d2dd1d7c2457", "36994": "bdc79c146c2e32f2cab629be240f01658cfb6cc2", "37314": "d9cdd2ee5a58015ef6f4d15c7226110c9aab8140", "38143": "0691c5cf90477d3503834d983f69350f250a6ff7", "38187": "0eb547b650d8eaa2b994fd7164e10121efb17b26", "38680": "fef01c5c58a72dd58e20c776bc30b21924131303", "38682": "1d33e4cedbb21b16917048358659bd96d1b8c8b6", "38683": "4c3b968a0a4de483c00d15bd267bc776a218337e", "38684": "60325b86e28edf40cb02444367efbc8deb2b5231", "38685": "222d7c7c5e3cc13d67facfa2d9bb7b6b03620a07", "38687": "be538ef0d07055113cbdbf9b3a22c4852c7fd6d7", "38688": "0c4ca3a9e4baa9b4fa8cbc81c57f2e2996636c10", "38689": "c168883f8f10e312e6d596d8d750a1e4647393c6", "38690": "d38706af66249ef74e42671a480261c68bedfbce", "38691": "354b61f88bc0523d4bb9f3cfe1d6c12f9a3d6567", "38695": "e3b2de852a87dc7b530302e0039730e7745b2fcf", "38697": "8fe27200e2d4ba1f9781f704becf889d7aa43c28", "38698": "f3045db91dbb89306c15b1673987cc70912a76b5", "38700": "84bf1ef82912ebf497a304b0ffd90914bfc41ea9", "38704": "e36b00035665d416fe10a3950880a6532eaf6131", "38705": "c0c778bdb75a54cf03cdfe76f5b3dadae6a67054", "38706": "8973c551895c2cd3619cadf554362e802b27e02a", "38707": "dec6eb29b35c884e78c82525e1bb30280208714c", "38709": "c430c613e6c712a39d07146b8adb083d55943840", "38710": "c36da3f6ded4141add4b3b16c252cedf4641e5ea", "38711": "ea7ff0ea4606f47a672f75793f4ea2b3eb0b87f5", "38712": "9b03dd4d22550403b75d74f8b54b422bd31c55f2", "38713": "d72f165eb327898b1597efe75ff8b54032c3ae7b", "38714": "f1441b218271178ebe18acecc3657f6549fb6c54", "38715": "a68048ea026f09fc56e1a9963c489ff0beaae651", "38716": "e4f6270a7b9338c439a6352fca8029be26d8e211", "38717": "2a49a4f218c3819e128cd1c8ea7fc9c1f2bdf92b", "38718": "569f94da9ecf0cd7c5eb565f5041b883726f6d3a", "38719": "4f664f156badac017c3775242559953a4da50b40", "38720": "3bd27ffa296398c974c19571ccacd1eea76ca034", "38721": "c6fc6d0d7978f3958264fd372f56edf686614dac", "38722": "e58bf26fa4d806f40624fb80d8321f2cc43d62a1", "38723": "e84a7f7b521d52812b227d9dab038f138373866f", "38724": "3866b98121e84b6fd01ed08de008372aa50e0841", "38725": "fc6da9c7f590ffd2eaec801060ee4b239fbf3d92", "38726": "e8306037a3a5782b18d3f8db81ae1dbde8ec21bf", "38727": "b2a7a262977391a09a49295dec4bebe0a120e316", "38728": "68569a683a9e1068a82397a113b6dd2d8fa9cdd1", "38729": "898bb02ec05d246bf4aa4f8f279c57d2a7716f9d", "38733": "1f106e06fd4829f6775dc90511dcbb6e7ab9f9c6", "38734": "348fd11b3c89fb7c91c35cb7cdfd302ba7b3d041", "38735": "aeb634aeb28b05c96c1fac3a8a33825e6227b7d9", "38736": "59e324f01530c46d91c890e5437828a42797f3c1", "38737": "dc315ee205e4e2dde7ba0c4c649ca81aeab6036e", "38738": "1cd4c63493960578c65c37e2902194c3b23baf82", "38739": "51b12e8d5fd67b22904aefda7cbadd4b83ef8970", "38740": "57340ecd08580f26ee4a976c1f68b2f563c41569", "38741": "0e245de0bd1b71f903bb16a03ff45fc6d7625946", "38742": "2cc9b21c9ad9b3df0f084b6d2e8462b1b78d4e8a", "38743": "51187b38c83d52a944434abe54cc0684d116608a", "38744": "70edaa0b4661df6f251f2e3d3ae5c55ef371fc74", "38745": "86c266840aef8dd7d7b692b385aa8ecbaf0371b8", "38746": "07d299343601cd6692d7a6c5adc74b274fff260f", "38747": "3979e954a339db9fc5e99b72ccb5ceda081c33e5", "38748": "d67055fee6654566d4ecb7cce66a8123f02c8323", "38749": "408abda757215e65e91b313d6b91b4db8ca799e8", "38750": "c5ea5248d8e1c3ec4e0414480e574b5f6710e377", "38751": "0d85d57b18b18e6b216ff081eac0952cb27d0e13", "38753": "5b16c06286000d923e35a1e4384e4bc7732a7691", "38755": "0a1577f2f0d1c9efda4b7b2d616177691d1ca73b", "38757": "3da2c1c14e8ad55d8cd22efee75e8477e4403997", "38758": "deafcf7ff3c7392f2153e7ed5faded5888131d4f", "38759": "9001cb2f080fded5af773d2f7e46c37a74c37cd0", "38760": "6309d04d0397953732faa11a8ab5d6104a913b82", "38761": "c9598ac6fbf7af68daa6d1a481da8257f3b5cf38", "38763": "e557039fda7d4325184cf76520892b3a635ec2dd", "38764": "4511251ccf409f2ba71cab0283bdf751697ee539", "38765": "d589aba2fc0227f59a9a99404ba50869ed2e5355", "38766": "a65e25d12937e4684452b20f58174bdd0cf77e7f", "38767": "ea3ff69042219a08adea3f26f78f9f7a9bd208f9", "38768": "859b8730a97b9d5a91e050609b1701bc1ad6f3cb", "38769": "a9a3047b6091114254250fa1f9120f4f925756cd", "38770": "4cccb7353786e7e9850c52ade00d66862c8e2e8a", "38771": "d14f7cf535a665f668f43fafc3fbeca6d28c4d11", "38772": "8f802cd01fd7cf83624d13e45a65c11dd2d221e2", "38773": "11e3dc2738befa5803aea676f1b68082a8b24a8b", "38774": "5e5da07104e710137bc73d9c0bf42078260e1b1c", "38775": "02de8140251096386cbefab0186d45af0c3d8ebd", "38777": "05de25381f71657bd425d2c4045d81a46b2d3740", "38780": "e3f544dc4f90e88e441a9f47e657ddc5564085e5", "38781": "b67668e5f7bf6f2e98e19615b00be22c16bc601a", "38782": "b601a0c88ce5345c0cfdb8b3c99222c61cea00b7", "38783": "03056560682bccd2a9e1ea1aa4c8d4914bd0fe89", "38784": "cb33796ee29625a5bb7a8f0449f821591fa2c8ff", "38785": "c73b380501220a692523d50cf9e74a9998a50c5a", "38787": "19ea997815d4dadf490d7052a0a3c289be898588", "38788": "6bcd30397d67c3887288c7a82c2c235ce8bc3c7f", "38790": "ee06e714fcb35e0b6d321b3edd454eb0e363e5e4", "38791": "0ec5f2668e9568d90595180d5ee925305ec7182e", "38792": "f77398c36ad43361103ee0f2c3c6470bf5815b2d", "38793": "63249f2aa95ef0b0300ea2f1cc68200cc8b13484", "38794": "5b2cddb81aaf20237966ad40b9f9280956b3fd82", "38795": "d4dff29713faeb74931407ebd3e441253f883708", "38796": "4e20195086e5cdd5bde56da7d95cf672b795b32e", "38797": "4c3b573f53481721fb1bacadd27ccc3a4335dd1c", "38798": "e2e37913f7020d9fcff4a7755b78dd89cea31590", "38799": "fe494c96eccd79936caf9e1bdf506f873de2305d", "38800": "b9419276f7b1e121281fcf600a9028c69531ad7d", "38801": "1d8bbb7a39cdab23a1ea4eeec93de79e56d22489", "38804": "ddcec676d9a5adcb2435cc403d839964d332a677", "38805": "454b9d4fd7ad883bf1294aaf107e7bcfeb618cf6", "38806": "946862476929007644eeea7afba2d38e60f97df0", "38807": "f46d853365b5c7b91594205730b5db3d5430bd81", "38808": "48b1571100a3f127b2aa2391e6df7be015f861ce", "38810": "2b466c2b808f2e9711f598647791675fb250a38d", "38811": "6bd74fab5f2dfe3512ecbd2797808399411bd452", "38812": "d575eeaeed67828bc4ae53afb1ee74654a149fd8", "38814": "840cb1fadbe40bac50090d78cc777f32503e3852", "38815": "d246fe79358f6eb5e7e509991e0f866fb6518635", "38816": "10762c6607b5b5807db34571f889f5e91a57127c", "38817": "b666f7813edc8c844a5b477942948fff8defcd77", "38818": "311c640817460f3e2f47288a93c4a43d0f5a32b2", "38819": "d1ec1a4c9b58a9ebff482af2b918094e39d87893", "38820": "6e137f4ac6440019106bde6badfb12eb2a54304d", "38821": "f13cd4cee8f756a5b6745fac42fbccd2bd7aa9c8", "38822": "5da9eb726c915412928ee44a0631a74bda614556", "38823": "928fb7eb9fa0147760a41892e479c0ec2fb15bd8", "38824": "c28c5896b8f7bccf276758ec886194738dace890", "38825": "6e61cf44ee847b871e1651b55e5e24a59b1b993b", "38826": "a66f59c33aae5beca38dd7e66e4c0760a9a3aa5d", "38827": "bc34e2497f1471409f144fde89330a71bb8ba892", "38828": "57fd50221ea3d5de63d909e168f10ad9fc0eee9b", "38829": "e2e01859dc56739a86c07f4b6c6697ccc6ad6d0b", "38830": "8e9487abcbc986194d8663370537c0a4bd0df8e7", "38831": "826f0d3d8fca69e600e422b7a06522a45d24ce51", "38832": "938763edea1ca4c5343f4174f0af4e72088ccbda", "38833": "72839535bc0222686a97437457adb48edc531acb", "38834": "010ffe2bf0d49b005ddcc585c9f7092e0135eb28", "38835": "4f273801aef6480093617d2bb993917e2e6851e9", "38837": "9e2e65a0966f89a2c05f205e01aed48fe1961cd8", "38838": "c1e57c9e9e7ece934a3e157cf0ee32ea1ae5c029", "38839": "56847c56c59bc3edf8607aaacb4f2d1b544204b2", "38840": "c8811fb655001572691e8842467a15e0f2c8a7b3", "38841": "b8f6bacc6a989dab62b4cc7a11c86f0a68612437", "38842": "95280573e15be59036f98d82a8792599c10c6603", "38843": "f2c3144dfd8818456333ba6d1434d6d2dfa47f65", "38844": "e59a411a34f38342552ad215e278a3baddbfcd6b", "38845": "12d1dda92273042bdc853b52e26eee9ac9f1ebbe", "38846": "2030d9d6cf3b63aae7ac61c9e3586d4099e1f746", "38847": "7f58d742d888ece51db85b6c112c2e68442c2934", "38848": "bc24e84c9feeecdd04481505a9327bdb04143410", "38849": "0acb9a0f380d3f2205001f2327ae0a44f273e19d", "38850": "f1b00b8e373aad54c83585b94076f53ae8e89da9", "38851": "dab1b881da2d7d49200808f45942868f1953effa", "38852": "781182cbb00d5587e29a0cb7a3d27459a0f0a6dc", "38853": "513e78760a8faee6723908ca23ea83dcabc5dd77", "38854": "89bc204e94cda860085865081cd18cd1d130cec1", "38855": "40a81803e707a053af2612e67a7752fe6f6fa1b4", "38856": "cdc9e952f139746c2e6816997d82b389f605ec58", "38857": "3c93d06d641621ff62453c9c7748eeec3d6d8a97", "38859": "9537cf456270b6fa138e769337122b9f4074d7a8", "38860": "44c8f207f7ec45c37a8828bce42f9b574e828a4b", "38861": "ddd0aa8dc73481017330892dfd0ea95c0dfaa1d3", "38863": "8943c97c597677ae989d47e612705f088aab4cd0", "38864": "5d9cf431f7b774a6724b1dd4c5e6f6fe95647aff"}, "revision_to_date": {"288": 1298163988000, "862": 1315859521000, "874": 1316017084000, "926": 1317000085000, "933": 1317048249000, "981": 1317617173000, "1029": 1318197429000, "1084": 1318951906000, "1185": 1319509932000, "1194": 1320196542000, "1342": 1322277354000, "1440": 1323817436000, "1632": 1325734840000, "1812": 1327034032000, "2072": 1328826175000, "2077": 1328843532000, "2196": 1330553078000, "2247": 1330658997000, "2358": 1331927660000, "2539": 1334253112000, "2555": 1334276689000, "3074": 1338253482000, "3262": 1339519295000, "3266": 1339521874000, "3344": 1340247840000, "3360": 1340393682000, "3361": 1340394271000, "3393": 1340820112000, "3412": 1340986814000, "3418": 1340991466000, "3494": 1342184152000, "3551": 1342986141000, "3557": 1343003671000, "3912": 1348197360000, "3955": 1348710085000, "4026": 1349655420000, "4249": 1352505519000, "4289": 1352940069000, "4723": 1355269526000, "4816": 1355762888000, "5022": 1358831994000, "5767": 1365818352000, "5863": 1366678471000, "6664": 1373346771000, "6794": 1374697106000, "7983": 1385527286000, "8139": 1388422887000, "8234": 1389186315000, "8327": 1389878709000, "8680": 1391395738000, "9617": 1400278770000, "9713": 1401450122000, "10140": 1405035967000, "10501": 1410094321000, "10793": 1412642319000, "10853": 1413672736000, "10956": 1415452422000, "11042": 1416578711000, "11188": 1418306362000, "11528": 1426255236000, "11564": 1427031398000, "11906": 1431306604000, "12077": 1434192334000, "12091": 1434584708000, "12722": 1441988415000, "12860": 1443887330000, "12889": 1444306718000, "13158": 1448038103000, "13520": 1455378460000, "13611": 1457534291000, "13622": 1457732611000, "13832": 1462283462000, "14278": 1473277332000, "14326": 1475416385000, "14431": 1478182795000, "14702": 1482594798000, "15296": 1492832004000, "15353": 1493909668000, "15361": 1493951109000, "15367": 1494003581000, "15368": 1494012477000, "15570": 1496609647000, "15682": 1499446527000, "16091": 1507858703000, "16137": 1509117925000, "16138": 1509128814000, "16588": 1513050947000, "16690": 1514550565000, "16717": 1514663812000, "17526": 1525259813000, "17528": 1525272424000, "17585": 1526415166000, "17586": 1526438450000, "17742": 1528825328000, "17912": 1530828264000, "17939": 1530976196000, "18114": 1533316766000, "19270": 1547215888000, "19350": 1548430346000, "19351": 1548451808000, "19432": 1549228549000, "19667": 1552425131000, "20326": 1562213026000, "20419": 1563465802000, "20420": 1563479338000, "20693": 1566484565000, "21092": 1571414970000, "21228": 1572553014000, "22233": 1578605090000, "22234": 1578622290000, "22534": 1580334415000, "22696": 1580919329000, "23181": 1584024103000, "23268": 1584537529000, "24127": 1590671799000, "24334": 1592394604000, "24589": 1595012630000, "24599": 1595942099000, "24600": 1595964517000, "24766": 1597942487000, "24985": 1599582504000, "25335": 1601911652000, "25721": 1604062750000, "26254": 1607341330000, "26272": 1607430704000, "26273": 1607434178000, "26505": 1608990420000, "26843": 1611141662000, "27074": 1612868119000, "27322": 1614678216000, "27733": 1618243153000, "28346": 1623498340000, "28347": 1623500344000, "28355": 1623604768000, "28488": 1624355610000, "28580": 1625213575000, "28765": 1627203891000, "28950": 1629031534000, "29202": 1631440969000, "29485": 1634473678000, "29966": 1639304448000, "30178": 1641387616000, "30179": 1641391555000, "30387": 1642847731000, "30635": 1644656651000, "30959": 1648885576000, "31382": 1655980525000, "31772": 1661275106000, "31773": 1661275563000, "31825": 1661936829000, "31984": 1663583846000, "32259": 1666086298000, "32630": 1669008974000, "33222": 1674098803000, "33589": 1676924115000, "33590": 1676924793000, "33911": 1678978724000, "34111": 1680526113000, "34390": 1682295401000, "34664": 1685307768000, "34934": 1687987644000, "35294": 1691771053000, "35295": 1691771337000, "35491": 1693394639000, "35668": 1695237853000, "35914": 1698336491000, "36024": 1699636443000, "36334": 1702045055000, "36457": 1703272496000, "36458": 1703272729000, "36666": 1705711121000, "36994": 1708699767000, "37314": 1712770972000, "38143": 1726834910000, "38187": 1727866263000, "38680": 1737571305000, "38682": 1737581309000, "38683": 1737586102000, "38684": 1737617906000, "38685": 1737648226000, "38687": 1737656384000, "38688": 1737658435000, "38689": 1737741882000, "38690": 1737750089000, "38691": 1737751170000, "38695": 1737760578000, "38697": 1737824426000, "38698": 1737881051000, "38700": 1737890965000, "38704": 1738011265000, "38705": 1738020577000, "38706": 1738047547000, "38707": 1738087914000, "38709": 1738109842000, "38710": 1738188424000, "38711": 1738258305000, "38712": 1738437406000, "38713": 1738437505000, "38714": 1738527150000, "38715": 1738592603000, "38716": 1738604734000, "38717": 1738604768000, "38718": 1738604796000, "38719": 1738604830000, "38720": 1738605091000, "38721": 1738605181000, "38722": 1738606123000, "38723": 1738610407000, "38724": 1738620469000, "38725": 1738621339000, "38726": 1738639652000, "38727": 1738691448000, "38728": 1738691717000, "38729": 1738723709000, "38733": 1738777243000, "38734": 1738777281000, "38735": 1738777320000, "38736": 1738777354000, "38737": 1738777385000, "38738": 1738777432000, "38739": 1738777606000, "38740": 1738777736000, "38741": 1738777771000, "38742": 1738777897000, "38743": 1738783972000, "38744": 1738791982000, "38745": 1738862134000, "38746": 1738864387000, "38747": 1738866529000, "38748": 1738952822000, "38749": 1738954467000, "38750": 1738955253000, "38751": 1738957802000, "38753": 1738959903000, "38755": 1738971159000, "38757": 1739019134000, "38758": 1739040853000, "38759": 1739040893000, "38760": 1739040929000, "38761": 1739040972000, "38763": 1739041213000, "38764": 1739197432000, "38765": 1739211455000, "38766": 1739211535000, "38767": 1739211570000, "38768": 1739211613000, "38769": 1739211657000, "38770": 1739211699000, "38771": 1739211732000, "38772": 1739211807000, "38773": 1739211893000, "38774": 1739211951000, "38775": 1739211988000, "38777": 1739293730000, "38780": 1739383186000, "38781": 1739384427000, "38782": 1739392647000, "38783": 1739468486000, "38784": 1739485711000, "38785": 1739495456000, "38787": 1739498105000, "38788": 1739557189000, "38790": 1739783741000, "38791": 1739842260000, "38792": 1739898523000, "38793": 1739900390000, "38794": 1739907371000, "38795": 1739910958000, "38796": 1739932541000, "38797": 1739984853000, "38798": 1739985229000, "38799": 1740018924000, "38800": 1740071467000, "38801": 1740071927000, "38804": 1740072878000, "38805": 1740100361000, "38806": 1740161102000, "38807": 1740161212000, "38808": 1740186750000, "38810": 1740382926000, "38811": 1740421534000, "38812": 1740433167000, "38814": 1740439779000, "38815": 1740505467000, "38816": 1740505913000, "38817": 1740523183000, "38818": 1740531088000, "38819": 1740531200000, "38820": 1740597313000, "38821": 1740604166000, "38822": 1740682549000, "38823": 1740766979000, "38824": 1740767220000, "38825": 1740779449000, "38826": 1740852509000, "38827": 1740856639000, "38828": 1740875466000, "38829": 1741025563000, "38830": 1741025606000, "38831": 1741026075000, "38832": 1741033365000, "38833": 1741042582000, "38834": 1741043509000, "38835": 1741051535000, "38837": 1741111395000, "38838": 1741111453000, "38839": 1741135148000, "38840": 1741198520000, "38841": 1741200438000, "38842": 1741212730000, "38843": 1741277924000, "38844": 1741277957000, "38845": 1741278039000, "38846": 1741278101000, "38847": 1741309077000, "38848": 1741309458000, "38849": 1741390255000, "38850": 1741391505000, "38851": 1741622813000, "38852": 1741626663000, "38853": 1741627975000, "38854": 1741667567000, "38855": 1741711774000, "38856": 1741731633000, "38857": 1741742842000, "38859": 1741823429000, "38860": 1741823489000, "38861": 1741880296000, "38863": 1741964590000, "38864": 1742104916000}, "params": {"machine": ["asvrunner"], "python": ["3.10"], "Cython": ["3.0"], "matplotlib": [""], "sqlalchemy": [""], "scipy": [""], "numba": [""], "numexpr": [""], "pyarrow": [""], "tables": [""], "openpyxl": [""], "xlsxwriter": [""], "xlrd": [""], "odfpy": [""], "jinja2": [""], "meson": [""], "meson-python": [""], "python-build": [""], "branch": ["main"]}, "graph_param_list": [{"machine": "asvrunner", "python": "3.10", "Cython": "3.0", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pyarrow": "", "tables": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "meson": "", "meson-python": "", "python-build": "", "branch": "main"}], "benchmarks": {"algorithms.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self, unique, keep, dtype):\n        self.idx.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self, unique, keep, dtype):\n        N = 10**5\n        if dtype in [\"int64\", \"uint64\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=\"float64\")\n        elif dtype == \"string\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype in [\"timestamp[ms][pyarrow]\", \"duration[s][pyarrow]\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        else:\n            raise NotImplementedError\n        if not unique:\n            data = data.repeat(5)\n        self.idx = data\n        # cache is_unique\n        self.idx.is_unique", "min_run_count": 2, "name": "algorithms.Duplicated.time_duplicated", "number": 0, "param_names": ["unique", "keep", "dtype"], "params": [["True", "False"], ["'first'", "'last'", "False"], ["'int64'", "'uint64'", "'float64'", "'string'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timestamp[ms][pyarrow]'", "'duration[s][pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fe53c1038d7b25e9c8911c3bea6fb5a1548d97c07d68025391c8e89c96d7e9ad", "warmup_time": -1}, "algorithms.DuplicatedMaskedArray.time_duplicated": {"code": "class DuplicatedMaskedArray:\n    def time_duplicated(self, unique, keep, dtype):\n        self.ser.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DuplicatedMaskedArray:\n    def setup(self, unique, keep, dtype):\n        N = 10**5\n        data = pd.Series(np.arange(N), dtype=dtype)\n        data[list(range(1, N, 100))] = pd.NA\n        if not unique:\n            data = data.repeat(5)\n        self.ser = data\n        # cache is_unique\n        self.ser.is_unique", "min_run_count": 2, "name": "algorithms.DuplicatedMaskedArray.time_duplicated", "number": 0, "param_names": ["unique", "keep", "dtype"], "params": [["True", "False"], ["'first'", "'last'", "False"], ["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9401d32efa9cbe647d328e01c1b90df12183cdceba73825c1c4d98e81f254886", "warmup_time": -1}, "algorithms.Factorize.peakmem_factorize": {"code": "class Factorize:\n    def peakmem_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10**5\n    \n        if dtype in [\"int64\", \"uint64\", \"Int64\", \"object\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=dtype)\n        elif dtype == \"boolean\":\n            data = pd.array(np.random.randint(0, 2, N), dtype=dtype)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype == \"object_str\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"string[pyarrow]\":\n            data = pd.array(\n                pd.Index([f\"i-{i}\" for i in range(N)], dtype=object),\n                dtype=\"string[pyarrow]\",\n            )\n        else:\n            raise NotImplementedError\n    \n        if not unique:\n            data = data.repeat(5)\n        self.data = data", "name": "algorithms.Factorize.peakmem_factorize", "param_names": ["unique", "sort", "dtype"], "params": [["True", "False"], ["True", "False"], ["'int64'", "'uint64'", "'float64'", "'object'", "'object_str'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'Int64'", "'boolean'", "'string[pyarrow]'"]], "type": "peakmemory", "unit": "bytes", "version": "ec743de3d9c5a026a891feb9ab8ecffae4612dcf9fba25aea48c6525c0fb7c0e"}, "algorithms.Factorize.time_factorize": {"code": "class Factorize:\n    def time_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10**5\n    \n        if dtype in [\"int64\", \"uint64\", \"Int64\", \"object\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=dtype)\n        elif dtype == \"boolean\":\n            data = pd.array(np.random.randint(0, 2, N), dtype=dtype)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype == \"object_str\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"string[pyarrow]\":\n            data = pd.array(\n                pd.Index([f\"i-{i}\" for i in range(N)], dtype=object),\n                dtype=\"string[pyarrow]\",\n            )\n        else:\n            raise NotImplementedError\n    \n        if not unique:\n            data = data.repeat(5)\n        self.data = data", "min_run_count": 2, "name": "algorithms.Factorize.time_factorize", "number": 0, "param_names": ["unique", "sort", "dtype"], "params": [["True", "False"], ["True", "False"], ["'int64'", "'uint64'", "'float64'", "'object'", "'object_str'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'Int64'", "'boolean'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7a47cb209b293a023d7673dfacf5f33fc761ee2bb76ef52d7ba9c2b0cf69f50f", "warmup_time": -1}, "algorithms.Hashing.time_frame": {"code": "class Hashing:\n    def time_frame(self, df):\n        hashing.hash_pandas_object(df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "type": "time", "unit": "seconds", "version": "4a05c799caa1b1f5e373a44ae3039987540f271f87111d92653f37c426c76443", "warmup_time": -1}, "algorithms.Hashing.time_series_categorical": {"code": "class Hashing:\n    def time_series_categorical(self, df):\n        hashing.hash_pandas_object(df[\"categories\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "type": "time", "unit": "seconds", "version": "c402e5979cad298ee4e24b9fb8fc1c18002315ac518eb757fc3dfdda2dfa8a70", "warmup_time": -1}, "algorithms.Hashing.time_series_dates": {"code": "class Hashing:\n    def time_series_dates(self, df):\n        hashing.hash_pandas_object(df[\"dates\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "type": "time", "unit": "seconds", "version": "480afaa0dc2d1bcfebbb58644d666d5e0110dce44f34335c99f3fc79ec3d7157", "warmup_time": -1}, "algorithms.Hashing.time_series_float": {"code": "class Hashing:\n    def time_series_float(self, df):\n        hashing.hash_pandas_object(df[\"floats\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_float", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "type": "time", "unit": "seconds", "version": "214d3d8f8bad077c365dabffe78fc06579e82078aaef4ea7f87b4a9154f3b17d", "warmup_time": -1}, "algorithms.Hashing.time_series_int": {"code": "class Hashing:\n    def time_series_int(self, df):\n        hashing.hash_pandas_object(df[\"ints\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "type": "time", "unit": "seconds", "version": "1e1e48b3441cae94aaaa9f1821af6faeb0ffb83a0e757306651eb81e6883ef37", "warmup_time": -1}, "algorithms.Hashing.time_series_string": {"code": "class Hashing:\n    def time_series_string(self, df):\n        hashing.hash_pandas_object(df[\"strings\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "type": "time", "unit": "seconds", "version": "1f1baa73746106531f50db15fbbbbb902f1b33f8c128829138fb6b494b91953e", "warmup_time": -1}, "algorithms.Hashing.time_series_timedeltas": {"code": "class Hashing:\n    def time_series_timedeltas(self, df):\n        hashing.hash_pandas_object(df[\"timedeltas\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_timedeltas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "type": "time", "unit": "seconds", "version": "03ae26b3725783046ce19f735dfb622e46318830e1297575ea97d8b9f5928199", "warmup_time": -1}, "algorithms.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, quantile, interpolation, dtype):\n        self.ser.quantile(quantile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, quantile, interpolation, dtype):\n        N = 10**5\n        if dtype in [\"int64\", \"uint64\"]:\n            data = np.arange(N, dtype=dtype)\n        elif dtype == \"float64\":\n            data = np.random.randn(N)\n        else:\n            raise NotImplementedError\n        self.ser = pd.Series(data.repeat(5))", "min_run_count": 2, "name": "algorithms.Quantile.time_quantile", "number": 0, "param_names": ["quantile", "interpolation", "dtype"], "params": [["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"], ["'float64'", "'int64'", "'uint64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "820d0dca81e53ef4f34628fac8053f5a961e38b58bf3b780a6b0f25372409868", "warmup_time": -1}, "algorithms.SortIntegerArray.time_argsort": {"code": "class SortIntegerArray:\n    def time_argsort(self, N):\n        self.array.argsort()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIntegerArray:\n    def setup(self, N):\n        data = np.arange(N, dtype=float)\n        data[40] = np.nan\n        self.array = pd.array(data, dtype=\"Int64\")", "min_run_count": 2, "name": "algorithms.SortIntegerArray.time_argsort", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "712d4e0ba6b3b003618d30611818ce2c36c039fe0900eafca3896d3863ebbc51", "warmup_time": -1}, "algos.isin.IsIn.time_isin": {"code": "class IsIn:\n    def time_isin(self, dtype):\n        self.series.isin(self.values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object)._values,\n                    dtype=dtype,\n                )\n            except ImportError as err:\n                raise NotImplementedError from err\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "865fbf7191863eeb821be25fad0a63ffe777808ff8616e4cab0031c8301e7153", "warmup_time": -1}, "algos.isin.IsIn.time_isin_categorical": {"code": "class IsIn:\n    def time_isin_categorical(self, dtype):\n        self.series.isin(self.cat_values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object)._values,\n                    dtype=dtype,\n                )\n            except ImportError as err:\n                raise NotImplementedError from err\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_categorical", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9369a8f4f0ec062e426a751644ce01ca508d066ce35ee6ff28d4c4c83c41eb3d", "warmup_time": -1}, "algos.isin.IsIn.time_isin_empty": {"code": "class IsIn:\n    def time_isin_empty(self, dtype):\n        self.series.isin([])\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object)._values,\n                    dtype=dtype,\n                )\n            except ImportError as err:\n                raise NotImplementedError from err\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_empty", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b9d421da039cb9b85f0c4f38a7b6d4598c0df5ad2743f8bb6d22196225360df9", "warmup_time": -1}, "algos.isin.IsIn.time_isin_mismatched_dtype": {"code": "class IsIn:\n    def time_isin_mismatched_dtype(self, dtype):\n        self.series.isin(self.mismatched)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object)._values,\n                    dtype=dtype,\n                )\n            except ImportError as err:\n                raise NotImplementedError from err\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_mismatched_dtype", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f0d4da28d0ffe353bb16748a63a1f7767990a4d22696a561e495e0d6526f4fdc", "warmup_time": -1}, "algos.isin.IsInFloat64.time_isin": {"code": "class IsInFloat64:\n    def time_isin(self, dtype, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, title):\n        N_many = 10**5\n        N_few = 10**6\n        self.series = Series([1, 2], dtype=dtype)\n    \n        if title == \"many_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.arange(N_many, dtype=np.float64)\n        elif title == \"few_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.zeros(N_few, dtype=np.float64)\n        elif title == \"only_nans_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.full(N_few, np.nan, dtype=np.float64)\n        else:\n            raise ValueError(title)", "min_run_count": 2, "name": "algos.isin.IsInFloat64.time_isin", "number": 0, "param_names": ["dtype", "title"], "params": [["<class 'numpy.float64'>", "'Float64'"], ["'many_different_values'", "'few_different_values'", "'only_nans_values'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "59baee11ef880339f8490c7d07fdf4f25b649d22624afd1242eefd4877e7c0bd", "warmup_time": -1}, "algos.isin.IsInForObjects.time_isin": {"code": "class IsInForObjects:\n    def time_isin(self, series_type, vals_type):\n        self.series.isin(self.values)\n\n    def setup(self, series_type, vals_type):\n        N_many = 10**5\n    \n        if series_type == \"nans\":\n            ser_vals = np.full(10**4, np.nan)\n        elif series_type == \"short\":\n            ser_vals = np.arange(2)\n        elif series_type == \"long\":\n            ser_vals = np.arange(N_many)\n        elif series_type == \"long_floats\":\n            ser_vals = np.arange(N_many, dtype=np.float64)\n    \n        self.series = Series(ser_vals).astype(object)\n    \n        if vals_type == \"nans\":\n            values = np.full(10**4, np.nan)\n        elif vals_type == \"short\":\n            values = np.arange(2)\n        elif vals_type == \"long\":\n            values = np.arange(N_many)\n        elif vals_type == \"long_floats\":\n            values = np.arange(N_many, dtype=np.float64)\n    \n        self.values = values.astype(object)", "min_run_count": 2, "name": "algos.isin.IsInForObjects.time_isin", "number": 0, "param_names": ["series_type", "vals_type"], "params": [["'nans'", "'short'", "'long'", "'long_floats'"], ["'nans'", "'short'", "'long'", "'long_floats'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "51416b624c4176717e96bb897c59ee9f59c2e4a9079df5c3893b1fb877979d84", "warmup_time": -1}, "algos.isin.IsInIndexes.time_isin_index": {"code": "class IsInIndexes:\n    def time_isin_index(self):\n        self.series.isin(self.index)\n\n    def setup(self):\n        self.range_idx = Index(range(1000))\n        self.index = Index(list(range(1000)))\n        self.series = Series(np.random.randint(100_000, size=1000))", "min_run_count": 2, "name": "algos.isin.IsInIndexes.time_isin_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ce5b0b4c6a85e2c007c90998aa18d4db0fb69a82cefb1549856c75004e42fbec", "warmup_time": -1}, "algos.isin.IsInIndexes.time_isin_range_index": {"code": "class IsInIndexes:\n    def time_isin_range_index(self):\n        self.series.isin(self.range_idx)\n\n    def setup(self):\n        self.range_idx = Index(range(1000))\n        self.index = Index(list(range(1000)))\n        self.series = Series(np.random.randint(100_000, size=1000))", "min_run_count": 2, "name": "algos.isin.IsInIndexes.time_isin_range_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f37d428d46aff6ec8ce8a340df54e194946db8454b6da0c7a39c2e85139b4efb", "warmup_time": -1}, "algos.isin.IsInLongSeriesLookUpDominates.time_isin": {"code": "class IsInLongSeriesLookUpDominates:\n    def time_isin(self, dtypes, MaxNumber, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, MaxNumber, series_type):\n        N = 10**7\n    \n        if series_type == \"random_hits\":\n            array = np.random.randint(0, MaxNumber, N)\n        if series_type == \"random_misses\":\n            array = np.random.randint(0, MaxNumber, N) + MaxNumber\n        if series_type == \"monotone_hits\":\n            array = np.repeat(np.arange(MaxNumber), N // MaxNumber)\n        if series_type == \"monotone_misses\":\n            array = np.arange(N) + MaxNumber\n    \n        self.series = Series(array).astype(dtype)\n    \n        self.values = np.arange(MaxNumber).astype(dtype.lower())", "min_run_count": 2, "name": "algos.isin.IsInLongSeriesLookUpDominates.time_isin", "number": 0, "param_names": ["dtype", "MaxNumber", "series_type"], "params": [["'int64'", "'int32'", "'float64'", "'float32'", "'object'", "'Int64'", "'Float64'"], ["5", "1000"], ["'random_hits'", "'random_misses'", "'monotone_hits'", "'monotone_misses'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0634a100f682c1a73f9cb5d84afc1695f117d58377c8ac19e9a1d4ecf3918bc4", "warmup_time": -1}, "algos.isin.IsInLongSeriesValuesDominate.time_isin": {"code": "class IsInLongSeriesValuesDominate:\n    def time_isin(self, dtypes, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, series_type):\n        N = 10**7\n    \n        if series_type == \"random\":\n            vals = np.random.randint(0, 10 * N, N)\n        if series_type == \"monotone\":\n            vals = np.arange(N)\n    \n        self.values = vals.astype(dtype.lower())\n        M = 10**6 + 1\n        self.series = Series(np.arange(M)).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsInLongSeriesValuesDominate.time_isin", "number": 0, "param_names": ["dtype", "series_type"], "params": [["'int64'", "'int32'", "'float64'", "'float32'", "'object'", "'Int64'", "'Float64'"], ["'random'", "'monotone'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8202afa03ab08eab3d80cdb10c821a35f6b73f1b178354429054668f213b8920", "warmup_time": -1}, "algos.isin.IsInWithLongTupples.time_isin": {"code": "class IsInWithLongTupples:\n    def time_isin(self):\n        self.series.isin(self.values)\n\n    def setup(self):\n        t = tuple(range(1000))\n        self.series = Series([t] * 1000)\n        self.values = [t]", "min_run_count": 2, "name": "algos.isin.IsInWithLongTupples.time_isin", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "55c634e065a928f8f1e9146932290a0b894f6f9f6f25b0d57ab2597ce60972ad", "warmup_time": -1}, "algos.isin.IsinAlmostFullWithRandomInt.time_isin": {"code": "class IsinAlmostFullWithRandomInt:\n    def time_isin(self, dtype, exponent, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, exponent, title):\n        M = 3 * 2 ** (exponent - 2)\n        # 0.77-the maximal share of occupied buckets\n        self.series = Series(np.random.randint(0, M, M)).astype(dtype)\n    \n        values = np.random.randint(0, M, M).astype(dtype)\n        if title == \"inside\":\n            self.values = values\n        elif title == \"outside\":\n            self.values = values + M\n        else:\n            raise ValueError(title)", "min_run_count": 2, "name": "algos.isin.IsinAlmostFullWithRandomInt.time_isin", "number": 0, "param_names": ["dtype", "exponent", "title"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20"], ["'inside'", "'outside'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4511839e6a4402d9c6a3c41e95fbfd6c61eb07d38c9d0069b10c837a5dfb0bb4", "warmup_time": -1}, "algos.isin.IsinWithArange.time_isin": {"code": "class IsinWithArange:\n    def time_isin(self, dtype, M, offset_factor):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, M, offset_factor):\n        offset = int(M * offset_factor)\n        tmp = Series(np.random.randint(offset, M + offset, 10**6))\n        self.series = tmp.astype(dtype)\n        self.values = np.arange(M).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsinWithArange.time_isin", "number": 0, "param_names": ["dtype", "M", "offset_factor"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["1000", "2000", "8000"], ["-2", "0", "2"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a595ea736176046325e6461769d666e50df44bc5ea923058dfbdf81bc2fa9848", "warmup_time": -1}, "algos.isin.IsinWithArangeSorted.time_isin": {"code": "class IsinWithArangeSorted:\n    def time_isin(self, dtype, size):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size):\n        self.series = Series(np.arange(size)).astype(dtype)\n        self.values = np.arange(size).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsinWithArangeSorted.time_isin", "number": 0, "param_names": ["dtype", "size"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["1000", "2000", "8000", "100000", "1000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b3b173cabf5fb2d94e06a9a5bce98458bf646cecae54b0966cfe66adcded0fdf", "warmup_time": -1}, "algos.isin.IsinWithRandomFloat.time_isin": {"code": "class IsinWithRandomFloat:\n    def time_isin(self, dtype, size, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size, title):\n        self.values = np.random.rand(size)\n        self.series = Series(self.values).astype(dtype)\n        np.random.shuffle(self.values)\n    \n        if title == \"outside\":\n            self.values = self.values + 0.1", "min_run_count": 2, "name": "algos.isin.IsinWithRandomFloat.time_isin", "number": 0, "param_names": ["dtype", "size", "title"], "params": [["<class 'numpy.float64'>", "<class 'numpy.object_'>"], ["1300", "2000", "7000", "8000", "70000", "80000", "750000", "900000"], ["'inside'", "'outside'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "15f9f9bb41efd706d95b1a43ff72e5572dedbb074050cd2b857e7a91213c60a8", "warmup_time": -1}, "arithmetic.ApplyIndex.time_apply_index": {"code": "class ApplyIndex:\n    def time_apply_index(self, offset):\n        self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyIndex:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng", "min_run_count": 2, "name": "arithmetic.ApplyIndex.time_apply_index", "number": 0, "param_names": ["offset"], "params": [["<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3a6382c9a7754ab42a9c9d4af8bdaeb073d03dbe05f80288c151c0cce34ffbb7", "warmup_time": -1}, "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex": {"code": "class BinaryOpsMultiIndex:\n    def time_binary_op_multiindex(self, func):\n        getattr(self.df, func)(self.arg_df, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BinaryOpsMultiIndex:\n    def setup(self, func):\n        array = date_range(\"20200101 00:00\", \"20200102 0:00\", freq=\"s\")\n        level_0_names = [str(i) for i in range(30)]\n    \n        index = pd.MultiIndex.from_product([level_0_names, array])\n        column_names = [\"col_1\", \"col_2\"]\n    \n        self.df = DataFrame(\n            np.random.rand(len(index), 2), index=index, columns=column_names\n        )\n    \n        self.arg_df = DataFrame(\n            np.random.randint(1, 10, (len(level_0_names), 2)),\n            index=level_0_names,\n            columns=column_names,\n        )", "min_run_count": 2, "name": "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex", "number": 0, "param_names": ["func"], "params": [["'sub'", "'add'", "'mul'", "'div'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f972c5787a16a41749c4e8447ef1ff42b310cd8aa3ef3b75ab7012164ff6cd12", "warmup_time": -1}, "arithmetic.CategoricalComparisons.time_categorical_op": {"code": "class CategoricalComparisons:\n    def time_categorical_op(self, op):\n        getattr(self.cat, op)(\"b\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalComparisons:\n    def setup(self, op):\n        N = 10**5\n        self.cat = pd.Categorical(list(\"aabbcd\") * N, ordered=True)", "min_run_count": 2, "name": "arithmetic.CategoricalComparisons.time_categorical_op", "number": 0, "param_names": ["op"], "params": [["'__lt__'", "'__le__'", "'__eq__'", "'__ne__'", "'__ge__'", "'__gt__'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2f0300d246b7a2099eaf59bd3d8baf6c12093061ade66b97a650fa54a8b028f1", "warmup_time": -1}, "arithmetic.DateInferOps.time_add_timedeltas": {"code": "class DateInferOps:\n    def time_add_timedeltas(self, df):\n        df[\"timedelta\"] + df[\"timedelta\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_add_timedeltas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:375", "type": "time", "unit": "seconds", "version": "d304b19271ea5e636b026bf3da9f4297f153721c9a2c3e0173d635d70bf17047", "warmup_time": -1}, "arithmetic.DateInferOps.time_subtract_datetimes": {"code": "class DateInferOps:\n    def time_subtract_datetimes(self, df):\n        df[\"datetime64\"] - df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_subtract_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:375", "type": "time", "unit": "seconds", "version": "0d0d777174d233a423d74dfef6d81ae5628aaf0098dd2ba538d20b71fa74a3a4", "warmup_time": -1}, "arithmetic.DateInferOps.time_timedelta_plus_datetime": {"code": "class DateInferOps:\n    def time_timedelta_plus_datetime(self, df):\n        df[\"timedelta\"] + df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_timedelta_plus_datetime", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:375", "type": "time", "unit": "seconds", "version": "d88c202e97a70579bbbc882c3e1887e44880bc361f354c724dfce863a33f80b3", "warmup_time": -1}, "arithmetic.FrameWithFrameWide.time_op_different_blocks": {"code": "class FrameWithFrameWide:\n    def time_op_different_blocks(self, op, shape):\n        # blocks (and dtypes) are not aligned\n        op(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shouldn't need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2", "min_run_count": 2, "name": "arithmetic.FrameWithFrameWide.time_op_different_blocks", "number": 0, "param_names": ["op", "shape"], "params": [["<built-in function add>", "<built-in function floordiv>", "<built-in function gt>"], ["(1000000, 10)", "(100000, 100)", "(10000, 1000)", "(1000, 10000)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "08d4888de43a21340c4ca998981b96bc41102332e11cc5e9f3fa24786b3387df", "warmup_time": -1}, "arithmetic.FrameWithFrameWide.time_op_same_blocks": {"code": "class FrameWithFrameWide:\n    def time_op_same_blocks(self, op, shape):\n        # blocks (and dtypes) are aligned\n        op(self.left, self.left)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shouldn't need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2", "min_run_count": 2, "name": "arithmetic.FrameWithFrameWide.time_op_same_blocks", "number": 0, "param_names": ["op", "shape"], "params": [["<built-in function add>", "<built-in function floordiv>", "<built-in function gt>"], ["(1000000, 10)", "(100000, 100)", "(10000, 1000)", "(1000, 10000)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5a9a092d047b1965d0bc9f942b0cf7c15def8265241bbeedb67e2fceab345e22", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_add": {"code": "class IndexArithmetic:\n    def time_add(self, dtype):\n        self.index + 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_add", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e3b336a2b91023f69241b1e98b2ab708a462124c6efae19a34cbfc4088ac5c30", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_divide": {"code": "class IndexArithmetic:\n    def time_divide(self, dtype):\n        self.index / 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_divide", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "34015b0ed303b7d7c8f55d6a9ad20ca0fa33aadc3daa21cd5aad136f74b8dd5a", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_modulo": {"code": "class IndexArithmetic:\n    def time_modulo(self, dtype):\n        self.index % 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "79e85d4d52e5fba7c78d4758aca6497d19481845699965996f6c198f8052f100", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_multiply": {"code": "class IndexArithmetic:\n    def time_multiply(self, dtype):\n        self.index * 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5969c44239435c557404661c30a6b18f3fdef2422cd4683cc4baa5856db98617", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_subtract": {"code": "class IndexArithmetic:\n    def time_subtract(self, dtype):\n        self.index - 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "064e28755b44443edfc8d9a9e01aa56cd0b70fde6e6ea290d84284e9bb03268a", "warmup_time": -1}, "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar": {"code": "class IntFrameWithScalar:\n    def time_frame_op_with_scalar(self, dtype, scalar, op):\n        op(self.df, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntFrameWithScalar:\n    def setup(self, dtype, scalar, op):\n        arr = np.random.randn(20000, 100)\n        self.df = DataFrame(arr.astype(dtype))", "min_run_count": 2, "name": "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar", "number": 0, "param_names": ["dtype", "scalar", "op"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>"], ["2", "3.0", "4", "5.0"], ["<built-in function add>", "<built-in function sub>", "<built-in function mul>", "<built-in function truediv>", "<built-in function floordiv>", "<built-in function pow>", "<built-in function mod>", "<built-in function eq>", "<built-in function ne>", "<built-in function gt>", "<built-in function ge>", "<built-in function lt>", "<built-in function le>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "17cc3015c45764be50024cbe52247cfe2100d4020bdf03e0b04bea2f932fe975", "warmup_time": -1}, "arithmetic.IrregularOps.time_add": {"code": "class IrregularOps:\n    def time_add(self):\n        self.left + self.right\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IrregularOps:\n    def setup(self):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        s = Series(np.random.randn(N), index=idx)\n        self.left = s.sample(frac=1)\n        self.right = s.sample(frac=1)", "min_run_count": 2, "name": "arithmetic.IrregularOps.time_add", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c48f5ee66f4fba32ce66ca585b4550f976b5632cf96bb22e9be34d3c2ea0a194", "warmup_time": -1}, "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0": {"code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis0(self, opname):\n        getattr(self.df, opname)(self.ser, axis=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10**6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]", "min_run_count": 2, "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0", "number": 0, "param_names": ["opname"], "params": [["'eq'", "'ne'", "'lt'", "'le'", "'ge'", "'gt'", "'add'", "'sub'", "'truediv'", "'floordiv'", "'mul'", "'pow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2ec044d527bdcad8450ef35a26f4caee5ca2d8cf69f36b99665adedc140d4b71", "warmup_time": -1}, "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1": {"code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis1(self, opname):\n        getattr(operator, opname)(self.df, self.ser)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10**6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]", "min_run_count": 2, "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1", "number": 0, "param_names": ["opname"], "params": [["'add'", "'sub'", "'truediv'", "'floordiv'", "'mul'", "'pow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1c5761284f2cd8adf60d3f65efee5881b415f0c986cfbbc8e313f298eb349a3e", "warmup_time": -1}, "arithmetic.NumericInferOps.time_add": {"code": "class NumericInferOps:\n    def time_add(self, dtype):\n        self.df[\"A\"] + self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_add", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d8c4f5e6dc0c54cff731395cacf041f5ccf4d5fdf6605e5aea2767fdea959165", "warmup_time": -1}, "arithmetic.NumericInferOps.time_divide": {"code": "class NumericInferOps:\n    def time_divide(self, dtype):\n        self.df[\"A\"] / self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_divide", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a435004455cc72252be9ec940814e96fbe3afb17fb5329b5d7c51208c9796979", "warmup_time": -1}, "arithmetic.NumericInferOps.time_modulo": {"code": "class NumericInferOps:\n    def time_modulo(self, dtype):\n        self.df[\"A\"] % self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "44d71d818e38047c0a9a5903a9d5707c2ff4eae84631c776e3dba9448493a767", "warmup_time": -1}, "arithmetic.NumericInferOps.time_multiply": {"code": "class NumericInferOps:\n    def time_multiply(self, dtype):\n        self.df[\"A\"] * self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fe621ddecbe036b8b2a50405324b8024f35d0412d89bf916c6adec56d4c5f360", "warmup_time": -1}, "arithmetic.NumericInferOps.time_subtract": {"code": "class NumericInferOps:\n    def time_subtract(self, dtype):\n        self.df[\"A\"] - self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2e26ca6727d932af0269ec66a57701c64b061d05601a076e2524ebf79e1b5cd6", "warmup_time": -1}, "arithmetic.OffsetArrayArithmetic.time_add_dti_offset": {"code": "class OffsetArrayArithmetic:\n    def time_add_dti_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng\n        self.ser = Series(rng)", "min_run_count": 2, "name": "arithmetic.OffsetArrayArithmetic.time_add_dti_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "773a2fe8364b7487aee29003e6fa3d183f2fb484205a9b055d70067c056ed277", "warmup_time": -1}, "arithmetic.OffsetArrayArithmetic.time_add_series_offset": {"code": "class OffsetArrayArithmetic:\n    def time_add_series_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.ser + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng\n        self.ser = Series(rng)", "min_run_count": 2, "name": "arithmetic.OffsetArrayArithmetic.time_add_series_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "14f080de541934c9cd028a210635eb42296006292989ffde9a52ae195ca39452", "warmup_time": -1}, "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas": {"code": "class OpWithFillValue:\n    def time_frame_op_with_fill_value_no_nas(self):\n        self.df.add(self.df, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10**6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser", "min_run_count": 2, "name": "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "162ff770e3fdcbc51f2d5140c2cf46f028d48a27268957104ac69d7d800cc1a0", "warmup_time": -1}, "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas": {"code": "class OpWithFillValue:\n    def time_series_op_with_fill_value_no_nas(self):\n        self.ser.add(self.ser, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10**6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser", "min_run_count": 2, "name": "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "81d51758d1b72e5df11be69874e29ffab5fdbe1e4cd1816754c197a4833d5d8e", "warmup_time": -1}, "arithmetic.Ops.time_frame_add": {"code": "class Ops:\n    def time_frame_add(self, use_numexpr, threads):\n        self.df + self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_add", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "173dfb8c14d4f1e45058ae77d74a28966785fc801b28902fd8448d30ac4ff7d8", "warmup_time": -1}, "arithmetic.Ops.time_frame_comparison": {"code": "class Ops:\n    def time_frame_comparison(self, use_numexpr, threads):\n        self.df > self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_comparison", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b9edf1afa79c0a69d8e9647b98beb73e32760b78ff938a190dc6b42ccac38b11", "warmup_time": -1}, "arithmetic.Ops.time_frame_mult": {"code": "class Ops:\n    def time_frame_mult(self, use_numexpr, threads):\n        self.df * self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_mult", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "911cfaa0ecf7737245490bf8a69723a5301ce60c296a33915a8eb9c09d7cd279", "warmup_time": -1}, "arithmetic.Ops.time_frame_multi_and": {"code": "class Ops:\n    def time_frame_multi_and(self, use_numexpr, threads):\n        self.df[(self.df > 0) & (self.df2 > 0)]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_multi_and", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "27fe96278213fdc7fe35ca52941a5bf4e3def23517666891d790d2d443a98ef2", "warmup_time": -1}, "arithmetic.Ops2.time_frame_dot": {"code": "class Ops2:\n    def time_frame_dot(self):\n        self.df.dot(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "efdf52d3f6066f576d98f9b78aef45d706022d5fdf431ac33a3d411c8915c028", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_div": {"code": "class Ops2:\n    def time_frame_float_div(self):\n        self.df // self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_div", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "859b0f256d5a19376ac8c740779c53fb2287fd0c6f8f0d2f48052d7a57050a0a", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_div_by_zero": {"code": "class Ops2:\n    def time_frame_float_div_by_zero(self):\n        self.df / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_div_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bacba426dd7890d79b38fd7575e9ba633c7ebc2252b393414e19e8838317b7a9", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_floor_by_zero": {"code": "class Ops2:\n    def time_frame_float_floor_by_zero(self):\n        self.df // 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_floor_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5096a00c147e73e2a7a0be3156a440a3dd813fff99c8ed11456981814df947a2", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_mod": {"code": "class Ops2:\n    def time_frame_float_mod(self):\n        self.df % self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_mod", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "72aa4cef09d38e4af67ae6e35e15b1304bd371e85fc3613e817cedd372852517", "warmup_time": -1}, "arithmetic.Ops2.time_frame_int_div_by_zero": {"code": "class Ops2:\n    def time_frame_int_div_by_zero(self):\n        self.df_int / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_int_div_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cdab6c35545be907f3db670b2114ccd527c652b9b3992d2ef767b26d538cc342", "warmup_time": -1}, "arithmetic.Ops2.time_frame_int_mod": {"code": "class Ops2:\n    def time_frame_int_mod(self):\n        self.df_int % self.df2_int\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_int_mod", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cb4f4230cb2354cccaed2ae0cd0fdfaf8ef908fbcf616544289f44a42a0f2eb4", "warmup_time": -1}, "arithmetic.Ops2.time_frame_series_dot": {"code": "class Ops2:\n    def time_frame_series_dot(self):\n        self.df.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_series_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "30c45d8348c1f30ed5962671b11e5a31ae976f64b960b8cbe8eceb8c1f3716b8", "warmup_time": -1}, "arithmetic.Ops2.time_series_dot": {"code": "class Ops2:\n    def time_series_dot(self):\n        self.s.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_series_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "524f0eb5deba6ae021936a6721c4fec9cb92fccf0ac27c1799ab70139a436fdc", "warmup_time": -1}, "arithmetic.TimedeltaOps.time_add_td_ts": {"code": "class TimedeltaOps:\n    def time_add_td_ts(self):\n        self.td + self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimedeltaOps:\n    def setup(self):\n        self.td = to_timedelta(np.arange(1000000))\n        self.ts = Timestamp(\"2000\")", "min_run_count": 2, "name": "arithmetic.TimedeltaOps.time_add_td_ts", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee3abda2771a3808efc316e236cd6de15f8678b03e2a27e6f75792edbbe543ec", "warmup_time": -1}, "arithmetic.Timeseries.time_series_timestamp_compare": {"code": "class Timeseries:\n    def time_series_timestamp_compare(self, tz):\n        self.s <= self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_series_timestamp_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2ed5f17ee3263c0675f3f6293f63a1432f5f306de89d694585642001a6522d84", "warmup_time": -1}, "arithmetic.Timeseries.time_series_timestamp_different_reso_compare": {"code": "class Timeseries:\n    def time_series_timestamp_different_reso_compare(self, tz):\n        self.s <= self.ts_different_reso\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_series_timestamp_different_reso_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3c7524e8c0a4069313b1ec51d6e534e708d5b1d735d3b48c3c2443ee4a65f1c8", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_ops_diff": {"code": "class Timeseries:\n    def time_timestamp_ops_diff(self, tz):\n        self.s2.diff()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_ops_diff", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "93c02a9bd33f19256f321c09451b0f35b9b4b1b1f54c9c3ff180aad5c57503ce", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift": {"code": "class Timeseries:\n    def time_timestamp_ops_diff_with_shift(self, tz):\n        self.s - self.s.shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8cab7c77baffeef8c23dde710dd4e428b68beaad2631fd5add6969cc56fb326a", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_series_compare": {"code": "class Timeseries:\n    def time_timestamp_series_compare(self, tz):\n        self.ts >= self.s\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_series_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ef8d8e370d78f1580db60bb5b8997ef11749938452601dbe3816c0a1b7184c75", "warmup_time": -1}, "array.ArrowExtensionArray.time_to_numpy": {"code": "class ArrowExtensionArray:\n    def time_to_numpy(self, dtype, hasna):\n        self.arr.to_numpy()\n\n    def setup(self, dtype, hasna):\n        N = 100_000\n        if dtype == \"boolean[pyarrow]\":\n            data = np.random.choice([True, False], N, replace=True)\n        elif dtype == \"float64[pyarrow]\":\n            data = np.random.randn(N)\n        elif dtype == \"int64[pyarrow]\":\n            data = np.arange(N)\n        elif dtype == \"string[pyarrow]\":\n            data = np.array([str(i) for i in range(N)], dtype=object)\n        elif dtype == \"timestamp[ns][pyarrow]\":\n            data = pd.date_range(\"2000-01-01\", freq=\"s\", periods=N)\n        else:\n            raise NotImplementedError\n    \n        arr = pd.array(data, dtype=dtype)\n        if hasna:\n            arr[::2] = pd.NA\n        self.arr = arr", "min_run_count": 2, "name": "array.ArrowExtensionArray.time_to_numpy", "number": 0, "param_names": ["dtype", "hasna"], "params": [["'boolean[pyarrow]'", "'float64[pyarrow]'", "'int64[pyarrow]'", "'string[pyarrow]'", "'timestamp[ns][pyarrow]'"], ["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ae6d3539d4bf1ab5add70aed593a5fd7a6e541a28b7a0eb633a73bb9abd71cc2", "warmup_time": -1}, "array.ArrowStringArray.time_setitem": {"code": "class ArrowStringArray:\n    def time_setitem(self, multiple_chunks):\n        for i in range(200):\n            self.array[i] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "82acb0306b4f74cfc3a9251e34f34e48f9d75f55cc88e4561cdfe665c404b57c", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_list": {"code": "class ArrowStringArray:\n    def time_setitem_list(self, multiple_chunks):\n        indexer = list(range(50)) + list(range(-1000, 0, 50))\n        self.array[indexer] = [\"foo\"] * len(indexer)\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_list", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3e18cf0ca3737e5f73e1077a467c9830fe02ddd6eb40a1445b2f2e1ef9201c39", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_null_slice": {"code": "class ArrowStringArray:\n    def time_setitem_null_slice(self, multiple_chunks):\n        self.array[:] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_null_slice", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ef3c4fb5f84005a87d9d784f8909aa263278e37b51b46700c42b11198ed40b1c", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_slice": {"code": "class ArrowStringArray:\n    def time_setitem_slice(self, multiple_chunks):\n        self.array[::10] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_slice", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6a0d09a5d23eb6dc7d6bb95140476cc1c1a896640e9d7bd005861c59072edc0d", "warmup_time": -1}, "array.ArrowStringArray.time_tolist": {"code": "class ArrowStringArray:\n    def time_tolist(self, multiple_chunks):\n        self.array.tolist()\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError as err:\n            raise NotImplementedError from err\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_tolist", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4f9947fe763b0abb9ed39a4a36de404cc91fc722c4cff1a0a5cf37ad0e99796f", "warmup_time": -1}, "array.BooleanArray.time_constructor": {"code": "class BooleanArray:\n    def time_constructor(self):\n        pd.arrays.BooleanArray(self.data, self.mask)\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_constructor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "31f0c0638e5908b3b2f79ec954e3e3c5f9b247f04708fe2a8ba53b4df1b161d5", "warmup_time": -1}, "array.BooleanArray.time_from_bool_array": {"code": "class BooleanArray:\n    def time_from_bool_array(self):\n        pd.array(self.values_bool, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_bool_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "49de818c0d3213d4624b41ad1583ffa3da28d65f2dd89a30c9ed9ce4d8902300", "warmup_time": -1}, "array.BooleanArray.time_from_float_array": {"code": "class BooleanArray:\n    def time_from_float_array(self):\n        pd.array(self.values_float, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_float_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "00f65facf261a9f506e825a7a84d17cc35d7f00ff17f090622cbbdb8e6a538dc", "warmup_time": -1}, "array.BooleanArray.time_from_integer_array": {"code": "class BooleanArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_integer_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d27d54d2b7793c51154ffb049d0e1508e27dc0b3cdfa4f734789da01a48e0abf", "warmup_time": -1}, "array.BooleanArray.time_from_integer_like": {"code": "class BooleanArray:\n    def time_from_integer_like(self):\n        pd.array(self.values_integer_like, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_integer_like", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6c37947cc0814a4fabfcf5fc4ebcb76a3e8d231c4fb5ca15eb3d0f502617a17d", "warmup_time": -1}, "array.IntegerArray.time_constructor": {"code": "class IntegerArray:\n    def time_constructor(self):\n        pd.arrays.IntegerArray(self.data, self.mask)\n\n    def setup(self):\n        N = 250_000\n        self.values_integer = np.tile(np.array([1, 0, 1, 0]), N)\n        self.data = np.tile(np.array([1, 2, 3, 4], dtype=\"int64\"), N)\n        self.mask = np.tile(np.array([False, False, True, False]), N)", "min_run_count": 2, "name": "array.IntegerArray.time_constructor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0ff5c1d57429763cebb625bcfc125d262aed2b7dc0532117078c943ad05a59d8", "warmup_time": -1}, "array.IntegerArray.time_from_integer_array": {"code": "class IntegerArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"Int64\")\n\n    def setup(self):\n        N = 250_000\n        self.values_integer = np.tile(np.array([1, 0, 1, 0]), N)\n        self.data = np.tile(np.array([1, 2, 3, 4], dtype=\"int64\"), N)\n        self.mask = np.tile(np.array([False, False, True, False]), N)", "min_run_count": 2, "name": "array.IntegerArray.time_from_integer_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5030e9d654d92c3c38ca4b4c07b3883d555809c78cb492b2ed1be77342068a36", "warmup_time": -1}, "array.IntervalArray.time_from_tuples": {"code": "class IntervalArray:\n    def time_from_tuples(self):\n        pd.arrays.IntervalArray.from_tuples(self.tuples)\n\n    def setup(self):\n        N = 10_000\n        self.tuples = [(i, i + 1) for i in range(N)]", "min_run_count": 2, "name": "array.IntervalArray.time_from_tuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ba4b21278924821c6bf31f74072230f7b2a24d7c87f7b4f0e1f99025ff60cdb8", "warmup_time": -1}, "array.StringArray.time_from_list": {"code": "class StringArray:\n    def time_from_list(self):\n        pd.array(self.values_list, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b59bfa587e60de31e3429e020a9a8949d3d221a3932af12a9624990f3a988291", "warmup_time": -1}, "array.StringArray.time_from_np_object_array": {"code": "class StringArray:\n    def time_from_np_object_array(self):\n        pd.array(self.values_obj, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_np_object_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5578afbd13efc40a2a7d729b43dd2c6bdc53313d61fb124133a837ade72dae9c", "warmup_time": -1}, "array.StringArray.time_from_np_str_array": {"code": "class StringArray:\n    def time_from_np_str_array(self):\n        pd.array(self.values_str, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_np_str_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "70416c5ccb3bddcfddc25060580b22d14a9fb8f45a6ff0cb06fb0c2ecf4a08ce", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_get_index": {"code": "class DataFrameAttributes:\n    def time_get_index(self):\n        self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_get_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3246f297f11fb6074032907dde5fb9690d93465c80b45bc0b29e284fd5c9c17c", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_set_index": {"code": "class DataFrameAttributes:\n    def time_set_index(self):\n        self.df.index = self.cur_index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_set_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b34bb7eb8426bdd2eb9d8e0550ea2573475694ddc9f971fd9a29f15bf16732b0", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_array": {"code": "class SeriesArrayAttribute:\n    def time_array(self, dtype):\n        self.series.array\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_array", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "71871bee8b7f7a74c594352ad1177b3201818e5ffe6296b02844d93f2e74c57b", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_extract_array": {"code": "class SeriesArrayAttribute:\n    def time_extract_array(self, dtype):\n        extract_array(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_extract_array", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5c9e10a019a9c3c1a6f4016572eac561387c3cc14086cde81066ae5d495b6bae", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy": {"code": "class SeriesArrayAttribute:\n    def time_extract_array_numpy(self, dtype):\n        extract_array(self.series, extract_numpy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "34310e30090bb516b844f357295ebbe46f2980040632e1178dffc041a7635892", "warmup_time": -1}, "boolean.TimeLogicalOps.time_and_array": {"code": "class TimeLogicalOps:\n    def time_and_array(self):\n        self.left & self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_and_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6f948c075c42597b3abbe166b111d3f02c0aa11a2fd01b376b96547a7a0ece18", "warmup_time": -1}, "boolean.TimeLogicalOps.time_and_scalar": {"code": "class TimeLogicalOps:\n    def time_and_scalar(self):\n        self.left & True\n        self.left & False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_and_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "73483ccace6f6debdb2fd885f8fd8ffee9883f4e6dad1587a13239b8be135868", "warmup_time": -1}, "boolean.TimeLogicalOps.time_or_array": {"code": "class TimeLogicalOps:\n    def time_or_array(self):\n        self.left | self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_or_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "dc01bb9cbcdc979b4fbe050df208268a15ff5f328081a7fd09c41283c33bfa5d", "warmup_time": -1}, "boolean.TimeLogicalOps.time_or_scalar": {"code": "class TimeLogicalOps:\n    def time_or_scalar(self):\n        self.left | True\n        self.left | False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_or_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a9dcf90a110c0c703887ee44358e18a6930758987f7f1e9f921dd5ff4c84234e", "warmup_time": -1}, "boolean.TimeLogicalOps.time_xor_array": {"code": "class TimeLogicalOps:\n    def time_xor_array(self):\n        self.left ^ self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_xor_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e093e59c2f51a4998acf114ad54d2ab5d62d38548aab71f3f5c6adbe6bc46792", "warmup_time": -1}, "boolean.TimeLogicalOps.time_xor_scalar": {"code": "class TimeLogicalOps:\n    def time_xor_scalar(self):\n        self.left ^ True\n        self.left ^ False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_xor_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "eb50d9fee1d2beff8da51a2f128bb84bfa76379e9a699ae60dec8e82655bef3c", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_bool_array": {"code": "class CategoricalSlicing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "392935c7d25151142e1191d330ed461794b00830ba9e56c8f000ae6eeb6e5d45", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list": {"code": "class CategoricalSlicing:\n    def time_getitem_list(self, index):\n        self.data[self.list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5ba8074c37da942843683f8b852bf64ef44ae6f2be96c77aba4bccac3bce8f10", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list_like": {"code": "class CategoricalSlicing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "30460a50c9cb11dd9282ec072489495e0335dcccb727a27666919c81757c0dde", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_scalar": {"code": "class CategoricalSlicing:\n    def time_getitem_scalar(self, index):\n        self.data[self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cede26e07c3b0d4aab9f6039da5d92a27c78c09893576e4fac2591b9115d35bb", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_slice": {"code": "class CategoricalSlicing:\n    def time_getitem_slice(self, index):\n        self.data[: self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9c3df2609445fec8c3f08508d3bef72e89181594564d1d1d6aa4916879ddd608", "warmup_time": -1}, "categoricals.Concat.time_append_non_overlapping_index": {"code": "class Concat:\n    def time_append_non_overlapping_index(self):\n        self.idx_a.append(self.idx_b)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_append_non_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7c08f6f4a37c69d20540206d1bb4eac69032087283c327ea354e4e58b28e8e8a", "warmup_time": -1}, "categoricals.Concat.time_append_overlapping_index": {"code": "class Concat:\n    def time_append_overlapping_index(self):\n        self.idx_a.append(self.idx_a)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_append_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "86138129674bef3e164dd5e409ec0b275c1168e83dd747378cf52b02eb2311ea", "warmup_time": -1}, "categoricals.Concat.time_concat": {"code": "class Concat:\n    def time_concat(self):\n        pd.concat([self.s, self.s])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "60e2b37af13d3ba791a2c5fa40b92f67b1d3f6421e301d9dfcfcd4ff1da10041", "warmup_time": -1}, "categoricals.Concat.time_concat_non_overlapping_index": {"code": "class Concat:\n    def time_concat_non_overlapping_index(self):\n        pd.concat([self.df_a, self.df_b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat_non_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "471ef66a2a2b2f051d1de9ad1ff46d1f9db09d862d97bedea6868f6ddd1f19f8", "warmup_time": -1}, "categoricals.Concat.time_concat_overlapping_index": {"code": "class Concat:\n    def time_concat_overlapping_index(self):\n        pd.concat([self.df_a, self.df_a])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ecdea66fab8e41b9f198da14c16f2281c65bcff35fb98ddab2baf37924133287", "warmup_time": -1}, "categoricals.Concat.time_union": {"code": "class Concat:\n    def time_union(self):\n        union_categoricals([self.a, self.b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_union", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b7637f08baccfad51b169c40b0d317647c40413dadb0068206d81bc916c9d71b", "warmup_time": -1}, "categoricals.Constructor.time_all_nan": {"code": "class Constructor:\n    def time_all_nan(self):\n        pd.Categorical(self.values_all_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_all_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fc34b2fc1aa3a8d989b3d4d4f43309050920b518ccb22742b8c9880fd2daeaa7", "warmup_time": -1}, "categoricals.Constructor.time_datetimes": {"code": "class Constructor:\n    def time_datetimes(self):\n        pd.Categorical(self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "21491bf24e30bce0fd02220d64dbbcf27433999a19ebeb8a4c2ada9323fffcec", "warmup_time": -1}, "categoricals.Constructor.time_datetimes_with_nat": {"code": "class Constructor:\n    def time_datetimes_with_nat(self):\n        pd.Categorical(self.datetimes_with_nat)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes_with_nat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fad1bc1045c1ecae82586b1bfc6206bd68dbf453b3c341f8b9626217a0dc98b6", "warmup_time": -1}, "categoricals.Constructor.time_existing_categorical": {"code": "class Constructor:\n    def time_existing_categorical(self):\n        pd.Categorical(self.categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9630a83b0e8907ccdd4ba4448efef4f94833f2b6c0de71b2b6c499f816eb2f9a", "warmup_time": -1}, "categoricals.Constructor.time_existing_series": {"code": "class Constructor:\n    def time_existing_series(self):\n        pd.Categorical(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e8f7fc0eafb5c42ec91db342f88e7ff30be72baf37daaeb01219128d72e36762", "warmup_time": -1}, "categoricals.Constructor.time_fastpath": {"code": "class Constructor:\n    def time_fastpath(self):\n        dtype = pd.CategoricalDtype(categories=self.cat_idx)\n        pd.Categorical._simple_new(self.codes, dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_fastpath", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a49c74359c6fac84f510b14b52c3b65bf4607a99672b5008c8e90d02ed151535", "warmup_time": -1}, "categoricals.Constructor.time_from_codes_all_int8": {"code": "class Constructor:\n    def time_from_codes_all_int8(self):\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_from_codes_all_int8", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7169835f266c2b716c0c53e03822c6b61e9364df39defea9a72e65866e9e799e", "warmup_time": -1}, "categoricals.Constructor.time_interval": {"code": "class Constructor:\n    def time_interval(self):\n        pd.Categorical(self.datetimes, categories=self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_interval", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a7acd5b43515c344aee35540db9d9e9ec60826748cc1ba87b0c033825ec7f8c3", "warmup_time": -1}, "categoricals.Constructor.time_regular": {"code": "class Constructor:\n    def time_regular(self):\n        pd.Categorical(self.values, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_regular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c754dc01772b33919c14f0db934ba900c9aae6bf7c650f0d3556c912c7a6a080", "warmup_time": -1}, "categoricals.Constructor.time_with_nan": {"code": "class Constructor:\n    def time_with_nan(self):\n        pd.Categorical(self.values_some_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_with_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "da4358563a341dff6688a7cd1f87a7ce42556de3a84132ec7d02247774bc922a", "warmup_time": -1}, "categoricals.Contains.time_categorical_contains": {"code": "class Contains:\n    def time_categorical_contains(self):\n        self.key in self.c\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N))\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "32365d05fca5315293e957770f928baaa798b4cd2133f97632aef854e0cbaf52", "warmup_time": -1}, "categoricals.Contains.time_categorical_index_contains": {"code": "class Contains:\n    def time_categorical_index_contains(self):\n        self.key in self.ci\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N))\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "761e6e22b7fea3c9293e4bc5bfb69fb4843ae255301402ca5202bab136712748", "warmup_time": -1}, "categoricals.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        pd.DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f218e6d543ab19db3fea1db2b664146198dd39dadac2966494426b556613d32d", "warmup_time": -1}, "categoricals.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.category)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5f38e85f8450cba2264bb47680c1a9cd76458677f62e8ec8b53aac9e29c4fe62", "warmup_time": -1}, "categoricals.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a413f3ef1a42a84770cc263a3ffc018c0623a71a70d26e58676660ab47210939", "warmup_time": -1}, "categoricals.Indexing.time_reindex": {"code": "class Indexing:\n    def time_reindex(self):\n        self.index.reindex(self.index[:500])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f068d9fbc3b599870598bc5ca8891b88762d7882d98234cd287b7021ae6ebdc2", "warmup_time": -1}, "categoricals.Indexing.time_reindex_missing": {"code": "class Indexing:\n    def time_reindex_missing(self):\n        self.index.reindex([\"a\", \"b\", \"c\", \"d\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8b7b5234b7e636fd26fb1d2ab98bfc3f744be66628ba69f7642a1f723887547f", "warmup_time": -1}, "categoricals.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a719f97efeb6e929cfd555a6be02dce8108efd04f1f5bda591f52a642f5adbf9", "warmup_time": -1}, "categoricals.Indexing.time_sort_values": {"code": "class Indexing:\n    def time_sort_values(self):\n        self.index.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_sort_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "57dcf263eeda37b74d296554b77303db6387683cbff9d7e4ec8fbd03cab2f4d4", "warmup_time": -1}, "categoricals.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "410cd9935506da614c2c46ec84a159befdeefe6b74e61c91bd5daa01f7d3e677", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_decreasing(self):\n        self.c.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c4d103c6279f0b80ce554b92ebb3e5bc2c44dc1e40f2fa4ab07455ea280ab8cb", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_increasing(self):\n        self.c.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fcebf885784c8e801b36cabd669598864a44b3d464eaef9eda7ca74df92105ad", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_decreasing(self):\n        self.s.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fa8a5687d97343fae36bb22d0c776cfb090faec43b933d9f88facde7ba72c762", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_increasing(self):\n        self.s.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "834fbde98d28981a9f726086c81fcfaed2914996bff27fdcdafe4769d95bb3d3", "warmup_time": -1}, "categoricals.Rank.time_rank_int": {"code": "class Rank:\n    def time_rank_int(self):\n        self.s_int.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7341bab0d3444509ae6d5889790fdd91da0b1c61f6f9417809486f6fd9ea7b41", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat": {"code": "class Rank:\n    def time_rank_int_cat(self):\n        self.s_int_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "73d1356f38bf95ad1cb847a06f70e5b406869b4257c3d29cda2b3324f960af3c", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat_ordered": {"code": "class Rank:\n    def time_rank_int_cat_ordered(self):\n        self.s_int_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "12fcb558345d99ff95da65bdfa35893f93ebf3851a96a7e82adb63a959b2f501", "warmup_time": -1}, "categoricals.Rank.time_rank_string": {"code": "class Rank:\n    def time_rank_string(self):\n        self.s_str.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1234230d925b2b0fb2ead89ed4cab63499e7382657ae6bb6de6149643645185c", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat": {"code": "class Rank:\n    def time_rank_string_cat(self):\n        self.s_str_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "03fe33c89451ca7fb520c8aec7c05066e1ec116e56df2993a738b4e57ab9fbf8", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat_ordered": {"code": "class Rank:\n    def time_rank_string_cat_ordered(self):\n        self.s_str_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "73135df6f2f87a366fb11675cc71b241c448b8d91ca00b54a9e95c3a239d1cb6", "warmup_time": -1}, "categoricals.RemoveCategories.time_remove_categories": {"code": "class RemoveCategories:\n    def time_remove_categories(self):\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RemoveCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.RemoveCategories.time_remove_categories", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f41a55fefb120d979e5bcb1f387b4b8b8929b1b97c1b49370b42482deb07b426", "warmup_time": -1}, "categoricals.Repr.time_rendering": {"code": "class Repr:\n    def time_rendering(self):\n        str(self.sel)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        self.sel = pd.Series([\"s1234\"]).astype(\"category\")", "min_run_count": 2, "name": "categoricals.Repr.time_rendering", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8d10d682b8918c4fac813851a9bf9304346e145623189c433d8d75ac72c1e1e6", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_contains": {"code": "class SearchSorted:\n    def time_categorical_contains(self):\n        self.c.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N)).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f33b78283987333ad6f166fd3f25a3cdf67998d5924b845d1372b1ac943eed47", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_index_contains": {"code": "class SearchSorted:\n    def time_categorical_index_contains(self):\n        self.ci.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N)).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7490e013ffd75c03cef3c770842c908f9b3f2e947c41b4f7398e117b125ff1ae", "warmup_time": -1}, "categoricals.SetCategories.time_set_categories": {"code": "class SetCategories:\n    def time_set_categories(self):\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.SetCategories.time_set_categories", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee0d827baaa17c4f7f69783df06df5805e927698ff8dca902182228231f975c1", "warmup_time": -1}, "categoricals.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, dropna):\n        self.ts.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dropna):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.ValueCounts.time_value_counts", "number": 0, "param_names": ["dropna"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4866939b81ce70129183c8d44e1a9d6b42c864346912c27670eb457cdf9fcfbb", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_dates": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_dates(self):\n        DatetimeIndex(self.list_of_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bacd3eaca4814bb06e43ffa8586971974452ebd4e463efae8cac42b893d58a82", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_datetimes": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_datetimes(self):\n        DatetimeIndex(self.list_of_datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "365ef0bfc846c299de2e9ec59316033adc76ea95a7f73a97d4ca958b3d6e913e", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_str": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_str(self):\n        DatetimeIndex(self.list_of_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_str", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "11575c62b8c3127835edd05f4d19329b690f6ef06c30d58b8e772d2b7e7f0abf", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_timestamps": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_timestamps(self):\n        DatetimeIndex(self.list_of_timestamps)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_timestamps", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1aba152c467ee66bcd374fe2d77743a9eef413d7057a74818aa8426b86441b71", "warmup_time": -1}, "ctors.MultiIndexConstructor.time_multiindex_from_iterables": {"code": "class MultiIndexConstructor:\n    def time_multiindex_from_iterables(self):\n        MultiIndex.from_product(self.iterables)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexConstructor:\n    def setup(self):\n        N = 10**4\n        self.iterables = [Index([f\"i-{i}\" for i in range(N)], dtype=object), range(20)]", "min_run_count": 2, "name": "ctors.MultiIndexConstructor.time_multiindex_from_iterables", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7f0175b308859072a4a56134ed322bfc0508e9bbe03567849e74731bd45665b6", "warmup_time": -1}, "ctors.SeriesConstructors.time_series_constructor": {"code": "class SeriesConstructors:\n    def time_series_constructor(self, data_fmt, with_index, dtype):\n        Series(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructors:\n    def setup(self, data_fmt, with_index, dtype):\n        if data_fmt in (gen_of_str, gen_of_tuples) and with_index:\n            raise NotImplementedError(\n                \"Series constructors do not support using generators with indexes\"\n            )\n        N = 10**4\n        if dtype == \"float\":\n            arr = np.random.randn(N)\n        else:\n            arr = np.arange(N)\n        self.data = data_fmt(arr)\n        self.index = np.arange(N) if with_index else None", "min_run_count": 2, "name": "ctors.SeriesConstructors.time_series_constructor", "number": 1, "param_names": ["data_fmt", "with_index", "dtype"], "params": [["<function no_change>", "<class 'list'>", "<function list_of_str>", "<function gen_of_str>", "<function arr_dict>", "<function list_of_tuples>", "<function gen_of_tuples>", "<function list_of_lists>", "<function list_of_tuples_with_none>", "<function list_of_lists_with_none>"], ["False", "True"], ["'float'", "'int'"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "796b7e6dd06a06983968b54d6752714fff49f711f0da87ab239d7c33fe9306ba", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_index_with_series(self):\n        Index(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "33f43d3855a48b47442f806cad0e6e7466e35fc29158753066509c648f173543", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_series(self):\n        DatetimeIndex(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "158ae6c81517f39c972e1bc3b7aab12bf753c0b37a15ca694e51998994283273", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_floats": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_floats(self):\n        Index(self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e0189b13b8400123e9a8d5d5c5d55240f975dd207efd63375f6fb000e228d534", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_string": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_string(self):\n        Index(self.arr_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1403f63eb248697b83050c2515ddca96862bb42fdcd2fd7d5453bcafb3a9881e", "warmup_time": -1}, "dtypes.CheckDtypes.time_is_extension_array_dtype_false": {"code": "class CheckDtypes:\n    def time_is_extension_array_dtype_false(self):\n        is_extension_array_dtype(self.np_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")", "min_run_count": 2, "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_false", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "81c7f57fc1b501fb5fe42b1928b850081d7fc62c6bda218e1faf99d2623a9dd7", "warmup_time": -1}, "dtypes.CheckDtypes.time_is_extension_array_dtype_true": {"code": "class CheckDtypes:\n    def time_is_extension_array_dtype_true(self):\n        is_extension_array_dtype(self.ext_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")", "min_run_count": 2, "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_true", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "23b5bb2e01f5d1546ced81b111d6d84415d3945fe1392317283755c6205327cf", "warmup_time": -1}, "dtypes.Dtypes.time_pandas_dtype": {"code": "class Dtypes:\n    def time_pandas_dtype(self, dtype):\n        pandas_dtype(dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.Dtypes.time_pandas_dtype", "number": 0, "param_names": ["dtype"], "params": [["dtype('int64')", "dtype('int32')", "dtype('uint32')", "dtype('uint64')", "dtype('float32')", "dtype('float64')", "dtype('int16')", "dtype('int8')", "dtype('uint16')", "dtype('uint8')", "dtype('<M8')", "dtype('<m8')", "dtype('O')", "<class 'pandas.core.arrays.integer.Int8Dtype'>", "<class 'pandas.core.arrays.integer.Int16Dtype'>", "<class 'pandas.core.arrays.integer.Int32Dtype'>", "<class 'pandas.core.arrays.integer.Int64Dtype'>", "<class 'pandas.core.arrays.integer.UInt8Dtype'>", "<class 'pandas.core.arrays.integer.UInt16Dtype'>", "<class 'pandas.core.arrays.integer.UInt32Dtype'>", "<class 'pandas.core.arrays.integer.UInt64Dtype'>", "<class 'pandas.CategoricalDtype'>", "<class 'pandas.IntervalDtype'>", "datetime64[ns, UTC]", "period[D]", "'int64'", "'int32'", "'uint32'", "'uint64'", "'float32'", "'float64'", "'int16'", "'int8'", "'uint16'", "'uint8'", "'datetime64'", "'timedelta64'", "'object'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'category'", "'interval'", "'datetime64[ns, UTC]'", "'period[D]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fd9b99f460a442066f655fd285e96e7bc3a2fd5599a6e62433c98e0811c6d2ad", "warmup_time": -1}, "dtypes.DtypesInvalid.time_pandas_dtype_invalid": {"code": "class DtypesInvalid:\n    def time_pandas_dtype_invalid(self, dtype):\n        try:\n            pandas_dtype(self.data_dict[dtype])\n        except TypeError:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.DtypesInvalid.time_pandas_dtype_invalid", "number": 0, "param_names": ["dtype"], "params": [["'scalar-string'", "'scalar-int'", "'list-string'", "'array-string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7f3ba4b4c7fbd54b7a1820ab3b4dd151e482f73fe3403b9bc5250c8abb048f3b", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_bool_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_bool_exclude(self, dtype):\n        self.df_bool.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_bool_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "df61255244e9be8fc0d248c55f3e063ddbef5c245f81a5411c66a28002c4bb65", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_bool_include": {"code": "class SelectDtypes:\n    def time_select_dtype_bool_include(self, dtype):\n        self.df_bool.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_bool_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f0c2f1bc4901e7d306373868e213c49d8d54794baf5de80fb27088cfe9bd4eef", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_float_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_float_exclude(self, dtype):\n        self.df_float.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_float_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c3819287ad630000615230fed62878a437c4adaf18567017b87aa79f998a39c8", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_float_include": {"code": "class SelectDtypes:\n    def time_select_dtype_float_include(self, dtype):\n        self.df_float.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_float_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ec02ea504a673f4cff6ac450fe51e76ad048e83ded067055b143b3124192c38c", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_int_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_int_exclude(self, dtype):\n        self.df_int.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_int_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "63425c0b6c4bfde374a64deda9bf4636080d34b8f7af826fa3f1d71c549ebc06", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_int_include": {"code": "class SelectDtypes:\n    def time_select_dtype_int_include(self, dtype):\n        self.df_int.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_int_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ded41b293fecd74fd41f47735fe03f5f06ddb9a870a1a2cac4c88816f0d12210", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_string_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_string_exclude(self, dtype):\n        self.df_string.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_string_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f7ec4762bcc09823b04a3e5cb9713f0e1e7120a85eb2c1f040a944a491e88f1e", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_string_include": {"code": "class SelectDtypes:\n    def time_select_dtype_string_include(self, dtype):\n        self.df_string.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_string_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2d8ac290640b9e1ef5db1c2db3a2f6aac6007549995a6004381d6499370d2cff", "warmup_time": -1}, "eval.Eval.time_add": {"code": "class Eval:\n    def time_add(self, engine, threads):\n        pd.eval(\"self.df + self.df2 + self.df3 + self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_add", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3b50f88f4cebf64200f50ab348ee13f8589e7dfb5962f7176004d30730f99112", "warmup_time": -1}, "eval.Eval.time_and": {"code": "class Eval:\n    def time_and(self, engine, threads):\n        pd.eval(\n            \"(self.df > 0) & (self.df2 > 0) & (self.df3 > 0) & (self.df4 > 0)\",\n            engine=engine,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_and", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e48d6e775f144cea8cd29b74723eb86f939c566bd1c688845dd864d16d60de1b", "warmup_time": -1}, "eval.Eval.time_chained_cmp": {"code": "class Eval:\n    def time_chained_cmp(self, engine, threads):\n        pd.eval(\"self.df < self.df2 < self.df3 < self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_chained_cmp", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0fe4b18c6cfabf06e6e4cac4c651276743a49df6a947913f8cabba517ba91786", "warmup_time": -1}, "eval.Eval.time_mult": {"code": "class Eval:\n    def time_mult(self, engine, threads):\n        pd.eval(\"self.df * self.df2 * self.df3 * self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_mult", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a2085f987e1ce9ac0c43a0fe2cba5ad5be060d477671017c4323e892a23899a2", "warmup_time": -1}, "eval.Query.time_query_datetime_column": {"code": "class Query:\n    def time_query_datetime_column(self):\n        self.df.query(\"dates < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1d140272522b8968337a65f5bbde890d721057d547e6496ce5ac4cacf49a12c6", "warmup_time": -1}, "eval.Query.time_query_datetime_index": {"code": "class Query:\n    def time_query_datetime_index(self):\n        self.df.query(\"index < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e92d36300cfda073c91694f6d7c09a034bfef434123510ab0a1a271d6f82893f", "warmup_time": -1}, "eval.Query.time_query_with_boolean_selection": {"code": "class Query:\n    def time_query_with_boolean_selection(self):\n        self.df.query(\"(a >= @self.min_val) & (a <= @self.max_val)\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_with_boolean_selection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2e364600de60ccd8ec4ba833f5c80ab650db44896f1fc7b6b1c3271ae2750fe2", "warmup_time": -1}, "finalize.Finalize.time_finalize_micro": {"code": "class Finalize:\n    def time_finalize_micro(self, param):\n        self.obj.__finalize__(self.obj, method=\"__finalize__\")\n\n    def setup(self, param):\n        N = 1000\n        obj = param(dtype=float)\n        for i in range(N):\n            obj.attrs[i] = i\n        self.obj = obj", "min_run_count": 2, "name": "finalize.Finalize.time_finalize_micro", "number": 0, "param_names": ["series"], "params": [["<class 'pandas.Series'>", "<class 'pandas.DataFrame'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bd2eab1eb436d45e913e54877c33d964695d4ac5fd0e7fd575f97eb347240a13", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_float": {"code": "class FromArrays:\n    def time_frame_from_arrays_float(self):\n        self.df = DataFrame._from_arrays(\n            self.float_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_float", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "325f63d87ecbf9ad645d78740a1aa8328bbd4c29f349c5b13a9117e526ce3866", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_int": {"code": "class FromArrays:\n    def time_frame_from_arrays_int(self):\n        self.df = DataFrame._from_arrays(\n            self.int_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0ea63af2ba6a6bc03ab7882f007240ed2d5183ed6fa7b85d15c9eb6f3c6f67f7", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_sparse": {"code": "class FromArrays:\n    def time_frame_from_arrays_sparse(self):\n        self.df = DataFrame._from_arrays(\n            self.sparse_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_sparse", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "225c22c0601994be668586bdb257030c2fd0d83e6dec0712bd820db812484318", "warmup_time": -1}, "frame_ctor.FromDicts.time_dict_of_categoricals": {"code": "class FromDicts:\n    def time_dict_of_categoricals(self):\n        # dict of arrays that we won't consolidate\n        DataFrame(self.dict_of_categoricals)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_dict_of_categoricals", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "31bd8e5276983e0e0e3b54a1067e23e1e752f382dbb023f29dfb8b0e7ac5e72d", "warmup_time": -1}, "frame_ctor.FromDicts.time_list_of_dict": {"code": "class FromDicts:\n    def time_list_of_dict(self):\n        DataFrame(self.dict_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_list_of_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6c0dbbebd6c0771feeaf375a1d39dbba020a4c12fad6bfee70c573d4414e1469", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict": {"code": "class FromDicts:\n    def time_nested_dict(self):\n        DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6a72f77f78250c8d1bad34fed6e994a8fd896e30b59e0d1802ea0ea8193f587e", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_columns": {"code": "class FromDicts:\n    def time_nested_dict_columns(self):\n        DataFrame(self.data, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e010dffc67442ff3250ce0a129b779c57637d00426ee53d397adc88b39992d63", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index": {"code": "class FromDicts:\n    def time_nested_dict_index(self):\n        DataFrame(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "48f1d011862f36806877b5da55102998d46466a016974d06f9495942c3585905", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index_columns": {"code": "class FromDicts:\n    def time_nested_dict_index_columns(self):\n        DataFrame(self.data, index=self.index, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e8d48e85e7f0256d3a1429fba5e9eb60305bb9282b505830ecd2625e858835d4", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_int64": {"code": "class FromDicts:\n    def time_nested_dict_int64(self):\n        # nested dict, integer indexes, regression described in #621\n        DataFrame(self.data2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "90614f59dcc399707a19e251cedb7098d4a033b2c6a6436a0225cb69703c33e0", "warmup_time": -1}, "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets": {"code": "class FromDictwithTimestamp:\n    def time_dict_with_timestamp_offsets(self, offset):\n        DataFrame(self.d)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDictwithTimestamp:\n    def setup(self, offset):\n        N = 10**3\n        idx = date_range(Timestamp(\"1/1/1900\"), freq=offset, periods=N)\n        df = DataFrame(np.random.randn(N, 10), index=idx)\n        self.d = df.to_dict()", "min_run_count": 2, "name": "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets", "number": 0, "param_names": ["offset"], "params": [["<Nano>", "<Hour>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "edbcf77be1e9f491a8866f3f510790d47d2c68aa69eb8e349b4662c23e071ce4", "warmup_time": -1}, "frame_ctor.FromLists.time_frame_from_lists": {"code": "class FromLists:\n    def time_frame_from_lists(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromLists:\n    def setup(self):\n        N = 1000\n        M = 100\n        self.data = [list(range(M)) for i in range(N)]", "min_run_count": 2, "name": "frame_ctor.FromLists.time_frame_from_lists", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "31e3e4ee69561a2f18687d4fe38117db21e57a6862eba4174561ab425ca7791a", "warmup_time": -1}, "frame_ctor.FromNDArray.time_frame_from_ndarray": {"code": "class FromNDArray:\n    def time_frame_from_ndarray(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromNDArray:\n    def setup(self):\n        N = 100000\n        self.data = np.random.randn(N)", "min_run_count": 2, "name": "frame_ctor.FromNDArray.time_frame_from_ndarray", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "42412f191926bccd17fde73d100476018ba3e35421ee311ca6a8d71ef8817e04", "warmup_time": -1}, "frame_ctor.FromRange.time_frame_from_range": {"code": "class FromRange:\n    def time_frame_from_range(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRange:\n    def setup(self):\n        N = 1_000_000\n        self.data = range(N)", "min_run_count": 2, "name": "frame_ctor.FromRange.time_frame_from_range", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8eac1f82a2a2f08e5f9e50dfcf68b362211c18712ce5adbbc12bc772d7d7f156", "warmup_time": -1}, "frame_ctor.FromRecords.time_frame_from_records_generator": {"code": "class FromRecords:\n    def time_frame_from_records_generator(self, nrows):\n        # issue-6700\n        self.df = DataFrame.from_records(self.gen, nrows=nrows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRecords:\n    def setup(self, nrows):\n        N = 100000\n        self.gen = ((x, (x * 20), (x * 100)) for x in range(N))", "min_run_count": 2, "name": "frame_ctor.FromRecords.time_frame_from_records_generator", "number": 1, "param_names": ["nrows"], "params": [["None", "1000"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "37ac2364875f70b5e255d9371c8fd77229fbb2bb221090c4004cce2af1f510b4", "warmup_time": -1}, "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64": {"code": "class FromScalar:\n    def time_frame_from_scalar_ea_float64(self):\n        DataFrame(\n            1.0,\n            index=range(self.nrows),\n            columns=list(\"abc\"),\n            dtype=Float64Dtype(),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromScalar:\n    def setup(self):\n        self.nrows = 100_000", "min_run_count": 2, "name": "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c0971ae1b0ebe91e20c2c53f71217475a9812d27e00b303f343bae2612d9828d", "warmup_time": -1}, "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64_na": {"code": "class FromScalar:\n    def time_frame_from_scalar_ea_float64_na(self):\n        DataFrame(\n            NA,\n            index=range(self.nrows),\n            columns=list(\"abc\"),\n            dtype=Float64Dtype(),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromScalar:\n    def setup(self):\n        self.nrows = 100_000", "min_run_count": 2, "name": "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64_na", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9075f068d48f77d734b775cec79405c4847fd0a6e1abfac3461c0dc12981f0b0", "warmup_time": -1}, "frame_ctor.FromSeries.time_mi_series": {"code": "class FromSeries:\n    def time_mi_series(self):\n        DataFrame(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromSeries:\n    def setup(self):\n        mi = MultiIndex.from_product([range(100), range(100)])\n        self.s = Series(np.random.randn(10000), index=mi)", "min_run_count": 2, "name": "frame_ctor.FromSeries.time_mi_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "00d66d6b3fb76fd4030a0096f492a7b2040615acbd38000c2317b116f3156fa2", "warmup_time": -1}, "frame_methods.Apply.time_apply_axis_1": {"code": "class Apply:\n    def time_apply_axis_1(self):\n        self.df.apply(lambda x: x + 1, axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_axis_1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1abb619fc583026b4a26e477881f01094dbeb880dded525e7cbea1815b8c3c7b", "warmup_time": -1}, "frame_methods.Apply.time_apply_lambda_mean": {"code": "class Apply:\n    def time_apply_lambda_mean(self):\n        self.df.apply(lambda x: x.mean())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_lambda_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e070e421516f44eee71e66e3fbf7ef0021872ca7eb578f4d11231ed83d441a64", "warmup_time": -1}, "frame_methods.Apply.time_apply_pass_thru": {"code": "class Apply:\n    def time_apply_pass_thru(self):\n        self.df.apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_pass_thru", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7ab6875c70f560ff825c524d780a53db1cad1e43c32e17fe6707f66113694e4c", "warmup_time": -1}, "frame_methods.Apply.time_apply_ref_by_name": {"code": "class Apply:\n    def time_apply_ref_by_name(self):\n        self.df3.apply(lambda x: x[\"A\"] + x[\"B\"], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_ref_by_name", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2195dd01ad2f3a289b3754239166687e0753c2a9d5efc0d8be4978c886628236", "warmup_time": -1}, "frame_methods.Apply.time_apply_str_mean": {"code": "class Apply:\n    def time_apply_str_mean(self):\n        self.df.apply(\"mean\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_str_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "521315810d8415e08556972f62c418fa4eabe181b49caea873ca989ae060e78f", "warmup_time": -1}, "frame_methods.Apply.time_apply_user_func": {"code": "class Apply:\n    def time_apply_user_func(self):\n        self.df2.apply(lambda x: np.corrcoef(x, self.s)[(0, 1)])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_user_func", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f52de9d070093a84321a5d00e1ff6810b8c4b83e274a1daabf52699c0244b257", "warmup_time": -1}, "frame_methods.AsType.time_astype": {"code": "class AsType:\n    def time_astype(self, from_to_dtypes, copy):\n        self.df.astype(from_to_dtypes[1], copy=copy)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsType:\n    def setup(self, from_to_dtypes, copy):\n        from_dtype = from_to_dtypes[0]\n        if from_dtype in (\"float64\", \"Float64\", \"float64[pyarrow]\"):\n            data = np.random.randn(100, 100)\n        elif from_dtype in (\"int64\", \"Int64\", \"int64[pyarrow]\"):\n            data = np.random.randint(0, 1000, (100, 100))\n        else:\n            raise NotImplementedError\n        self.df = DataFrame(data, dtype=from_dtype)", "min_run_count": 2, "name": "frame_methods.AsType.time_astype", "number": 0, "param_names": ["from_to_dtypes", "copy"], "params": [["('Float64', 'Float64')", "('float64[pyarrow]', 'float64[pyarrow]')", "('float64', 'Float64')", "('float64', 'float64[pyarrow]')", "('Float64', 'float64')", "('float64[pyarrow]', 'float64')", "('Int64', 'Float64')", "('int64[pyarrow]', 'float64[pyarrow]')"], ["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a9374f8b9c978c55710c85c55c7a9fd7794a57da8cf27963be077ff661b3c688", "warmup_time": -1}, "frame_methods.Clip.time_clip": {"code": "class Clip:\n    def time_clip(self, dtype):\n        self.df.clip(-1.0, 1.0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, dtype):\n        data = np.random.randn(100_000, 10)\n        df = DataFrame(data, dtype=dtype)\n        self.df = df", "min_run_count": 2, "name": "frame_methods.Clip.time_clip", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e377218cbb14d1e57e275faade93ca8bb525a9a1b596836b7b181b935186f968", "warmup_time": -1}, "frame_methods.Count.time_count": {"code": "class Count:\n    def time_count(self, axis):\n        self.df.count(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Count.time_count", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6d0fb3a3427b887565c31a8e63dda9d7ddd21b17b3f6da46237aac13dcc606e1", "warmup_time": -1}, "frame_methods.Count.time_count_mixed_dtypes": {"code": "class Count:\n    def time_count_mixed_dtypes(self, axis):\n        self.df_mixed.count(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Count.time_count_mixed_dtypes", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7676f0fd5db04a5cff602ddb81b98c1ced3e13ae9438e99839dab87c73cfced6", "warmup_time": -1}, "frame_methods.Describe.time_dataframe_describe": {"code": "class Describe:\n    def time_dataframe_describe(self):\n        self.df.describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10**6),\n                \"b\": np.random.randint(0, 100, 10**6),\n                \"c\": np.random.randint(0, 100, 10**6),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_dataframe_describe", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a874bed44cb683ca51210e26724792fcdf88f6ff721f785384c8fb834049538a", "warmup_time": -1}, "frame_methods.Describe.time_series_describe": {"code": "class Describe:\n    def time_series_describe(self):\n        self.df[\"a\"].describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10**6),\n                \"b\": np.random.randint(0, 100, 10**6),\n                \"c\": np.random.randint(0, 100, 10**6),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_series_describe", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bec8143392a0ea823e7bb51cdbc8e7e85a7655f739b8e049e7568f9d33a744f4", "warmup_time": -1}, "frame_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, how, axis):\n        self.df.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0ae9be10365366634edb6b6490363a365b53e5bb30376f429aa6cd8501e99f60", "warmup_time": -1}, "frame_methods.Dropna.time_dropna_axis_mixed_dtypes": {"code": "class Dropna:\n    def time_dropna_axis_mixed_dtypes(self, how, axis):\n        self.df_mixed.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna_axis_mixed_dtypes", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "211ec5d6bd6568e1ab93ad31c07d7ea015f9540b948fa60ae1ce9846c9d0aaf8", "warmup_time": -1}, "frame_methods.Dtypes.time_frame_dtypes": {"code": "class Dtypes:\n    def time_frame_dtypes(self):\n        self.df.dtypes\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dtypes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 1000))", "min_run_count": 2, "name": "frame_methods.Dtypes.time_frame_dtypes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a32eaac056e26349ac255f6354f2a8916b634a88bcf2fd8439b28dc9a21e4ff4", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated": {"code": "class Duplicated:\n    def time_frame_duplicated(self):\n        self.df.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8a4abe4aaf65e24b3da4f462809f17932a37cc967c623d8b7ff091daba1eb543", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated_subset": {"code": "class Duplicated:\n    def time_frame_duplicated_subset(self):\n        self.df.duplicated(subset=[\"a\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated_subset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "23f21c0b6b3f598648f33cbab727152cfaee3599521704a18f47a8184502b9f2", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated_wide": {"code": "class Duplicated:\n    def time_frame_duplicated_wide(self):\n        self.df2.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "097f9842171e94103f87e1898827b9193a138985565752f4880b1b4df539adb7", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_equal": {"code": "class Equals:\n    def time_frame_float_equal(self):\n        self.float_df.equals(self.float_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3e43e40c9afb93fdb9e4dc0b1153cb7e251f37639262f67e949b58d4cdec6de6", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_unequal": {"code": "class Equals:\n    def time_frame_float_unequal(self):\n        self.float_df.equals(self.float_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "096c7821b123d68c85d2ed32adda440daf4043608ac9a04e121f66aef041e33a", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_equal": {"code": "class Equals:\n    def time_frame_nonunique_equal(self):\n        self.nonunique_cols.equals(self.nonunique_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ea0c51f42ef266ee9b0fafafaa48a2192674cd615ae9f7b648b83aafbc5dcdce", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_unequal": {"code": "class Equals:\n    def time_frame_nonunique_unequal(self):\n        self.nonunique_cols.equals(self.nonunique_cols_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0afac18ed2411295c0adc10e398c9e4b02682bb882a28427a848f9b9455ad7dd", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_equal": {"code": "class Equals:\n    def time_frame_object_equal(self):\n        self.object_df.equals(self.object_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fcfdbbe9b7bbe39721d77c9ea49fde74df25c32913469a26570f9cedeeebe789", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_unequal": {"code": "class Equals:\n    def time_frame_object_unequal(self):\n        self.object_df.equals(self.object_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8bb79f98af91ebb0756c6d77ad92778236c4b7ac8b01c041ed655dfb3fed7ce7", "warmup_time": -1}, "frame_methods.Fillna.time_bfill": {"code": "class Fillna:\n    def time_bfill(self, inplace, dtype):\n        self.df.bfill(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()", "min_run_count": 2, "name": "frame_methods.Fillna.time_bfill", "number": 0, "param_names": ["inplace", "dtype"], "params": [["True", "False"], ["'float64'", "'float32'", "'object'", "'Int64'", "'Float64'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timedelta64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ab1619ca6d7bbaad9c0eac1f7dd4ea723ac82673224aa8dbce70c1984f22acb3", "warmup_time": -1}, "frame_methods.Fillna.time_ffill": {"code": "class Fillna:\n    def time_ffill(self, inplace, dtype):\n        self.df.ffill(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()", "min_run_count": 2, "name": "frame_methods.Fillna.time_ffill", "number": 0, "param_names": ["inplace", "dtype"], "params": [["True", "False"], ["'float64'", "'float32'", "'object'", "'Int64'", "'Float64'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timedelta64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0912aa084abd2d5fc47d46ff25b6d897cec70cdab63de87d29937622654d060a", "warmup_time": -1}, "frame_methods.Fillna.time_fillna": {"code": "class Fillna:\n    def time_fillna(self, inplace, dtype):\n        self.df.fillna(value=self.fill_values, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()", "min_run_count": 2, "name": "frame_methods.Fillna.time_fillna", "number": 0, "param_names": ["inplace", "dtype"], "params": [["True", "False"], ["'float64'", "'float32'", "'object'", "'Int64'", "'Float64'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timedelta64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ba97c9ea4cd6a522136714fca9cc26d5060c052e08f8ff392def7c3b1ce4578e", "warmup_time": -1}, "frame_methods.FindValidIndex.time_first_valid_index": {"code": "class FindValidIndex:\n    def time_first_valid_index(self, dtype):\n        self.df.first_valid_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FindValidIndex:\n    def setup(self, dtype):\n        df = DataFrame(\n            np.random.randn(100000, 2),\n            columns=list(\"AB\"),\n            dtype=dtype,\n        )\n        df.iloc[:100, 0] = None\n        df.iloc[:200, 1] = None\n        df.iloc[-100:, 0] = None\n        df.iloc[-200:, 1] = None\n        self.df = df", "min_run_count": 2, "name": "frame_methods.FindValidIndex.time_first_valid_index", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "25a643509f423207f4a1c6d8a57a39a4a2fb113489c72c587ab77425b9d0ed8c", "warmup_time": -1}, "frame_methods.FindValidIndex.time_last_valid_index": {"code": "class FindValidIndex:\n    def time_last_valid_index(self, dtype):\n        self.df.last_valid_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FindValidIndex:\n    def setup(self, dtype):\n        df = DataFrame(\n            np.random.randn(100000, 2),\n            columns=list(\"AB\"),\n            dtype=dtype,\n        )\n        df.iloc[:100, 0] = None\n        df.iloc[:200, 1] = None\n        df.iloc[-100:, 0] = None\n        df.iloc[-200:, 1] = None\n        self.df = df", "min_run_count": 2, "name": "frame_methods.FindValidIndex.time_last_valid_index", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7aa1cbbe0fc10c07e441950795f86f657072d95abb3fc53a6cd08af9ca145bb5", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts": {"code": "class GetDtypeCounts:\n    def time_frame_get_dtype_counts(self):\n        with warnings.catch_warnings(record=True):\n            self.df.dtypes.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d1e0466afc9058166debec31e7ff688df837d407655e8faf0621969115aee0dd", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_info": {"code": "class GetDtypeCounts:\n    def time_info(self):\n        self.df.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_info", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e08ed8e2402f26a376b2c946606fe2bc255214bd7eebee091fe34b3aa4df80db", "warmup_time": -1}, "frame_methods.GetNumericData.time_frame_get_numeric_data": {"code": "class GetNumericData:\n    def time_frame_get_numeric_data(self):\n        self.df._get_numeric_data()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetNumericData:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 25))\n        self.df[\"foo\"] = \"bar\"\n        self.df[\"bar\"] = \"baz\"\n        self.df = self.df._consolidate()", "min_run_count": 2, "name": "frame_methods.GetNumericData.time_frame_get_numeric_data", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a6f6ccd03d2a3e6a5b9533bf09fd1f3d852fb8c066e10da43dee6c5b1b958b16", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate": {"code": "class Interpolate:\n    def time_interpolate(self):\n        self.df.interpolate()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c596eeb3d29c229642e5985525a061a7048ea58730234346a6a62d19c92dbac7", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate_some_good": {"code": "class Interpolate:\n    def time_interpolate_some_good(self):\n        self.df2.interpolate()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate_some_good", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a33fc1bf97cd98d64d979695f6cd8a828368e681b17fd24a2064470b41e314f5", "warmup_time": -1}, "frame_methods.Isna.time_isna": {"code": "class Isna:\n    def time_isna(self, dtype):\n        self.df.isna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isna:\n    def setup(self, dtype):\n        data = np.random.randn(10000, 1000)\n        # all-na columns\n        data[:, 600:800] = np.nan\n        # partial-na columns\n        data[800:1000, 4000:5000] = np.nan\n        self.df = DataFrame(data, dtype=dtype)", "min_run_count": 2, "name": "frame_methods.Isna.time_isna", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "16c807e189d1c06f5c7693f87fb8211e7206b4807b9eba3c390f1dd2c5e5cf37", "warmup_time": -1}, "frame_methods.Isnull.time_isnull": {"code": "class Isnull:\n    def time_isnull(self):\n        isnull(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "de22a45fa388dfa02f30c3a7cb1acae9fe966c2d1e68671882fa38eda4e52b3e", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_floats_no_null": {"code": "class Isnull:\n    def time_isnull_floats_no_null(self):\n        isnull(self.df_no_null)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_floats_no_null", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d52c0900c393b15f62670fa1ccbc7018957cad8e340de411ad4bd5b33da9ee72", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_obj": {"code": "class Isnull:\n    def time_isnull_obj(self):\n        isnull(self.df_obj)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_obj", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "02fc103a644b76b012203138d72c1aedc60734a2ca5eaa97a80a3cac46bcf039", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_strngs": {"code": "class Isnull:\n    def time_isnull_strngs(self):\n        isnull(self.df_strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_strngs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ff2d41de239a32889b66173e7caa3c0017fac8052762ae9703e5f9e07e1ef5a5", "warmup_time": -1}, "frame_methods.Iteration.mem_itertuples_raw_start": {"code": "class Iteration:\n    def mem_itertuples_raw_start(self):\n        return self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "bde9d2373c7953bbf4a4d7fe73bd19e60eb7c15b50f8978637098fec3d837ed1"}, "frame_methods.Iteration.mem_itertuples_raw_to_list": {"code": "class Iteration:\n    def mem_itertuples_raw_to_list(self):\n        return list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "14959ad0e6b16ce24b2986d509e67eeccc6ad44f09ce481e44781dd903d37a04"}, "frame_methods.Iteration.mem_itertuples_read_first": {"code": "class Iteration:\n    def mem_itertuples_read_first(self):\n        return next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_read_first", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "fa14a67958421e77045287ab0dfe58c2d22462f3b77070715024772201c64770"}, "frame_methods.Iteration.mem_itertuples_start": {"code": "class Iteration:\n    def mem_itertuples_start(self):\n        return self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "cf2518d7a524f33405fe8b9f5e7dd8af1e52820e56cf14f92d6ff79ca33bbca9"}, "frame_methods.Iteration.mem_itertuples_to_list": {"code": "class Iteration:\n    def mem_itertuples_to_list(self):\n        return list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "fc2c86822b2a65a5dd8df96b9003fe69eb2c82b3b8543140d1744b7d7fbc099f"}, "frame_methods.Iteration.peakmem_itertuples": {"code": "class Iteration:\n    def peakmem_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "f8c4bb246773a09f62d6963200ac6dd08accf63f8701099b39f34450db0baa76"}, "frame_methods.Iteration.peakmem_itertuples_raw": {"code": "class Iteration:\n    def peakmem_itertuples_raw(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "51be24a7edeb484ceaa5e24c608c890c59c56b210c778564af1c40cde9c6582b"}, "frame_methods.Iteration.peakmem_itertuples_raw_read_first": {"code": "class Iteration:\n    def peakmem_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_read_first", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "3bcec70cbf3d3ea880425ba6e3a7a604504d19716e82dbbb4a70fb8351eda7f3"}, "frame_methods.Iteration.peakmem_itertuples_raw_start": {"code": "class Iteration:\n    def peakmem_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "8d85d7a2d0ceb456c1eae16a3f138a7ea0a13edf1bd76492d262b00cc32013cf"}, "frame_methods.Iteration.peakmem_itertuples_raw_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_raw_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "702541458ae59bd0fa6a7654edf93ba6de30013419a4591073b4077ffaaa9ec1"}, "frame_methods.Iteration.peakmem_itertuples_start": {"code": "class Iteration:\n    def peakmem_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "2e9870eb171bfbc3718dac5dc495cf2a5fc860a65acca33db4110a97d819f905"}, "frame_methods.Iteration.peakmem_itertuples_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "3b1c891c821d3baa961e2ac7bbba794eaaa5fdde90643e15273782165349694d"}, "frame_methods.Iteration.time_items": {"code": "class Iteration:\n    def time_items(self):\n        # (monitor no-copying behaviour)\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "a6f7587a4f64433c91d33b1870cb0f27c4cf206efd215b5ef8c197f6515465e4", "warmup_time": -1}, "frame_methods.Iteration.time_iteritems_indexing": {"code": "class Iteration:\n    def time_iteritems_indexing(self):\n        for col in self.df3:\n            self.df3[col]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iteritems_indexing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "32a0d9e470a05a943e062be7e53224b0a8d3c4753f3ea203564451fe73e00be6", "warmup_time": -1}, "frame_methods.Iteration.time_iterrows": {"code": "class Iteration:\n    def time_iterrows(self):\n        for row in self.df.iterrows():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iterrows", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "1872356d18d8d38838ccef4e38aea113cb033fcd589da146758d76d6aba725c1", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples": {"code": "class Iteration:\n    def time_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "bc1f6d845378bd6d1c53d1ef7b8e0f725f9a6ca74b0b1bfe928c5a21e6829fd9", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_read_first": {"code": "class Iteration:\n    def time_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_read_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "78a787f4a6eb7dd27f3ac2434d4d26567eca763890c14bd2b86b54d88ade5db4", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_start": {"code": "class Iteration:\n    def time_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_start", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "e34eb99379456d0e4ff1da68c34d436747af447b5d80f49bca78a9095da18426", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples": {"code": "class Iteration:\n    def time_itertuples_raw_tuples(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "ef2cf1b3767b908e25cbd488502ea2b91b43cfcd491b12389acfbea37699cc95", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples_to_list": {"code": "class Iteration:\n    def time_itertuples_raw_tuples_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples_to_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "f372d26bf89b90dd1e24ac2a01493a7435fdf11710e9e65324adc1d350725816", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_read_first": {"code": "class Iteration:\n    def time_itertuples_read_first(self):\n        next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_read_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9ed674f5820c7707be515d2f9a891d84a09efcf8f785fc428335dac028a682a6", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_start": {"code": "class Iteration:\n    def time_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_start", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "beae2a24376ed50a9a214101ac7828899ca3db4436d6f61cc38ac099202d2dfd", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_to_list": {"code": "class Iteration:\n    def time_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_to_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "a5fc1a49acb90aa9c123ba866a88ff4f8c508c4cfef59faa117d0da770f63698", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_bools": {"code": "class MaskBool:\n    def time_frame_mask_bools(self):\n        self.bools.mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_bools", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "75d26deea512c14af4e7569f5dc1e43324ed79283c789db2fb4999d0d7853441", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_floats": {"code": "class MaskBool:\n    def time_frame_mask_floats(self):\n        self.bools.astype(float).mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "77725b9d5309bb967bcd8a8abd4d5a8168f1759ac192d051fe68d191166e9b7e", "warmup_time": -1}, "frame_methods.MemoryUsage.time_memory_usage": {"code": "class MemoryUsage:\n    def time_memory_usage(self):\n        self.df.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")", "min_run_count": 2, "name": "frame_methods.MemoryUsage.time_memory_usage", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "abaa03ed61b94b958c09bee89d52d1b87d72796639ec7588559d5b158f8dede9", "warmup_time": -1}, "frame_methods.MemoryUsage.time_memory_usage_object_dtype": {"code": "class MemoryUsage:\n    def time_memory_usage_object_dtype(self):\n        self.df2.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")", "min_run_count": 2, "name": "frame_methods.MemoryUsage.time_memory_usage_object_dtype", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f25a399ce1ee970c20943c1c0c1d8359a80848bf10be1b7912eae51ee454231a", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_one_column": {"code": "class NSort:\n    def time_nlargest_one_column(self, keep):\n        self.df.nlargest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ae8ee646412a2720d7755ec64e5f1a787ddb6242469e44c8e3f548a93c55eb32", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_two_columns": {"code": "class NSort:\n    def time_nlargest_two_columns(self, keep):\n        self.df.nlargest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fb06c1f8251bd2a6af6ab02b7dbf651402818b3898c88c5f634d4999eb180730", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_one_column": {"code": "class NSort:\n    def time_nsmallest_one_column(self, keep):\n        self.df.nsmallest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "602770ac5530f5b88477e395308b8146dcf5adb79187c8d34b0201ba44680a2e", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_two_columns": {"code": "class NSort:\n    def time_nsmallest_two_columns(self, keep):\n        self.df.nsmallest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "27757c983389573bb278541de8a55e9ac92f47fc4c94a64054207953192b17d7", "warmup_time": -1}, "frame_methods.Nunique.time_frame_nunique": {"code": "class Nunique:\n    def time_frame_nunique(self):\n        self.df.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nunique:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 1000))", "min_run_count": 2, "name": "frame_methods.Nunique.time_frame_nunique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7b4f1bb3132faa41cd11750a8882705594d2e2437af6d28e1c6648950e7d0c46", "warmup_time": -1}, "frame_methods.Quantile.time_frame_quantile": {"code": "class Quantile:\n    def time_frame_quantile(self, axis):\n        self.df.quantile([0.1, 0.5], axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Quantile.time_frame_quantile", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e46972758e099994281698947a2e05eda1f226d307e25f58fb72796cedd8908f", "warmup_time": -1}, "frame_methods.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, dtype):\n        self.df.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(10000, 10).astype(dtype), columns=range(10), dtype=dtype\n        )", "min_run_count": 2, "name": "frame_methods.Rank.time_rank", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4512f531d4398c0997ffb9c0b076476cab3bef280e5662032d20d3b76f2e26cb", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis0": {"code": "class Reindex:\n    def time_reindex_axis0(self):\n        self.df.reindex(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis0", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8e312cd3e03e3d1f3c1440ed72a1f0a6056d79a9045d8f1ee844b2188f613054", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis1": {"code": "class Reindex:\n    def time_reindex_axis1(self):\n        self.df.reindex(columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4a93950c7bd7528bd910907cda4f0ff4d5194febad4f498b87cc400feff0d1a6", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis1_missing": {"code": "class Reindex:\n    def time_reindex_axis1_missing(self):\n        self.df.reindex(columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis1_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7749b0b3b38ff50cbd6509455c235277f2f3cc7ea7bb8642397cfe79fcd2025d", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_both_axes": {"code": "class Reindex:\n    def time_reindex_both_axes(self):\n        self.df.reindex(index=self.idx, columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "06ce9de462c065fcb31edc17bbaa87b044287b757a29abc717d85764e418e727", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_upcast": {"code": "class Reindex:\n    def time_reindex_upcast(self):\n        self.df2.reindex(np.random.permutation(range(1200)))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_upcast", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8d05018638e09bdfc144121f846b4c2bef1cf019e84b76006bbdef08e268a466", "warmup_time": -1}, "frame_methods.Rename.time_dict_rename_both_axes": {"code": "class Rename:\n    def time_dict_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_dict_rename_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "060b0d33988e4009693f1109e6274a165c7e1b54c2ce817d60a436c7b6f46325", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis0": {"code": "class Rename:\n    def time_rename_axis0(self):\n        self.df.rename(self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis0", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7442ed7fc2e73ac7a280c1909b8a01ab6e5269f51652c483a3af6288beea66ea", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis1": {"code": "class Rename:\n    def time_rename_axis1(self):\n        self.df.rename(columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "95e21d6ec76ff34607840fa82609ec8b610013d6bd877d0092453f968a5384f6", "warmup_time": -1}, "frame_methods.Rename.time_rename_both_axes": {"code": "class Rename:\n    def time_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "57060b21c7592bb4bd46070429134f61a772694a95ed1014c9c65df5e0f43873", "warmup_time": -1}, "frame_methods.Rename.time_rename_single": {"code": "class Rename:\n    def time_rename_single(self):\n        self.df.rename({0: 0})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_single", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ddc80d464ece8f0b4fabad5fcb4cbb0729ffdb09e225469ff23f5e49ed1ac8c4", "warmup_time": -1}, "frame_methods.Repr.time_frame_repr_wide": {"code": "class Repr:\n    def time_frame_repr_wide(self):\n        repr(self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_frame_repr_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b7c902cd0a2f02eebcb938f83eb0bc567c8bf80146ce7c09a335b559e8715a33", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_mi": {"code": "class Repr:\n    def time_html_repr_trunc_mi(self):\n        self.df3._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_mi", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c5988920e0b3d00d1ec74379b4576a53ad6b17e4c9b71625316958d163ed4164", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_si": {"code": "class Repr:\n    def time_html_repr_trunc_si(self):\n        self.df4._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_si", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8fd8968223faa897090a27941e475b84b23f11c40bb5c7541e6f71c9fb9376a3", "warmup_time": -1}, "frame_methods.Repr.time_repr_tall": {"code": "class Repr:\n    def time_repr_tall(self):\n        repr(self.df_tall)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_repr_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "57c3fcd319895e084cdc6f5e24084880d4817e72dd3fe35856b00b69e7ea1742", "warmup_time": -1}, "frame_methods.Round.peakmem_round": {"code": "class Round:\n    def peakmem_round(self):\n        self.df.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "name": "frame_methods.Round.peakmem_round", "param_names": [], "params": [], "type": "peakmemory", "unit": "bytes", "version": "6030b93289557c8c988898eb2865291b8bbb65999e8761c6dedd7d32eeae984c"}, "frame_methods.Round.peakmem_round_transposed": {"code": "class Round:\n    def peakmem_round_transposed(self):\n        self.df_t.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "name": "frame_methods.Round.peakmem_round_transposed", "param_names": [], "params": [], "type": "peakmemory", "unit": "bytes", "version": "919cd08ae6984fe9193852f5e8b5432e1bc12537c5e39da7333f549a5e72ab37"}, "frame_methods.Round.time_round": {"code": "class Round:\n    def time_round(self):\n        self.df.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "min_run_count": 2, "name": "frame_methods.Round.time_round", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "96ca48bf009b1f5637ae83a659df490757d37c26fee67d6a45104d6e0bf32219", "warmup_time": -1}, "frame_methods.Round.time_round_transposed": {"code": "class Round:\n    def time_round_transposed(self):\n        self.df_t.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "min_run_count": 2, "name": "frame_methods.Round.time_round_transposed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "19596a27ad277a08b79ca33e2b9773ebc43379e2443ff070f4b60f930bcef9d8", "warmup_time": -1}, "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan": {"code": "class SeriesNuniqueWithNan:\n    def time_series_nunique_nan(self):\n        self.ser.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesNuniqueWithNan:\n    def setup(self):\n        values = 100 * [np.nan] + list(range(100))\n        self.ser = Series(np.tile(values, 10000), dtype=float)", "min_run_count": 2, "name": "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bdb51c04637dc0c9c73bb2a3b6a2ffee3ae1b5517fb485dfb8f1c5e562c5c6c7", "warmup_time": -1}, "frame_methods.Shift.time_shift": {"code": "class Shift:\n    def time_shift(self, axis):\n        self.df.shift(1, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.rand(10000, 500))", "min_run_count": 2, "name": "frame_methods.Shift.time_shift", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "09d28e1e7b36fe4dfa6ed22317da40bcde0164c120b61d4efff8f61b02c768af", "warmup_time": -1}, "frame_methods.SortMultiKey.time_sort_index": {"code": "class SortMultiKey:\n    def time_sort_index(self, monotonic):\n        self.df_by_index.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortMultiKey:\n    def setup(self, monotonic):\n        N = 10000\n        K = 10\n        df = DataFrame(\n            {\n                \"key1\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"key2\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"value\": np.random.randn(N * K),\n            }\n        )\n        if monotonic:\n            df = df.sort_values([\"key1\", \"key2\"])\n        self.df_by_columns = df\n        self.df_by_index = df.set_index([\"key1\", \"key2\"])", "min_run_count": 2, "name": "frame_methods.SortMultiKey.time_sort_index", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "14e8d6aab1e556f8caea675776001969164ccf76049c529a3e0077ee8a56b7ba", "warmup_time": -1}, "frame_methods.SortMultiKey.time_sort_values": {"code": "class SortMultiKey:\n    def time_sort_values(self, monotonic):\n        self.df_by_columns.sort_values(by=[\"key1\", \"key2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortMultiKey:\n    def setup(self, monotonic):\n        N = 10000\n        K = 10\n        df = DataFrame(\n            {\n                \"key1\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"key2\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"value\": np.random.randn(N * K),\n            }\n        )\n        if monotonic:\n            df = df.sort_values([\"key1\", \"key2\"])\n        self.df_by_columns = df\n        self.df_by_index = df.set_index([\"key1\", \"key2\"])", "min_run_count": 2, "name": "frame_methods.SortMultiKey.time_sort_values", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2742a8d577f8f9f13eee3c04ba10dec5ca223b766b72708333b2bb9240ff7007", "warmup_time": -1}, "frame_methods.SortValues.time_frame_sort_values": {"code": "class SortValues:\n    def time_frame_sort_values(self, ascending):\n        self.df.sort_values(by=\"A\", ascending=ascending)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, ascending):\n        self.df = DataFrame(np.random.randn(1000000, 2), columns=list(\"AB\"))", "min_run_count": 2, "name": "frame_methods.SortValues.time_frame_sort_values", "number": 0, "param_names": ["ascending"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bf9c8ff877f2cd95431692cfe963e37b3de4634176be673d3de0b663177d7ad3", "warmup_time": -1}, "frame_methods.ToDict.time_to_dict_datetimelike": {"code": "class ToDict:\n    def time_to_dict_datetimelike(self, orient):\n        self.datetimelike_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")", "min_run_count": 2, "name": "frame_methods.ToDict.time_to_dict_datetimelike", "number": 0, "param_names": ["orient"], "params": [["'dict'", "'list'", "'series'", "'split'", "'records'", "'index'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "939f612766529ae46a0b196a3dc13061331265310113f5a5c18d503fd623eb63", "warmup_time": -1}, "frame_methods.ToDict.time_to_dict_ints": {"code": "class ToDict:\n    def time_to_dict_ints(self, orient):\n        self.int_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")", "min_run_count": 2, "name": "frame_methods.ToDict.time_to_dict_ints", "number": 0, "param_names": ["orient"], "params": [["'dict'", "'list'", "'series'", "'split'", "'records'", "'index'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8ca05db38583b86c56e9781a0ba1f399533c5e196accee6737c23ade9750f5c9", "warmup_time": -1}, "frame_methods.ToHTML.time_to_html_mixed": {"code": "class ToHTML:\n    def time_to_html_mixed(self):\n        self.df2.to_html()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToHTML:\n    def setup(self):\n        nrows = 500\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\n        self.df2[0] = period_range(\"2000\", periods=nrows)\n        self.df2[1] = range(nrows)", "min_run_count": 2, "name": "frame_methods.ToHTML.time_to_html_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a63bfb2f9452ef12121452e5a13a47f1ddf16d3a2ecc961f1d143598ae48a31a", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_mixed_tall": {"code": "class ToNumpy:\n    def time_to_numpy_mixed_tall(self):\n        self.df_mixed_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_mixed_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5609d5ea9c8d63719954d185af31995af502969500f52a283b95dee96b206b21", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_mixed_wide": {"code": "class ToNumpy:\n    def time_to_numpy_mixed_wide(self):\n        self.df_mixed_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_mixed_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b8cf4cdbf480bfa101b1e9bbf6df8e6a9516540d5888f9acf40c29f0b39c4178", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_tall": {"code": "class ToNumpy:\n    def time_to_numpy_tall(self):\n        self.df_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5569b6deed04489b4f459b07dc638df2d11771fc68bd230503521874fd8280e9", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_wide": {"code": "class ToNumpy:\n    def time_to_numpy_wide(self):\n        self.df_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bf654b3ba6daa0281ee0f2802eb3d2aeda580273f37f51975c0a6949c7f80d88", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_mixed_tall": {"code": "class ToNumpy:\n    def time_values_mixed_tall(self):\n        self.df_mixed_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_mixed_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "63f9938602ca8bd629ccf01754db81ac30be79e67c04b0f0773bc5b0d042f33d", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_mixed_wide": {"code": "class ToNumpy:\n    def time_values_mixed_wide(self):\n        self.df_mixed_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_mixed_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fafed5c463a9d832b1c45ce00e7755cf10235ae288cb4939713e9e25b2884d1e", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_tall": {"code": "class ToNumpy:\n    def time_values_tall(self):\n        self.df_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d7415d8faba6d4a8ac5b59b9db979d88981de08547167f51ec5c31b322149dfb", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_wide": {"code": "class ToNumpy:\n    def time_values_wide(self):\n        self.df_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5f1b62f28c9211bb22340a6af83d5b86811950ef975bfd00e0684048cb2de22f", "warmup_time": -1}, "frame_methods.ToRecords.time_to_records": {"code": "class ToRecords:\n    def time_to_records(self):\n        self.df.to_records(index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToRecords:\n    def setup(self):\n        N = 100_000\n        data = np.random.randn(N, 2)\n        mi = MultiIndex.from_arrays(\n            [\n                np.arange(N),\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\n            ]\n        )\n        self.df = DataFrame(data)\n        self.df_mi = DataFrame(data, index=mi)", "min_run_count": 2, "name": "frame_methods.ToRecords.time_to_records", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f42f25126b3a450ab55465c858ae504d2ded8b644488689fa856b421d41c0cba", "warmup_time": -1}, "frame_methods.ToRecords.time_to_records_multiindex": {"code": "class ToRecords:\n    def time_to_records_multiindex(self):\n        self.df_mi.to_records(index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToRecords:\n    def setup(self):\n        N = 100_000\n        data = np.random.randn(N, 2)\n        mi = MultiIndex.from_arrays(\n            [\n                np.arange(N),\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\n            ]\n        )\n        self.df = DataFrame(data)\n        self.df_mi = DataFrame(data, index=mi)", "min_run_count": 2, "name": "frame_methods.ToRecords.time_to_records_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ba7c2132dec45f9679103e1739697a3c005f6921b9c766546d8535303d90777d", "warmup_time": -1}, "frame_methods.ToString.time_to_string_floats": {"code": "class ToString:\n    def time_to_string_floats(self):\n        self.df.to_string()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToString:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100, 10))", "min_run_count": 2, "name": "frame_methods.ToString.time_to_string_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e56ad6695cac3b92e88feb11d8c47fa92f10fb86e51634e87529d771f168cdbf", "warmup_time": -1}, "frame_methods.Update.time_to_update_big_frame_small_arg": {"code": "class Update:\n    def time_to_update_big_frame_small_arg(self):\n        self.df.update(self.df_sample)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Update:\n    def setup(self):\n        rng = np.random.default_rng()\n        self.df = DataFrame(rng.uniform(size=(1_000_000, 10)))\n    \n        idx = rng.choice(range(1_000_000), size=1_000_000, replace=False)\n        self.df_random = DataFrame(self.df, index=idx)\n    \n        idx = rng.choice(range(1_000_000), size=100_000, replace=False)\n        cols = rng.choice(range(10), size=2, replace=False)\n        self.df_sample = DataFrame(\n            rng.uniform(size=(100_000, 2)), index=idx, columns=cols\n        )", "min_run_count": 2, "name": "frame_methods.Update.time_to_update_big_frame_small_arg", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d30ce943b59f73cac30317b7fbc940e85ec5efc11638d04af2b7ccdeedc32dc0", "warmup_time": -1}, "frame_methods.Update.time_to_update_random_indices": {"code": "class Update:\n    def time_to_update_random_indices(self):\n        self.df_random.update(self.df_sample)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Update:\n    def setup(self):\n        rng = np.random.default_rng()\n        self.df = DataFrame(rng.uniform(size=(1_000_000, 10)))\n    \n        idx = rng.choice(range(1_000_000), size=1_000_000, replace=False)\n        self.df_random = DataFrame(self.df, index=idx)\n    \n        idx = rng.choice(range(1_000_000), size=100_000, replace=False)\n        cols = rng.choice(range(10), size=2, replace=False)\n        self.df_sample = DataFrame(\n            rng.uniform(size=(100_000, 2)), index=idx, columns=cols\n        )", "min_run_count": 2, "name": "frame_methods.Update.time_to_update_random_indices", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8b95fcbe44de6c6f894ae33695436745b5ac38ab262704a34b30f2ad6395be80", "warmup_time": -1}, "frame_methods.Update.time_to_update_small_frame_big_arg": {"code": "class Update:\n    def time_to_update_small_frame_big_arg(self):\n        self.df_sample.update(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Update:\n    def setup(self):\n        rng = np.random.default_rng()\n        self.df = DataFrame(rng.uniform(size=(1_000_000, 10)))\n    \n        idx = rng.choice(range(1_000_000), size=1_000_000, replace=False)\n        self.df_random = DataFrame(self.df, index=idx)\n    \n        idx = rng.choice(range(1_000_000), size=100_000, replace=False)\n        cols = rng.choice(range(10), size=2, replace=False)\n        self.df_sample = DataFrame(\n            rng.uniform(size=(100_000, 2)), index=idx, columns=cols\n        )", "min_run_count": 2, "name": "frame_methods.Update.time_to_update_small_frame_big_arg", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fe0be300fb64f1ec27a8b2258356397b32881365b73bc4871821a0e3342d4732", "warmup_time": -1}, "frame_methods.Where.time_where": {"code": "class Where:\n    def time_where(self, inplace, dtype):\n        self.df.where(self.mask, other=0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Where:\n    def setup(self, inplace, dtype):\n        self.df = DataFrame(np.random.randn(100_000, 10), dtype=dtype)\n        self.mask = self.df < 0", "min_run_count": 2, "name": "frame_methods.Where.time_where", "number": 0, "param_names": ["dtype", "param2"], "params": [["True", "False"], ["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d16b5044f854c91f698425fe60c4f71b7f819334706ddf4e2e6bb35a27c1a928", "warmup_time": -1}, "frame_methods.XS.time_frame_xs": {"code": "class XS:\n    def time_frame_xs(self, axis):\n        self.df.xs(self.N / 2, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass XS:\n    def setup(self, axis):\n        self.N = 10**4\n        self.df = DataFrame(np.random.randn(self.N, self.N))", "min_run_count": 2, "name": "frame_methods.XS.time_frame_xs", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4c10ba567aab8044d880b7e51f27220a7353cda967ee331f4bf88ebbc2406d4f", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_day": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_day(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.day\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_day", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "57949cef8376be9aca572d8c68a05289b9950b538c13e861ad1b71df817c3515", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_daysinmonth(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.days_in_month\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e08964e060471859275a5a734b94e650445f8e0db22890e06d5c36b207e103a8", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_normalize": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_normalize(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.normalize()\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_normalize", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "59282e48b58fc897cac7af777786d7dc152983bf0f08d5e8ca7049410a9edfb1", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_year": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_year(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.year\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_year", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4e6d8e9847ac5022c75aabaff81f2a4ce4528c29b8d2f44d50f8729b732bef51", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_to_period": {"code": "class ParallelDatetimeFields:\n    def time_datetime_to_period(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.to_period(\"s\")\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_to_period", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cf5a4f24f7ea1d7e1842a834d7a3ed311331d1375098ccb8bd2423d9df91f03c", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_period_to_datetime": {"code": "class ParallelDatetimeFields:\n    def time_period_to_datetime(self):\n        @test_parallel(num_threads=2)\n        def run(period):\n            period.to_timestamp()\n    \n        run(self.period)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_period_to_datetime", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3766967574deb647b538a27545eb395e8fce97e83e988ac9785f6865c97084d1", "warmup_time": -1}, "gil.ParallelFactorize.time_loop": {"code": "class ParallelFactorize:\n    def time_loop(self, threads):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        strings = Index([f\"i-{i}\" for i in range(100000)], dtype=object)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_loop", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3d702042bf0b72599271c4f0aca5d1cc55c8de89f03071bd59d498a5dbdb8448", "warmup_time": -1}, "gil.ParallelFactorize.time_parallel": {"code": "class ParallelFactorize:\n    def time_parallel(self, threads):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        strings = Index([f\"i-{i}\" for i in range(100000)], dtype=object)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_parallel", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7a105748ab3e006bf2a891c0883f2103a5c368902e13d14f3a64656e1968793a", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_loop": {"code": "class ParallelGroupbyMethods:\n    def time_loop(self, threads, method):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_loop", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "eb7b8df45f4491f84224614922e1b5e9a4f93453147833890ec096562f96b248", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_parallel": {"code": "class ParallelGroupbyMethods:\n    def time_parallel(self, threads, method):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_parallel", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee3c7c1d8ffe98d3bbc8c64cb4af33754566e6351c3bb50458012a695887b895", "warmup_time": -1}, "gil.ParallelGroups.time_get_groups": {"code": "class ParallelGroups:\n    def time_get_groups(self, threads):\n        self.get_groups()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroups:\n    def setup(self, threads):\n        size = 2**22\n        ngroups = 10**3\n        data = Series(np.random.randint(0, ngroups, size=size))\n    \n        @test_parallel(num_threads=threads)\n        def get_groups():\n            data.groupby(data).groups\n    \n        self.get_groups = get_groups", "min_run_count": 2, "name": "gil.ParallelGroups.time_get_groups", "number": 0, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "171c8e07e2d81baa3dde5f287fa352a1692571b4e8ab6bc86a6f308969c770f0", "warmup_time": -1}, "gil.ParallelKth.time_kth_smallest": {"code": "class ParallelKth:\n    def time_kth_smallest(self):\n        self.parallel_kth_smallest()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelKth:\n    def setup(self):\n        N = 10**7\n        k = 5 * 10**5\n        kwargs_list = [{\"arr\": np.random.randn(N)}, {\"arr\": np.random.randn(N)}]\n    \n        @test_parallel(num_threads=2, kwargs_list=kwargs_list)\n        def parallel_kth_smallest(arr):\n            algos.kth_smallest(arr, k)\n    \n        self.parallel_kth_smallest = parallel_kth_smallest", "min_run_count": 2, "name": "gil.ParallelKth.time_kth_smallest", "number": 1, "param_names": [], "params": [], "repeat": 5, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "728baeaaeac8eda248c8708b2a4bc45d00a0df43c2103cac65cbfc9c8aff7dcd", "warmup_time": -1}, "gil.ParallelReadCSV.time_read_csv": {"code": "class ParallelReadCSV:\n    def time_read_csv(self, dtype):\n        self.parallel_read_csv()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelReadCSV:\n    def setup(self, dtype):\n        rows = 10000\n        cols = 50\n        if dtype == \"float\":\n            df = DataFrame(np.random.randn(rows, cols))\n        elif dtype == \"datetime\":\n            df = DataFrame(\n                np.random.randn(rows, cols), index=date_range(\"1/1/2000\", periods=rows)\n            )\n        elif dtype == \"object\":\n            df = DataFrame(\n                \"foo\", index=range(rows), columns=[\"object%03d\" for _ in range(5)]\n            )\n        else:\n            raise NotImplementedError\n    \n        self.fname = f\"__test_{dtype}__.csv\"\n        df.to_csv(self.fname)\n    \n        @test_parallel(num_threads=2)\n        def parallel_read_csv():\n            read_csv(self.fname)\n    \n        self.parallel_read_csv = parallel_read_csv", "min_run_count": 2, "name": "gil.ParallelReadCSV.time_read_csv", "number": 1, "param_names": ["dtype"], "params": [["'float'", "'object'", "'datetime'"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8228e9d157c6aea95c1ffcdea89ba3331e5dec17b88134f572f22bbf274ea99c", "warmup_time": -1}, "gil.ParallelRolling.time_rolling": {"code": "class ParallelRolling:\n    def time_rolling(self, method):\n        self.parallel_rolling()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelRolling:\n    def setup(self, method):\n        win = 100\n        arr = np.random.rand(100000)\n        if hasattr(DataFrame, \"rolling\"):\n            df = DataFrame(arr).rolling(win)\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                getattr(df, method)()\n    \n            self.parallel_rolling = parallel_rolling\n        elif have_rolling_methods:\n            rolling = {\n                \"median\": rolling_median,\n                \"mean\": rolling_mean,\n                \"min\": rolling_min,\n                \"max\": rolling_max,\n                \"var\": rolling_var,\n                \"skew\": rolling_skew,\n                \"kurt\": rolling_kurt,\n                \"std\": rolling_std,\n            }\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                rolling[method](arr, win)\n    \n            self.parallel_rolling = parallel_rolling\n        else:\n            raise NotImplementedError", "min_run_count": 2, "name": "gil.ParallelRolling.time_rolling", "number": 0, "param_names": ["method"], "params": [["'median'", "'mean'", "'min'", "'max'", "'var'", "'skew'", "'kurt'", "'std'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "982eb24280f1da753438825641a9861564da7d7a000c415ab86a6bc7522c160b", "warmup_time": -1}, "gil.ParallelTake1D.time_take1d": {"code": "class ParallelTake1D:\n    def time_take1d(self, dtype):\n        self.parallel_take1d()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelTake1D:\n    def setup(self, dtype):\n        N = 10**6\n        df = DataFrame({\"col\": np.arange(N, dtype=dtype)})\n        indexer = np.arange(100, len(df) - 100)\n    \n        @test_parallel(num_threads=2)\n        def parallel_take1d():\n            take_nd(df[\"col\"].values, indexer)\n    \n        self.parallel_take1d = parallel_take1d", "min_run_count": 2, "name": "gil.ParallelTake1D.time_take1d", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fd7379c21f5111cc9ec16f330e4ffc0e029ced1a7cd13e6b78511e7099f53926", "warmup_time": -1}, "groupby.AggEngine.time_dataframe_cython": {"code": "class AggEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_dataframe_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b631e4aa17bbb96c2171d4d72e155061807325d0b39f89014e9ce5de10bfebd2", "warmup_time": -1}, "groupby.AggEngine.time_dataframe_numba": {"code": "class AggEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_dataframe_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ac6601fa086e8c75d228fd781b72c5b02d2053fd155682b074b03fbd6562ccff", "warmup_time": -1}, "groupby.AggEngine.time_series_cython": {"code": "class AggEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_series_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e376d34069b9e05138d16b62f5314f36da3d7a957bb6f040793626df9edcb7ee", "warmup_time": -1}, "groupby.AggEngine.time_series_numba": {"code": "class AggEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_series_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c1e4164d5e903fe4335a07378a9a567a3e4f7c80cb9960c112d95f8919a292aa", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions": {"code": "class AggFunctions:\n    def time_different_str_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:316", "type": "time", "unit": "seconds", "version": "176cde1b06cc31bb98fa33e5c2d0b5b504f18a26bc5160ce4eba434ee86f286c", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions_multicol": {"code": "class AggFunctions:\n    def time_different_str_functions_multicol(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg([\"sum\", \"min\", \"max\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions_multicol", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:316", "type": "time", "unit": "seconds", "version": "665a15402546613d3a9f8692562e3df5bb8e802b90bbaab60dc777323d8c2af2", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions_singlecol": {"code": "class AggFunctions:\n    def time_different_str_functions_singlecol(self, df):\n        df.groupby(\"key1\").agg({\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions_singlecol", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:316", "type": "time", "unit": "seconds", "version": "f5e3f8571351af65c0ab394b69b2a896e28ad315f97c21d89abd45facf73ae1e", "warmup_time": -1}, "groupby.Apply.time_copy_function_multi_col": {"code": "class Apply:\n    def time_copy_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_copy_function_multi_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "508a1bf90ae09cc26585902afd9774deccb6c4fd643ff3f6e3cd66018ca60057", "warmup_time": -1}, "groupby.Apply.time_copy_overhead_single_col": {"code": "class Apply:\n    def time_copy_overhead_single_col(self, factor):\n        self.df.groupby(\"key\").apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_copy_overhead_single_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "004ee6e703ae1fbf983c0b4353be97cb81fcd0c0dde8175bbac3fe70f25e2eeb", "warmup_time": -1}, "groupby.Apply.time_scalar_function_multi_col": {"code": "class Apply:\n    def time_scalar_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_multi_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c2684326af2c29dbc66ddff0ed5b88aa9ec425dbd70bb2874943b0ee3e8f916d", "warmup_time": -1}, "groupby.Apply.time_scalar_function_single_col": {"code": "class Apply:\n    def time_scalar_function_single_col(self, factor):\n        self.df.groupby(\"key\").apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_single_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "69063f137e8f55d96073f5bed6cb8a4784eed89b8accd6d82bd386218d1d1e79", "warmup_time": -1}, "groupby.ApplyDictReturn.time_groupby_apply_dict_return": {"code": "class ApplyDictReturn:\n    def time_groupby_apply_dict_return(self):\n        self.data.groupby(self.labels).apply(\n            lambda x: {\"first\": x.values[0], \"last\": x.values[-1]}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyDictReturn:\n    def setup(self):\n        self.labels = np.arange(1000).repeat(10)\n        self.data = Series(np.random.randn(len(self.labels)))", "min_run_count": 2, "name": "groupby.ApplyDictReturn.time_groupby_apply_dict_return", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5924f4088fcf382ce33f346ce7ddfd12e83ed70b71b93eaec422e9d9eebf6683", "warmup_time": -1}, "groupby.ApplyNonUniqueUnsortedIndex.time_groupby_apply_non_unique_unsorted_index": {"code": "class ApplyNonUniqueUnsortedIndex:\n    def time_groupby_apply_non_unique_unsorted_index(self):\n        self.df.groupby(\"key\", group_keys=False).apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyNonUniqueUnsortedIndex:\n    def setup(self):\n        # GH 46527\n        # unsorted and non-unique index\n        idx = np.arange(100)[::-1]\n        idx = Index(np.repeat(idx, 200), name=\"key\")\n        self.df = DataFrame(np.random.randn(len(idx), 10), index=idx)", "min_run_count": 2, "name": "groupby.ApplyNonUniqueUnsortedIndex.time_groupby_apply_non_unique_unsorted_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f7c3bea0e579df6a33360dfc8c3303ce3a07b11bf0bd48d962a46d5522f4dcfd", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_nosort": {"code": "class Categories:\n    def time_groupby_extra_cat_nosort(self, observed):\n        self.df_extra_cat.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_nosort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "62133a9620af8ea979a326f99617e0e3bbddcc3f3fe81c6bdbf1618701267fde", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_sort": {"code": "class Categories:\n    def time_groupby_extra_cat_sort(self, observed):\n        self.df_extra_cat.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_sort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bfeb5009688d6d10146eaf165cd717a5783a74a5ec7f081c90f52eeb9663f708", "warmup_time": -1}, "groupby.Categories.time_groupby_nosort": {"code": "class Categories:\n    def time_groupby_nosort(self, observed):\n        self.df.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_nosort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e21931e9e69907f384dfe0d9e8a359e13f8b1293c757b0702b3677c3c6d36e3e", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_nosort": {"code": "class Categories:\n    def time_groupby_ordered_nosort(self, observed):\n        self.df_ordered.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_nosort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9e1ed16652daf9b539439c46eab3fc29bfd10b5ba12908c936274bc9d8dc6caa", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_sort": {"code": "class Categories:\n    def time_groupby_ordered_sort(self, observed):\n        self.df_ordered.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_sort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e61e682f371daea64397593a361f55b612c4870d5c7d34a214d012e1f2e346f4", "warmup_time": -1}, "groupby.Categories.time_groupby_sort": {"code": "class Categories:\n    def time_groupby_sort(self, observed):\n        self.df.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_sort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "27b91ff09ded66431067f94886fa27b9fafe051869103620cc7baffc8e0be7fb", "warmup_time": -1}, "groupby.CountMultiDtype.time_multi_count": {"code": "class CountMultiDtype:\n    def time_multi_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiDtype:\n    def setup_cache(self):\n        n = 10000\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        dates[np.random.rand(n) > 0.5] = np.datetime64(\"nat\")\n        offsets[np.random.rand(n) > 0.5] = np.timedelta64(\"nat\")\n        value2 = np.random.randn(n)\n        value2[np.random.rand(n) > 0.5] = np.nan\n        obj = np.random.choice(list(\"ab\"), size=n).astype(object)\n        obj[np.random.randn(n) > 0.5] = np.nan\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"dates\": dates,\n                \"value2\": value2,\n                \"value3\": np.random.randn(n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"obj\": obj,\n                \"offsets\": offsets,\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiDtype.time_multi_count", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:267", "type": "time", "unit": "seconds", "version": "781eccf167f79b9db2b42e6637dca3e0917b3ee82948078ab34ec1fdd55a8ba7", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_count": {"code": "class CountMultiInt:\n    def time_multi_int_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_count", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:296", "type": "time", "unit": "seconds", "version": "c0c648960106b54be2a606e2093e04045e55e61c502f37ec87315025300cc688", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_nunique": {"code": "class CountMultiInt:\n    def time_multi_int_nunique(self, df):\n        df.groupby([\"key1\", \"key2\"]).nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_nunique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:296", "type": "time", "unit": "seconds", "version": "02179b80a10ef56e163f7134b90b2b3a14e1e783c29bcd78e8c839cc49c2b89a", "warmup_time": -1}, "groupby.Cumulative.time_frame_transform": {"code": "class Cumulative:\n    def time_frame_transform(self, dtype, method, with_nans):\n        self.df.groupby(\"key\").transform(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cumulative:\n    def setup(self, dtype, method, with_nans):\n        if with_nans and dtype == \"int64\":\n            raise NotImplementedError(\"Construction of df would raise\")\n    \n        N = 500_000\n        keys = np.random.randint(0, 100, size=N)\n        vals = np.random.randint(-10, 10, (N, 5))\n    \n        if with_nans:\n            null_vals = vals.astype(float, copy=True)\n            null_vals[::2, :] = np.nan\n            null_vals[::3, :] = np.nan\n            df = DataFrame(null_vals, columns=list(\"abcde\"), dtype=dtype)\n            df[\"key\"] = keys\n            self.df = df\n        else:\n            df = DataFrame(vals, columns=list(\"abcde\")).astype(dtype, copy=False)\n            df[\"key\"] = keys\n            self.df = df", "min_run_count": 2, "name": "groupby.Cumulative.time_frame_transform", "number": 0, "param_names": ["dtype", "method", "with_nans"], "params": [["'float64'", "'int64'", "'Float64'", "'Int64'"], ["'cummin'", "'cummax'", "'cumsum'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "508bbc112e0877babc3aaf14b674b720e942cd27f59280bc4678e5cca617dd6d", "warmup_time": -1}, "groupby.DateAttributes.time_len_groupby_object": {"code": "class DateAttributes:\n    def time_len_groupby_object(self):\n        len(self.ts.groupby([self.year, self.month, self.day]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateAttributes:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", \"12/31/2005\", freq=\"h\")\n        self.year, self.month, self.day = rng.year, rng.month, rng.day\n        self.ts = Series(np.random.randn(len(rng)), index=rng)", "min_run_count": 2, "name": "groupby.DateAttributes.time_len_groupby_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8afdc2d8ced7d3eae328dd9110607db5fb11b9f1345b32d6f85c95f2a0790f13", "warmup_time": -1}, "groupby.Datelike.time_sum": {"code": "class Datelike:\n    def time_sum(self, grouper):\n        self.df.groupby(self.grouper).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datelike:\n    def setup(self, grouper):\n        N = 10**4\n        rng_map = {\n            \"period_range\": period_range,\n            \"date_range\": date_range,\n            \"date_range_tz\": partial(date_range, tz=\"US/Central\"),\n        }\n        self.grouper = rng_map[grouper](\"1900-01-01\", freq=\"D\", periods=N)\n        self.df = DataFrame(np.random.randn(10**4, 2))", "min_run_count": 2, "name": "groupby.Datelike.time_sum", "number": 0, "param_names": ["grouper"], "params": [["'period_range'", "'date_range'", "'date_range_tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e8e6e1030bf91e85db8d838621c86faee1e19b8f21d49efe9d147e58d9b54307", "warmup_time": -1}, "groupby.Fillna.time_df_bfill": {"code": "class Fillna:\n    def time_df_bfill(self):\n        self.df.groupby(\"group\").bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.Fillna.time_df_bfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7ff1f9cf6c6df0928b8c57fd5409cd697220c5294222532ee686299c3410b840", "warmup_time": -1}, "groupby.Fillna.time_df_ffill": {"code": "class Fillna:\n    def time_df_ffill(self):\n        self.df.groupby(\"group\").ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.Fillna.time_df_ffill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "40586a88db43958ca78216d046b99f037c1d2538d8ecbb88e73f0f3fec775b8f", "warmup_time": -1}, "groupby.Fillna.time_srs_bfill": {"code": "class Fillna:\n    def time_srs_bfill(self):\n        self.df.groupby(\"group\")[\"value\"].bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.Fillna.time_srs_bfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "579f258a2de5f21f32a2705c8b4de416b0d90092be5b8db9155802b3114e5eba", "warmup_time": -1}, "groupby.Fillna.time_srs_ffill": {"code": "class Fillna:\n    def time_srs_ffill(self):\n        self.df.groupby(\"group\")[\"value\"].ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.Fillna.time_srs_ffill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "836866b476636343cf2f78c006849b25914c07fb61542a85b138c258c1bdb0b2", "warmup_time": -1}, "groupby.Float32.time_sum": {"code": "class Float32:\n    def time_sum(self):\n        self.df.groupby([\"a\"])[\"b\"].sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float32:\n    def setup(self):\n        tmp1 = (np.random.random(10000) * 0.1).astype(np.float32)\n        tmp2 = (np.random.random(10000) * 10.0).astype(np.float32)\n        tmp = np.concatenate((tmp1, tmp2))\n        arr = np.repeat(tmp, 10)\n        self.df = DataFrame({\"a\": arr, \"b\": arr})", "min_run_count": 2, "name": "groupby.Float32.time_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ffe9e34b1eb793ed006421668ab941faed0e6f0e51c5142f0940d4117f1aedb4", "warmup_time": -1}, "groupby.GroupByCythonAgg.time_frame_agg": {"code": "class GroupByCythonAgg:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAgg:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(np.random.randn(N, 10), columns=list(\"abcdefghij\"))\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df", "min_run_count": 2, "name": "groupby.GroupByCythonAgg.time_frame_agg", "number": 0, "param_names": ["dtype", "method"], "params": [["'float64'"], ["'sum'", "'prod'", "'min'", "'max'", "'idxmin'", "'idxmax'", "'mean'", "'median'", "'var'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "08ae292d77e9806660d8e3c10232a024c7526f433635c0290aa62b6b313af20f", "warmup_time": -1}, "groupby.GroupByCythonAggEaDtypes.time_frame_agg": {"code": "class GroupByCythonAggEaDtypes:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAggEaDtypes:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(\n            np.random.randint(0, high=100, size=(N, 10)),\n            columns=list(\"abcdefghij\"),\n            dtype=dtype,\n        )\n        df.loc[list(range(1, N, 5)), list(\"abcdefghij\")] = NA\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df", "min_run_count": 2, "name": "groupby.GroupByCythonAggEaDtypes.time_frame_agg", "number": 0, "param_names": ["dtype", "method"], "params": [["'Float64'", "'Int64'", "'Int32'"], ["'sum'", "'prod'", "'min'", "'max'", "'mean'", "'median'", "'var'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9d0957d40f08e9fb265f5ca8f466358e6742a3b6b934d1714c6cfc2f9604ded1", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_field": {"code": "class GroupByMethods:\n    def time_dtype_as_field(self, dtype, method, application, ncols, engine):\n        self.as_field_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols, engine):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"describe\",\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        # Numba currently doesn't support\n        # multiple transform functions or strs for transform,\n        # grouping on multiple columns\n        # and we lack kernels for a bunch of methods\n        if (\n            (engine == \"numba\" and method in _numba_unsupported_methods)\n            or ncols > 1\n            or application == \"transformation\"\n            or dtype == \"datetime\"\n        ):\n            raise NotImplementedError\n    \n        if method == \"describe\":\n            ngroups = 20\n        elif method == \"skew\":\n            ngroups = 100\n        else:\n            ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype in (\"int16\", \"uint\"):\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        # Not everything supports the engine keyword yet\n        kwargs = {}\n        if engine == \"numba\":\n            kwargs[\"engine\"] = engine\n    \n        if application == \"transformation\":\n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(\n                method, **kwargs\n            )\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(\n                method, **kwargs\n            )\n        else:\n            self.as_group_method = partial(\n                getattr(df.groupby(\"key\")[cols], method), **kwargs\n            )\n            self.as_field_method = partial(\n                getattr(df.groupby(cols)[\"key\"], method), **kwargs\n            )", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_field", "number": 0, "param_names": ["dtype", "method", "application", "ncols", "param5"], "params": [["'int'", "'int16'", "'float'", "'object'", "'datetime'", "'uint'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'diff'", "'ffill'", "'first'", "'head'", "'last'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"], ["1", "5"], ["'cython'", "'numba'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4a0d02d2fd8fa6995ea8a55cc82dafbc7c15fe6a2c3973eaca14da8b7a16c993", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_group": {"code": "class GroupByMethods:\n    def time_dtype_as_group(self, dtype, method, application, ncols, engine):\n        self.as_group_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols, engine):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"describe\",\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        # Numba currently doesn't support\n        # multiple transform functions or strs for transform,\n        # grouping on multiple columns\n        # and we lack kernels for a bunch of methods\n        if (\n            (engine == \"numba\" and method in _numba_unsupported_methods)\n            or ncols > 1\n            or application == \"transformation\"\n            or dtype == \"datetime\"\n        ):\n            raise NotImplementedError\n    \n        if method == \"describe\":\n            ngroups = 20\n        elif method == \"skew\":\n            ngroups = 100\n        else:\n            ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype in (\"int16\", \"uint\"):\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        # Not everything supports the engine keyword yet\n        kwargs = {}\n        if engine == \"numba\":\n            kwargs[\"engine\"] = engine\n    \n        if application == \"transformation\":\n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(\n                method, **kwargs\n            )\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(\n                method, **kwargs\n            )\n        else:\n            self.as_group_method = partial(\n                getattr(df.groupby(\"key\")[cols], method), **kwargs\n            )\n            self.as_field_method = partial(\n                getattr(df.groupby(cols)[\"key\"], method), **kwargs\n            )", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_group", "number": 0, "param_names": ["dtype", "method", "application", "ncols", "param5"], "params": [["'int'", "'int16'", "'float'", "'object'", "'datetime'", "'uint'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'diff'", "'ffill'", "'first'", "'head'", "'last'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"], ["1", "5"], ["'cython'", "'numba'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c29ed2bf3480091302fef3e2a837053440b872af4b447a58b03a9452c461ff1d", "warmup_time": -1}, "groupby.GroupByNumbaAgg.time_frame_agg": {"code": "class GroupByNumbaAgg:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method, engine=\"numba\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByNumbaAgg:\n    def setup(self, dtype, method):\n        if method in _numba_unsupported_methods:\n            raise NotImplementedError\n        super().setup(dtype, method)", "min_run_count": 2, "name": "groupby.GroupByNumbaAgg.time_frame_agg", "number": 0, "param_names": ["dtype", "method"], "params": [["'float64'"], ["'sum'", "'prod'", "'min'", "'max'", "'idxmin'", "'idxmax'", "'mean'", "'median'", "'var'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "485567a7945b89dfbcc8517d268d1572570c908383b9f7fdbc1b173bc67a292a", "warmup_time": -1}, "groupby.GroupManyLabels.time_sum": {"code": "class GroupManyLabels:\n    def time_sum(self, ncols):\n        self.df.groupby(self.labels).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupManyLabels:\n    def setup(self, ncols):\n        N = 1000\n        data = np.random.randn(N, ncols)\n        self.labels = np.random.randint(0, 100, size=N)\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "groupby.GroupManyLabels.time_sum", "number": 0, "param_names": ["ncols"], "params": [["1", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "66b2e0c8c016da785fe5cc599d0ce7892b1c5657f8af53ff854fed498e28878a", "warmup_time": -1}, "groupby.GroupStrings.time_multi_columns": {"code": "class GroupStrings:\n    def time_multi_columns(self):\n        self.df.groupby(list(\"abcd\")).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupStrings:\n    def setup(self):\n        n = 2 * 10**5\n        alpha = list(map(\"\".join, product(ascii_letters, repeat=4)))\n        data = np.random.choice(alpha, (n // 5, 4), replace=False)\n        data = np.repeat(data, 5, axis=0)\n        self.df = DataFrame(data, columns=list(\"abcd\"))\n        self.df[\"joe\"] = (np.random.randn(len(self.df)) * 10).round(3)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)", "min_run_count": 2, "name": "groupby.GroupStrings.time_multi_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e2cad1f849665339cebeef8f37279cd4824c4fa1e86e39fe618e4052a76b7dd6", "warmup_time": -1}, "groupby.Groups.time_series_groups": {"code": "class Groups:\n    def time_series_groups(self, data, key):\n        self.ser.groupby(self.ser).groups\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                Index([f\"i-{i}\" for i in range(100)], dtype=object).take(\n                    np.random.randint(0, 100, size=size)\n                )\n            ),\n            \"object_large\": Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                    np.random.randint(0, 10000, size=size)\n                )\n            ),\n        }\n        return data", "min_run_count": 2, "name": "groupby.Groups.time_series_groups", "number": 0, "param_names": ["key"], "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:162", "type": "time", "unit": "seconds", "version": "dbc6b8b2b071005f9ce14efc5386fc68124c154c0787e714bcf9be17ee3b4bba", "warmup_time": -1}, "groupby.Groups.time_series_indices": {"code": "class Groups:\n    def time_series_indices(self, data, key):\n        self.ser.groupby(self.ser).indices\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                Index([f\"i-{i}\" for i in range(100)], dtype=object).take(\n                    np.random.randint(0, 100, size=size)\n                )\n            ),\n            \"object_large\": Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                    np.random.randint(0, 10000, size=size)\n                )\n            ),\n        }\n        return data", "min_run_count": 2, "name": "groupby.Groups.time_series_indices", "number": 0, "param_names": ["key"], "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:162", "type": "time", "unit": "seconds", "version": "36d7245a7a3b2bd56d7270e0d6981e83fed5d32bed580a99567addff40ccbd17", "warmup_time": -1}, "groupby.Int64.time_overflow": {"code": "class Int64:\n    def time_overflow(self):\n        self.df.groupby(self.cols).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Int64:\n    def setup(self):\n        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 17, 5))\n        i = np.random.choice(len(arr), len(arr) * 5)\n        arr = np.vstack((arr, arr[i]))\n        i = np.random.permutation(len(arr))\n        arr = arr[i]\n        self.cols = list(\"abcde\")\n        self.df = DataFrame(arr, columns=self.cols)\n        self.df[\"jim\"], self.df[\"joe\"] = np.random.randn(2, len(self.df)) * 10", "min_run_count": 2, "name": "groupby.Int64.time_overflow", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c59f5b180f618f9de6657c8e0c5a373add1e863a6f3969b4097836f1f4e40929", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_lambda_sum": {"code": "class MultiColumn:\n    def time_col_select_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_lambda_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:358", "type": "time", "unit": "seconds", "version": "cada8d1efcf927c41db4c7b33b88a6816790e5d361e4cf10f3f03f390386a717", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_str_sum": {"code": "class MultiColumn:\n    def time_col_select_str_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_str_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:358", "type": "time", "unit": "seconds", "version": "452b0de34f34dcbafb7d59c7c44e17908f0342ebb248d7b61f8ef1ee63c7d175", "warmup_time": -1}, "groupby.MultiColumn.time_cython_sum": {"code": "class MultiColumn:\n    def time_cython_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_cython_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:358", "type": "time", "unit": "seconds", "version": "9ba6f25ceb0666279babb6760f71ea64c8a52a817294261fed73699bc7b516f3", "warmup_time": -1}, "groupby.MultiColumn.time_lambda_sum": {"code": "class MultiColumn:\n    def time_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_lambda_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:358", "type": "time", "unit": "seconds", "version": "38b6452a313f2508f0dfd7fa593d129b13ec9c33f22753679877d5f06818a566", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_extra_cat_nosort": {"code": "class MultipleCategories:\n    def time_groupby_extra_cat_nosort(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_extra_cat_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "83cff68f64c01bc265f6f67706237d37c6f96f20ccb947373ea0fbdb9c5c605a", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_extra_cat_sort": {"code": "class MultipleCategories:\n    def time_groupby_extra_cat_sort(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_extra_cat_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "96635202ed41a374fefefbfbd2317b32d2475a1d07384a99feb40c69b419e024", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_nosort": {"code": "class MultipleCategories:\n    def time_groupby_nosort(self):\n        self.df.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bd1d5b9e0fdabacec5cfdcbec5af5cf24e4a7871654e201e2e36e94e9d50bf9a", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_ordered_nosort": {"code": "class MultipleCategories:\n    def time_groupby_ordered_nosort(self):\n        self.df_ordered.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_ordered_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "efc218534283dc987433d4dda645ee117699de0a41f79f59cfcb381a56f55bfa", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_ordered_sort": {"code": "class MultipleCategories:\n    def time_groupby_ordered_sort(self):\n        self.df_ordered.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_ordered_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "24d3606f6b66cd0cf252b6566e5c8a44adae7e06ecb2c17a06917ab0f801a0ab", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_sort": {"code": "class MultipleCategories:\n    def time_groupby_sort(self):\n        self.df.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "869bac12201294cce4dabbed58d29db90d95b9d4060f99ab5acd2d7c3b1426a6", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_transform": {"code": "class MultipleCategories:\n    def time_groupby_transform(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].cumsum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_transform", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9e6ce565eecb66a3cd8ceec5c6d78a2fc6aefeb48742cc69c8ad9a311a77873b", "warmup_time": -1}, "groupby.Nth.time_frame_nth": {"code": "class Nth:\n    def time_frame_nth(self, dtype):\n        self.df.groupby(\"key\").nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e1d08a270138a89c0f1723213b6519ab3f5bf1373d8e8d2c2b54a43b065b76be", "warmup_time": -1}, "groupby.Nth.time_frame_nth_any": {"code": "class Nth:\n    def time_frame_nth_any(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a44829e68092f64486a6572a1a5465f5a0d577ee765ee5ad2e38c472e85346bd", "warmup_time": -1}, "groupby.Nth.time_groupby_nth_all": {"code": "class Nth:\n    def time_groupby_nth_all(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_groupby_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "866ef9a468514b755b4464d8fd09949132454a4161d7a99770caeec775a2bba6", "warmup_time": -1}, "groupby.Nth.time_series_nth": {"code": "class Nth:\n    def time_series_nth(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c5b1e05da00cd08da75c885c95b13c18db12dc3332aafd79a79049e66f996c1e", "warmup_time": -1}, "groupby.Nth.time_series_nth_all": {"code": "class Nth:\n    def time_series_nth_all(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "42ed669cc8c03e7351add656e29a89d0fb07fc43ed2931e70701a559f09f12e1", "warmup_time": -1}, "groupby.Nth.time_series_nth_any": {"code": "class Nth:\n    def time_series_nth_any(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "011dc9ba29511d4b5f0b1bb7c6f5a991ef7a1590ce479e354646546de88cfea6", "warmup_time": -1}, "groupby.RankWithTies.time_rank_ties": {"code": "class RankWithTies:\n    def time_rank_ties(self, dtype, tie_method):\n        self.df.groupby(\"key\").rank(method=tie_method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RankWithTies:\n    def setup(self, dtype, tie_method):\n        N = 10**4\n        if dtype == \"datetime64\":\n            data = np.array([Timestamp(\"2011/01/01\")] * N, dtype=dtype)\n        else:\n            data = np.ones(N, dtype=dtype)\n        self.df = DataFrame({\"values\": data, \"key\": [\"foo\"] * N})", "min_run_count": 2, "name": "groupby.RankWithTies.time_rank_ties", "number": 0, "param_names": ["dtype", "tie_method"], "params": [["'float64'", "'float32'", "'int64'", "'datetime64'"], ["'first'", "'average'", "'dense'", "'min'", "'max'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "622ded2b5e5432518f83a22d3ed8f82cc9f43e2ca4ab46c97e7aa4dd1daf7f10", "warmup_time": -1}, "groupby.Resample.time_resample": {"code": "class Resample:\n    def time_resample(self):\n        self.df.groupby(level=\"groups\").resample(\"10s\", on=\"timedeltas\").mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Resample:\n    def setup(self):\n        num_timedeltas = 20_000\n        num_groups = 3\n    \n        index = MultiIndex.from_product(\n            [\n                np.arange(num_groups),\n                to_timedelta(np.arange(num_timedeltas), unit=\"s\"),\n            ],\n            names=[\"groups\", \"timedeltas\"],\n        )\n        data = np.random.randint(0, 1000, size=(len(index)))\n    \n        self.df = DataFrame(data, index=index).reset_index(\"timedeltas\")\n        self.df_multiindex = DataFrame(data, index=index)", "min_run_count": 2, "name": "groupby.Resample.time_resample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2f73c1abc5cfc408cd8604b1badf9ee4f00ceb2a76c77b5b5a78af2d74228f7b", "warmup_time": -1}, "groupby.Resample.time_resample_multiindex": {"code": "class Resample:\n    def time_resample_multiindex(self):\n        self.df_multiindex.groupby(level=\"groups\").resample(\n            \"10s\", level=\"timedeltas\"\n        ).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Resample:\n    def setup(self):\n        num_timedeltas = 20_000\n        num_groups = 3\n    \n        index = MultiIndex.from_product(\n            [\n                np.arange(num_groups),\n                to_timedelta(np.arange(num_timedeltas), unit=\"s\"),\n            ],\n            names=[\"groups\", \"timedeltas\"],\n        )\n        data = np.random.randint(0, 1000, size=(len(index)))\n    \n        self.df = DataFrame(data, index=index).reset_index(\"timedeltas\")\n        self.df_multiindex = DataFrame(data, index=index)", "min_run_count": 2, "name": "groupby.Resample.time_resample_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "07304b920f854bdb1422e0b993c60857e6e2d6ad9ce2664f92ee8e113c3df234", "warmup_time": -1}, "groupby.Sample.time_sample": {"code": "class Sample:\n    def time_sample(self):\n        self.df.groupby(self.groups).sample(n=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)", "min_run_count": 2, "name": "groupby.Sample.time_sample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d06fc92a35cfb5f7ef26863259f097f3aabbef9d90438fde13891e042fa2cff9", "warmup_time": -1}, "groupby.Sample.time_sample_weights": {"code": "class Sample:\n    def time_sample_weights(self):\n        self.df.groupby(self.groups).sample(n=1, weights=self.weights)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)", "min_run_count": 2, "name": "groupby.Sample.time_sample_weights", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "66bb261674cbd4d0e341aebd067908473e0734bca8091cd8bae8282d7706dd4d", "warmup_time": -1}, "groupby.Shift.time_defaults": {"code": "class Shift:\n    def time_defaults(self):\n        self.df.groupby(\"g\").shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})", "min_run_count": 2, "name": "groupby.Shift.time_defaults", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6a3a41956cf53e5cacf8be90a4432268657d065e708f3681cb0da232d8442b7b", "warmup_time": -1}, "groupby.Shift.time_fill_value": {"code": "class Shift:\n    def time_fill_value(self):\n        self.df.groupby(\"g\").shift(fill_value=99)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})", "min_run_count": 2, "name": "groupby.Shift.time_fill_value", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "92e908ccaf513773d03d593373379bb94d333da277d2214a08ee1905d58e0c3b", "warmup_time": -1}, "groupby.Size.time_category_size": {"code": "class Size:\n    def time_category_size(self):\n        self.draws.groupby(self.cats, observed=True).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_category_size", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5eddb01370059c88e32f412a47746b638593daac39af9c786d43aafdf2e803b3", "warmup_time": -1}, "groupby.Size.time_multi_size": {"code": "class Size:\n    def time_multi_size(self):\n        self.df.groupby([\"key1\", \"key2\"]).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_multi_size", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "34694723d47ec5028bd8d513e5986c685e58d7219113ca9a4be7e030a9a98aa1", "warmup_time": -1}, "groupby.String.time_str_func": {"code": "class String:\n    def time_str_func(self, dtype, method):\n        self.df.groupby(\"a\")[self.df.columns[1:]].agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass String:\n    def setup(self, dtype, method):\n        cols = list(\"abcdefghjkl\")\n        self.df = DataFrame(\n            np.random.randint(0, 100, size=(10_000, len(cols))),\n            columns=cols,\n            dtype=dtype,\n        )", "min_run_count": 2, "name": "groupby.String.time_str_func", "number": 0, "param_names": ["dtype", "method"], "params": [["'str'", "'string[python]'"], ["'sum'", "'min'", "'max'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b49dcaf61606c8e3e1fd9bd0ca3f1d1b8833147e2b729e1e363d481f98270ec4", "warmup_time": -1}, "groupby.SumBools.time_groupby_sum_booleans": {"code": "class SumBools:\n    def time_groupby_sum_booleans(self):\n        self.df.groupby(\"ii\").sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumBools:\n    def setup(self):\n        N = 500\n        self.df = DataFrame({\"ii\": range(N), \"bb\": [True] * N})", "min_run_count": 2, "name": "groupby.SumBools.time_groupby_sum_booleans", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c3539588ce95b04f6cfe6c310ff1d827826da14d25eafe09e1d58cf28f0f2020", "warmup_time": -1}, "groupby.SumMultiLevel.time_groupby_sum_multiindex": {"code": "class SumMultiLevel:\n    def time_groupby_sum_multiindex(self):\n        self.df.groupby(level=[0, 1]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumMultiLevel:\n    def setup(self):\n        N = 50\n        self.df = DataFrame(\n            {\"A\": list(range(N)) * 2, \"B\": range(N * 2), \"C\": 1}\n        ).set_index([\"A\", \"B\"])", "min_run_count": 2, "name": "groupby.SumMultiLevel.time_groupby_sum_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120.0, "type": "time", "unit": "seconds", "version": "b34947d529ea832ced0c45868dd46b91974ce4d6a23b4212210c255083673ef8", "warmup_time": -1}, "groupby.SumTimeDelta.time_groupby_sum_int": {"code": "class SumTimeDelta:\n    def time_groupby_sum_int(self):\n        self.df_int.groupby(lambda x: x).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumTimeDelta:\n    def setup(self):\n        N = 10**4\n        self.df = DataFrame(\n            np.random.randint(1000, 100000, (N, 100)),\n            index=np.random.randint(200, size=(N,)),\n        ).astype(\"timedelta64[ns]\")\n        self.df_int = self.df.copy().astype(\"int64\")", "min_run_count": 2, "name": "groupby.SumTimeDelta.time_groupby_sum_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3ac04c1b47b978a60e2dd36712fe8b5546ca48524e482437ab7dd05d74d70b51", "warmup_time": -1}, "groupby.SumTimeDelta.time_groupby_sum_timedelta": {"code": "class SumTimeDelta:\n    def time_groupby_sum_timedelta(self):\n        self.df.groupby(lambda x: x).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumTimeDelta:\n    def setup(self):\n        N = 10**4\n        self.df = DataFrame(\n            np.random.randint(1000, 100000, (N, 100)),\n            index=np.random.randint(200, size=(N,)),\n        ).astype(\"timedelta64[ns]\")\n        self.df_int = self.df.copy().astype(\"int64\")", "min_run_count": 2, "name": "groupby.SumTimeDelta.time_groupby_sum_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2399de64ddcb9b1503469e78a45205ffbc8d6c7780eb674273569e1a06d55607", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max": {"code": "class Transform:\n    def time_transform_lambda_max(self):\n        self.df.groupby(level=\"lev1\").transform(lambda x: max(x))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "291190f0a573b88f867178ceac1295c04bb53f214b480bc15fced8ee95dd4089", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max_tall": {"code": "class Transform:\n    def time_transform_lambda_max_tall(self):\n        self.df_tall.groupby(level=0).transform(lambda x: np.max(x, axis=0))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0715fe48299e582fbe65937e99c6a8d54e797598178532c197eb7628502c9550", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max_wide": {"code": "class Transform:\n    def time_transform_lambda_max_wide(self):\n        self.df_wide.groupby(level=0).transform(lambda x: np.max(x, axis=0))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e300e23373f04b050335813db183ab5f4fdc3090aa3c7c010731410139b922a2", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key1": {"code": "class Transform:\n    def time_transform_multi_key1(self):\n        self.df1.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "366e371c2918778eb64606950f5d97720245d6f5c1d70398a7d693b6806cff22", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key2": {"code": "class Transform:\n    def time_transform_multi_key2(self):\n        self.df2.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key2", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "07ba2bab8a423416e13164dea63101908acca0e0e9c2a38d7276dec381baa054", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key3": {"code": "class Transform:\n    def time_transform_multi_key3(self):\n        self.df3.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key3", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0535ec60ed264575ec4171ebd7c700b11428d714ccba8793dd6e2f3c2b093233", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key4": {"code": "class Transform:\n    def time_transform_multi_key4(self):\n        self.df4.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key4", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "909a4078e8d6a175f6cada96c1bdf3a92bb698109b6d4b03667bdae77cebbfb0", "warmup_time": -1}, "groupby.Transform.time_transform_str_max": {"code": "class Transform:\n    def time_transform_str_max(self):\n        self.df.groupby(level=\"lev1\").transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_str_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f0a9ece43b99ebb197312d9bb8296b5f64c894b31c206c02264bf0bca0f4b27d", "warmup_time": -1}, "groupby.TransformBools.time_transform_mean": {"code": "class TransformBools:\n    def time_transform_mean(self):\n        self.df[\"signal\"].groupby(self.g).transform(\"mean\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformBools:\n    def setup(self):\n        N = 120000\n        transition_points = np.sort(np.random.choice(np.arange(N), 1400))\n        transitions = np.zeros(N, dtype=np.bool_)\n        transitions[transition_points] = True\n        self.g = transitions.cumsum()\n        self.df = DataFrame({\"signal\": np.random.rand(N)})", "min_run_count": 2, "name": "groupby.TransformBools.time_transform_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fbf9d5bd6f37110a204b7a248de7080198abd4d49e10d7e866f785439364bb84", "warmup_time": -1}, "groupby.TransformEngine.time_dataframe_cython": {"code": "class TransformEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper.transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_dataframe_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d0c83497327280f78a5062c9717764f36483b50943b5eb9fe60025ca086edb53", "warmup_time": -1}, "groupby.TransformEngine.time_dataframe_numba": {"code": "class TransformEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper.transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_dataframe_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "146b7844bad06cc92400f5337ad2abbbb2ef4e7262b9ecf7bf2f369e08df9e5c", "warmup_time": -1}, "groupby.TransformEngine.time_series_cython": {"code": "class TransformEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper[1].transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_series_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2826562b07220b11d0e02a233f43f754b8f9b1b0dbed50ca3f2b3bf25b71995d", "warmup_time": -1}, "groupby.TransformEngine.time_series_numba": {"code": "class TransformEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper[1].transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_series_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b20f5b20c80e1abd068634154b292c0cc05eaed4af84c3f95bdd4fb09e654937", "warmup_time": -1}, "groupby.TransformNaN.time_first": {"code": "class TransformNaN:\n    def time_first(self):\n        self.df_nans.groupby(\"key\").transform(\"first\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformNaN:\n    def setup(self):\n        self.df_nans = DataFrame(\n            {\"key\": np.repeat(np.arange(1000), 10), \"B\": np.nan, \"C\": np.nan}\n        )\n        self.df_nans.loc[4::10, \"B\":\"C\"] = 5", "min_run_count": 2, "name": "groupby.TransformNaN.time_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "466258ae973db79b6c4ae80572d3424a11b6997e4ab98b9751eb9a5d30f468e8", "warmup_time": -1}, "hash_functions.Float64GroupIndex.time_groupby": {"code": "class Float64GroupIndex:\n    def time_groupby(self):\n        self.df.groupby(self.group_index).last()\n\n    def setup(self):\n        self.df = pd.date_range(\n            start=\"1/1/2018\", end=\"1/2/2018\", periods=10**6\n        ).to_frame()\n        self.group_index = np.round(self.df.index.astype(int) / 10**9)", "min_run_count": 2, "name": "hash_functions.Float64GroupIndex.time_groupby", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "16fa99f7d4871f73a649b4eb9085ebd39124ac1b6451a2321c9fb1e2792d9569", "warmup_time": -1}, "hash_functions.NumericSeriesIndexing.time_loc_slice": {"code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, dtype, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype)\n        indices = pd.Index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)", "min_run_count": 2, "name": "hash_functions.NumericSeriesIndexing.time_loc_slice", "number": 0, "param_names": ["dtype", "N"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["10000", "100000", "500000", "1000000", "5000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bbd9b15d7f65d1d2a57335626da432a02c7db5e70cbd8098c13b4e3d4b391802", "warmup_time": -1}, "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice": {"code": "class NumericSeriesIndexingShuffled:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, dtype, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype)\n        np.random.shuffle(vals)\n        indices = pd.Index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)", "min_run_count": 2, "name": "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice", "number": 0, "param_names": ["dtype", "N"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["10000", "100000", "500000", "1000000", "5000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "432c7f2c138c103e14be8ce799b1975974eeda009197320865b48b0310220376", "warmup_time": -1}, "hash_functions.Unique.time_unique": {"code": "class Unique:\n    def time_unique(self, exponent):\n        pd.unique(self.ser_unique)\n\n    def setup(self, dtype):\n        self.ser = pd.Series(([1, pd.NA, 2] + list(range(100_000))) * 3, dtype=dtype)\n        self.ser_unique = pd.Series(list(range(300_000)) + [pd.NA], dtype=dtype)", "min_run_count": 2, "name": "hash_functions.Unique.time_unique", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b4e9501a2d788652cf742d899e45ee6697865981d8caebbc02b5c662b0207edf", "warmup_time": -1}, "hash_functions.Unique.time_unique_with_duplicates": {"code": "class Unique:\n    def time_unique_with_duplicates(self, exponent):\n        pd.unique(self.ser)\n\n    def setup(self, dtype):\n        self.ser = pd.Series(([1, pd.NA, 2] + list(range(100_000))) * 3, dtype=dtype)\n        self.ser_unique = pd.Series(list(range(300_000)) + [pd.NA], dtype=dtype)", "min_run_count": 2, "name": "hash_functions.Unique.time_unique_with_duplicates", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "167e56c7e4063b7bb8cad24ce741ad07d7714185a453ada8f9296eb9acf885af", "warmup_time": -1}, "hash_functions.UniqueAndFactorizeArange.time_factorize": {"code": "class UniqueAndFactorizeArange:\n    def time_factorize(self, exponent):\n        pd.factorize(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10**4, dtype=\"float64\")\n        self.a2 = (a + 10**exponent).repeat(100)", "min_run_count": 2, "name": "hash_functions.UniqueAndFactorizeArange.time_factorize", "number": 0, "param_names": ["exponent"], "params": [["4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0f26f4d8f2608aa8c5a85a0f06b3d3035de285c9a423a8f0f98688da07c40443", "warmup_time": -1}, "hash_functions.UniqueAndFactorizeArange.time_unique": {"code": "class UniqueAndFactorizeArange:\n    def time_unique(self, exponent):\n        pd.unique(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10**4, dtype=\"float64\")\n        self.a2 = (a + 10**exponent).repeat(100)", "min_run_count": 2, "name": "hash_functions.UniqueAndFactorizeArange.time_unique", "number": 0, "param_names": ["exponent"], "params": [["4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "871707976cd021a306828a6723cac7ae71087078cf1b78c6d17c352b6b600d9c", "warmup_time": -1}, "hash_functions.UniqueForLargePyObjectInts.time_unique": {"code": "class UniqueForLargePyObjectInts:\n    def time_unique(self):\n        pd.unique(self.arr)\n\n    def setup(self):\n        lst = [x << 32 for x in range(5000)]\n        self.arr = np.array(lst, dtype=np.object_)", "min_run_count": 2, "name": "hash_functions.UniqueForLargePyObjectInts.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2b911217a8295551fd862ba4e9a94107678d903c84a5a197b90acce421e6f8c6", "warmup_time": -1}, "index_cached_properties.IndexCache.time_engine": {"code": "class IndexCache:\n    def time_engine(self, index_type):\n        self.idx._engine\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_engine", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "740507bf126b994b6d6ebc6be8ebf07edb76586f565ac510ca9368d909d709d4", "warmup_time": -1}, "index_cached_properties.IndexCache.time_inferred_type": {"code": "class IndexCache:\n    def time_inferred_type(self, index_type):\n        self.idx.inferred_type\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_inferred_type", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f3ebbac92d68a71460a35d139fd438638cdb972b17c7453a5812797d0a732216", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_decreasing": {"code": "class IndexCache:\n    def time_is_monotonic_decreasing(self, index_type):\n        self.idx.is_monotonic_decreasing\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_decreasing", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0bb371064863d37bb2c6463fec281d4385b45e96f82db5c35dd8465a0914d022", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_increasing": {"code": "class IndexCache:\n    def time_is_monotonic_increasing(self, index_type):\n        self.idx.is_monotonic_increasing\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_increasing", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "de17e7db24a14fda30802ea91555a4f31065f43168acb8e3e31a1e92468b2ab5", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_unique": {"code": "class IndexCache:\n    def time_is_unique(self, index_type):\n        self.idx.is_unique\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_unique", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee6b34e14ea2eceb624910b4953fddcf15d45041d74a3636af086e47e0523800", "warmup_time": -1}, "index_cached_properties.IndexCache.time_shape": {"code": "class IndexCache:\n    def time_shape(self, index_type):\n        self.idx.shape\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_shape", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8546f1125c3d98d90e592f3e476bbea39ecc261b095952bcf45985ed5b90c619", "warmup_time": -1}, "index_cached_properties.IndexCache.time_values": {"code": "class IndexCache:\n    def time_values(self, index_type):\n        self.idx._values\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_values", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8fc19379f5cae741e4d0deaa9154de9d3ccffef1b639f850c8c2ace4093c3566", "warmup_time": -1}, "index_object.Float64IndexMethod.time_get_loc": {"code": "class Float64IndexMethod:\n    def time_get_loc(self):\n        self.ind.get_loc(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float64IndexMethod:\n    def setup(self):\n        N = 100_000\n        a = np.arange(N, dtype=np.float64)\n        self.ind = Index(a * 4.8000000418824129e-08)", "min_run_count": 2, "name": "index_object.Float64IndexMethod.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "95061ed30b62c0b9d9cf95faffe63e95be78a617811548ad955f451532cb0fba", "warmup_time": -1}, "index_object.GC.peakmem_gc_instances": {"code": "class GC:\n    def peakmem_gc_instances(self, N):\n        try:\n            gc.disable()\n    \n            for _ in range(N):\n                self.create_use_drop()\n        finally:\n            gc.enable()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "name": "index_object.GC.peakmem_gc_instances", "param_names": ["param1"], "params": [["1", "2", "5"]], "type": "peakmemory", "unit": "bytes", "version": "7b1c36ff9e60323ef8e4df7fa94a4764bdb5c6dce62bfea0095812ca55841ff9"}, "index_object.IndexAppend.time_append_int_list": {"code": "class IndexAppend:\n    def time_append_int_list(self):\n        self.int_idx.append(self.int_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)\n        self.same_range_idx = [self.range_idx] * N", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_int_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "187b4bea8d14dcc06f65835569b1c5e971944530ec8cb67458abf0a48d63a9fe", "warmup_time": -1}, "index_object.IndexAppend.time_append_obj_list": {"code": "class IndexAppend:\n    def time_append_obj_list(self):\n        self.obj_idx.append(self.object_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)\n        self.same_range_idx = [self.range_idx] * N", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_obj_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1eb3444e584db6402181f1963f7d223d14b319f378532e86d0026c1c4c7c951e", "warmup_time": -1}, "index_object.IndexAppend.time_append_range_list": {"code": "class IndexAppend:\n    def time_append_range_list(self):\n        self.range_idx.append(self.range_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)\n        self.same_range_idx = [self.range_idx] * N", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_range_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0e304a4e79c4ee646b5ebb948712ae73512cb69027375ac7df1bb411a938f290", "warmup_time": -1}, "index_object.IndexAppend.time_append_range_list_same": {"code": "class IndexAppend:\n    def time_append_range_list_same(self):\n        self.range_idx.append(self.same_range_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)\n        self.same_range_idx = [self.range_idx] * N", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_range_list_same", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ff402b8c39150bf9edff26f66ab0e7092c6dd67e49ec116b99e0d6b4abe54295", "warmup_time": -1}, "index_object.IndexEquals.time_non_object_equals_multiindex": {"code": "class IndexEquals:\n    def time_non_object_equals_multiindex(self):\n        self.idx_non_object.equals(self.mi_large_slow)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexEquals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100_000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "index_object.IndexEquals.time_non_object_equals_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bc0a852a1647f5faba1ff3d27b24d6f703432910d3e11571a9d33ab853b195fe", "warmup_time": -1}, "index_object.Indexing.time_boolean_array": {"code": "class Indexing:\n    def time_boolean_array(self, dtype):\n        self.idx[self.array_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_array", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2872d6ea2933595acc8996735ecb7a9132a4426fb1407ccec9aa7efdd4ad85ad", "warmup_time": -1}, "index_object.Indexing.time_boolean_series": {"code": "class Indexing:\n    def time_boolean_series(self, dtype):\n        self.idx[self.series_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_series", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "171ff47df045dded77e36fb401cca8017353337080c278f199fb8dcb639b5464", "warmup_time": -1}, "index_object.Indexing.time_get": {"code": "class Indexing:\n    def time_get(self, dtype):\n        self.idx[1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c57b57260524bc53aea830758c7b5709073ec090659a1d47c36095f2fb15dff7", "warmup_time": -1}, "index_object.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self, dtype):\n        self.idx.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "69319b49f855f411ba4637d014498c805bf3ed2a7094c32bd645b68fc1cd4f0e", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique": {"code": "class Indexing:\n    def time_get_loc_non_unique(self, dtype):\n        self.non_unique.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c8473ef7870230376ca8a19b46b05af3eca2e5e512dc4b793c2815ca20baf1d4", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique_sorted": {"code": "class Indexing:\n    def time_get_loc_non_unique_sorted(self, dtype):\n        self.non_unique_sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d3b10e0134711d5f0ab40869cd8d2c7bdb5c3036812bcd69d10d62fb1747b2d9", "warmup_time": -1}, "index_object.Indexing.time_get_loc_sorted": {"code": "class Indexing:\n    def time_get_loc_sorted(self, dtype):\n        self.sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "739af3c9409d4e9d6c8df759ed8f56c0fd3d26f455934fbf3bb864fae82ad7df", "warmup_time": -1}, "index_object.Indexing.time_slice": {"code": "class Indexing:\n    def time_slice(self, dtype):\n        self.idx[:-1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "11119f3458bfba6b765f0d88bdf470a536cb9627fe0038c74fff6a0713250654", "warmup_time": -1}, "index_object.Indexing.time_slice_step": {"code": "class Indexing:\n    def time_slice_step(self, dtype):\n        self.idx[::2]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice_step", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c9173d384d9c83e3f8d59ac1ffc9ef13805aa187d563490d88c3fe8968f7bc68", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection": {"code": "class IntervalIndexMethod:\n    def time_intersection(self, N):\n        self.left.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4211da5ac938e20dc8e3ebad85e3fd809e9b9485898f7bc9fa4b78bf51836ba1", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_both_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_both_duplicate(self, N):\n        self.intv.intersection(self.intv2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_both_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "51c27b25f860d486d8b165a9a8fff37e4de68c2b0a193957783434e9151daaaa", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_one_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_one_duplicate(self, N):\n        self.intv.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_one_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d690ff28419653e49b71207cafa08bd0c7e2901de3773c422f3c20c5659c70da", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_is_unique": {"code": "class IntervalIndexMethod:\n    def time_is_unique(self, N):\n        self.intv.is_unique\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_is_unique", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b17a38c55c09eaaebc6e2a4010627e28285f0f0b8e734cf754a82d09ba25a090", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_monotonic_inc": {"code": "class IntervalIndexMethod:\n    def time_monotonic_inc(self, N):\n        self.intv.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_monotonic_inc", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2f556c42b4ba4b668eb1eb25dfddbcc31dc3735f52e12303ef99ae8a4b9243e0", "warmup_time": -1}, "index_object.Range.time_get_loc_dec": {"code": "class Range:\n    def time_get_loc_dec(self):\n        self.idx_dec.get_loc(100_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_dec", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cf79b8ebe5bba662336f38ac055b59d39696daca21fa516ec6f3d586ef77fbeb", "warmup_time": -1}, "index_object.Range.time_get_loc_inc": {"code": "class Range:\n    def time_get_loc_inc(self):\n        self.idx_inc.get_loc(900_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_inc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e65b3c2e45ffd07fe90c70762651887bf917e0004b33efeabc1a1513961834af", "warmup_time": -1}, "index_object.Range.time_iter_dec": {"code": "class Range:\n    def time_iter_dec(self):\n        for _ in self.idx_dec:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_iter_dec", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0a8939329588ad2b3dccc5769b034e1cc2e6af1940fac168fcfa5dc2b425573c", "warmup_time": -1}, "index_object.Range.time_iter_inc": {"code": "class Range:\n    def time_iter_inc(self):\n        for _ in self.idx_inc:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_iter_inc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "83fc9b98da37845cad00c4fbdc28fc193a5ba6fe4036f48c28387979e66deb80", "warmup_time": -1}, "index_object.Range.time_max": {"code": "class Range:\n    def time_max(self):\n        self.idx_inc.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3fe3d3e0faeaa6aca9e99b56ed9428c2909cf685bc2777ad15b8b139f7f9b6fc", "warmup_time": -1}, "index_object.Range.time_max_trivial": {"code": "class Range:\n    def time_max_trivial(self):\n        self.idx_dec.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max_trivial", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4e25e4137da187681125aee125ed76c646d75254e914e5a610454f0dab1bdbf2", "warmup_time": -1}, "index_object.Range.time_min": {"code": "class Range:\n    def time_min(self):\n        self.idx_dec.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5d8be4d1e9900d49eb6d2838b94ceaf7b5b6044f15d46b44772fd09d2ed706ed", "warmup_time": -1}, "index_object.Range.time_min_trivial": {"code": "class Range:\n    def time_min_trivial(self):\n        self.idx_inc.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min_trivial", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9406fe8e0431d861ebb9af746fdd854868498b66f1a43f0b7184b8a5955f901b", "warmup_time": -1}, "index_object.Range.time_sort_values_asc": {"code": "class Range:\n    def time_sort_values_asc(self):\n        self.idx_inc.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_sort_values_asc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ad0ef7f510dcd8d00149b95616b19281a15359db8f2989bf9b4db306fdf0153f", "warmup_time": -1}, "index_object.Range.time_sort_values_des": {"code": "class Range:\n    def time_sort_values_des(self):\n        self.idx_inc.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_sort_values_des", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c7ce6ea7bb8b8649240594fbbc1a612d9d42aa3b0e41c90f92cfb40283cbbd45", "warmup_time": -1}, "index_object.SetDisjoint.time_datetime_difference_disjoint": {"code": "class SetDisjoint:\n    def time_datetime_difference_disjoint(self):\n        self.datetime_left.difference(self.datetime_right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetDisjoint:\n    def setup(self):\n        N = 10**5\n        B = N + 20000\n        self.datetime_left = DatetimeIndex(range(N))\n        self.datetime_right = DatetimeIndex(range(N, B))", "min_run_count": 2, "name": "index_object.SetDisjoint.time_datetime_difference_disjoint", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5f314bb98034f50776d52507597278df13b4f23a7942559fc0dedf93d1c11c62", "warmup_time": -1}, "index_object.SetOperations.time_operation": {"code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method):\n        N = 10**5\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n        date_str_left = Index(dates_left.strftime(fmt))\n        int_left = Index(np.arange(N))\n        ea_int_left = Index(np.arange(N), dtype=\"Int64\")\n        str_left = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n    \n        data = {\n            \"datetime\": dates_left,\n            \"date_string\": date_str_left,\n            \"int\": int_left,\n            \"strings\": str_left,\n            \"ea_int\": ea_int_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": idx, \"right\": idx[:-1]} for k, idx in data.items()}\n    \n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "index_object.SetOperations.time_operation", "number": 0, "param_names": ["index_structure", "dtype", "method"], "params": [["'monotonic'", "'non_monotonic'"], ["'datetime'", "'date_string'", "'int'", "'strings'", "'ea_int'"], ["'intersection'", "'union'", "'symmetric_difference'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "705854d266f8227ee3d9b1eebe268d69ac27a014c6ad4691945dfab9b8c3707b", "warmup_time": -1}, "index_object.UnionWithDuplicates.time_union_with_duplicates": {"code": "class UnionWithDuplicates:\n    def time_union_with_duplicates(self):\n        self.left.union(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass UnionWithDuplicates:\n    def setup(self):\n        self.left = Index(np.repeat(np.arange(1000), 100))\n        self.right = Index(np.tile(np.arange(500, 1500), 50))", "min_run_count": 2, "name": "index_object.UnionWithDuplicates.time_union_with_duplicates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0420e720a40b09b5a83ef4ace67c704a238d521a86a8cb00c673aae12cfa2f25", "warmup_time": -1}, "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index": {"code": "class AssignTimeseriesIndex:\n    def time_frame_assign_timeseries_index(self):\n        self.df[\"date\"] = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AssignTimeseriesIndex:\n    def setup(self):\n        N = 100000\n        idx = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        self.df = DataFrame(np.random.randn(N, 1), columns=[\"A\"], index=idx)", "min_run_count": 2, "name": "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8a46e2b72c84ebbe38a56cb3270fe056a22bae89403a8b5abbba563b26d08524", "warmup_time": -1}, "indexing.Block.time_test": {"code": "class Block:\n    def time_test(self):\n        start = datetime(2010, 5, 1)\n        end = datetime(2010, 9, 1)\n        self.df.loc[start:end, :] = True\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Block:\n    def setup(self):\n        self.df = DataFrame(\n            False,\n            columns=np.arange(500).astype(str),\n            index=date_range(\"2010-01-01\", \"2011-01-01\"),\n        )", "min_run_count": 2, "name": "indexing.Block.time_test", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "39e6c3768a47acba71f7629130e05fa40727ceee91cea7b9615069e0d7ff1970", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_indexer_list": {"code": "class CategoricalIndexIndexing:\n    def time_get_indexer_list(self, index):\n        self.data_unique.get_indexer(self.cat_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_indexer_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "62150e3781f883d8f6823c45067fcac0fefeb8ec685a47ce8057bed4cbaf3de7", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_loc_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_get_loc_scalar(self, index):\n        self.data.get_loc(self.cat_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_loc_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f37f9a77340871ef67cae5bac921473a106ea7e1c707babd9a5d708a28df0d9a", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_bool_array": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b4c1625b9c78f360819094fa2e243d9c3671eccf5396bd00cc7d4298824b370d", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list(self, index):\n        self.data[self.int_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "25f5a440360e857bbf13b393292f058291a0fe0e335aa56339d4690c25ac147c", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list_like": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.int_scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d616c85b999476b17108e8f7e22f95a195640eb4a2d59226df18c1f7eb5fbc26", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_scalar(self, index):\n        self.data[self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a18201ebf2cfad696d0e413b9cbc8eb4884b1f5b7447ca8f974fe3f765766278", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_slice": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_slice(self, index):\n        self.data[: self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4c7a1c61821c96671e21fd7ce147081487558bee846c82a1db1d2a696acb4761", "warmup_time": -1}, "indexing.ChainIndexing.time_chained_indexing": {"code": "class ChainIndexing:\n    def time_chained_indexing(self, mode):\n        df = self.df\n        N = self.N\n        with warnings.catch_warnings(record=True):\n            with option_context(\"mode.chained_assignment\", mode):\n                df2 = df[df.A > N // 2]\n                df2[\"C\"] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ChainIndexing:\n    def setup(self, mode):\n        self.N = 1000000\n        self.df = DataFrame({\"A\": np.arange(self.N), \"B\": \"foo\"})", "min_run_count": 2, "name": "indexing.ChainIndexing.time_chained_indexing", "number": 0, "param_names": ["mode"], "params": [["None", "'warn'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "16258f12b7c725f7ffc21ffed9c69bd9751f02f6a459f86e81c20750c1fc1bba", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_bool_indexer": {"code": "class DataFrameNumericIndexing:\n    def time_bool_indexer(self, index, index_structure):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_bool_indexer", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5b49ac8c1fc01d2dc2c19c3edcf588116fa02ee673f47dde99584eb435361fed", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc": {"code": "class DataFrameNumericIndexing:\n    def time_iloc(self, index, index_structure):\n        self.df.iloc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d4f1ee902bd3f0617b7fe7bfbca605d0c34d424476e2ea162e220ee701e530eb", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_iloc_dups(self, index, index_structure):\n        self.df_dup.iloc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc_dups", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4390803cba45b26841ac1b3f27cffcaed921e6083822e3d13e9eff994ee542e5", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc": {"code": "class DataFrameNumericIndexing:\n    def time_loc(self, index, index_structure):\n        self.df.loc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a85621866c240f052375710c72ffe0cc190d797923084092e4984bff4240dfdf", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_loc_dups(self, index, index_structure):\n        self.df_dup.loc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc_dups", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9789412267c4eba4099218c01b54dc8d5055978255c8cae7cd1d3f96cf362b7e", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_at": {"code": "class DataFrameStringIndexing:\n    def time_at(self):\n        self.df.at[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_at", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "04739f5bfcf96a2f809bfa8f746b3114f7e77b97abc35344668e4ca4a11170d4", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_at_setitem": {"code": "class DataFrameStringIndexing:\n    def time_at_setitem(self):\n        self.df.at[self.idx_scalar, self.col_scalar] = 0.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_at_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "16329486e02da43d62eec0a291532ad60f0896602155cbceaedcad8754660605", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8c68634926f34e2c9bc0f70108b33cfe3e2b04a295ea8cd25fc43f47be736790", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_boolean": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_boolean(self):\n        self.df[self.boolean_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_boolean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6dab0adc8de5d2f64428f7448f101efc6b11cbcc807586ed900490d1d9afb74d", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_object": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_object(self):\n        self.df[self.bool_obj_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "17f00e8889b2275c34fb7afa8d331fedfd9d5e12704117ffc4055d512bd2bd60", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_getitem_scalar": {"code": "class DataFrameStringIndexing:\n    def time_getitem_scalar(self):\n        self.df[self.col_scalar][self.idx_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fcea3e53ee2d996215560d161151b94b0177c7b2d2cbbc4580f324f6dc2de27a", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_loc": {"code": "class DataFrameStringIndexing:\n    def time_loc(self):\n        self.df.loc[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "12b067d7b3c3ffe25275292b557ba18517ad4d2c5b6e1b41fdfb018f4889d00c", "warmup_time": -1}, "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz": {"code": "class DatetimeIndexIndexing:\n    def time_get_indexer_mismatched_tz(self):\n        # reached via e.g.\n        #  ser = Series(range(len(dti)), index=dti)\n        #  ser[dti2]\n        self.dti.get_indexer(self.dti2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexIndexing:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        dti2 = dti.tz_convert(\"UTC\")\n        self.dti = dti\n        self.dti2 = dti2", "min_run_count": 2, "name": "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c9cf20755eb4a51e544f3173086738738b06c2840acdc00a8c905a951594ce03", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_int(self):\n        self.df_int_col[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8516566e6a549f1f7c5a48623aa1378d299f882af8c200a8ab04eb7d321f0a23", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_label(self):\n        self.df_string_col[\"A\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a03a82b5117e7c2d6cccfe8ac22ef652a2ac9b039e27f15814a7bfab97c94f00", "warmup_time": -1}, "indexing.IndexSingleRow.time_iloc_row": {"code": "class IndexSingleRow:\n    def time_iloc_row(self, unique_cols):\n        self.df.iloc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10**7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df", "min_run_count": 2, "name": "indexing.IndexSingleRow.time_iloc_row", "number": 0, "param_names": ["unique_cols"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4e20d2ce44a18740b78a7eae0eab3b3352a211486335db125fa22f685c9c5c68", "warmup_time": -1}, "indexing.IndexSingleRow.time_loc_row": {"code": "class IndexSingleRow:\n    def time_loc_row(self, unique_cols):\n        self.df.loc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10**7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df", "min_run_count": 2, "name": "indexing.IndexSingleRow.time_loc_row", "number": 0, "param_names": ["unique_cols"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b1ae71b2de36f0424ee21d6b377c7e4370496ce8ed29f92ce82786280ff4c9db", "warmup_time": -1}, "indexing.InsertColumns.time_assign_list_like_with_setitem": {"code": "class InsertColumns:\n    def time_assign_list_like_with_setitem(self):\n        self.df[list(range(100))] = np.random.randn(self.N, 100)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_list_like_with_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3bb24f36b40d94be98724ac3ffea9a7afbc390d394fa5fa9475cc77a13ffdf7b", "warmup_time": -1}, "indexing.InsertColumns.time_assign_list_of_columns_concat": {"code": "class InsertColumns:\n    def time_assign_list_of_columns_concat(self):\n        df = DataFrame(np.random.randn(self.N, 100))\n        concat([self.df, df], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_list_of_columns_concat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "41cef472b41bd56488365882e9724052692d13ec0abf67f3fa395e44af3a045d", "warmup_time": -1}, "indexing.InsertColumns.time_assign_with_setitem": {"code": "class InsertColumns:\n    def time_assign_with_setitem(self):\n        for i in range(100):\n            self.df[i] = np.random.randn(self.N)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_with_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "594d490a7116f20753d8366d82e417220b8035ce74080b41de66a9f64d7b2abd", "warmup_time": -1}, "indexing.InsertColumns.time_insert": {"code": "class InsertColumns:\n    def time_insert(self):\n        for i in range(100):\n            self.df.insert(0, i, np.random.randn(self.N), allow_duplicates=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_insert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0021e91e2211b243fded9954bae458921f73a3e5ded206d0817555b44c945c0d", "warmup_time": -1}, "indexing.InsertColumns.time_insert_middle": {"code": "class InsertColumns:\n    def time_insert_middle(self):\n        # same as time_insert but inserting to a middle column rather than\n        #  front or back (which have fast-paths)\n        for i in range(100):\n            self.df2.insert(\n                1, \"colname\", np.random.randn(self.N), allow_duplicates=True\n            )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_insert_middle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c08ac878c8c7f19edcae9cddb8525e726ef5328f5fb06d9932ca3e83158e4a7d", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_list": {"code": "class IntervalIndexing:\n    def time_getitem_list(self, monotonic):\n        monotonic[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:324", "type": "time", "unit": "seconds", "version": "ae80a330a1a4becae8c369fe9bcb0c8f430beb2d8ac3986f5e2f82490c50e071", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_scalar": {"code": "class IntervalIndexing:\n    def time_getitem_scalar(self, monotonic):\n        monotonic[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:324", "type": "time", "unit": "seconds", "version": "f160eaae3bf3bcbcc3fd20357b12c28670839282da6644be0e8024f97b21204b", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_list": {"code": "class IntervalIndexing:\n    def time_loc_list(self, monotonic):\n        monotonic.loc[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:324", "type": "time", "unit": "seconds", "version": "634735f3995a5c9be2542706652ca9d8a024f91ded9a8e3ec8653b176bb9c556", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_scalar": {"code": "class IntervalIndexing:\n    def time_loc_scalar(self, monotonic):\n        monotonic.loc[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:324", "type": "time", "unit": "seconds", "version": "9682c17d993a421023a33cdfbf1ae6a67d4f2b1a8a9eb98fb60445f56f4d892e", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_iloc": {"code": "class MethodLookup:\n    def time_lookup_iloc(self, s):\n        s.iloc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_iloc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:418", "type": "time", "unit": "seconds", "version": "de130c1315ebaff60daa5132a0ffba11a1513d688c4d7465c4f0b75fa3b40d4d", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_loc": {"code": "class MethodLookup:\n    def time_lookup_loc(self, s):\n        s.loc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:418", "type": "time", "unit": "seconds", "version": "8f3e9ba1fa6ae32795b77d4fb0a2cb3a36108a494ac5a33197076f41a75cee6c", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_bool_indexers": {"code": "class MultiIndexing:\n    def time_loc_all_bool_indexers(self, unique_levels):\n        target = tuple([self.tgt_bool_indexer] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_bool_indexers", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1771918b3fe0b5cbe067324593f312813f66ac1576a3387207feb5abfb7ca806", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_lists": {"code": "class MultiIndexing:\n    def time_loc_all_lists(self, unique_levels):\n        target = tuple([self.tgt_list] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_lists", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "472ab8a43bc8d905a0c7bfecd2190e954a7da13e4e29ddbaf54d1ffa9c50a846", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_null_slices": {"code": "class MultiIndexing:\n    def time_loc_all_null_slices(self, unique_levels):\n        target = tuple([self.tgt_null_slice] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_null_slices", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee13de44701c0630572b0428b6d08740c41bc7278df47aae6f015bed57f20896", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_scalars": {"code": "class MultiIndexing:\n    def time_loc_all_scalars(self, unique_levels):\n        target = tuple([self.tgt_scalar] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_scalars", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "52fba5b8883c06b2ad277a711b4ac49603c38321be1afb8a2daf975deff153af", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_slices": {"code": "class MultiIndexing:\n    def time_loc_all_slices(self, unique_levels):\n        target = tuple([self.tgt_slice] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_slices", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7ee6845e7a946179e2f28eb51291bf1e8dc5aa663346c5e70b7db58cf6a415d4", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_multiindex": {"code": "class MultiIndexing:\n    def time_loc_multiindex(self, unique_levels):\n        target = self.df.index[::10]\n        self.df.loc[target]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_multiindex", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "845e85441994edf43d432790182cf5f3f1c8a8d11260d19322d4f9c26e9ea82e", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_null_slice_plus_slice": {"code": "class MultiIndexing:\n    def time_loc_null_slice_plus_slice(self, unique_levels):\n        target = (self.tgt_null_slice, self.tgt_slice)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_null_slice_plus_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f8a8667e507761ed75e543d5d59a9b99abf35fbbd88506af79bba513db537b1d", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_bool_indexer": {"code": "class MultiIndexing:\n    def time_loc_partial_key_bool_indexer(self, unique_levels):\n        self.df.loc[self.tgt_bool_indexer, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_bool_indexer", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f4163b15e26adc988dcb7d895e5ced6f1fa85495a29d44c6f1df7010fff0d379", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_list": {"code": "class MultiIndexing:\n    def time_loc_partial_key_list(self, unique_levels):\n        self.df.loc[self.tgt_list, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_list", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3d998427658ce79d9730202287dfc27f39d7b70b94481fc82cc28c58bb10fc2c", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_null_slice": {"code": "class MultiIndexing:\n    def time_loc_partial_key_null_slice(self, unique_levels):\n        self.df.loc[self.tgt_null_slice, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_null_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "777e2da95dafebe327dcbfc63277290e5760e3bb51661ddfe6a5fd3c7e0702bc", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_scalar": {"code": "class MultiIndexing:\n    def time_loc_partial_key_scalar(self, unique_levels):\n        self.df.loc[self.tgt_scalar, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_scalar", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7fff81ab0ee84cd8d0d1cbb857a086f21277e9956a9dd836bbe17b4070bf4188", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_slice": {"code": "class MultiIndexing:\n    def time_loc_partial_key_slice(self, unique_levels):\n        self.df.loc[self.tgt_slice, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7e493377f1a856eeb73c21aae1208537b26a4a29edb1afaa8ac89e4ffa29ef49", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_slice_plus_null_slice": {"code": "class MultiIndexing:\n    def time_loc_slice_plus_null_slice(self, unique_levels):\n        target = (self.tgt_slice, self.tgt_null_slice)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_slice_plus_null_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e35e95d2686e9edb9c298e881d73f80b937d8cc77b9c363ce78a9e6f079157f9", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_full_key": {"code": "class MultiIndexing:\n    def time_xs_full_key(self, unique_levels):\n        target = tuple([self.tgt_scalar] * self.nlevels)\n        self.df.xs(target)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_full_key", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d9bbac09a6803b7e0d554f99cfbfa0517a1d7320e6a6af606bce52ec78fe89d5", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_level_0": {"code": "class MultiIndexing:\n    def time_xs_level_0(self, unique_levels):\n        target = self.tgt_scalar\n        self.df.xs(target, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_level_0", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "daaf4beb33874670dbba4df791aff72a906678fd1058938bc990e56cd7b733e3", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_level_1": {"code": "class MultiIndexing:\n    def time_xs_level_1(self, unique_levels):\n        target = self.tgt_scalar\n        self.df.xs(target, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_level_1", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "464f6f9822548adbb0a5afc6fd74b0fa4a5077d6215ac2a85daf48a6454b74b8", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_label_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_label_slice(self, index, index_structure):\n        self.s[: self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_label_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b7149a98ec037ac1cf628a59eae2af60f74f9e88aa8a8184591977e3c6053734", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_list_like": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.s[[self.lbl]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6a98622cf697e3e9ee3a5279589dc8280e8ed223e48a847e90691ad95248b8fe", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_pos_slice(self, index, index_structure):\n        self.s[:80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "06c57330892af61624a8f99c03e8af71fe978ac9049882d56369cf5f4b0ab7a7", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_scalar": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.s[self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9eff631ecc5e93c0bc45f0d7cfa28a9241c82461e4e1af909e9e0f1bcae15268", "warmup_time": -1}, "indexing.NumericMaskedIndexing.time_get_indexer": {"code": "class NumericMaskedIndexing:\n    def time_get_indexer(self, dtype, monotonic):\n        self.data.get_indexer(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericMaskedIndexing:\n    def setup(self, dtype, monotonic):\n        indices = {\n            True: Index(self.monotonic_list, dtype=dtype),\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\n                Index([NA], dtype=dtype)\n            ),\n        }\n        self.data = indices[monotonic]\n        self.indexer = np.arange(300, 1_000)\n        self.data_dups = self.data.append(self.data)", "min_run_count": 2, "name": "indexing.NumericMaskedIndexing.time_get_indexer", "number": 0, "param_names": ["dtype", "monotonic"], "params": [["'Int64'", "'UInt64'", "'Float64'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c9f9a8ac9f8595fa973302687b629db6bf6b9924be4c3431f56d1b61c68570d2", "warmup_time": -1}, "indexing.NumericMaskedIndexing.time_get_indexer_dups": {"code": "class NumericMaskedIndexing:\n    def time_get_indexer_dups(self, dtype, monotonic):\n        self.data.get_indexer_for(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericMaskedIndexing:\n    def setup(self, dtype, monotonic):\n        indices = {\n            True: Index(self.monotonic_list, dtype=dtype),\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\n                Index([NA], dtype=dtype)\n            ),\n        }\n        self.data = indices[monotonic]\n        self.indexer = np.arange(300, 1_000)\n        self.data_dups = self.data.append(self.data)", "min_run_count": 2, "name": "indexing.NumericMaskedIndexing.time_get_indexer_dups", "number": 0, "param_names": ["dtype", "monotonic"], "params": [["'Int64'", "'UInt64'", "'Float64'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "650c0af5a8f5231315bb45ae613c0b6e4fe1a990510b7c6ef5cb41e20818e616", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_array": {"code": "class NumericSeriesIndexing:\n    def time_getitem_array(self, index, index_structure):\n        self.data[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f8dbc1486bd95bff70285ace102a5d9ae45c39e61501c81985e19c24fef1d788", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_list_like": {"code": "class NumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.data[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "767f017c9055f888f75b6eed2e15a080b0b64319d1095620556c015c88fa110d", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_lists": {"code": "class NumericSeriesIndexing:\n    def time_getitem_lists(self, index, index_structure):\n        self.data[self.array_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_lists", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "443e55142dfd34591a735feb3d4d744e6958acb9018b753424bb95601e47a666", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_scalar": {"code": "class NumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.data[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "73c063a362862485753efeb9a6fbc07336e18a6c35add26bec792086df47b674", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_slice": {"code": "class NumericSeriesIndexing:\n    def time_getitem_slice(self, index, index_structure):\n        self.data[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "53dd251b95b13c6d4735cc1d1ad7f926e4ec0328748779a56fa1c63f4fa359a0", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_array": {"code": "class NumericSeriesIndexing:\n    def time_iloc_array(self, index, index_structure):\n        self.data.iloc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7ca4d36d48a371195da509750de2d5dbb5fe15f466c419bd88a3d832c7339921", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_iloc_list_like(self, index, index_structure):\n        self.data.iloc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e6eb0977e121dbf9c0f8fed57bba4cbd0712e219c303813a323edfbeb879ca5f", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_iloc_scalar(self, index, index_structure):\n        self.data.iloc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d5a3df9b91de4f27357390975b96e77f6fe4ed9eced3a16044211134bc38617b", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_slice": {"code": "class NumericSeriesIndexing:\n    def time_iloc_slice(self, index, index_structure):\n        self.data.iloc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6dd75593c3e3cf6040fc6b6152cae16559fec377ae607105dc5867d7257d6e6b", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_array": {"code": "class NumericSeriesIndexing:\n    def time_loc_array(self, index, index_structure):\n        self.data.loc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3165bdce66ae50b67ee74bf5b720ddc68ab182ec7445bc812e1c0a6282bdf773", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_loc_list_like(self, index, index_structure):\n        self.data.loc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9bd41a8e0e77f49c1815e6441bfed382f1642a7ffd8d470af8ae822095871ce7", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_loc_scalar(self, index, index_structure):\n        self.data.loc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ca036299851e1902e2e167658690aabd8b3c4a23c4565717eaed87565bac7725", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_slice": {"code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, index_structure):\n        self.data.loc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7ec9524466f40bb446af6342c1220299a782e5c6c08e8a074782d963360ff732", "warmup_time": -1}, "indexing.Setitem.time_setitem": {"code": "class Setitem:\n    def time_setitem(self):\n        self.df[100] = 100\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Setitem:\n    def setup(self):\n        N = 500_000\n        cols = 500\n        self.df = DataFrame(np.random.rand(N, cols))", "min_run_count": 2, "name": "indexing.Setitem.time_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "05f726f7641992ec4777d8bd735c1ae3ec9b5046bec013ae0c155fe1b3e37560", "warmup_time": -1}, "indexing.Setitem.time_setitem_list": {"code": "class Setitem:\n    def time_setitem_list(self):\n        self.df[[100, 200, 300]] = 100\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Setitem:\n    def setup(self):\n        N = 500_000\n        cols = 500\n        self.df = DataFrame(np.random.rand(N, cols))", "min_run_count": 2, "name": "indexing.Setitem.time_setitem_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6ae63a2e6c513edbdfdf8c6e2acfeca129311e22230ada6b94c26bda50916b2b", "warmup_time": -1}, "indexing.SetitemObjectDtype.time_setitem_object_dtype": {"code": "class SetitemObjectDtype:\n    def time_setitem_object_dtype(self):\n        self.df.loc[0, 1] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetitemObjectDtype:\n    def setup(self):\n        N = 1000\n        cols = 500\n        self.df = DataFrame(index=range(N), columns=range(cols), dtype=object)", "min_run_count": 2, "name": "indexing.SetitemObjectDtype.time_setitem_object_dtype", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8097d4d139957ec4def40f768092a69c123eb5734fd79de749c28d017fcf96d8", "warmup_time": -1}, "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_sorted": {"code": "class SortedAndUnsortedDatetimeIndexLoc:\n    def time_loc_sorted(self):\n        self.df_sort.loc[\"2016-6-11\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortedAndUnsortedDatetimeIndexLoc:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        index = np.array(dti)\n    \n        unsorted_index = index.copy()\n        unsorted_index[10] = unsorted_index[20]\n    \n        self.df_unsorted = DataFrame(index=unsorted_index, data={\"a\": 1})\n        self.df_sort = DataFrame(index=index, data={\"a\": 1})", "min_run_count": 2, "name": "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_sorted", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0f65be8fdfcef229110b3366c9eeec8b227559f9db6dbbae3de7e915928496c4", "warmup_time": -1}, "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_unsorted": {"code": "class SortedAndUnsortedDatetimeIndexLoc:\n    def time_loc_unsorted(self):\n        self.df_unsorted.loc[\"2016-6-11\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortedAndUnsortedDatetimeIndexLoc:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        index = np.array(dti)\n    \n        unsorted_index = index.copy()\n        unsorted_index[10] = unsorted_index[20]\n    \n        self.df_unsorted = DataFrame(index=unsorted_index, data={\"a\": 1})\n        self.df_sort = DataFrame(index=index, data={\"a\": 1})", "min_run_count": 2, "name": "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_unsorted", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7f7406b54217c050b92bb548cd77d9e99371a9102aed4a513cc83b2677d7dd3d", "warmup_time": -1}, "indexing.Take.time_take": {"code": "class Take:\n    def time_take(self, index):\n        self.s.take(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": Index(np.arange(N), dtype=np.int64),\n            \"datetime\": date_range(\"2011-01-01\", freq=\"s\", periods=N),\n        }\n        index = indexes[index]\n        self.s = Series(np.random.rand(N), index=index)\n        self.indexer = np.random.randint(0, N, size=N)", "min_run_count": 2, "name": "indexing.Take.time_take", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "aaab1dd97f72161e6764c891742376656b295e9c0af44239f220454e583034c4", "warmup_time": -1}, "indexing_engines.MaskedNumericEngineIndexing.time_get_loc": {"code": "class MaskedNumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n        dtype = dtype.lower()\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.zeros(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n    \n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n            mask[-1] = True\n    \n        self.data = engine(BaseMaskedArray(arr, mask))\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.MaskedNumericEngineIndexing.time_get_loc", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.MaskedInt64Engine'>, 'Int64')", "(<class 'pandas._libs.index.MaskedInt32Engine'>, 'Int32')", "(<class 'pandas._libs.index.MaskedInt16Engine'>, 'Int16')", "(<class 'pandas._libs.index.MaskedInt8Engine'>, 'Int8')", "(<class 'pandas._libs.index.MaskedUInt64Engine'>, 'UInt64')", "(<class 'pandas._libs.index.MaskedUInt32Engine'>, 'UInt32')", "(<class 'pandas._libs.index.MaskedUInt8Engine'>, 'UInt8')", "(<class 'pandas._libs.index.MaskedFloat64Engine'>, 'Float64')", "(<class 'pandas._libs.index.MaskedFloat32Engine'>, 'Float32')"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7c394755b12d2c3e21c69c1654a1096049d5ff48d44e9fa5e68c13a5edd9a2de", "warmup_time": -1}, "indexing_engines.MaskedNumericEngineIndexing.time_get_loc_near_middle": {"code": "class MaskedNumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n        dtype = dtype.lower()\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.zeros(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n    \n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n            mask[-1] = True\n    \n        self.data = engine(BaseMaskedArray(arr, mask))\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.MaskedNumericEngineIndexing.time_get_loc_near_middle", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.MaskedInt64Engine'>, 'Int64')", "(<class 'pandas._libs.index.MaskedInt32Engine'>, 'Int32')", "(<class 'pandas._libs.index.MaskedInt16Engine'>, 'Int16')", "(<class 'pandas._libs.index.MaskedInt8Engine'>, 'Int8')", "(<class 'pandas._libs.index.MaskedUInt64Engine'>, 'UInt64')", "(<class 'pandas._libs.index.MaskedUInt32Engine'>, 'UInt32')", "(<class 'pandas._libs.index.MaskedUInt8Engine'>, 'UInt8')", "(<class 'pandas._libs.index.MaskedFloat64Engine'>, 'Float64')", "(<class 'pandas._libs.index.MaskedFloat32Engine'>, 'Float32')"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "33a4604e2edf65feda97d75cabe7a94bc517e629c63acaf5c3a788c199e7eff6", "warmup_time": -1}, "indexing_engines.NumericEngineIndexing.time_get_loc": {"code": "class NumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n    \n        self.data = engine(arr)\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.NumericEngineIndexing.time_get_loc", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "65b3d11b3c6faf12c8e905404b7d91d9b5495adad1b0e3d7af303b94c66d754d", "warmup_time": -1}, "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle": {"code": "class NumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n    \n        self.data = engine(arr)\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "beaa25ddfea801a7e7b25d2d14e6fa0d37145eb2280a06ed4fdc06bbf2b9dc37", "warmup_time": -1}, "indexing_engines.ObjectEngineIndexing.time_get_loc": {"code": "class ObjectEngineIndexing:\n    def time_get_loc(self, index_type):\n        self.data.get_loc(\"b\")\n\n    def setup(self, index_type):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=object),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=object),\n            \"non_monotonic\": np.array(list(\"abc\") * N, dtype=object),\n        }[index_type]\n    \n        self.data = libindex.ObjectEngine(arr)\n        # code below avoids populating the mapping etc. while timing.\n        self.data.get_loc(\"b\")", "min_run_count": 2, "name": "indexing_engines.ObjectEngineIndexing.time_get_loc", "number": 0, "param_names": ["index_type"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d2f16137376532b74997179666987b5cf12d74dd819aeeae3a8b339bd1faf320", "warmup_time": -1}, "inference.MaybeConvertNumeric.time_convert": {"code": "class MaybeConvertNumeric:\n    def time_convert(self, data):\n        lib.maybe_convert_numeric(data, set(), coerce_numeric=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertNumeric:\n    def setup_cache(self):\n        N = 10**6\n        arr = np.repeat([2**63], N) + np.arange(N).astype(\"uint64\")\n        data = arr.astype(object)\n        data[1::2] = arr[1::2].astype(str)\n        data[-1] = -1\n        return data", "min_run_count": 2, "name": "inference.MaybeConvertNumeric.time_convert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "inference:80", "type": "time", "unit": "seconds", "version": "cf27dbc37431d8df629b71882573a765fb8244c558a5874dc6c8d279f80c581e", "warmup_time": -1}, "inference.MaybeConvertObjects.time_maybe_convert_objects": {"code": "class MaybeConvertObjects:\n    def time_maybe_convert_objects(self):\n        lib.maybe_convert_objects(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertObjects:\n    def setup(self):\n        N = 10**5\n    \n        data = list(range(N))\n        data[0] = NaT\n        data = np.array(data)\n        self.data = data", "min_run_count": 2, "name": "inference.MaybeConvertObjects.time_maybe_convert_objects", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5e7742ec3e74701df6d7944b29f2a86f87a571e7c29cdd82373fbc1264620fcf", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_dup_seconds_and_unit(self, cache):\n        to_datetime(self.dup_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "115495d011e90c1e84334a047f0989bfb9edee09d9a3180f0c98d9d55a4f5d9e", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates(self, cache):\n        to_datetime(self.dup_string_dates, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "98daac9ccb43e22cad7edf108a8f9ef3f7dfbf2eb8deb23ea7df594845b8af4c", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_dates_and_format": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates_and_format(self, cache):\n        to_datetime(self.dup_string_dates, format=\"%Y-%m-%d\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_dates_and_format", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee70077e5420259875c0f2299f011187d7baaef6f1cdeb4826b8ef8b1552dbce", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_tzoffset_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_tzoffset_dates(self, cache):\n        to_datetime(self.dup_string_with_tz, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_tzoffset_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9e31f01ac2515ecaf953530ced77a145692dd110a116641738e36e284fe36dd6", "warmup_time": -1}, "inference.ToDatetimeCache.time_unique_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_unique_seconds_and_unit(self, cache):\n        to_datetime(self.unique_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_unique_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0cd72e287b8884f32a7696a5bae419aa06c002232f3f3e5644000bec0a231d7c", "warmup_time": -1}, "inference.ToDatetimeCacheSmallCount.time_unique_date_strings": {"code": "class ToDatetimeCacheSmallCount:\n    def time_unique_date_strings(self, cache, count):\n        to_datetime(self.unique_date_strings, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCacheSmallCount:\n    def setup(self, cache, count):\n        rng = date_range(start=\"1/1/1971\", periods=count)\n        self.unique_date_strings = rng.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "inference.ToDatetimeCacheSmallCount.time_unique_date_strings", "number": 0, "param_names": ["cache", "count"], "params": [["True", "False"], ["50", "500", "5000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a56323da170a0fe1ab82a8aa298f38bf720a11efd9c5e53816e754fbfa0d2c10", "warmup_time": -1}, "inference.ToDatetimeFormat.time_different_offset_to_utc": {"code": "class ToDatetimeFormat:\n    def time_different_offset_to_utc(self):\n        to_datetime(self.diff_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_different_offset_to_utc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1134fb9d2267ce314aafafd3994e3faf459b0ffb6f88a729c01ab4ea6bb44302", "warmup_time": -1}, "inference.ToDatetimeFormat.time_exact": {"code": "class ToDatetimeFormat:\n    def time_exact(self):\n        to_datetime(self.s2, format=\"%d%b%y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_exact", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "76d9d38bf86802c26b9548453bc209c70d50d02a2d30f7ae0469155f0576cb0a", "warmup_time": -1}, "inference.ToDatetimeFormat.time_no_exact": {"code": "class ToDatetimeFormat:\n    def time_no_exact(self):\n        to_datetime(self.s, format=\"%d%b%y\", exact=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_no_exact", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1cbd72079d4edb0010f0b4016b0fd8ef613e37fb9f6c47a4de28327121902b19", "warmup_time": -1}, "inference.ToDatetimeFormat.time_same_offset": {"code": "class ToDatetimeFormat:\n    def time_same_offset(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_same_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "081651f9c7ef04560ccff0b7e01f00e729a8f50007024b8be6ae5df6d8252682", "warmup_time": -1}, "inference.ToDatetimeFormat.time_same_offset_to_utc": {"code": "class ToDatetimeFormat:\n    def time_same_offset_to_utc(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_same_offset_to_utc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "19b041862541f6a61d1616096316f0f2de3452b56a3bf5c720c671b4f0bad85f", "warmup_time": -1}, "inference.ToDatetimeFormatQuarters.time_infer_quarter": {"code": "class ToDatetimeFormatQuarters:\n    def time_infer_quarter(self):\n        to_datetime(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormatQuarters:\n    def setup(self):\n        self.s = Series([\"2Q2005\", \"2Q05\", \"2005Q1\", \"05Q1\"] * 10000)", "min_run_count": 2, "name": "inference.ToDatetimeFormatQuarters.time_infer_quarter", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "87bb6a74eb91c588ca3c6a25551ece61b8b7585eb61f04410973d650e0964120", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_float64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_float64(self):\n        to_datetime(self.ts_nanosec_float, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2a6fbb3b51b828848e8d7f73b076d8fae1161c6e4d53f48a8c4524fb4bd1820e", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_int64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_int64(self):\n        to_datetime(self.ts_nanosec, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8970f8a6a15aef3813dcea5bb9bf3a7c39853f92d88c59907ac2830fd16daef2", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_uint64(self):\n        to_datetime(self.ts_nanosec_uint, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "55b37560ce70ea683ab6134ede09ee43de470162b68416ec0ef8b0f469e90e97", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_float64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_float64(self):\n        to_datetime(self.ts_sec_float, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "412960192629b47bdb51536bd1acc465c6644d94331ec0b060809f15f2270d21", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_int64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_int64(self):\n        to_datetime(self.ts_sec, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "723bef42790ad2535ae6772086a189690bbc81c0dc720a9ae78f79b14541e1ed", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_uint64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_uint64(self):\n        to_datetime(self.ts_sec_uint, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ca17f492874efa6d87297d7a5eb649d9b0235ba934649a093f70ea48bc399454", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601": {"code": "class ToDatetimeISO8601:\n    def time_iso8601(self):\n        to_datetime(self.strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c01e071dec3afc28fb8a6bcd6b0d157e5a0fb6281c3ae6da7ee509aa2dfe980a", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_format": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format(self):\n        to_datetime(self.strings, format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_format", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bed05451c81f560e10f4add4bbd244599ac8758951990f8804a6c0e8ecde2f59", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_format_no_sep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format_no_sep(self):\n        to_datetime(self.strings_nosep, format=\"%Y%m%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_format_no_sep", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "97f94b8084cbb68f27ace40b4638b64544d81de4239a98b0ea7a5171624c9547", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_infer_zero_tz_fromat(self):\n        # GH 41047\n        to_datetime(self.strings_zero_tz)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "09c70549ea4de0f71bbbc97d084cd8ba946f2497635d0d05907a074e9e1c6c33", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_nosep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_nosep(self):\n        to_datetime(self.strings_nosep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_nosep", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "30412f207bfd54b6590f2cdb46e9d487f1c49b618946150f4befc00b60adfa74", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_tz_spaceformat(self):\n        to_datetime(self.strings_tz_space)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4c99d43165a9bb12c372d05ec434c5809826524a4733adfa440a3308cc4d8325", "warmup_time": -1}, "inference.ToDatetimeNONISO8601.time_different_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset, utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "inference.ToDatetimeNONISO8601.time_different_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c4d2dac26604bd44f4fbe5d20e10cfe4e33ee4e0caf00f554cd8ac8bd0b01544", "warmup_time": -1}, "inference.ToDatetimeNONISO8601.time_same_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_same_offset(self):\n        to_datetime(self.same_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "inference.ToDatetimeNONISO8601.time_same_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f4cfe5cc89ed121e911be978f375ccb3976e7f6b8bc0e40ffd649e75abf676dc", "warmup_time": -1}, "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD": {"code": "class ToDatetimeYYYYMMDD:\n    def time_format_YYYYMMDD(self):\n        to_datetime(self.stringsD, format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeYYYYMMDD:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=10000, freq=\"D\")\n        self.stringsD = Series(rng.strftime(\"%Y%m%d\"))", "min_run_count": 2, "name": "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1231af2c8acd673f7622a4a5cda34d3f69371a14c6d712e970653093e409349a", "warmup_time": -1}, "inference.ToNumeric.time_from_float": {"code": "class ToNumeric:\n    def time_from_float(self):\n        to_numeric(self.float, errors=\"coerce\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_float", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9d75d9dac86525757a5986d2c2dee84dba189d19de4e669b52b14d80836074ed", "warmup_time": -1}, "inference.ToNumeric.time_from_numeric_str": {"code": "class ToNumeric:\n    def time_from_numeric_str(self):\n        to_numeric(self.numstr, errors=\"coerce\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_numeric_str", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b0102b1d044bac37afcd31c72237a09f674c1507572f573689182f5a8741c57a", "warmup_time": -1}, "inference.ToNumeric.time_from_str": {"code": "class ToNumeric:\n    def time_from_str(self):\n        to_numeric(self.str, errors=\"coerce\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_str", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "94e2154cf6f33f78190c75601c38cc6b42e2c4147b864e5142b57a9b140c7165", "warmup_time": -1}, "inference.ToNumericDowncast.time_downcast": {"code": "class ToNumericDowncast:\n    def time_downcast(self, dtype, downcast):\n        to_numeric(self.data, downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumericDowncast:\n    def setup(self, dtype, downcast):\n        self.data = self.data_dict[dtype]", "min_run_count": 2, "name": "inference.ToNumericDowncast.time_downcast", "number": 0, "param_names": ["dtype", "downcast"], "params": [["'string-float'", "'string-int'", "'string-nint'", "'datetime64'", "'int-list'", "'int32'"], ["None", "'integer'", "'signed'", "'unsigned'", "'float'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0c056f48d7870e4188d6e5d83b2fae5d416f447632d4ee4e9e8c1ccec4b933bc", "warmup_time": -1}, "inference.ToTimedelta.time_convert_int": {"code": "class ToTimedelta:\n    def time_convert_int(self):\n        to_timedelta(self.ints, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e3d32b170c7865f14153be4d1dfe4cedbbfa407716af9b931a20cbf2be09aa76", "warmup_time": -1}, "inference.ToTimedelta.time_convert_string_days": {"code": "class ToTimedelta:\n    def time_convert_string_days(self):\n        to_timedelta(self.str_days)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_string_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b10b9c32557f6894a8d5cdad6099b33d92453d78580ed6ac9bce54eeda6ac731", "warmup_time": -1}, "inference.ToTimedelta.time_convert_string_seconds": {"code": "class ToTimedelta:\n    def time_convert_string_seconds(self):\n        to_timedelta(self.str_seconds)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_string_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ab0555d598557f0386f6743a49658aed686a61742a1a10086b99506a9dc533ba", "warmup_time": -1}, "inference.ToTimedeltaErrors.time_convert": {"code": "class ToTimedeltaErrors:\n    def time_convert(self):\n        to_timedelta(self.arr, errors=\"coerce\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedeltaErrors:\n    def setup(self):\n        ints = np.random.randint(0, 60, size=10000)\n        self.arr = [f\"{i} days\" for i in ints]\n        self.arr[-1] = \"apple\"", "min_run_count": 2, "name": "inference.ToTimedeltaErrors.time_convert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8939aa39071f3beefd6e45525ee345620bdf5dee832181f748ff4078ed239fe1", "warmup_time": -1}, "io.csv.ParseDateComparison.time_read_csv_dayfirst": {"code": "class ParseDateComparison:\n    def time_read_csv_dayfirst(self, cache_dates):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                sep=\",\",\n                header=None,\n                names=[\"Date\"],\n                parse_dates=[\"Date\"],\n                cache_dates=cache_dates,\n                dayfirst=True,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_read_csv_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b531fbcabfa9f50a40159c707fc3c7f6e7b08d581c7b1d7a345041defb16e66f", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_dayfirst": {"code": "class ParseDateComparison:\n    def time_to_datetime_dayfirst(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "50d96a36fe567c997d3c1a6fbd696fe9705f2ea698a08554aa84d41cd77fcd4d", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY": {"code": "class ParseDateComparison:\n    def time_to_datetime_format_DD_MM_YYYY(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, format=\"%d-%m-%Y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "22583c40b98481bf789be587a51186ee7ff145dc4fb7e8e302872d06333449c9", "warmup_time": -1}, "io.csv.ReadCSVCParserLowMemory.peakmem_over_2gb_input": {"code": "class ReadCSVCParserLowMemory:\n    def peakmem_over_2gb_input(self):\n        read_csv(self.csv, engine=\"c\", low_memory=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCParserLowMemory:\n    def setup(self):\n        self.csv = StringIO(\n            \"strings\\n\" + \"\\n\".join([\"x\" * (1 << 20) for _ in range(2100)])\n        )", "name": "io.csv.ReadCSVCParserLowMemory.peakmem_over_2gb_input", "param_names": [], "params": [], "type": "peakmemory", "unit": "bytes", "version": "a48446a53498bc61ad769b708252358aea4b14b242699d3724820c38150f87ab"}, "io.csv.ReadCSVCachedParseDates.time_read_csv_cached": {"code": "class ReadCSVCachedParseDates:\n    def time_read_csv_cached(self, do_cache, engine):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                engine=engine,\n                header=None,\n                parse_dates=[0],\n                cache_dates=do_cache,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCachedParseDates:\n    def setup(self, do_cache, engine):\n        data = (\"\\n\".join([f\"10/{year}\" for year in range(2000, 2100)]) + \"\\n\") * 10\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVCachedParseDates.time_read_csv_cached", "number": 0, "param_names": ["do_cache", "engine"], "params": [["True", "False"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bd18017d7e35c75b5b8e7641eba13970add0683431db08d765c8d0c218e4a37d", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_direct": {"code": "class ReadCSVCategorical:\n    def time_convert_direct(self, engine):\n        read_csv(self.fname, engine=engine, dtype=\"category\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_direct", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b2e9577b100c6272d45c9326e6ae5cc423be2a61cded554dcded5c3f443ab3d3", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_post": {"code": "class ReadCSVCategorical:\n    def time_convert_post(self, engine):\n        read_csv(self.fname, engine=engine).apply(Categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_post", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b7f42a0fff0e3f819147a800861b2f3c3bfe6ed2893ab8f978bbc88396a2df45", "warmup_time": -1}, "io.csv.ReadCSVComment.time_comment": {"code": "class ReadCSVComment:\n    def time_comment(self, engine):\n        read_csv(\n            self.data(self.StringIO_input), comment=\"#\", header=None, names=list(\"abc\")\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVComment:\n    def setup(self, engine):\n        data = [\"A,B,C\"] + ([\"1,2,3 # comment\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))", "min_run_count": 2, "name": "io.csv.ReadCSVComment.time_comment", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a90bbb38eb91ba9eeed032776bd52d7fd80b20ac0f6bc97853a821d08e98cf4b", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetime.time_read_csv": {"code": "class ReadCSVConcatDatetime:\n    def time_read_csv(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=50000, freq=\"s\")\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(self.iso8601).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetime.time_read_csv", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e9dddefec004c49888fad8124ac5f7f21e37497376bb8d3366b4c79d8aadebb6", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv": {"code": "class ReadCSVConcatDatetimeBadDateValue:\n    def time_read_csv(self, bad_date_value):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\", \"bar\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetimeBadDateValue:\n    def setup(self, bad_date_value):\n        self.StringIO_input = StringIO((f\"{bad_date_value},\\n\") * 50000)", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv", "number": 0, "param_names": ["bad_date_value"], "params": [["'nan'", "'0'", "''"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bbf5c349092a736709a8ab77f99aac07e8537b14babc5371d15b985c262ba233", "warmup_time": -1}, "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv": {"code": "class ReadCSVDInferDatetimeFormat:\n    def time_read_csv(self, format):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDInferDatetimeFormat:\n    def setup(self, format):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        formats = {\n            None: None,\n            \"custom\": \"%m/%d/%Y %H:%M:%S.%f\",\n            \"iso8601\": \"%Y-%m-%d %H:%M:%S\",\n            \"ymd\": \"%Y%m%d\",\n        }\n        dt_format = formats[format]\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(dt_format).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv", "number": 0, "param_names": ["format"], "params": [["None", "'custom'", "'iso8601'", "'ymd'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "24fbc7cd7577a0d332b069a46fd6569ee2f6763c413b3881ae61d2f2076a8a2e", "warmup_time": -1}, "io.csv.ReadCSVDatePyarrowEngine.time_read_csv_index_col": {"code": "class ReadCSVDatePyarrowEngine:\n    def time_read_csv_index_col(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            parse_dates=[\"a\"],\n            engine=\"pyarrow\",\n            dtype_backend=\"pyarrow\",\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDatePyarrowEngine:\n    def setup(self):\n        count_elem = 100_000\n        data = \"a\\n\" + \"2019-12-31\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVDatePyarrowEngine.time_read_csv_index_col", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ab535d209bd4b1a968a990f24391747a6fe7684b99cbd8d3ed50c2ca9869b133", "warmup_time": -1}, "io.csv.ReadCSVEngine.peakmem_read_csv": {"code": "class ReadCSVEngine:\n    def peakmem_read_csv(self, engine):\n        read_csv(self.data(self.BytesIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))", "name": "io.csv.ReadCSVEngine.peakmem_read_csv", "param_names": ["engine"], "params": [["'c'", "'python'", "'pyarrow'"]], "type": "peakmemory", "unit": "bytes", "version": "85d9dcbcd51f8538733f7a37f3f653c6eafe85a442cd76faccd8832554af70c6"}, "io.csv.ReadCSVEngine.time_read_bytescsv": {"code": "class ReadCSVEngine:\n    def time_read_bytescsv(self, engine):\n        read_csv(self.data(self.BytesIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))", "min_run_count": 2, "name": "io.csv.ReadCSVEngine.time_read_bytescsv", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c55db1629ca6d2b9c2cc35edb1684bf28f0a642354365378b739990b2beb3b36", "warmup_time": -1}, "io.csv.ReadCSVEngine.time_read_stringcsv": {"code": "class ReadCSVEngine:\n    def time_read_stringcsv(self, engine):\n        read_csv(self.data(self.StringIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))", "min_run_count": 2, "name": "io.csv.ReadCSVEngine.time_read_stringcsv", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bcd2541e7d01564732b9ee7d1a6eb25bc0640eba5345d2109c242f2887344d0b", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            names=list(\"abc\"),\n            float_precision=float_precision,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}{{}}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "663280822afc0347b49d14d5e3295794e4e85cd460cf06e6afe197b7a034a74d", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv_python_engine(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            engine=\"python\",\n            float_precision=None,\n            names=list(\"abc\"),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}{{}}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8904e1f9bcabd952d3ac2b41f754258e2e24205b0106b3bde4ba9fe99d668d64", "warmup_time": -1}, "io.csv.ReadCSVIndexCol.time_read_csv_index_col": {"code": "class ReadCSVIndexCol:\n    def time_read_csv_index_col(self):\n        read_csv(self.data(self.StringIO_input), index_col=\"a\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVIndexCol:\n    def setup(self):\n        count_elem = 100_000\n        data = \"a,b\\n\" + \"1,2\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVIndexCol.time_read_csv_index_col", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3e032e9f81b1221965b2e243ded96c0c63c65763cd3a0f1cd55e498a0728243e", "warmup_time": -1}, "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8": {"code": "class ReadCSVMemMapUTF8:\n    def time_read_memmapped_utf8(self):\n        read_csv(self.fname, header=None, memory_map=True, encoding=\"utf-8\", engine=\"c\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemMapUTF8:\n    def setup(self):\n        lines = []\n        line_length = 128\n        start_char = \" \"\n        end_char = \"\\U00010080\"\n        # This for loop creates a list of 128-char strings\n        # consisting of consecutive Unicode chars\n        for lnum in range(ord(start_char), ord(end_char), line_length):\n            line = \"\".join([chr(c) for c in range(lnum, lnum + 0x80)]) + \"\\n\"\n            try:\n                line.encode(\"utf-8\")\n            except UnicodeEncodeError:\n                # Some 16-bit words are not valid Unicode chars and must be skipped\n                continue\n            lines.append(line)\n        df = DataFrame(lines)\n        df = concat([df for n in range(100)], ignore_index=True)\n        df.to_csv(self.fname, index=False, header=False, encoding=\"utf-8\")", "min_run_count": 2, "name": "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8", "number": 5, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "28f7fd520f718e3d43c75304bfe758d8db2e0e48f9ecbcc93c96af3d09bb34c5", "warmup_time": -1}, "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks": {"code": "class ReadCSVMemoryGrowth:\n    def mem_parser_chunks(self, engine):\n        # see gh-24805.\n        result = read_csv(self.fname, chunksize=self.chunksize, engine=engine)\n    \n        for _ in result:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemoryGrowth:\n    def setup(self, engine):\n        with open(self.fname, \"w\", encoding=\"utf-8\") as f:\n            for i in range(self.num_rows):\n                f.write(f\"{i}\\n\")", "name": "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks", "param_names": ["engine"], "params": [["'c'", "'python'"]], "type": "memory", "unit": "bytes", "version": "387998c7983127f8fd0c8355a485887a7bbb6b50be4b44fb222cf04d96bd4298"}, "io.csv.ReadCSVParseDates.time_baseline": {"code": "class ReadCSVParseDates:\n    def time_baseline(self, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            parse_dates=[1],\n            names=list(string.digits[:9]),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self, engine):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_baseline", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "221a4700fd1f02faac09f891ec2ff4bf841f4f8838d4912b40bd070ce1747d0d", "warmup_time": -1}, "io.csv.ReadCSVParseSpecialDate.time_read_special_date": {"code": "class ReadCSVParseSpecialDate:\n    def time_read_special_date(self, value, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            names=[\"Date\"],\n            parse_dates=[\"Date\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseSpecialDate:\n    def setup(self, value, engine):\n        count_elem = 10000\n        data = self.objects[value] * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseSpecialDate.time_read_special_date", "number": 0, "param_names": ["value", "engine"], "params": [["'mY'", "'mdY'", "'hm'"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4adfa495cb5b837ceef161540601f8b0378f4433acbcd79ec36d1936f32b0276", "warmup_time": -1}, "io.csv.ReadCSVSkipRows.time_skipprows": {"code": "class ReadCSVSkipRows:\n    def time_skipprows(self, skiprows, engine):\n        read_csv(self.fname, skiprows=skiprows, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVSkipRows:\n    def setup(self, skiprows, engine):\n        N = 20000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        df = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        df.to_csv(self.fname)", "min_run_count": 2, "name": "io.csv.ReadCSVSkipRows.time_skipprows", "number": 0, "param_names": ["skiprows", "engine"], "params": [["None", "10000"], ["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fbe9957f14169d7708d3647b72449031d3ce2d6804cdb3dd942f15ce72a7fb63", "warmup_time": -1}, "io.csv.ReadCSVThousands.time_thousands": {"code": "class ReadCSVThousands:\n    def time_thousands(self, sep, thousands, engine):\n        read_csv(self.fname, sep=sep, thousands=thousands, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVThousands:\n    def setup(self, sep, thousands, engine):\n        N = 10000\n        K = 8\n        data = np.random.randn(N, K) * np.random.randint(100, 10000, (N, K))\n        df = DataFrame(data)\n        if thousands is not None:\n            fmt = f\":{thousands}\"\n            fmt = \"{\" + fmt + \"}\"\n            df = df.map(lambda x: fmt.format(x))\n        df.to_csv(self.fname, sep=sep)", "min_run_count": 2, "name": "io.csv.ReadCSVThousands.time_thousands", "number": 0, "param_names": ["sep", "thousands", "engine"], "params": [["','", "'|'"], ["None", "','"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "28174298e72aa540f2c967d0ae4c27033f3635114bea61298cf59ac2e8364ef5", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64": {"code": "class ReadUint64Integers:\n    def time_read_uint64(self):\n        read_csv(self.data(self.data1), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d4d93b300cdd080ede9b4b6103d9f29b7d9a87955c39dab1b41661f3b1836158", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_na_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_na_values(self):\n        read_csv(\n            self.data(self.data1), header=None, names=[\"foo\"], na_values=self.na_values\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_na_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "36be6bf3e25ad59106e12794881da1b2cb92dfed243163b4c6802ee873fff567", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_neg_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_neg_values(self):\n        read_csv(self.data(self.data2), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_neg_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2ff84e494ccdcd98ac1f99314c9865a5af568a2a806ace6dd69261d3ff23bd17", "warmup_time": -1}, "io.csv.ToCSV.time_frame": {"code": "class ToCSV:\n    def time_frame(self, kind):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSV:\n    def setup(self, kind):\n        wide_frame = DataFrame(np.random.randn(3000, 30))\n        long_frame = DataFrame(\n            {\n                \"A\": np.arange(50000),\n                \"B\": np.arange(50000) + 1.0,\n                \"C\": np.arange(50000) + 2.0,\n                \"D\": np.arange(50000) + 3.0,\n            }\n        )\n        mixed_frame = DataFrame(\n            {\n                \"float\": np.random.randn(5000),\n                \"int\": np.random.randn(5000).astype(int),\n                \"bool\": (np.arange(5000) % 2) == 0,\n                \"datetime\": date_range(\"2001\", freq=\"s\", periods=5000),\n                \"object\": [\"foo\"] * 5000,\n            }\n        )\n        mixed_frame.loc[30:500, \"float\"] = np.nan\n        data = {\"wide\": wide_frame, \"long\": long_frame, \"mixed\": mixed_frame}\n        self.df = data[kind]", "min_run_count": 2, "name": "io.csv.ToCSV.time_frame", "number": 0, "param_names": ["kind"], "params": [["'wide'", "'long'", "'mixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b207acadf1f9b5992775d04050e8e1c95f5b672a69adc5ea1bb47fac8c558b49", "warmup_time": -1}, "io.csv.ToCSVDatetime.time_frame_date_formatting": {"code": "class ToCSVDatetime:\n    def time_frame_date_formatting(self):\n        self.data.to_csv(self.fname, date_format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        self.data = DataFrame(rng, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetime.time_frame_date_formatting", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "48aec9f413466587de05eec973105aa3ca66fba9830fc6165228f306cfa384d0", "warmup_time": -1}, "io.csv.ToCSVDatetimeBig.time_frame": {"code": "class ToCSVDatetimeBig:\n    def time_frame(self, nobs):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeBig:\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeBig.time_frame", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "fa395b3a3f41934aecbec3ec06ce6f479c37e6f98c7e1bae1bc958330e6dcfdb", "warmup_time": -1}, "io.csv.ToCSVDatetimeIndex.time_frame_date_formatting_index": {"code": "class ToCSVDatetimeIndex:\n    def time_frame_date_formatting_index(self):\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeIndex:\n    def setup(self):\n        rng = date_range(\"2000\", periods=100_000, freq=\"s\")\n        self.data = DataFrame({\"a\": 1}, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeIndex.time_frame_date_formatting_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "be53e0ea21b907c9caf3497a41461ca870f2b3189772b5c4ed6008a199faff36", "warmup_time": -1}, "io.csv.ToCSVDatetimeIndex.time_frame_date_no_format_index": {"code": "class ToCSVDatetimeIndex:\n    def time_frame_date_no_format_index(self):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeIndex:\n    def setup(self):\n        rng = date_range(\"2000\", periods=100_000, freq=\"s\")\n        self.data = DataFrame({\"a\": 1}, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeIndex.time_frame_date_no_format_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a29d8f3cec0c25a7cbfc00d1da20a757fd4c53994cb8622eb1ebfd0e0cb2d5ba", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_head_of_multiindex": {"code": "class ToCSVIndexes:\n    def time_head_of_multiindex(self):\n        self.df_custom_index_then_head.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_head_of_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b19bd98ca4e016f0e4a61cb075ab765fe428f49a7a406dd786bf37617833558c", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_multiindex": {"code": "class ToCSVIndexes:\n    def time_multiindex(self):\n        self.df_head_then_custom_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e6c356ab53559b97134b83598c7406d7849f7d72f0cd33999f3ed3a1388ae70b", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_standard_index": {"code": "class ToCSVIndexes:\n    def time_standard_index(self):\n        self.df_standard_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_standard_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4d8e112a392acdd1a4bdd4008abb8a96e5e23ac65da30366feda0363459f118b", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_full_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_full_frame(self):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_full_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "724d348ca5334e593a849378524d8ed762f78bff3cdf32b12389521b5d4296d6", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_single_index_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_single_index_frame(self):\n        self.df_single_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_single_index_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fddcb69899294d5fe6894ce1add6d4d9dd6b6c889218886482b796f7df3f0718", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_sliced_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_sliced_frame(self):\n        self.df_unused_levels.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_sliced_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c52b3c8ffc9d375d7d7fe89c76149484b884cdab2db3b786aa976b2a571dc669", "warmup_time": -1}, "io.csv.ToCSVPeriod.time_frame_period_formatting": {"code": "class ToCSVPeriod:\n    def time_frame_period_formatting(self, nobs, freq):\n        # Nb: `date_format` is not actually taken into account here today, so the\n        # performance is currently identical to `time_frame_period_formatting_default`\n        # above. This timer is therefore expected to degrade when GH#51621 is fixed.\n        # (Remove this comment when GH#51621 is fixed.)\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d___%H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriod.time_frame_period_formatting", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5170753217ef6733879fd3238ebf2cc66780345d552f0cd80797bc50fbfa8f9a", "warmup_time": -1}, "io.csv.ToCSVPeriod.time_frame_period_formatting_default": {"code": "class ToCSVPeriod:\n    def time_frame_period_formatting_default(self, nobs, freq):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriod.time_frame_period_formatting_default", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "97fe0df229e93c48eb91efabbb13c673ea37727315d159564845c312e2b6d0bb", "warmup_time": -1}, "io.csv.ToCSVPeriod.time_frame_period_formatting_default_explicit": {"code": "class ToCSVPeriod:\n    def time_frame_period_formatting_default_explicit(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=self.default_fmt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriod.time_frame_period_formatting_default_explicit", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "70a4e40c81c34918091a014201d45867a489c6949e7de705876a37f9a70981f7", "warmup_time": -1}, "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index": {"code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d___%H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0331c31f8b48949b743fcd0aaae50203e37d79f16702b6c3e627c8c8f72d4a7d", "warmup_time": -1}, "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default": {"code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index_default(self, nobs, freq):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "deb79b68a5a3d0c5dee09ca8f3e00032d4cdbe53e595d7a4633bae09e0998e4e", "warmup_time": -1}, "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default_explicit": {"code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index_default_explicit(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=self.default_fmt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default_explicit", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "438b06aa750f7ccc6158ee25ad424220362457cc9ea8d2413071ae2a3570c671", "warmup_time": -1}, "io.excel.ReadExcel.time_read_excel": {"code": "class ReadExcel:\n    def time_read_excel(self, engine):\n        if engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()", "min_run_count": 2, "name": "io.excel.ReadExcel.time_read_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'odf'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "io.excel:85", "type": "time", "unit": "seconds", "version": "5b4c727b29b6c7a2c1a6679ecdebdf57f4082a33d80b1b263e51a694d738c7f8", "warmup_time": -1}, "io.excel.ReadExcelNRows.time_read_excel": {"code": "class ReadExcelNRows:\n    def time_read_excel(self, engine):\n        if engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine, nrows=10)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()", "min_run_count": 2, "name": "io.excel.ReadExcelNRows.time_read_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'odf'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "io.excel:85", "type": "time", "unit": "seconds", "version": "3e5f8dfb13ec7132e6defe6d8e37342d4d227165982cfc87986a70725225b237", "warmup_time": -1}, "io.excel.WriteExcel.time_write_excel": {"code": "class WriteExcel:\n    def time_write_excel(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        with ExcelWriter(bio, engine=engine) as writer:\n            self.df.to_excel(writer, sheet_name=\"Sheet1\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcel:\n    def setup(self, engine):\n        self.df = _generate_dataframe()", "min_run_count": 2, "name": "io.excel.WriteExcel.time_write_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'xlsxwriter'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7578b2403493bd3778db1aadd2c8d24328372b68145f847a4e479265ddccd155", "warmup_time": -1}, "io.excel.WriteExcelStyled.time_write_excel_style": {"code": "class WriteExcelStyled:\n    def time_write_excel_style(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        with ExcelWriter(bio, engine=engine) as writer:\n            df_style = self.df.style\n            df_style.map(lambda x: \"border: red 1px solid;\")\n            df_style.map(lambda x: \"color: blue\")\n            df_style.map(lambda x: \"border-color: green black\", subset=[\"float1\"])\n            df_style.to_excel(writer, sheet_name=\"Sheet1\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcelStyled:\n    def setup(self, engine):\n        self.df = _generate_dataframe()", "min_run_count": 2, "name": "io.excel.WriteExcelStyled.time_write_excel_style", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'xlsxwriter'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "35f39ed22d0a5c540ef5e9f7b05a346a1e0d747b934181b07307d760f10dca5c", "warmup_time": -1}, "io.hdf.HDF.peakmem_read_hdf": {"code": "class HDF:\n    def peakmem_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, key=\"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, key=\"df1\", format=format)", "name": "io.hdf.HDF.peakmem_read_hdf", "param_names": ["format"], "params": [["'table'", "'fixed'"]], "type": "peakmemory", "unit": "bytes", "version": "aaaba56d83f41d2e23cac92e27feaad11f59b9fa6d3f769aca477dde545c7932"}, "io.hdf.HDF.time_read_hdf": {"code": "class HDF:\n    def time_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, key=\"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, key=\"df1\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_read_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3e0703c9fab38fa828e5d37a9fb080d2e463bee144fc5317f25738e6bc003f7b", "warmup_time": -1}, "io.hdf.HDF.time_write_hdf": {"code": "class HDF:\n    def time_write_hdf(self, format):\n        self.df.to_hdf(self.fname, key=\"df\", format=format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, key=\"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, key=\"df1\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_write_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b081f5fb51c8d13a4691214bd0372806f6a9605fb3b5fbd69d0e571e8ae80444", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table(self):\n        self.store.select(\"table\", where=\"index > self.start and index < self.stop\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "40b2068f3fa64a0e6a20da79476d70035884e866d3b4994f9da2e7828cd555c2", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table_wide(self):\n        self.store.select(\n            \"table_wide\", where=\"index > self.start_wide and index < self.stop_wide\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "205842891832cc3189d2d8c107fb32a32951b545c2567df596beea6814ece721", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store": {"code": "class HDFStoreDataFrame:\n    def time_read_store(self):\n        self.store.get(\"fixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b81c7b37b744fb0fe641d2b6d817db00b609a32efd08df6d7d7071fdae8ba8a0", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_mixed(self):\n        self.store.get(\"fixed_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "80585e918467a2bc34f9d22dfec4aea16e3ca27199eb3eada198f0a8d01db954", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table(self):\n        self.store.select(\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a0b2d2c3b5db0383751a7133216ac82e5c8e2f2460d14a9743250eeca3476216", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_mixed(self):\n        self.store.select(\"table_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "654b809e344f0e10c8a3baac21f45bab7ad0ee525970e4f37cc667bf431c09a9", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_wide(self):\n        self.store.select(\"table_wide\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "68e77ec6a80f61239b61938e5edcde665dcb40aabeecd31c67093d3e89dc0224", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_info": {"code": "class HDFStoreDataFrame:\n    def time_store_info(self):\n        self.store.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_info", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "49715b28d77dba64c85fec14ce3fe1d467fb262c9f60bdb37036c71df679a8dc", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_repr": {"code": "class HDFStoreDataFrame:\n    def time_store_repr(self):\n        repr(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_repr", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "56bf271ad7094e3cd93786522fded365bab13a2eb8463232c31dd7d346f35024", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_str": {"code": "class HDFStoreDataFrame:\n    def time_store_str(self):\n        str(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_str", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d579449dfe09044c2900a1f5cbeaf78ea5bbedab0e10f8949912bc68b36591f0", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store": {"code": "class HDFStoreDataFrame:\n    def time_write_store(self):\n        self.store.put(\"fixed_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee8346e909168ac76078a6746c4bb841bbd325a8e9a633a593ba4e3be629591b", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_mixed(self):\n        self.store.put(\"fixed_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d9a86e316a21f2f06f6a5510d44c49901d77f3ff3e328dc05884b09657635842", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table(self):\n        self.store.append(\"table_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d47058fa561771efea619eea183eab7a6d5b7802df94c96d7e940bb000111118", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_dc": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_dc(self):\n        self.store.append(\"table_dc_write\", self.df_dc, data_columns=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_dc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3835d70e0f39619d661465373c95f90fdcb126a771138196ed2761ef7b7a8bcd", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_mixed(self):\n        self.store.append(\"table_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cfc399c3925c502380baf60452f942cc9fccdc9f9fe9a3d13c6bc9f9bc06b710", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_wide(self):\n        self.store.append(\"table_wide_write\", self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d4ab189fff466312714744b38e13c09f0a3eb767a53878d0309b322701e5ab04", "warmup_time": -1}, "io.json.NormalizeJSON.time_normalize_json": {"code": "class NormalizeJSON:\n    def time_normalize_json(self, orient, frame):\n        json_normalize(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NormalizeJSON:\n    def setup(self, orient, frame):\n        data = {\n            \"hello\": [\"thisisatest\", 999898, \"mixed types\"],\n            \"nest1\": {\"nest2\": {\"nest3\": \"nest3_value\", \"nest3_int\": 3445}},\n            \"nest1_list\": {\"nest2\": [\"blah\", 32423, 546456.876, 92030234]},\n            \"hello2\": \"string\",\n        }\n        self.data = [data for i in range(10000)]", "min_run_count": 2, "name": "io.json.NormalizeJSON.time_normalize_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "318fc7d7f7bff26fc7a49a190be4dc0e2690469149e9fda19e3a8074d89cde6c", "warmup_time": -1}, "io.json.ReadJSON.time_read_json": {"code": "class ReadJSON:\n    def time_read_json(self, orient, index):\n        read_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSON:\n    def setup(self, orient, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=orient)", "min_run_count": 2, "name": "io.json.ReadJSON.time_read_json", "number": 0, "param_names": ["orient", "index"], "params": [["'split'", "'index'", "'records'"], ["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "060ff02601813d99dcb85d35f2248cc6d5ee446b65bd53e44b8047fbff44c093", "warmup_time": -1}, "io.json.ReadJSONLines.peakmem_read_json_lines": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "type": "peakmemory", "unit": "bytes", "version": "453a39b717c84b10924b6c7381d2d4ac3ca4b6b34daf8038481adc4c63b37684"}, "io.json.ReadJSONLines.peakmem_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines_concat", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "type": "peakmemory", "unit": "bytes", "version": "8ae93d7aa059d6ca9dbd26187d6b3782176449620b47b2e321dd8f4d891393f3"}, "io.json.ReadJSONLines.peakmem_read_json_lines_nrows": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=15000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines_nrows", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "type": "peakmemory", "unit": "bytes", "version": "ac250f3377bcd575593ac2b371b4c45a47c3ba22cf6904c83289edccf77211ae"}, "io.json.ReadJSONLines.time_read_json_lines": {"code": "class ReadJSONLines:\n    def time_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "279f192d538915c094d4ea8ba8b0fd1ef396291dafe6751c31424148be445ad6", "warmup_time": -1}, "io.json.ReadJSONLines.time_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def time_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines_concat", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "777bcd588c46f7ee722bd31443ac6db78bd8e01de64a0d7e4a09b0f778b1319f", "warmup_time": -1}, "io.json.ReadJSONLines.time_read_json_lines_nrows": {"code": "class ReadJSONLines:\n    def time_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=25000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines_nrows", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7f3ac492e006023c74a0a50408cf85b315c2115bbd11ea92acc78c6cc2af2385", "warmup_time": -1}, "io.json.ToJSON.peakmem_to_json": {"code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "name": "io.json.ToJSON.peakmem_to_json", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "type": "peakmemory", "unit": "bytes", "version": "87eb3ebd846df1b3f04989da149647f27085e365975bb82ce1a093db9bac8f5b"}, "io.json.ToJSON.time_to_json": {"code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSON.time_to_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9c17efa9080b8d5102c0beaef576f498ed86d1fe6e4fba86df65a39335f72728", "warmup_time": -1}, "io.json.ToJSONISO.time_iso_format": {"code": "class ToJSONISO:\n    def time_iso_format(self, orient):\n        self.df.to_json(orient=orient, date_format=\"iso\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONISO:\n    def setup(self, orient):\n        N = 10**5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        self.df = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONISO.time_iso_format", "number": 0, "param_names": ["orient"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "de31091c8c9695232ad7a580672fe1150d42e0e74f06119dbe4a85b76c1e6c4a", "warmup_time": -1}, "io.json.ToJSONLines.time_delta_int_tstamp_lines": {"code": "class ToJSONLines:\n    def time_delta_int_tstamp_lines(self):\n        self.df_td_int_ts.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_delta_int_tstamp_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7a68f6c940cbfe5b7a9d9027dbcf1d2f2156232603726e0c67f7c89c756638fa", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_lines": {"code": "class ToJSONLines:\n    def time_float_int_lines(self):\n        self.df_int_floats.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e13146fb82a5dad2ab3bd80cf8af40ebd2cd8d8cbae32a4d4ec10a5dfe13d0ec", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_str_lines": {"code": "class ToJSONLines:\n    def time_float_int_str_lines(self):\n        self.df_int_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_str_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1517c8c4bbfff332b785506b826f50dcfad142f899a967b7afafdc636cd64789", "warmup_time": -1}, "io.json.ToJSONLines.time_float_longint_str_lines": {"code": "class ToJSONLines:\n    def time_float_longint_str_lines(self):\n        self.df_longint_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_longint_str_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5a0cc00815b32129927ef8c2875f9c5597779d59ef8b197ab9020ad5aea6df17", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_dt_index_lines": {"code": "class ToJSONLines:\n    def time_floats_with_dt_index_lines(self):\n        self.df_date_idx.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_dt_index_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2414d07086e041907667e8b1ba53fa8258be5e0ae02f44cba6c71675e8e82d90", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_int_idex_lines": {"code": "class ToJSONLines:\n    def time_floats_with_int_idex_lines(self):\n        self.df.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_int_idex_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1a872bf1a0dbe4c6dacf8368bd57159ad9f6e13729f234362d97480564486430", "warmup_time": -1}, "io.json.ToJSONMem.peakmem_float": {"code": "class ToJSONMem:\n    def peakmem_float(self, frames):\n        df = frames[\"float\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_float", "param_names": [], "params": [], "setup_cache_key": "io.json:289", "type": "peakmemory", "unit": "bytes", "version": "00ee9841b98283beeb453d7dfd4cd72008d10a2028768798140f0ad54c56b581"}, "io.json.ToJSONMem.peakmem_int": {"code": "class ToJSONMem:\n    def peakmem_int(self, frames):\n        df = frames[\"int\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_int", "param_names": [], "params": [], "setup_cache_key": "io.json:289", "type": "peakmemory", "unit": "bytes", "version": "a0f0fbfe022c1f66c3bb2fb28d8e1a6ecea8488a0a4252439e9a1cb94f397c3e"}, "io.json.ToJSONMem.peakmem_time": {"code": "class ToJSONMem:\n    def peakmem_time(self, frames):\n        df = frames[\"datetime\"]\n        for _ in range(10_000):\n            df.to_json(orient=\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_time", "param_names": [], "params": [], "setup_cache_key": "io.json:289", "type": "peakmemory", "unit": "bytes", "version": "2260dc5c098f332173c0b87ea1e18f2c50b70b762d04871af1f0c6186d9cfb2f"}, "io.json.ToJSONWide.peakmem_to_json": {"code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "name": "io.json.ToJSONWide.peakmem_to_json", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "type": "peakmemory", "unit": "bytes", "version": "f179e468594888d4ad11b82d624fc4c3925d4831054986c7642b6a7938e395d8"}, "io.json.ToJSONWide.peakmem_to_json_wide": {"code": "class ToJSONWide:\n    def peakmem_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "name": "io.json.ToJSONWide.peakmem_to_json_wide", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "type": "peakmemory", "unit": "bytes", "version": "350c040ee03cb09b3b2af80aacdb6f89f0b64fb12027e7abfcecf1754316da0d"}, "io.json.ToJSONWide.time_to_json": {"code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "min_run_count": 2, "name": "io.json.ToJSONWide.time_to_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3efe5275ae2f37aaa5320e63422ce5b375719e691728af347d4018c67aef213a", "warmup_time": -1}, "io.json.ToJSONWide.time_to_json_wide": {"code": "class ToJSONWide:\n    def time_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "min_run_count": 2, "name": "io.json.ToJSONWide.time_to_json_wide", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "aae5665173eb24e14595380fcf07cfeeab21783b5862479ee4e358e042ba6c38", "warmup_time": -1}, "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes": {"code": "class DoesStringLookLikeDatetime:\n    def time_check_datetimes(self, value):\n        for obj in self.objects:\n            _does_string_look_like_datetime(obj)\n\n    def setup(self, value):\n        self.objects = [value] * 1000000", "min_run_count": 2, "name": "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes", "number": 0, "param_names": ["value"], "params": [["'2Q2005'", "'0.0'", "'10000'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a023015f4dc4ff2fbfce3252f6fd4b6c28970e462a5e405f7c2febd9b2256de7", "warmup_time": -1}, "io.pickle.Pickle.peakmem_read_pickle": {"code": "class Pickle:\n    def peakmem_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)", "name": "io.pickle.Pickle.peakmem_read_pickle", "param_names": [], "params": [], "type": "peakmemory", "unit": "bytes", "version": "4f88c24f38210faf3621a5f3c8a3f69477ec21a24d2ddc6be2c8470c01aa40e3"}, "io.pickle.Pickle.peakmem_write_pickle": {"code": "class Pickle:\n    def peakmem_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)", "name": "io.pickle.Pickle.peakmem_write_pickle", "param_names": [], "params": [], "type": "peakmemory", "unit": "bytes", "version": "d6e455195b782b35e91ceac2d611911bb32493f8c4d4487fc4c4e31f0f4e0ceb"}, "io.pickle.Pickle.time_read_pickle": {"code": "class Pickle:\n    def time_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_read_pickle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b91906f3a4f0e0fc6d0e7c75087708710c17306f6261154037cce4d579f9a168", "warmup_time": -1}, "io.pickle.Pickle.time_write_pickle": {"code": "class Pickle:\n    def time_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_write_pickle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "197a465e7ef1ae675a5470d939c4e2ce2d4f98b1f7d774e82a579024a5626166", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat": {"code": "class SAS:\n    def time_read_sas7bdat(self):\n        read_sas(ROOT / \"test1.sas7bdat\")", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "90750b4b8570b3ae59cde41f15ee1b854b9ab5ce81313090b40ed33623373ac0", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat_2": {"code": "class SAS:\n    def time_read_sas7bdat_2(self):\n        next(read_sas(ROOT / \"0x00controlbyte.sas7bdat.bz2\", chunksize=11000))", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat_2", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6634a822c4810085a951c2a037c4c61eeb579b792626fe9e9258ee6c42746e28", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat_2_chunked": {"code": "class SAS:\n    def time_read_sas7bdat_2_chunked(self):\n        for i, _ in enumerate(\n            read_sas(ROOT / \"0x00controlbyte.sas7bdat.bz2\", chunksize=1000)\n        ):\n            if i == 10:\n                break", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat_2_chunked", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d10bf08f751bef710fda95bf4064e7efe3c337d520294711968c04867570b2e1", "warmup_time": -1}, "io.sas.SAS.time_read_xpt": {"code": "class SAS:\n    def time_read_xpt(self):\n        read_sas(ROOT / \"paxraw_d_short.xpt\")", "min_run_count": 2, "name": "io.sas.SAS.time_read_xpt", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e400235073dafa325dfdd6e6eda51419eff1337191b1178a5f5ab43af9d3bb9a", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_all": {"code": "class ReadSQLTable:\n    def time_read_sql_table_all(self):\n        read_sql_table(self.table_name, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_all", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8805189ad353a53259e1140e68baa586a0df8cd9d72c69b5a8cb9423e2338323", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_parse_dates": {"code": "class ReadSQLTable:\n    def time_read_sql_table_parse_dates(self):\n        read_sql_table(\n            self.table_name,\n            self.con,\n            columns=[\"datetime_string\"],\n            parse_dates=[\"datetime_string\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_parse_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "dd4c0ad3318162e5578f5184117e902602f575122eb690a13703523fafe2ebd4", "warmup_time": -1}, "io.sql.ReadSQLTableDtypes.time_read_sql_table_column": {"code": "class ReadSQLTableDtypes:\n    def time_read_sql_table_column(self, dtype):\n        read_sql_table(self.table_name, self.con, columns=[dtype])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTableDtypes:\n    def setup(self, dtype):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTableDtypes.time_read_sql_table_column", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3715243646c52bd93b31afb5ade91a7fb8659472bee04546210dcbfc423b0e34", "warmup_time": -1}, "io.sql.SQL.time_read_sql_query": {"code": "class SQL:\n    def time_read_sql_query(self, connection):\n        read_sql_query(self.query_all, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_read_sql_query", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6e9c468300eee3818a1fdb1388194e0442416d67fe7b467ea3551de7b486cec8", "warmup_time": -1}, "io.sql.SQL.time_to_sql_dataframe": {"code": "class SQL:\n    def time_to_sql_dataframe(self, connection):\n        self.df.to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_to_sql_dataframe", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e83de9885c2f942c647a56d72031c18606ffbee73b7ee38d1dc227d2b1f69cda", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_read_sql_query_select_column": {"code": "class WriteSQLDtypes:\n    def time_read_sql_query_select_column(self, connection, dtype):\n        read_sql_query(self.query_col, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_read_sql_query_select_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6a6d2a3f39d33e0506f5c087cd7c7a253eaacac063a5aa53e54f846897e5c243", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column": {"code": "class WriteSQLDtypes:\n    def time_to_sql_dataframe_column(self, connection, dtype):\n        self.df[[dtype]].to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1ef8f5f1c2e6e522fda7b7be0b4b74a02379fca208bdedc44c04133a3168ee4d", "warmup_time": -1}, "io.stata.Stata.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(self.N)], dtype=object)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "373dd72e429ef636629454da90e787c31ecff5cea8dd978c7f0a2d01b864b846", "warmup_time": -1}, "io.stata.Stata.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(self.N)], dtype=object)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fecc2ef1a45be678d915bdc0d91dfe1927166b223d0f0fb6ff194407d6cdeb18", "warmup_time": -1}, "io.stata.StataMissing.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b28404f018d5ce3e6f6e9f4f573bfc333203130ac26b6ad0a55ab363d4091d56", "warmup_time": -1}, "io.stata.StataMissing.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "12dd8e544d5d5dc0ff5c73373ffa7a2338cc235fc3829df79060f21c721b21c1", "warmup_time": -1}, "io.style.Render.peakmem_apply_format_hide_render": {"code": "class Render:\n    def peakmem_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_apply_format_hide_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "type": "peakmemory", "unit": "bytes", "version": "e60cd641e7276e782ea6f8cb9e79fe72d440e194edc99f56ce7355285abebda8"}, "io.style.Render.peakmem_apply_render": {"code": "class Render:\n    def peakmem_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_apply_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "type": "peakmemory", "unit": "bytes", "version": "d8e987bc198784acca05098b72e32f3828525879d751666a8c96839cc90fdb91"}, "io.style.Render.peakmem_classes_render": {"code": "class Render:\n    def peakmem_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_classes_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "type": "peakmemory", "unit": "bytes", "version": "bfa5f3ec26d4b069d8d7a5dd601bd5c31efd4ac1b8d820c64eea58b84d5bef2c"}, "io.style.Render.peakmem_format_render": {"code": "class Render:\n    def peakmem_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_format_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "type": "peakmemory", "unit": "bytes", "version": "7de58be51c40c9b9a4b9ead6fe0febd2fd965be97091c0975d3a81aa65db7a9a"}, "io.style.Render.peakmem_tooltips_render": {"code": "class Render:\n    def peakmem_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_tooltips_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "type": "peakmemory", "unit": "bytes", "version": "eed00f8f4762083fcf457ab05ac4675cb67055f639beef3675b4c59568431ff5"}, "io.style.Render.time_apply_format_hide_render": {"code": "class Render:\n    def time_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_apply_format_hide_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "aa58fd1e34e914254af81f08c5f248b6d9b182868a30e1523dd28e19c0980ea1", "warmup_time": -1}, "io.style.Render.time_apply_render": {"code": "class Render:\n    def time_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_apply_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "24e0e3280fc243c94907c7f372b5b9fa036c35bbefc27581c1049b384b031a73", "warmup_time": -1}, "io.style.Render.time_classes_render": {"code": "class Render:\n    def time_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_classes_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2e500c4d225f53d0cf58c3cc3538e87a87e5b8d102fa6da9283d4f7514e0b794", "warmup_time": -1}, "io.style.Render.time_format_render": {"code": "class Render:\n    def time_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_format_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e5eb35968f97219c6c14dad0735479a4052caa09196f6a8c3a4809034bcad5f3", "warmup_time": -1}, "io.style.Render.time_tooltips_render": {"code": "class Render:\n    def time_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i + 1}\" for i in range(cols)],\n            index=[f\"row_{i + 1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_tooltips_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f48a8961f8ea22f1738a314276c3d5889bd91362f000813a8be2062a8745270b", "warmup_time": -1}, "join_merge.Align.time_series_align_int64_index": {"code": "class Align:\n    def time_series_align_int64_index(self):\n        self.ts1 + self.ts2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_int64_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "59ba8b3aa681ebdec8f5b793e2c2d9f7edd0cc1306163877b74d2788ac7102c0", "warmup_time": -1}, "join_merge.Align.time_series_align_left_monotonic": {"code": "class Align:\n    def time_series_align_left_monotonic(self):\n        self.ts1.align(self.ts2, join=\"left\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_left_monotonic", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1c381483982c07fac3b6c437f2f740ae055cad4035d9a2bdf325a4acfe440e76", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_left": {"code": "class Concat:\n    def time_concat_empty_left(self, axis):\n        concat(self.empty_left, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_left", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c24f8d889c69b6fddab68477db7feb9bdd64d0bfc8a437af267480d6244476bc", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_right": {"code": "class Concat:\n    def time_concat_empty_right(self, axis):\n        concat(self.empty_right, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_right", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "50a67de8903652dc050970bc82dc1e728dd0803fb2d35b1eefd98d1b5771497b", "warmup_time": -1}, "join_merge.Concat.time_concat_mixed_ndims": {"code": "class Concat:\n    def time_concat_mixed_ndims(self, axis):\n        concat(self.mixed_ndims, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_mixed_ndims", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c9ed31fc560eb4af434e4a5f9c1c3f4661613c9c160b2335cbe6555ce327feac", "warmup_time": -1}, "join_merge.Concat.time_concat_series": {"code": "class Concat:\n    def time_concat_series(self, axis):\n        concat(self.series, axis=axis, sort=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_series", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bf170cabb255499f965da712f65e57cd5f3a050cf5c35d2069e104851dd6e5a0", "warmup_time": -1}, "join_merge.Concat.time_concat_small_frames": {"code": "class Concat:\n    def time_concat_small_frames(self, axis):\n        concat(self.small_frames, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_small_frames", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "470adfb2d6977cd7074d1f42533fea5a4d223b74619f161758021c6161815779", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_c_ordered": {"code": "class ConcatDataFrames:\n    def time_c_ordered(self, axis, ignore_index):\n        concat(self.frame_c, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_c_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a747cecacb0f57e2d282f77dbc9ba6108bb55d137dcb4cdef4d0cb94bd2ef909", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_f_ordered": {"code": "class ConcatDataFrames:\n    def time_f_ordered(self, axis, ignore_index):\n        concat(self.frame_f, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_f_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4ae3b6dda3a99cfd094de14c2550530e69a1ede87ff9911c02706ef1acf501eb", "warmup_time": -1}, "join_merge.ConcatIndexDtype.time_concat_series": {"code": "class ConcatIndexDtype:\n    def time_concat_series(self, dtype, structure, axis, sort):\n        concat(self.series, axis=axis, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatIndexDtype:\n    def setup(self, dtype, structure, axis, sort):\n        N = 10_000\n        if dtype == \"datetime64[ns]\":\n            vals = date_range(\"1970-01-01\", periods=N)\n        elif dtype in (\"int64\", \"Int64\", \"int64[pyarrow]\"):\n            vals = np.arange(N, dtype=np.int64)\n        elif dtype in (\"string[python]\", \"string[pyarrow]\"):\n            vals = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        else:\n            raise NotImplementedError\n    \n        idx = Index(vals, dtype=dtype)\n    \n        if structure == \"monotonic\":\n            idx = idx.sort_values()\n        elif structure == \"non_monotonic\":\n            idx = idx[::-1]\n        elif structure == \"has_na\":\n            if not idx._can_hold_na:\n                raise NotImplementedError\n            idx = Index([None], dtype=dtype).append(idx)\n        else:\n            raise NotImplementedError\n    \n        self.series = [Series(i, idx[:-i]) for i in range(1, 6)]", "min_run_count": 2, "name": "join_merge.ConcatIndexDtype.time_concat_series", "number": 0, "param_names": ["dtype", "structure", "axis", "sort"], "params": [["'datetime64[ns]'", "'int64'", "'Int64'", "'int64[pyarrow]'", "'string[python]'", "'string[pyarrow]'"], ["'monotonic'", "'non_monotonic'", "'has_na'"], ["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3f0be47c3aec82696fed8b66f103fb17e1c8ade9f27aed2205614c881c60a48a", "warmup_time": -1}, "join_merge.I8Merge.time_i8merge": {"code": "class I8Merge:\n    def time_i8merge(self, how):\n        merge(self.left, self.right, how=how)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass I8Merge:\n    def setup(self, how):\n        low, high, n = -1000, 1000, 10**6\n        self.left = DataFrame(\n            np.random.randint(low, high, (n, 7)), columns=list(\"ABCDEFG\")\n        )\n        self.left[\"left\"] = self.left.sum(axis=1)\n        self.right = self.left.sample(frac=1).rename({\"left\": \"right\"}, axis=1)\n        self.right = self.right.reset_index(drop=True)\n        self.right[\"right\"] *= -1", "min_run_count": 2, "name": "join_merge.I8Merge.time_i8merge", "number": 0, "param_names": ["how"], "params": [["'inner'", "'outer'", "'left'", "'right'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d4abb49d5f599a151d5e78dad2990f16fe5bf60710912a404da24856006a297a", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_multi": {"code": "class Join:\n    def time_join_dataframe_index_multi(self, sort):\n        self.df.join(self.df_multi, on=[\"key1\", \"key2\"], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_multi", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4333bf6cde7671e71926340c558300735ccf5294d204d4e0c4c81a51d019eb1c", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort": {"code": "class Join:\n    def time_join_dataframe_index_shuffle_key_bigger_sort(self, sort):\n        self.df_shuf.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c4db5e399d8b3f5fe10c825360367198fb61e0ea906c2842d56ec531c4cd5f97", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_bigger": {"code": "class Join:\n    def time_join_dataframe_index_single_key_bigger(self, sort):\n        self.df.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_bigger", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c91255828f8625e649458aaa81a177dd077c288fe7beb2a8349f154536f30000", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_small": {"code": "class Join:\n    def time_join_dataframe_index_single_key_small(self, sort):\n        self.df.join(self.df_key1, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_small", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "eec67ca32224c312bdba6f34b701b8fcea4192407ff25bca0a093889a2c86f01", "warmup_time": -1}, "join_merge.Join.time_join_dataframes_cross": {"code": "class Join:\n    def time_join_dataframes_cross(self, sort):\n        self.df.loc[:2000].join(self.df_key1, how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframes_cross", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3a48d807904c7c932eb0f8012602129fcf2c528ffbf8a19bb5af2fa0084b6b29", "warmup_time": -1}, "join_merge.JoinEmpty.time_inner_join_left_empty": {"code": "class JoinEmpty:\n    def time_inner_join_left_empty(self):\n        self.df_empty.join(self.df, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinEmpty:\n    def setup(self):\n        N = 100_000\n        self.df = DataFrame({\"A\": np.arange(N)})\n        self.df_empty = DataFrame(columns=[\"B\", \"C\"], dtype=\"int64\")", "min_run_count": 2, "name": "join_merge.JoinEmpty.time_inner_join_left_empty", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bfdd1b4564785774724d06a1078e1417803a55bc67f678a1cdd417a1aedc2f04", "warmup_time": -1}, "join_merge.JoinEmpty.time_inner_join_right_empty": {"code": "class JoinEmpty:\n    def time_inner_join_right_empty(self):\n        self.df.join(self.df_empty, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinEmpty:\n    def setup(self):\n        N = 100_000\n        self.df = DataFrame({\"A\": np.arange(N)})\n        self.df_empty = DataFrame(columns=[\"B\", \"C\"], dtype=\"int64\")", "min_run_count": 2, "name": "join_merge.JoinEmpty.time_inner_join_right_empty", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "dcfe17741af364f20337e68e1210e4775f3da625571f7a163b7a94dd7ba6ab00", "warmup_time": -1}, "join_merge.JoinIndex.time_left_outer_join_index": {"code": "class JoinIndex:\n    def time_left_outer_join_index(self):\n        self.left.join(self.right, on=\"jim\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinIndex:\n    def setup(self):\n        N = 5000\n        self.left = DataFrame(\n            np.random.randint(1, N / 50, (N, 2)), columns=[\"jim\", \"joe\"]\n        )\n        self.right = DataFrame(\n            np.random.randint(1, N / 50, (N, 2)), columns=[\"jolie\", \"jolia\"]\n        ).set_index(\"jolie\")", "min_run_count": 2, "name": "join_merge.JoinIndex.time_left_outer_join_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1745a459c7417d954ba2b1543c89580f2da4fae87754d704488eb8a230577907", "warmup_time": -1}, "join_merge.JoinMultiindexSubset.time_join_multiindex_subset": {"code": "class JoinMultiindexSubset:\n    def time_join_multiindex_subset(self):\n        self.left.join(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinMultiindexSubset:\n    def setup(self):\n        N = 100_000\n        mi1 = MultiIndex.from_arrays([np.arange(N)] * 4, names=[\"a\", \"b\", \"c\", \"d\"])\n        mi2 = MultiIndex.from_arrays([np.arange(N)] * 2, names=[\"a\", \"b\"])\n        self.left = DataFrame({\"col1\": 1}, index=mi1)\n        self.right = DataFrame({\"col2\": 2}, index=mi2)", "min_run_count": 2, "name": "join_merge.JoinMultiindexSubset.time_join_multiindex_subset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "27bf46b67e61ae20d7d34733a62c67fd8dd46b37dcd0a578e046d57b6c6a5751", "warmup_time": -1}, "join_merge.JoinNonUnique.time_join_non_unique_equal": {"code": "class JoinNonUnique:\n    def time_join_non_unique_equal(self):\n        self.fracofday * self.temp\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinNonUnique:\n    def setup(self):\n        date_index = date_range(\"01-Jan-2013\", \"23-Jan-2013\", freq=\"min\")\n        daily_dates = date_index.to_period(\"D\").to_timestamp(\"s\", \"s\")\n        self.fracofday = date_index.values - daily_dates.values\n        self.fracofday = self.fracofday.astype(\"timedelta64[ns]\")\n        self.fracofday = self.fracofday.astype(np.float64) / 86_400_000_000_000\n        self.fracofday = Series(self.fracofday, daily_dates)\n        index = date_range(date_index.min(), date_index.max(), freq=\"D\")\n        self.temp = Series(1.0, index)[self.fracofday.index]", "min_run_count": 2, "name": "join_merge.JoinNonUnique.time_join_non_unique_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0e34c149af187b7f4eaa9c905928f5605dabce492f1114f9878a83fcfa4be311", "warmup_time": -1}, "join_merge.Merge.time_merge_2intkey": {"code": "class Merge:\n    def time_merge_2intkey(self, sort):\n        merge(self.left, self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_2intkey", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "02c985ca0f91e858a760146877c62a3ce45e8e49ad16d9cf150e01a8e45d60f8", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_empty_left": {"code": "class Merge:\n    def time_merge_dataframe_empty_left(self, sort):\n        merge(self.left.iloc[:0], self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_empty_left", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5385d6eda16a400f6398618dc87406e053b44c3237148b4a88ee3af3bd997e7e", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_empty_right": {"code": "class Merge:\n    def time_merge_dataframe_empty_right(self, sort):\n        merge(self.left, self.right.iloc[:0], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_empty_right", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1c458073428462f9afadf4c68a397a523995779eb31f4ba9dfa01d7b1c86853d", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_2key": {"code": "class Merge:\n    def time_merge_dataframe_integer_2key(self, sort):\n        merge(self.df, self.df3, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_2key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "82965bb5c88367b7ca51c2841a96d09f5e13ef409582a2df03886b979a391141", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_key": {"code": "class Merge:\n    def time_merge_dataframe_integer_key(self, sort):\n        merge(self.df, self.df2, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2de11a2e31283d7107f028ba38e3768119a8b6727421ad035d81d7523bc31df5", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframes_cross": {"code": "class Merge:\n    def time_merge_dataframes_cross(self, sort):\n        merge(self.left.loc[:2000], self.right.loc[:2000], how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframes_cross", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "16ca5aa7ee0537da110abb59b4c2c6890937b10500617006e027f576afa9bf99", "warmup_time": -1}, "join_merge.MergeAsof.time_by_int": {"code": "class MergeAsof:\n    def time_by_int(self, direction, tolerance):\n        merge_asof(\n            self.df1c,\n            self.df2c,\n            on=\"time\",\n            by=\"key2\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9388814b37a8f7c3e8196e0e5e974f1114e5d09931e00ac3f102f86743babca9", "warmup_time": -1}, "join_merge.MergeAsof.time_by_object": {"code": "class MergeAsof:\n    def time_by_object(self, direction, tolerance):\n        merge_asof(\n            self.df1b,\n            self.df2b,\n            on=\"time\",\n            by=\"key\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_object", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "164ee691bc50a6d10e4f62c99daae4dce68786d7b02f5bd35af7bf33191d0405", "warmup_time": -1}, "join_merge.MergeAsof.time_multiby": {"code": "class MergeAsof:\n    def time_multiby(self, direction, tolerance):\n        merge_asof(\n            self.df1e,\n            self.df2e,\n            on=\"time\",\n            by=[\"key\", \"key2\"],\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_multiby", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "464ed78df4c5a78bcd7350edc12851af5dd87d18c63ed889b0ee80e806eed6a1", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int": {"code": "class MergeAsof:\n    def time_on_int(self, direction, tolerance):\n        merge_asof(\n            self.df1a, self.df2a, on=\"time\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a0ba76e01b99515f8c84950f1a4683fb1e2b601110a25798072287f3d1574ca1", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int32": {"code": "class MergeAsof:\n    def time_on_int32(self, direction, tolerance):\n        merge_asof(\n            self.df1d, self.df2d, on=\"time32\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int32", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5c26b3578593ec04d313f1cbf97df60936516fb7691a67ad03f78d68554fa57f", "warmup_time": -1}, "join_merge.MergeAsof.time_on_uint64": {"code": "class MergeAsof:\n    def time_on_uint64(self, direction, tolerance):\n        merge_asof(\n            self.df1f, self.df2f, on=\"timeu64\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_uint64", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "272c9034f60d2e7af35cd9d80009bb4f6d2ed987924efec03f83106e40c406be", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_cat": {"code": "class MergeCategoricals:\n    def time_merge_cat(self):\n        merge(self.left_cat, self.right_cat, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "00a33d8aa98005ee74e2a9419efbcba37da5a72412cf5677491a0d7e883e16ac", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_object": {"code": "class MergeCategoricals:\n    def time_merge_object(self):\n        merge(self.left_object, self.right_object, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "77cf8c07c705b35dc8457937294233b8bb0eefee79f670c7293bc9c2381afe22", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_on_cat_col": {"code": "class MergeCategoricals:\n    def time_merge_on_cat_col(self):\n        merge(self.left_cat_col, self.right_cat_col, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_on_cat_col", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "332c136f45e9500d990f645254420649a7483fe922cc1518686320b47d002d4d", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_on_cat_idx": {"code": "class MergeCategoricals:\n    def time_merge_on_cat_idx(self):\n        merge(self.left_cat_idx, self.right_cat_idx, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_on_cat_idx", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fa95749bee211b87d0765b6dd09a6130d3f28acb1b0d329273458f1ffba8efd8", "warmup_time": -1}, "join_merge.MergeDatetime.time_merge": {"code": "class MergeDatetime:\n    def time_merge(self, units, tz, monotonic):\n        merge(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeDatetime:\n    def setup(self, units, tz, monotonic):\n        unit_left, unit_right = units\n        N = 10_000\n        keys = Series(date_range(\"2012-01-01\", freq=\"min\", periods=N, tz=tz))\n        self.left = DataFrame(\n            {\n                \"key\": keys.sample(N * 10, replace=True).dt.as_unit(unit_left),\n                \"value1\": np.random.randn(N * 10),\n            }\n        )\n        self.right = DataFrame(\n            {\n                \"key\": keys[:8000].dt.as_unit(unit_right),\n                \"value2\": np.random.randn(8000),\n            }\n        )\n        if monotonic:\n            self.left = self.left.sort_values(\"key\")\n            self.right = self.right.sort_values(\"key\")", "min_run_count": 2, "name": "join_merge.MergeDatetime.time_merge", "number": 0, "param_names": ["units", "tz", "monotonic"], "params": [["('ns', 'ns')", "('ms', 'ms')", "('ns', 'ms')"], ["None", "'Europe/Brussels'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7fefbf78c16bc3a08818771113e2d29c712563606490a20e5d16660d9870a115", "warmup_time": -1}, "join_merge.MergeEA.time_merge": {"code": "class MergeEA:\n    def time_merge(self, dtype, monotonic):\n        merge(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeEA:\n    def setup(self, dtype, monotonic):\n        N = 10_000\n        indices = np.arange(1, N)\n        key = np.tile(indices[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": Series(key, dtype=dtype), \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": Series(indices[2000:], dtype=dtype),\n                \"value2\": np.random.randn(7999),\n            }\n        )\n        if monotonic:\n            self.left = self.left.sort_values(\"key\")\n            self.right = self.right.sort_values(\"key\")", "min_run_count": 2, "name": "join_merge.MergeEA.time_merge", "number": 0, "param_names": ["dtype", "monotonic"], "params": [["'Int64'", "'Int32'", "'Int16'", "'UInt64'", "'UInt32'", "'UInt16'", "'Float64'", "'Float32'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f0e5552415c5bc8cd8e34955cf48492cb0932495123062d6282b85ea95868817", "warmup_time": -1}, "join_merge.MergeMultiIndex.time_merge_sorted_multiindex": {"code": "class MergeMultiIndex:\n    def time_merge_sorted_multiindex(self, dtypes, how):\n        # copy to avoid MultiIndex._values caching\n        df1 = self.df1.copy()\n        df2 = self.df2.copy()\n        merge(df1, df2, how=how, left_index=True, right_index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeMultiIndex:\n    def setup(self, dtypes, how):\n        n = 100_000\n        offset = 50_000\n        mi1 = MultiIndex.from_arrays(\n            [\n                array(np.arange(n), dtype=dtypes[0]),\n                array(np.arange(n), dtype=dtypes[1]),\n            ]\n        )\n        mi2 = MultiIndex.from_arrays(\n            [\n                array(np.arange(offset, n + offset), dtype=dtypes[0]),\n                array(np.arange(offset, n + offset), dtype=dtypes[1]),\n            ]\n        )\n        self.df1 = DataFrame({\"col1\": 1}, index=mi1)\n        self.df2 = DataFrame({\"col2\": 2}, index=mi2)", "min_run_count": 2, "name": "join_merge.MergeMultiIndex.time_merge_sorted_multiindex", "number": 0, "param_names": ["dtypes", "how"], "params": [["('int64', 'int64')", "('datetime64[ns]', 'int64')", "('Int64', 'Int64')"], ["'left'", "'right'", "'inner'", "'outer'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "87d6032a44f31143b8c18c1f04684f8a2aa12fbf908500d9bb17310283004aa3", "warmup_time": -1}, "join_merge.MergeOrdered.time_merge_ordered": {"code": "class MergeOrdered:\n    def time_merge_ordered(self):\n        merge_ordered(self.left, self.right, on=\"key\", left_by=\"group\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeOrdered:\n    def setup(self):\n        groups = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        self.left = DataFrame(\n            {\n                \"group\": groups.repeat(5000),\n                \"key\": np.tile(np.arange(0, 10000, 2), 10),\n                \"lvalue\": np.random.randn(50000),\n            }\n        )\n        self.right = DataFrame(\n            {\"key\": np.arange(10000), \"rvalue\": np.random.randn(10000)}\n        )", "min_run_count": 2, "name": "join_merge.MergeOrdered.time_merge_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d15295cd5ee465cbd2aaa4c0bfe30d6feba058e0379020f3360c6857fd4a6781", "warmup_time": -1}, "join_merge.UniqueMerge.time_unique_merge": {"code": "class UniqueMerge:\n    def time_unique_merge(self, unique_elements):\n        merge(self.left, self.right, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass UniqueMerge:\n    def setup(self, unique_elements):\n        N = 1_000_000\n        self.left = DataFrame({\"a\": np.random.randint(1, unique_elements, (N,))})\n        self.right = DataFrame({\"a\": np.random.randint(1, unique_elements, (N,))})\n        uniques = self.right.a.drop_duplicates()\n        self.right[\"a\"] = concat(\n            [uniques, Series(np.arange(0, -(N - len(uniques)), -1))], ignore_index=True\n        )", "min_run_count": 2, "name": "join_merge.UniqueMerge.time_unique_merge", "number": 0, "param_names": ["unique_elements"], "params": [["4000000", "1000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "581e60a84032b51ebdf5071b2cbe5b27a5b4a5db94d2966a6145b815b235c390", "warmup_time": -1}, "libs.CacheReadonly.time_cache_readonly": {"code": "class CacheReadonly:\n    def time_cache_readonly(self):\n        self.obj.prop\n\n    def setup(self):\n        class Foo:\n            @cache_readonly\n            def prop(self):\n                return 5\n    \n        self.obj = Foo()", "min_run_count": 2, "name": "libs.CacheReadonly.time_cache_readonly", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0c1cb69a185e93f75c8a4df1942cf6b4e0cf583d0eb2f7e80d1df4e75305b788", "warmup_time": -1}, "libs.FastZip.time_lib_fast_zip": {"code": "class FastZip:\n    def time_lib_fast_zip(self):\n        lib.fast_zip(self.col_array_list)\n\n    def setup(self):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        col_array = np.vstack([key1, key2, np.random.randn(N * K)])\n        col_array2 = col_array.copy()\n        col_array2[:, :10000] = np.nan\n        self.col_array_list = list(col_array)", "min_run_count": 2, "name": "libs.FastZip.time_lib_fast_zip", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "91a51ca613db8362ac81df82eb2a907dd705058cd702a87ce9542e1b208d187e", "warmup_time": -1}, "libs.InferDtype.time_infer_dtype": {"code": "class InferDtype:\n    def time_infer_dtype(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=False)", "min_run_count": 2, "name": "libs.InferDtype.time_infer_dtype", "number": 0, "param_names": ["dtype"], "params": [["'np-object'", "'py-object'", "'np-null'", "'py-null'", "'np-int'", "'np-floating'", "'empty'", "'bytes'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "125f86966c05a7552f7d61e8833a505c865982149242f645b314a569f9830a3e", "warmup_time": -1}, "libs.InferDtype.time_infer_dtype_skipna": {"code": "class InferDtype:\n    def time_infer_dtype_skipna(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=True)", "min_run_count": 2, "name": "libs.InferDtype.time_infer_dtype_skipna", "number": 0, "param_names": ["dtype"], "params": [["'np-object'", "'py-object'", "'np-null'", "'py-null'", "'np-int'", "'np-floating'", "'empty'", "'bytes'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "92424cbc247a56269a3db019273c9b16434c61cd8f83fd7210ea2168ac4e31e0", "warmup_time": -1}, "libs.ScalarListLike.time_is_list_like": {"code": "class ScalarListLike:\n    def time_is_list_like(self, param):\n        is_list_like(param)", "min_run_count": 2, "name": "libs.ScalarListLike.time_is_list_like", "number": 0, "param_names": ["param1"], "params": [["0", "1.0", "(1+2j)", "True", "'foo'", "b'bar'", "None", "numpy.datetime64('1970-01-01T00:00:00.000000123')", "numpy.timedelta64(123,'ns')", "NaT", "<NA>", "array('123', dtype='<U3')", "array([1, 2, 3])", "{0: 1}", "{1, 2, 3}", "[1, 2, 3]", "(1, 2, 3)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f12c7f398bcc1c4a71e6dbe7b8aec6631a2565dd2a614a6f834dee7e64388bf8", "warmup_time": -1}, "libs.ScalarListLike.time_is_scalar": {"code": "class ScalarListLike:\n    def time_is_scalar(self, param):\n        is_scalar(param)", "min_run_count": 2, "name": "libs.ScalarListLike.time_is_scalar", "number": 0, "param_names": ["param1"], "params": [["0", "1.0", "(1+2j)", "True", "'foo'", "b'bar'", "None", "numpy.datetime64('1970-01-01T00:00:00.000000123')", "numpy.timedelta64(123,'ns')", "NaT", "<NA>", "array('123', dtype='<U3')", "array([1, 2, 3])", "{0: 1}", "{1, 2, 3}", "[1, 2, 3]", "(1, 2, 3)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ec357011e1e42690c47ad59e42ea37c1b167ef442f92e787301c3ef26d40a34d", "warmup_time": -1}, "multiindex_object.Append.time_append": {"code": "class Append:\n    def time_append(self, dtype):\n        self.left.append(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self, dtype):\n        N1 = 1000\n        N2 = 500\n        left_level1 = range(N1)\n        right_level1 = range(N1, N1 + N1)\n    \n        if dtype == \"datetime64[ns]\":\n            level2 = date_range(start=\"2000-01-01\", periods=N2)\n        elif dtype == \"int64\":\n            level2 = range(N2)\n        elif dtype == \"string\":\n            level2 = Index([f\"i-{i}\" for i in range(N2)], dtype=object)\n        else:\n            raise NotImplementedError\n    \n        self.left = MultiIndex.from_product([left_level1, level2])\n        self.right = MultiIndex.from_product([right_level1, level2])", "min_run_count": 2, "name": "multiindex_object.Append.time_append", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns]'", "'int64'", "'string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "76fd9f729ee3cd6d46110db9ab4c9d1c758cc7e3341892fdeda30d892e6c82ae", "warmup_time": -1}, "multiindex_object.CategoricalLevel.time_categorical_level": {"code": "class CategoricalLevel:\n    def time_categorical_level(self):\n        self.df.set_index([\"a\", \"b\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalLevel:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.arange(1_000_000, dtype=np.int32),\n                \"b\": np.arange(1_000_000, dtype=np.int64),\n                \"c\": np.arange(1_000_000, dtype=float),\n            }\n        ).astype({\"a\": \"category\", \"b\": \"category\"})", "min_run_count": 2, "name": "multiindex_object.CategoricalLevel.time_categorical_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "95746db84674b4c2c4a999d967e65da698fe749fb6a989c5cfa92e4a34dfe20f", "warmup_time": -1}, "multiindex_object.Difference.time_difference": {"code": "class Difference:\n    def time_difference(self, dtype):\n        self.left.difference(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Difference:\n    def setup(self, dtype):\n        N = 10**4 * 2\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Series(range(N // 1000), dtype=\"Int64\")\n        level2[0] = NA\n        ea_int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"ea_int\": ea_int_left,\n            \"string\": str_left,\n        }\n    \n        data = {k: {\"left\": mi, \"right\": mi[:5]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "multiindex_object.Difference.time_difference", "number": 0, "param_names": ["dtype"], "params": [["'datetime'", "'int'", "'string'", "'ea_int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0168a00ca95fba1c258cd54bdc3faf908f061cbf0a054c35404c75be0273497f", "warmup_time": -1}, "multiindex_object.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self):\n        self.mi.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n, k = 200, 5000\n        levels = [\n            np.arange(n),\n            Index([f\"i-{i}\" for i in range(n)], dtype=object).values,\n            1000 + np.arange(n),\n        ]\n        codes = [np.random.choice(n, (k * n)) for lev in levels]\n        self.mi = MultiIndex(levels=levels, codes=codes)", "min_run_count": 2, "name": "multiindex_object.Duplicated.time_duplicated", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a38c9fead000e3b6fd3c54f7de782d3ba37dd31161e8fdd82c58194ae7324c22", "warmup_time": -1}, "multiindex_object.Duplicates.time_remove_unused_levels": {"code": "class Duplicates:\n    def time_remove_unused_levels(self):\n        self.mi_unused_levels.remove_unused_levels()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicates:\n    def setup(self):\n        size = 65536\n        arrays = [np.random.randint(0, 8192, size), np.random.randint(0, 1024, size)]\n        mask = np.random.rand(size) < 0.1\n        self.mi_unused_levels = MultiIndex.from_arrays(arrays)\n        self.mi_unused_levels = self.mi_unused_levels[mask]", "min_run_count": 2, "name": "multiindex_object.Duplicates.time_remove_unused_levels", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "858a4d9728167fda18b01dd248d011becaf52569cc3789ebc23781748020a547", "warmup_time": -1}, "multiindex_object.Equals.time_equals_deepcopy": {"code": "class Equals:\n    def time_equals_deepcopy(self):\n        self.mi.equals(self.mi_deepcopy)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        self.mi = MultiIndex.from_product(\n            [\n                date_range(\"2000-01-01\", periods=1000),\n                RangeIndex(1000),\n            ]\n        )\n        self.mi_deepcopy = self.mi.copy(deep=True)\n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "multiindex_object.Equals.time_equals_deepcopy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3c8ee7ba225f03d3cf9c2afce902b41bea67d5d6a541fe7074939ee82f3f7cf6", "warmup_time": -1}, "multiindex_object.Equals.time_equals_non_object_index": {"code": "class Equals:\n    def time_equals_non_object_index(self):\n        self.mi.equals(self.idx_non_object)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        self.mi = MultiIndex.from_product(\n            [\n                date_range(\"2000-01-01\", periods=1000),\n                RangeIndex(1000),\n            ]\n        )\n        self.mi_deepcopy = self.mi.copy(deep=True)\n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "multiindex_object.Equals.time_equals_non_object_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "90c7f091d490800450f501a3c2b4c17889809056c889ada043abc9c6fcaad06b", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc": {"code": "class GetLoc:\n    def time_large_get_loc(self):\n        self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "dd084286aabcc048d0407dfacebe59f29ed1f976d92d013a0a10f35ba2e96bdb", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc_warm": {"code": "class GetLoc:\n    def time_large_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "137653619e4d1b432e07d94aa7a9cf46441e320de449aa65f5129efc13888912", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc": {"code": "class GetLoc:\n    def time_med_get_loc(self):\n        self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b783d9cb5dbdc6787a0879e0f8c0862c4014d5ea0611abb97c342d46f77826e1", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc_warm": {"code": "class GetLoc:\n    def time_med_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "50ea4f6a67d9f88227e60e668996edef05b7564987506a1145e7b2c23a2ccb41", "warmup_time": -1}, "multiindex_object.GetLoc.time_small_get_loc_warm": {"code": "class GetLoc:\n    def time_small_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_small_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fe1c2475d50cac160a619e2371fc123f6053a4346c2f4d01018f499d4cfec4e7", "warmup_time": -1}, "multiindex_object.GetLoc.time_string_get_loc": {"code": "class GetLoc:\n    def time_string_get_loc(self):\n        self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_string_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e96912b143865fa80131f906e8f63d1f3c40b3d142b8571de3b1b9615adf1801", "warmup_time": -1}, "multiindex_object.GetLocs.time_large_get_locs": {"code": "class GetLocs:\n    def time_large_get_locs(self):\n        self.mi_large.get_locs([999, 19, \"Z\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_large_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f6945fa307f8737f7231a2a44181eb523a78c225bc91dbcb18e3b75194dfc5bc", "warmup_time": -1}, "multiindex_object.GetLocs.time_med_get_locs": {"code": "class GetLocs:\n    def time_med_get_locs(self):\n        self.mi_med.get_locs([999, 9, \"A\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_med_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cf1640cb0f946d097ff83e7740951339843061148884ca31b8394c7abfa2c016", "warmup_time": -1}, "multiindex_object.GetLocs.time_small_get_locs": {"code": "class GetLocs:\n    def time_small_get_locs(self):\n        self.mi_small.get_locs([99, \"A\", \"A\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_small_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e20e0ac51b10b4dd999beefc7d99e3da94d32206cbb5cad3f13e2f9f110c765e", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer": {"code": "class Integer:\n    def time_get_indexer(self):\n        self.mi_int.get_indexer(self.obj_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fbdc58718b979f87ea6a8c82f9bc10f0b1ebc5fb70ea385528f54cff5edb41e7", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer_and_backfill": {"code": "class Integer:\n    def time_get_indexer_and_backfill(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"backfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer_and_backfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f3a337ce0bc68b9b181e2f10744c48edfc0aea4481ed3ae1d3daf65dc1c9d53b", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer_and_pad": {"code": "class Integer:\n    def time_get_indexer_and_pad(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"pad\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer_and_pad", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee2af65e57a49d84022609e04c926f032e6e248514ffaccf6af4a25038d13f78", "warmup_time": -1}, "multiindex_object.Integer.time_is_monotonic": {"code": "class Integer:\n    def time_is_monotonic(self):\n        self.mi_int.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_is_monotonic", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fe8e8d89536abf16fb7a6ef01595817776ab712a6865435f65f407568be53b2b", "warmup_time": -1}, "multiindex_object.Isin.time_isin_large": {"code": "class Isin:\n    def time_isin_large(self, dtype):\n        self.midx.isin(self.values_large)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_midx = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_midx,\n            \"int\": int_midx,\n            \"string\": str_midx,\n        }\n    \n        self.midx = data[dtype]\n        self.values_small = self.midx[:100]\n        self.values_large = self.midx[100:]", "min_run_count": 2, "name": "multiindex_object.Isin.time_isin_large", "number": 0, "param_names": ["dtype"], "params": [["'string'", "'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7d85e0708b91ce1073f3eb5be362351b5419529c28ad4c98794a4fea4adf8773", "warmup_time": -1}, "multiindex_object.Isin.time_isin_small": {"code": "class Isin:\n    def time_isin_small(self, dtype):\n        self.midx.isin(self.values_small)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_midx = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_midx,\n            \"int\": int_midx,\n            \"string\": str_midx,\n        }\n    \n        self.midx = data[dtype]\n        self.values_small = self.midx[:100]\n        self.values_large = self.midx[100:]", "min_run_count": 2, "name": "multiindex_object.Isin.time_isin_small", "number": 0, "param_names": ["dtype"], "params": [["'string'", "'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6c13190c2ec3169da4f76b0363e486cf173c635d7bb1edba8daec0a6a089f193", "warmup_time": -1}, "multiindex_object.Putmask.time_putmask": {"code": "class Putmask:\n    def time_putmask(self):\n        self.midx.putmask(self.mask, self.midx_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Putmask:\n    def setup(self):\n        N = 10**5\n        level1 = range(1_000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        self.midx = MultiIndex.from_product([level1, level2])\n    \n        level1 = range(1_000, 2_000)\n        self.midx_values = MultiIndex.from_product([level1, level2])\n    \n        level2 = date_range(start=\"1/1/2010\", periods=N // 1000)\n        self.midx_values_different = MultiIndex.from_product([level1, level2])\n        self.mask = np.array([True, False] * (N // 2))", "min_run_count": 2, "name": "multiindex_object.Putmask.time_putmask", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "50b446c4932ddf04ca8086ddae7020ac3b1392556c9a5ec0bceee4a3471b774c", "warmup_time": -1}, "multiindex_object.Putmask.time_putmask_all_different": {"code": "class Putmask:\n    def time_putmask_all_different(self):\n        self.midx.putmask(self.mask, self.midx_values_different)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Putmask:\n    def setup(self):\n        N = 10**5\n        level1 = range(1_000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        self.midx = MultiIndex.from_product([level1, level2])\n    \n        level1 = range(1_000, 2_000)\n        self.midx_values = MultiIndex.from_product([level1, level2])\n    \n        level2 = date_range(start=\"1/1/2010\", periods=N // 1000)\n        self.midx_values_different = MultiIndex.from_product([level1, level2])\n        self.mask = np.array([True, False] * (N // 2))", "min_run_count": 2, "name": "multiindex_object.Putmask.time_putmask_all_different", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "df38cba739c0876f17aa511e01ea4c5d6ae937fab90a3c6ba526fe149c270ac5", "warmup_time": -1}, "multiindex_object.SetOperations.time_operation": {"code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method, sort):\n        getattr(self.left, method)(self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method, sort):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        ea_int_left = MultiIndex.from_product([level1, Series(level2, dtype=\"Int64\")])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"string\": str_left,\n            \"ea_int\": ea_int_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": mi, \"right\": mi[:-1]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "multiindex_object.SetOperations.time_operation", "number": 0, "param_names": ["index_structure", "dtype", "method", "sort"], "params": [["'monotonic'", "'non_monotonic'"], ["'datetime'", "'int'", "'string'", "'ea_int'"], ["'intersection'", "'union'", "'symmetric_difference'"], ["False", "None"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "dc16c7e3877db2721ec17de5cc8eb031f00bbf400e50f5f1e1565c4c64ba78aa", "warmup_time": -1}, "multiindex_object.SortValues.time_sort_values": {"code": "class SortValues:\n    def time_sort_values(self, dtype):\n        self.mi.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, dtype):\n        a = array(np.tile(np.arange(100), 1000), dtype=dtype)\n        b = array(np.tile(np.arange(1000), 100), dtype=dtype)\n        self.mi = MultiIndex.from_arrays([a, b])", "min_run_count": 2, "name": "multiindex_object.SortValues.time_sort_values", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'Int64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "eb98215f2130dc70e3c3979ccb2442480cccf2a7f1fe46dabae490de9fa669ce", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_int64": {"code": "class Sortlevel:\n    def time_sortlevel_int64(self):\n        self.mi_int.sortlevel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a8b2951c7f045b903e0cd3abcea3295e405768580e65c267316e5d7993c375e4", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_one": {"code": "class Sortlevel:\n    def time_sortlevel_one(self):\n        self.mi.sortlevel(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_one", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "17b98983847e3899dd3aecd51f007b8eee9219cafba180bcd18d23a273f074e4", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_zero": {"code": "class Sortlevel:\n    def time_sortlevel_zero(self):\n        self.mi.sortlevel(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1f7d209d70d9ce641fdba817c8598ab8212457073e4f1218e5ecec974b8af00b", "warmup_time": -1}, "multiindex_object.Unique.time_unique": {"code": "class Unique:\n    def time_unique(self, dtype_val):\n        self.midx.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unique:\n    def setup(self, dtype_val):\n        level = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(1_000_000)),\n            dtype=dtype_val[0],\n        )\n        self.midx = MultiIndex.from_arrays([level, level])\n    \n        level_dups = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(500_000)) * 2,\n            dtype=dtype_val[0],\n        )\n    \n        self.midx_dups = MultiIndex.from_arrays([level_dups, level_dups])", "min_run_count": 2, "name": "multiindex_object.Unique.time_unique", "number": 0, "param_names": ["dtype_val"], "params": [["('Int64', <NA>)", "('int64', 0)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "92002a61c3c2deb0be986b18be58b6f290334692a0ddda344728454264d8c69f", "warmup_time": -1}, "multiindex_object.Unique.time_unique_dups": {"code": "class Unique:\n    def time_unique_dups(self, dtype_val):\n        self.midx_dups.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unique:\n    def setup(self, dtype_val):\n        level = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(1_000_000)),\n            dtype=dtype_val[0],\n        )\n        self.midx = MultiIndex.from_arrays([level, level])\n    \n        level_dups = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(500_000)) * 2,\n            dtype=dtype_val[0],\n        )\n    \n        self.midx_dups = MultiIndex.from_arrays([level_dups, level_dups])", "min_run_count": 2, "name": "multiindex_object.Unique.time_unique_dups", "number": 0, "param_names": ["dtype_val"], "params": [["('Int64', <NA>)", "('int64', 0)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e7f6ae2612b4e61ab7e9b6ec0fa03d09c37653dcccd19cf141ea041ff0d0eec7", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_copy": {"code": "class Values:\n    def time_datetime_level_values_copy(self, mi):\n        mi.copy().values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "multiindex_object:197", "type": "time", "unit": "seconds", "version": "63e7a47c0b022503f19576c75633ea3ca8a93ecce618be6e102892f9bd42dc33", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_sliced": {"code": "class Values:\n    def time_datetime_level_values_sliced(self, mi):\n        mi[:10].values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_sliced", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "multiindex_object:197", "type": "time", "unit": "seconds", "version": "6cfa5ee6916e13b58f6d108ca083f0ce269ffc3682b201c7fb24a2c4f82119bf", "warmup_time": -1}, "package.TimeImport.time_import": {"code": "class TimeImport:\n    def time_import(self):\n        # on py37+ we the \"-X importtime\" usage gives us a more precise\n        #  measurement of the import time we actually care about,\n        #  without the subprocess or interpreter overhead\n        cmd = [sys.executable, \"-X\", \"importtime\", \"-c\", \"import pandas as pd\"]\n        p = subprocess.run(cmd, stderr=subprocess.PIPE, check=True)\n    \n        line = p.stderr.splitlines()[-1]\n        field = line.split(b\"|\")[-2].strip()\n        total = int(field)  # microseconds\n        return total", "min_run_count": 2, "name": "package.TimeImport.time_import", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "83a56070bd7dda7f68a557d63e6b32341f956e6303d5820f6f5f3cfd62ac924b", "warmup_time": -1}, "period.Algorithms.time_drop_duplicates": {"code": "class Algorithms:\n    def time_drop_duplicates(self, typ):\n        self.vector.drop_duplicates()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_drop_duplicates", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5ed71a0e29ea9fe94acdf37fe778becc6a166703e59fe06b43693190e73c358c", "warmup_time": -1}, "period.Algorithms.time_value_counts": {"code": "class Algorithms:\n    def time_value_counts(self, typ):\n        self.vector.value_counts()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_value_counts", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7aaad3304a09d800100a2dc5f7da82c36953722c7da6aca2ca4c2e446a3badc8", "warmup_time": -1}, "period.DataFramePeriodColumn.time_set_index": {"code": "class DataFramePeriodColumn:\n    def time_set_index(self):\n        # GH#21582 limited by comparisons of Period objects\n        self.df[\"col2\"] = self.rng\n        self.df.set_index(\"col2\", append=True)\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"s\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_set_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "575f1539efb942f285e06bed12d6e468229977eb8dfe5637e627fc97f98d5c0a", "warmup_time": -1}, "period.DataFramePeriodColumn.time_setitem_period_column": {"code": "class DataFramePeriodColumn:\n    def time_setitem_period_column(self):\n        self.df[\"col\"] = self.rng\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"s\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_setitem_period_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "da793a842fd7c5e41b19f604fed3ece4f2373f1946c06c9733baad3cc9ae9168", "warmup_time": -1}, "period.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7ba91f5b4184a97b1e578ce06acd5823a15ef927984c534ef97a97209494f3e9", "warmup_time": -1}, "period.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.period)\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "16c0233f1354d0efad7e0568b42faab3ceda761dbe321e610db062449c038b2b", "warmup_time": -1}, "period.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e473ad8ce23861754e1a2322452188035f32546b5106e9c354504575f161c9dc", "warmup_time": -1}, "period.Indexing.time_series_loc": {"code": "class Indexing:\n    def time_series_loc(self):\n        self.series.loc[self.period]\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_series_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "051bdec8fea0886aa445b372b56bf9dc434ca870d0168882015b967bb1545aa4", "warmup_time": -1}, "period.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ec340ef909e8666710788924d6a879a98eceecf319ce9ddaa3afaef7f7c6a891", "warmup_time": -1}, "period.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c4ce9c886be5dcc91f24921a741cee9552a169c54f69f0ec4893b19145ca6cda", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_date_range": {"code": "class PeriodIndexConstructor:\n    def time_from_date_range(self, freq, is_offset):\n        PeriodIndex(self.rng, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_date_range", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "90341c890b6fd853e93fe5ad5a5d9935048545a0c2bf70da9324aca627215961", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints": {"code": "class PeriodIndexConstructor:\n    def time_from_ints(self, freq, is_offset):\n        PeriodIndex(self.ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "40e20dbe294496152b0cab99ad8277ec6836602167d363e0c665de9915971d7d", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints_daily": {"code": "class PeriodIndexConstructor:\n    def time_from_ints_daily(self, freq, is_offset):\n        PeriodIndex(self.daily_ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints_daily", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7ec1c957be1d06e33b08c4eb1a645648cba0172013a8b73a1e8c8d8f8e5725a8", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_pydatetime": {"code": "class PeriodIndexConstructor:\n    def time_from_pydatetime(self, freq, is_offset):\n        PeriodIndex(self.rng2, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_pydatetime", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2e9a86e7434b9d0777e5ccc8fc9165eaf99b3ae701c88bb9a2f2bfbb3a8742c1", "warmup_time": -1}, "plotting.BackendLoading.time_get_plot_backend": {"code": "class BackendLoading:\n    def time_get_plot_backend(self):\n        # finds the first my_ep_backend\n        _get_plot_backend(\"my_ep_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        mod = importlib.util.module_from_spec(\n            importlib.machinery.ModuleSpec(\"pandas_dummy_backend\", None)\n        )\n        mod.plot = lambda *args, **kwargs: 1\n    \n        with contextlib.ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {\"pandas_dummy_backend\": mod})\n            )\n            tmp_path = pathlib.Path(stack.enter_context(tempfile.TemporaryDirectory()))\n    \n            sys.path.insert(0, os.fsdecode(tmp_path))\n            stack.callback(sys.path.remove, os.fsdecode(tmp_path))\n    \n            dist_info = tmp_path / \"my_backend-0.0.0.dist-info\"\n            dist_info.mkdir()\n            (dist_info / \"entry_points.txt\").write_bytes(\n                b\"[pandas_plotting_backends]\\n\"\n                b\"my_ep_backend = pandas_dummy_backend\\n\"\n                b\"my_ep_backend0 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend1 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend2 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend3 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend4 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend5 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend6 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend7 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend8 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend9 = pandas_dummy_backend\\n\"\n            )\n            self.stack = stack.pop_all()", "min_run_count": 2, "name": "plotting.BackendLoading.time_get_plot_backend", "number": 1, "param_names": [], "params": [], "repeat": 1, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "275ed8f1d87eb6e40f19e678ae4e0130a88ef153363ae407c9576044f4455591", "warmup_time": 0}, "plotting.BackendLoading.time_get_plot_backend_fallback": {"code": "class BackendLoading:\n    def time_get_plot_backend_fallback(self):\n        # iterates through all the my_ep_backend[0-9] before falling back\n        # to importlib.import_module\n        _get_plot_backend(\"pandas_dummy_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        mod = importlib.util.module_from_spec(\n            importlib.machinery.ModuleSpec(\"pandas_dummy_backend\", None)\n        )\n        mod.plot = lambda *args, **kwargs: 1\n    \n        with contextlib.ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {\"pandas_dummy_backend\": mod})\n            )\n            tmp_path = pathlib.Path(stack.enter_context(tempfile.TemporaryDirectory()))\n    \n            sys.path.insert(0, os.fsdecode(tmp_path))\n            stack.callback(sys.path.remove, os.fsdecode(tmp_path))\n    \n            dist_info = tmp_path / \"my_backend-0.0.0.dist-info\"\n            dist_info.mkdir()\n            (dist_info / \"entry_points.txt\").write_bytes(\n                b\"[pandas_plotting_backends]\\n\"\n                b\"my_ep_backend = pandas_dummy_backend\\n\"\n                b\"my_ep_backend0 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend1 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend2 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend3 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend4 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend5 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend6 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend7 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend8 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend9 = pandas_dummy_backend\\n\"\n            )\n            self.stack = stack.pop_all()", "min_run_count": 2, "name": "plotting.BackendLoading.time_get_plot_backend_fallback", "number": 1, "param_names": [], "params": [], "repeat": 1, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5910845eb9f1e056392eea6799696858a13e4b42bcc4462d896f69e4c4e69fdc", "warmup_time": 0}, "plotting.FramePlotting.time_frame_plot": {"code": "class FramePlotting:\n    def time_frame_plot(self, kind):\n        self.df.plot(x=\"x\", y=\"y\", kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FramePlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\", \"scatter\", \"hexbin\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.x = Series(np.random.randn(n))\n        self.y = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.x = self.x.abs()\n            self.y = self.y.abs()\n        self.df = DataFrame({\"x\": self.x, \"y\": self.y})", "min_run_count": 2, "name": "plotting.FramePlotting.time_frame_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'", "'scatter'", "'hexbin'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d6c19f0e6ee8994eb981863b029fa07bc3dc6e28ca77fd1947a32124682e279a", "warmup_time": -1}, "plotting.Misc.time_plot_andrews_curves": {"code": "class Misc:\n    def time_plot_andrews_curves(self):\n        andrews_curves(self.df, \"Name\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Misc:\n    def setup(self):\n        N = 500\n        M = 10\n        self.df = DataFrame(np.random.randn(N, M))\n        self.df[\"Name\"] = [\"A\"] * N", "min_run_count": 2, "name": "plotting.Misc.time_plot_andrews_curves", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c5cdb631131db0763b96053825ebc29d36564b7efc93174553deebff526d0e51", "warmup_time": -1}, "plotting.SeriesPlotting.time_series_plot": {"code": "class SeriesPlotting:\n    def time_series_plot(self, kind):\n        self.s.plot(kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesPlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.s = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.s = self.s.abs()", "min_run_count": 2, "name": "plotting.SeriesPlotting.time_series_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "160ab68dd1bbcfdc4cb7ac7c745857d954d7b49e2140f072e93341253436ffb2", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_irregular": {"code": "class TimeseriesPlotting:\n    def time_plot_irregular(self):\n        self.df2.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_irregular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "eebbebf937fc740e9be07af175a3643c600ac60a98e1f1606d1ed7150b2966b0", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular": {"code": "class TimeseriesPlotting:\n    def time_plot_regular(self):\n        self.df.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c3871908c149bdf0cd9d3c7cdce5ed7bd993762db8bacec201061775ac030be2", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular_compat": {"code": "class TimeseriesPlotting:\n    def time_plot_regular_compat(self):\n        self.df.plot(x_compat=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular_compat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6b83eb693399183277a784aee0704171f06e4913b66ddd6bddde0dcc2fb427ff", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_table": {"code": "class TimeseriesPlotting:\n    def time_plot_table(self):\n        self.df.plot(table=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2c526eb7965a6c381c8aa22565224994f1cbd2c378f4a0aa87af283821f76da3", "warmup_time": -1}, "reindex.Align.time_align_series_irregular_string": {"code": "class Align:\n    def time_align_series_irregular_string(self):\n        self.x + self.y\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        n = 50000\n        indices = Index([f\"i-{i}\" for i in range(n)], dtype=object)\n        subsample_size = 40000\n        self.x = Series(np.random.randn(n), indices)\n        self.y = Series(\n            np.random.randn(subsample_size),\n            index=np.random.choice(indices, subsample_size, replace=False),\n        )", "min_run_count": 2, "name": "reindex.Align.time_align_series_irregular_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "99535222ff12826c671cd482a3e3dce8a1feb88c9e23e1a204057e24eff7019a", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups": {"code": "class DropDuplicates:\n    def time_frame_drop_dups(self, inplace):\n        self.df.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9e3407f683cc7f16fac045b6c3c7aa89bb7ab9c2f86d11a22aa26844cdfc8bd8", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_bool": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_bool(self, inplace):\n        self.df_bool.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_bool", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ff1fe38fe30683f1f77e7f0d500e80fdc6a7c481f9529f0faceacb438bf8acf3", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_int": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_int(self, inplace):\n        self.df_int.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "219d98c5c189760cab8a4753d551329b822cec481ba3587429a5918348833430", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_na": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_na(self, inplace):\n        self.df_nan.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_na", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6645f4d4309d703c15aee91e0cccb7387dddfe3a50a13a8ee231b2e8598539f0", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_int": {"code": "class DropDuplicates:\n    def time_series_drop_dups_int(self, inplace):\n        self.s.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0d5f8b5b9a0532b4bf319dbe2d7ccb87052976d4333850a3eaf137b4d9b23e5d", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_string": {"code": "class DropDuplicates:\n    def time_series_drop_dups_string(self, inplace):\n        self.s_str.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_string", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0c0a1fb01f308c8f6dfbb4593af90cb7d596b775640ebe908d4556cc6e00938c", "warmup_time": -1}, "reindex.LevelAlign.time_align_level": {"code": "class LevelAlign:\n    def time_align_level(self):\n        self.df.align(self.df_level, level=1, copy=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_align_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cced19c77cf2154fcd7f760f955314b571a4c552f1c3dda834b08449c39cf96a", "warmup_time": -1}, "reindex.LevelAlign.time_reindex_level": {"code": "class LevelAlign:\n    def time_reindex_level(self):\n        self.df_level.reindex(self.index, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_reindex_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9c4e829ee0f877d248f2dca88a52830e615dd62d42be7dc5b046cd79771b41d2", "warmup_time": -1}, "reindex.Reindex.time_reindex_columns": {"code": "class Reindex:\n    def time_reindex_columns(self):\n        self.df2.reindex(columns=self.df.columns[1:5])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "00a301c16f6c5bce541f67b2a6f047a8d90ab2341ce70509821a6cfb1c0d38df", "warmup_time": -1}, "reindex.Reindex.time_reindex_dates": {"code": "class Reindex:\n    def time_reindex_dates(self):\n        self.df.reindex(self.rng_subset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d8bf7e54481378634e8e80cc8c0c55d1700f313f036d19ab3de1dca31e190f66", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_no_cache": {"code": "class Reindex:\n    def time_reindex_multiindex_no_cache(self):\n        # Copy to avoid MultiIndex._values getting cached\n        self.s.reindex(self.s_subset_no_cache.index.copy())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_no_cache", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a87224c6ab473aaa760c5bef29410e56f6234562f30eaa05cd52c79d7ee74f25", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_no_cache_dates": {"code": "class Reindex:\n    def time_reindex_multiindex_no_cache_dates(self):\n        # Copy to avoid MultiIndex._values getting cached\n        self.s2_subset.reindex(self.s2.index.copy())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_no_cache_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "34d18834462d53c009ef308fc30cfadd3c904d729da717f68d96a14ef887073a", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_with_cache": {"code": "class Reindex:\n    def time_reindex_multiindex_with_cache(self):\n        # MultiIndex._values gets cached\n        self.s.reindex(self.s_subset.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_with_cache", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fcee94dfdbc0f691c1052335d9fe83cbb8a3adf26ff91b6a60701a0f2b512526", "warmup_time": -1}, "reindex.ReindexMethod.time_reindex_method": {"code": "class ReindexMethod:\n    def time_reindex_method(self, method, constructor):\n        self.ts.reindex(self.idx, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReindexMethod:\n    def setup(self, method, constructor):\n        N = 100000\n        self.idx = constructor(\"1/1/2000\", periods=N, freq=\"1min\")\n        self.ts = Series(np.random.randn(N), index=self.idx)[::2]", "min_run_count": 2, "name": "reindex.ReindexMethod.time_reindex_method", "number": 0, "param_names": ["method", "constructor"], "params": [["'pad'", "'backfill'"], ["<function date_range>", "<function period_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "52e66df756313fc255334a8a0cb3c1dbaf796d0b655126ff3c140d0a2207a3bc", "warmup_time": -1}, "replace.Convert.time_replace": {"code": "class Convert:\n    def time_replace(self, constructor, replace_data):\n        self.data.replace(self.to_replace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Convert:\n    def setup(self, constructor, replace_data):\n        N = 10**3\n        data = {\n            \"Series\": pd.Series(np.random.randint(N, size=N)),\n            \"DataFrame\": pd.DataFrame(\n                {\"A\": np.random.randint(N, size=N), \"B\": np.random.randint(N, size=N)}\n            ),\n        }\n        self.to_replace = {i: getattr(pd, replace_data) for i in range(N)}\n        self.data = data[constructor]", "min_run_count": 2, "name": "replace.Convert.time_replace", "number": 0, "param_names": ["constructor", "replace_data"], "params": [["'DataFrame'", "'Series'"], ["'Timestamp'", "'Timedelta'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a744fa5ba9e82cf960d86890e5316fd597568f0134b134ef39e6a068d4a6fcaa", "warmup_time": -1}, "replace.FillNa.time_fillna": {"code": "class FillNa:\n    def time_fillna(self, inplace):\n        self.ts.fillna(0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_fillna", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0b76c4847fb4ab0037ada56a69ae0191854beb20a29f7c1fdb937679f1a20cfa", "warmup_time": -1}, "replace.FillNa.time_replace": {"code": "class FillNa:\n    def time_replace(self, inplace):\n        self.ts.replace(np.nan, 0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_replace", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ce112dec862dc388710999d0a5afaf6410c6e73eb37747f783c8f0f031390817", "warmup_time": -1}, "replace.ReplaceDict.time_replace_series": {"code": "class ReplaceDict:\n    def time_replace_series(self, inplace):\n        self.s.replace(self.to_rep, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceDict:\n    def setup(self, inplace):\n        N = 10**5\n        start_value = 10**5\n        self.to_rep = dict(enumerate(np.arange(N) + start_value))\n        self.s = pd.Series(np.random.randint(N, size=10**3))", "min_run_count": 2, "name": "replace.ReplaceDict.time_replace_series", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8597d90cda40f0b788096a546f8abbf5caa952c6eea9f9e47eb8d4ce2d3c1aa2", "warmup_time": -1}, "replace.ReplaceList.time_replace_list": {"code": "class ReplaceList:\n    def time_replace_list(self, inplace):\n        self.df.replace([np.inf, -np.inf], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(10**7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "959eed35fcb7e64cf2b5aec83263f040060cf5f6bbbff9dcbc719a20863b5eac", "warmup_time": -1}, "replace.ReplaceList.time_replace_list_one_match": {"code": "class ReplaceList:\n    def time_replace_list_one_match(self, inplace):\n        # the 1 can be held in self._df.blocks[0], while the inf and -inf can't\n        self.df.replace([np.inf, -np.inf, 1], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(10**7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list_one_match", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6d505bdc8d7c3ba7390852b2bee3c44fcb2c810e807722f5dbc7bbf9e5969c02", "warmup_time": -1}, "reshape.Crosstab.time_crosstab": {"code": "class Crosstab:\n    def time_crosstab(self):\n        pd.crosstab(self.vec1, self.vec2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9111a9ad9a258688c45ba6a0c05b7b226f360b676432ed650b695e5397fde93e", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize": {"code": "class Crosstab:\n    def time_crosstab_normalize(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5aca65001068430d0914d98785bddb8561273e9c8aa15b387c7dd93043ebf568", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize_margins": {"code": "class Crosstab:\n    def time_crosstab_normalize_margins(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True, margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize_margins", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4c136fc000722c789e91a8ae69e2c658c5bedd669b2178c0fc2a1f4f2b42727b", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_values": {"code": "class Crosstab:\n    def time_crosstab_values(self):\n        pd.crosstab(self.vec1, self.vec2, values=self.ind1, aggfunc=\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3b4ec27deb69daa12d4b65e15cc4b7b2edcc88df3a066962121c333f57a3423e", "warmup_time": -1}, "reshape.Cut.peakmem_cut_interval": {"code": "class Cut:\n    def peakmem_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "name": "reshape.Cut.peakmem_cut_interval", "param_names": ["bins"], "params": [["4", "10", "1000"]], "type": "peakmemory", "unit": "bytes", "version": "4a50cdb22148145d78b66b3246a5d917de2b2b2c2a79baab6c336150c6028996"}, "reshape.Cut.time_cut_datetime": {"code": "class Cut:\n    def time_cut_datetime(self, bins):\n        pd.cut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "58412e44ffc063ce05ec9eabf6599316b54c12e85398a5cd91280e5f2eaec7de", "warmup_time": -1}, "reshape.Cut.time_cut_float": {"code": "class Cut:\n    def time_cut_float(self, bins):\n        pd.cut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "85096ca698be2f3208680d4f35d7aeded90a2e9795781508cbc5dfdf35e7e36b", "warmup_time": -1}, "reshape.Cut.time_cut_int": {"code": "class Cut:\n    def time_cut_int(self, bins):\n        pd.cut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e8b43cd5e06cec8978579ef14b528be88fb90d1577ba5cc34c0c00559616d982", "warmup_time": -1}, "reshape.Cut.time_cut_interval": {"code": "class Cut:\n    def time_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_interval", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "379c2ec4450e760810c91f3626fdd11aad35e5d872d5b8912a9db3362f42e133", "warmup_time": -1}, "reshape.Cut.time_cut_timedelta": {"code": "class Cut:\n    def time_cut_timedelta(self, bins):\n        pd.cut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "758ab752e664d48441ccb021304bc8e71171846cee22a64b2e72be3351f00447", "warmup_time": -1}, "reshape.Cut.time_qcut_datetime": {"code": "class Cut:\n    def time_qcut_datetime(self, bins):\n        pd.qcut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d04a2db349c29907a75caab0e3a9c580e577e50262df736e1650eb96f77d134d", "warmup_time": -1}, "reshape.Cut.time_qcut_float": {"code": "class Cut:\n    def time_qcut_float(self, bins):\n        pd.qcut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0482097ddcc850236edbae620fd920d073c84d385fe332eaefbfb40041f64df2", "warmup_time": -1}, "reshape.Cut.time_qcut_int": {"code": "class Cut:\n    def time_qcut_int(self, bins):\n        pd.qcut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "83d5a7e00e70a8e2dae57a0f38abad70d2db20c1bc5fe39c202f1d94ba5f6360", "warmup_time": -1}, "reshape.Cut.time_qcut_timedelta": {"code": "class Cut:\n    def time_qcut_timedelta(self, bins):\n        pd.qcut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ce5e325613d980c2c58926140ecd066ba1caa5ff13d1f13c4b028bf98cb83b0f", "warmup_time": -1}, "reshape.Explode.time_explode": {"code": "class Explode:\n    def time_explode(self, n_rows, max_list_length):\n        self.series.explode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Explode:\n    def setup(self, n_rows, max_list_length):\n        data = [np.arange(np.random.randint(max_list_length)) for _ in range(n_rows)]\n        self.series = pd.Series(data)", "min_run_count": 2, "name": "reshape.Explode.time_explode", "number": 0, "param_names": ["n_rows", "max_list_length"], "params": [["100", "1000", "10000"], ["3", "5", "10"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1e8e8da03418f2a12d85f80f073278296ec8c8f9e43fc8bcc690b704c5f258de", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d": {"code": "class GetDummies:\n    def time_get_dummies_1d(self):\n        pd.get_dummies(self.s, sparse=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f6981c8b44fbd13f60eff496356529e393625318426d340155a55ed3d7ffb4ee", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d_sparse": {"code": "class GetDummies:\n    def time_get_dummies_1d_sparse(self):\n        pd.get_dummies(self.s, sparse=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d_sparse", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f4b85a94bf96350e6ae89b0267fcb36cf05e306063a0915e425fc9e5a1a4467e", "warmup_time": -1}, "reshape.Melt.time_melt_dataframe": {"code": "class Melt:\n    def time_melt_dataframe(self, dtype):\n        melt(self.df, id_vars=[\"id1\", \"id2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Melt:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(100_000, 3), columns=[\"A\", \"B\", \"C\"], dtype=dtype\n        )\n        self.df[\"id1\"] = pd.Series(np.random.randint(0, 10, 10000))\n        self.df[\"id2\"] = pd.Series(np.random.randint(100, 1000, 10000))", "min_run_count": 2, "name": "reshape.Melt.time_melt_dataframe", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "22a1727a0e67859dc0ec65b547a3d44f8c9725863c959eba27153fb0d8f66d4c", "warmup_time": -1}, "reshape.Pivot.time_reshape_pivot_time_series": {"code": "class Pivot:\n    def time_reshape_pivot_time_series(self):\n        self.df.pivot(index=\"date\", columns=\"variable\", values=\"value\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pivot:\n    def setup(self):\n        N = 10000\n        index = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        data = {\n            \"value\": np.random.randn(N * 50),\n            \"variable\": np.arange(50).repeat(N),\n            \"date\": np.tile(index.values, 50),\n        }\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "reshape.Pivot.time_reshape_pivot_time_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7466faab8bdadd61fa94c30f9a91cca68cb993c7d0bcf34c64f2b9a31994d7b8", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table": {"code": "class PivotTable:\n    def time_pivot_table(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "03f1827427df23f7923b9d2b4ff8790a8896570fbbccf7ccd79cda77f3b29fb6", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_agg": {"code": "class PivotTable:\n    def time_pivot_table_agg(self):\n        self.df.pivot_table(\n            index=\"key1\", columns=[\"key2\", \"key3\"], aggfunc=[\"sum\", \"mean\"]\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_agg", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e31596884db26ad8a96fbca432b50937254b59d0e4139cefbc2d930b6835d13b", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical": {"code": "class PivotTable:\n    def time_pivot_table_categorical(self):\n        self.df2.pivot_table(\n            index=\"col1\", values=\"col3\", columns=\"col2\", aggfunc=\"sum\", fill_value=0\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d8d0ae28f6fb18e72ed98a04ed6ec36ca77902bf4ebba37acf33e7df0fd6ca21", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical_observed": {"code": "class PivotTable:\n    def time_pivot_table_categorical_observed(self):\n        self.df2.pivot_table(\n            index=\"col1\",\n            values=\"col3\",\n            columns=\"col2\",\n            aggfunc=\"sum\",\n            fill_value=0,\n            observed=True,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical_observed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "06e19f29bad0004311d0422c04884a94e54d725e383443b1c5476d40e62a64df", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_margins": {"code": "class PivotTable:\n    def time_pivot_table_margins(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_margins", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0afefd1f2578cc7e47b9f9ef6791eac3f77b8ec807c5725b2ef687d228c99241", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_margins_only_column": {"code": "class PivotTable:\n    def time_pivot_table_margins_only_column(self):\n        self.df.pivot_table(columns=[\"key1\", \"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_margins_only_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "21e105d206932a8572d6c9e47758f4bc5a6ee77cb384c346e1d145fd2bb9bbfe", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_stack": {"code": "class ReshapeExtensionDtype:\n    def time_stack(self, dtype):\n        self.df.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_stack", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "71f50c1837c91a2ab25587dc3675ead2ce4cc6662b0442f0b8aabc7677405330", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_transpose": {"code": "class ReshapeExtensionDtype:\n    def time_transpose(self, dtype):\n        self.df.T\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_transpose", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "de98fb88e477fc5bd7f6b256e4a9b735100ef3450027db1f429fee20265ecde3", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_unstack_fast": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_fast(self, dtype):\n        # last level -> doesn't have to make copies\n        self.ser.unstack(\"bar\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_unstack_fast", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bfb452390fbd0c8f64654a5fa654ae3cba890d1d7668880d51f418f1c2ea0059", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_unstack_slow": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_slow(self, dtype):\n        # first level -> must make copies\n        self.ser.unstack(\"foo\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_unstack_slow", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "19cf929eb6cc86687d322f9c25207cd480041be2aafd11fe37cf4815e5be49c8", "warmup_time": -1}, "reshape.ReshapeMaskedArrayDtype.time_stack": {"code": "class ReshapeExtensionDtype:\n    def time_stack(self, dtype):\n        self.df.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeMaskedArrayDtype.time_stack", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1eeaeec84de4310b0b92095ad52b62f6c1ec17563f5cc993db36df1fc9f1bc86", "warmup_time": -1}, "reshape.ReshapeMaskedArrayDtype.time_transpose": {"code": "class ReshapeExtensionDtype:\n    def time_transpose(self, dtype):\n        self.df.T\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeMaskedArrayDtype.time_transpose", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bb124b2b5f9cfebdc4507a7ef8c75f1112caf5fa34c040451cb2ef3ad5f0040e", "warmup_time": -1}, "reshape.ReshapeMaskedArrayDtype.time_unstack_fast": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_fast(self, dtype):\n        # last level -> doesn't have to make copies\n        self.ser.unstack(\"bar\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeMaskedArrayDtype.time_unstack_fast", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a267ffdd7317e4df0f6a83ebde82619df89c2a8e4737cf4d9563453b9b18ddc0", "warmup_time": -1}, "reshape.ReshapeMaskedArrayDtype.time_unstack_slow": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_slow(self, dtype):\n        # first level -> must make copies\n        self.ser.unstack(\"foo\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeMaskedArrayDtype.time_unstack_slow", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e11dd322f7d3a2fa04944bb0e94c949b1f27eb0b27cef49390542c77bc015bc9", "warmup_time": -1}, "reshape.SimpleReshape.time_stack": {"code": "class SimpleReshape:\n    def time_stack(self):\n        self.udf.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_stack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a6d770036abb815e9c3a58b1e211a9731ce733599757aa8153db703496818011", "warmup_time": -1}, "reshape.SimpleReshape.time_unstack": {"code": "class SimpleReshape:\n    def time_unstack(self):\n        self.df.unstack(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_unstack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee883fcccbd0ef7d6c8bb60b550c2de5d2bc5b98458113c63b9f23a2f652e873", "warmup_time": -1}, "reshape.SparseIndex.time_unstack": {"code": "class SparseIndex:\n    def time_unstack(self):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseIndex:\n    def setup(self):\n        NUM_ROWS = 1000\n        self.df = DataFrame(\n            {\n                \"A\": np.random.randint(50, size=NUM_ROWS),\n                \"B\": np.random.randint(50, size=NUM_ROWS),\n                \"C\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"D\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"E\": np.random.randint(10, size=NUM_ROWS),\n                \"F\": np.random.randn(NUM_ROWS),\n            }\n        )\n        self.df = self.df.set_index([\"A\", \"B\", \"C\", \"D\", \"E\"])", "min_run_count": 2, "name": "reshape.SparseIndex.time_unstack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "41381253268a24b9d6ee1f0c20e6602a24860a05d0e483f11a992776103b51be", "warmup_time": -1}, "reshape.Unstack.time_full_product": {"code": "class Unstack:\n    def time_full_product(self, dtype):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(dict(enumerate(values)), index, columns)\n    \n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_full_product", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b28492d9054e9dc56a19db0f8cd8638ff873d22ea2faeb49de210add68896584", "warmup_time": -1}, "reshape.Unstack.time_without_last_row": {"code": "class Unstack:\n    def time_without_last_row(self, dtype):\n        self.df2.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(dict(enumerate(values)), index, columns)\n    \n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_without_last_row", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0c546381b8ec02b2e96bf78f998f4f2a191ac77f0045346909d25e8b88f3e1e1", "warmup_time": -1}, "reshape.WideToLong.time_wide_to_long_big": {"code": "class WideToLong:\n    def time_wide_to_long_big(self):\n        wide_to_long(self.df, self.letters, i=\"id\", j=\"year\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WideToLong:\n    def setup(self):\n        nyrs = 20\n        nidvars = 20\n        N = 5000\n        self.letters = list(\"ABCD\")\n        yrvars = [\n            letter + str(num)\n            for letter, num in product(self.letters, range(1, nyrs + 1))\n        ]\n        columns = [str(i) for i in range(nidvars)] + yrvars\n        self.df = DataFrame(np.random.randn(N, nidvars + len(yrvars)), columns=columns)\n        self.df[\"id\"] = self.df.index", "min_run_count": 2, "name": "reshape.WideToLong.time_wide_to_long_big", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "38b6ee0820735de02ad64b598a14cbe298769f714808e915411fde11e73f8598", "warmup_time": -1}, "rolling.Apply.time_rolling": {"code": "class Apply:\n    def time_rolling(self, constructor, window, dtype, function, raw):\n        self.roll.apply(function, raw=raw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, constructor, window, dtype, function, raw):\n        N = 10**3\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Apply.time_rolling", "number": 0, "param_names": ["constructor", "window", "dtype", "function", "raw"], "params": [["'DataFrame'", "'Series'"], ["3", "300"], ["'int'", "'float'"], ["<built-in function sum>", "<function sum>", "<function Apply.<lambda>>"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "871accb43f689bd0f04df4d9d50bb65a4d3403027f3ff0b5e49789cf4cf80a70", "warmup_time": -1}, "rolling.EWMMethods.time_ewm": {"code": "class EWMMethods:\n    def time_ewm(self, constructor, kwargs_method, dtype):\n        getattr(self.ewm, self.method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass EWMMethods:\n    def setup(self, constructor, kwargs_method, dtype):\n        N = 10**5\n        kwargs, method = kwargs_method\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.method = method\n        self.ewm = getattr(pd, constructor)(arr).ewm(**kwargs)", "min_run_count": 2, "name": "rolling.EWMMethods.time_ewm", "number": 0, "param_names": ["constructor", "kwargs_method", "dtype"], "params": [["'DataFrame'", "'Series'"], ["({'halflife': 10}, 'mean')", "({'halflife': 10}, 'std')", "({'halflife': 1000}, 'mean')", "({'halflife': 1000}, 'std')", "({'halflife': '1 Day', 'times': DatetimeIndex(['1900-01-01 00:00:00', '1900-01-01 00:00:23',\n               '1900-01-01 00:00:46', '1900-01-01 00:01:09',\n               '1900-01-01 00:01:32', '1900-01-01 00:01:55',\n               '1900-01-01 00:02:18', '1900-01-01 00:02:41',\n               '1900-01-01 00:03:04', '1900-01-01 00:03:27',\n               ...\n               '1900-01-27 14:49:30', '1900-01-27 14:49:53',\n               '1900-01-27 14:50:16', '1900-01-27 14:50:39',\n               '1900-01-27 14:51:02', '1900-01-27 14:51:25',\n               '1900-01-27 14:51:48', '1900-01-27 14:52:11',\n               '1900-01-27 14:52:34', '1900-01-27 14:52:57'],\n              dtype='datetime64[ns]', length=100000, freq='23s')}, 'mean')"], ["'int'", "'float'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "44cf214a28e488cb440a036e0178da2f3f3ea426055c4f0952f4fdedbd55eff8", "warmup_time": -1}, "rolling.ForwardWindowMethods.peakmem_rolling": {"code": "class ForwardWindowMethods:\n    def peakmem_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)", "name": "rolling.ForwardWindowMethods.peakmem_rolling", "param_names": ["constructor", "window_size", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum'"]], "type": "peakmemory", "unit": "bytes", "version": "9ac3a0bf8c769f331e8cd492fdbc30f03ab699681211d932253349936b2ec964"}, "rolling.ForwardWindowMethods.time_rolling": {"code": "class ForwardWindowMethods:\n    def time_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)", "min_run_count": 2, "name": "rolling.ForwardWindowMethods.time_rolling", "number": 0, "param_names": ["constructor", "window_size", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6dfc98201296ab54c1be4d985a80b8f835a8c4b225f3719c6869e418405eac45", "warmup_time": -1}, "rolling.Groupby.time_method": {"code": "class Groupby:\n    def time_method(self, method, window_kwargs):\n        getattr(self.groupby_window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groupby:\n    def setup(self, method, window_kwargs):\n        N = 1000\n        window, kwargs = window_kwargs\n        df = pd.DataFrame(\n            {\n                \"A\": [str(i) for i in range(N)] * 10,\n                \"B\": list(range(N)) * 10,\n            }\n        )\n        if isinstance(kwargs.get(\"window\", None), str):\n            df.index = pd.date_range(start=\"1900-01-01\", freq=\"1min\", periods=N * 10)\n        self.groupby_window = getattr(df.groupby(\"A\"), window)(**kwargs)", "min_run_count": 2, "name": "rolling.Groupby.time_method", "number": 0, "param_names": ["param1", "param2"], "params": [["'sum' (0)", "'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum' (1)"], ["('rolling', {'window': 2})", "('rolling', {'window': '30s'})", "('expanding', {})"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1f0550f768119c2d4aa887f71e8c464ca76822e8f39b17def026e6701ff98501", "warmup_time": -1}, "rolling.GroupbyEWM.time_groupby_method": {"code": "class GroupbyEWM:\n    def time_groupby_method(self, method):\n        getattr(self.gb_ewm, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWM:\n    def setup(self, method):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)", "min_run_count": 2, "name": "rolling.GroupbyEWM.time_groupby_method", "number": 0, "param_names": ["method"], "params": [["'var'", "'std'", "'cov'", "'corr'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ad6a51326eb042f1ee88615e2048d6bc92adf02dfecb26d43ba24834f3c61150", "warmup_time": -1}, "rolling.GroupbyEWMEngine.time_groupby_mean": {"code": "class GroupbyEWMEngine:\n    def time_groupby_mean(self, engine):\n        self.gb_ewm.mean(engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWMEngine:\n    def setup(self, engine):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)", "min_run_count": 2, "name": "rolling.GroupbyEWMEngine.time_groupby_mean", "number": 0, "param_names": ["engine"], "params": [["'cython'", "'numba'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d69e116193dcb411ee111f0a146b8d596d2d73236f686eb16ef4e9221bd2bd52", "warmup_time": -1}, "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation": {"code": "class GroupbyLargeGroups:\n    def time_rolling_multiindex_creation(self):\n        self.df.groupby(\"A\").rolling(3).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyLargeGroups:\n    def setup(self):\n        N = 100000\n        self.df = pd.DataFrame({\"A\": [1, 2] * (N // 2), \"B\": np.random.randn(N)})", "min_run_count": 2, "name": "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "31a34a6b020d62e4c7b595aeb804a131f135c1fd1497365577c3bbf2fe7c511c", "warmup_time": -1}, "rolling.Methods.peakmem_method": {"code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10**5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)", "name": "rolling.Methods.peakmem_method", "param_names": ["constructor", "window_kwargs", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["('rolling', {'window': 10})", "('rolling', {'window': 1000})", "('expanding', {})"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'", "'nunique'"]], "type": "peakmemory", "unit": "bytes", "version": "0c01a9273a20049fc5dfd09ead608a5e199977644711bc856c0dbaf525d6d0d5"}, "rolling.Methods.time_method": {"code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10**5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)", "min_run_count": 2, "name": "rolling.Methods.time_method", "number": 0, "param_names": ["constructor", "window_kwargs", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["('rolling', {'window': 10})", "('rolling', {'window': 1000})", "('expanding', {})"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'", "'nunique'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5402683efd6d1e8b4bab7594be55921fa6334cec6319e73a3f3660d99df1a7a5", "warmup_time": -1}, "rolling.Pairwise.time_groupby": {"code": "class Pairwise:\n    def time_groupby(self, kwargs_window, method, pairwise):\n        getattr(self.window_group, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10**4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)", "min_run_count": 2, "name": "rolling.Pairwise.time_groupby", "number": 0, "param_names": ["window_kwargs", "method", "pairwise"], "params": [["({'window': 10}, 'rolling')", "({'window': 1000}, 'rolling')", "({}, 'expanding')"], ["'corr'", "'cov'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f1e4be4e4d441bdc8b2cebdbc678ae970eb20874fa682bb1ca41352d98a0a23e", "warmup_time": -1}, "rolling.Pairwise.time_pairwise": {"code": "class Pairwise:\n    def time_pairwise(self, kwargs_window, method, pairwise):\n        getattr(self.window, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10**4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)", "min_run_count": 2, "name": "rolling.Pairwise.time_pairwise", "number": 0, "param_names": ["window_kwargs", "method", "pairwise"], "params": [["({'window': 10}, 'rolling')", "({'window': 1000}, 'rolling')", "({}, 'expanding')"], ["'corr'", "'cov'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "315ccdf22c0f4d21fa6ee729bdd8f21c51913704006fbcdfc1f4e2500d816ef3", "warmup_time": -1}, "rolling.PeakMemFixedWindowMinMax.peakmem_fixed": {"code": "class PeakMemFixedWindowMinMax:\n    def peakmem_fixed(self, operation):\n        for x in range(5):\n            getattr(self.roll, operation)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PeakMemFixedWindowMinMax:\n    def setup(self, operation):\n        N = 10**6\n        arr = np.random.random(N)\n        self.roll = pd.Series(arr).rolling(2)", "name": "rolling.PeakMemFixedWindowMinMax.peakmem_fixed", "param_names": ["param1"], "params": [["'min'", "'max'"]], "type": "peakmemory", "unit": "bytes", "version": "b9767f691709345094cdfdc4984bb728c9e78389a22aa1bae02462af8dd67ec2"}, "rolling.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, constructor, window, dtype, percentile, interpolation):\n        self.roll.quantile(percentile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, constructor, window, dtype, percentile, interpolation):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Quantile.time_quantile", "number": 0, "param_names": ["constructor", "window", "dtype", "percentile", "param5"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f94389cbc4b3cca82ab4db4970a4acd0daa3c0fbf9cc3f230a6b7d69e841bc4f", "warmup_time": -1}, "rolling.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, constructor, window, dtype, percentile, ascending, method):\n        self.roll.rank(pct=percentile, ascending=ascending, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, window, dtype, percentile, ascending, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Rank.time_rank", "number": 0, "param_names": ["constructor", "window", "dtype", "percentile", "ascending", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["True", "False"], ["True", "False"], ["'min'", "'max'", "'average'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f02fd2586b260b9f5ab15f641e1279b2d47c07b805c6059cdf5f0e5f424a5b6c", "warmup_time": -1}, "rolling.TableMethod.time_apply": {"code": "class TableMethod:\n    def time_apply(self, method):\n        self.df.rolling(2, method=method).apply(\n            table_method_func, raw=True, engine=\"numba\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))", "min_run_count": 2, "name": "rolling.TableMethod.time_apply", "number": 0, "param_names": ["method"], "params": [["'single'", "'table'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "30880eb453b9d41a953d95fc25ba24088b0a48b94ab49ea12406e4abc0b976ac", "warmup_time": -1}, "rolling.TableMethod.time_ewm_mean": {"code": "class TableMethod:\n    def time_ewm_mean(self, method):\n        self.df.ewm(1, method=method).mean(engine=\"numba\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))", "min_run_count": 2, "name": "rolling.TableMethod.time_ewm_mean", "number": 0, "param_names": ["method"], "params": [["'single'", "'table'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "446dcdc251bda1381a3cf943305e8a6a22ea15ca4513ec2dc7454a8692ab99ad", "warmup_time": -1}, "rolling.VariableWindowMethods.peakmem_method": {"code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)", "name": "rolling.VariableWindowMethods.peakmem_method", "param_names": ["constructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "type": "peakmemory", "unit": "bytes", "version": "7b52c11d6e1b242c90ddaa78b88fb15e12a3676d5faf98af9807087e0243c3e8"}, "rolling.VariableWindowMethods.time_method": {"code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)", "min_run_count": 2, "name": "rolling.VariableWindowMethods.time_method", "number": 0, "param_names": ["constructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f5b8129df64b00950a4dbfbcf89e760f149ee8ffb5df1d544c0b87cceb86c41b", "warmup_time": -1}, "series_methods.All.time_all": {"code": "class All:\n    def time_all(self, N, case, dtype):\n        self.s.all()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass All:\n    def setup(self, N, case, dtype):\n        val = case != \"fast\"\n        self.s = Series([val] * N, dtype=dtype)", "min_run_count": 2, "name": "series_methods.All.time_all", "number": 0, "param_names": ["N", "case", "dtype"], "params": [["1000", "1000000"], ["'fast'", "'slow'"], ["'bool'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "45f86547ce03394cb299551fd376fc8a763de3a613d475e1b9b2e71852b8c4f9", "warmup_time": -1}, "series_methods.Any.time_any": {"code": "class Any:\n    def time_any(self, N, case, dtype):\n        self.s.any()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Any:\n    def setup(self, N, case, dtype):\n        val = case == \"fast\"\n        self.s = Series([val] * N, dtype=dtype)", "min_run_count": 2, "name": "series_methods.Any.time_any", "number": 0, "param_names": ["N", "case", "dtype"], "params": [["1000", "1000000"], ["'fast'", "'slow'"], ["'bool'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2e53bbc75704910ed273c169cc5a41b3037436503911ac1dd4fa9a62a7261c44", "warmup_time": -1}, "series_methods.Clip.time_clip": {"code": "class Clip:\n    def time_clip(self, n):\n        self.s.clip(0, 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, n):\n        self.s = Series(np.random.randn(n))", "min_run_count": 2, "name": "series_methods.Clip.time_clip", "number": 0, "param_names": ["n"], "params": [["50", "1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8179a96510fbe69a1326ac0c3cdb1466db7b5719d20b59a243564362d9b56a4a", "warmup_time": -1}, "series_methods.ClipDt.time_clip": {"code": "class ClipDt:\n    def time_clip(self):\n        self.s.clip(upper=self.clipper_dt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ClipDt:\n    def setup(self):\n        dr = date_range(\"20220101\", periods=100_000, freq=\"s\", tz=\"UTC\")\n        self.clipper_dt = dr[0:1_000].repeat(100)\n        self.s = Series(dr)", "min_run_count": 2, "name": "series_methods.ClipDt.time_clip", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5e24ee89ae59664da88494ca3070b3c7d1a6c1fe48429471f94661dbff272408", "warmup_time": -1}, "series_methods.Dir.time_dir_strings": {"code": "class Dir:\n    def time_dir_strings(self):\n        dir(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dir:\n    def setup(self):\n        self.s = Series(index=Index([f\"i-{i}\" for i in range(10000)], dtype=object))", "min_run_count": 2, "name": "series_methods.Dir.time_dir_strings", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7d61c7dcd41b858046d7576d5e7a6ab11653a5972d6c06e62c3537f02301c81e", "warmup_time": -1}, "series_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, dtype):\n        self.s.dropna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, dtype):\n        N = 10**6\n        data = {\n            \"int\": np.random.randint(1, 10, N),\n            \"datetime\": date_range(\"2000-01-01\", freq=\"s\", periods=N),\n        }\n        self.s = Series(data[dtype])\n        if dtype == \"datetime\":\n            self.s[np.random.randint(1, N, 100)] = NaT", "min_run_count": 2, "name": "series_methods.Dropna.time_dropna", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d04113f96c3ce4c734ec801a839150033050d2312e0df5c6763e3e5093c05792", "warmup_time": -1}, "series_methods.Fillna.time_bfill": {"code": "class Fillna:\n    def time_bfill(self, dtype):\n        self.ser.bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value", "min_run_count": 2, "name": "series_methods.Fillna.time_bfill", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns]'", "'float32'", "'float64'", "'Float64'", "'Int64'", "'int64[pyarrow]'", "'string'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "956fc00ef50dc099cc2bf7e02378c6f7503e72c339b42237bafe8c85c2981f61", "warmup_time": -1}, "series_methods.Fillna.time_ffill": {"code": "class Fillna:\n    def time_ffill(self, dtype):\n        self.ser.ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value", "min_run_count": 2, "name": "series_methods.Fillna.time_ffill", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns]'", "'float32'", "'float64'", "'Float64'", "'Int64'", "'int64[pyarrow]'", "'string'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e625516727ac9a43cf480c4279e94bf2cd7ed62ea4a68ac86fe8c6e10fc4ef81", "warmup_time": -1}, "series_methods.Fillna.time_fillna": {"code": "class Fillna:\n    def time_fillna(self, dtype):\n        self.ser.fillna(value=self.fill_value)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value", "min_run_count": 2, "name": "series_methods.Fillna.time_fillna", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns]'", "'float32'", "'float64'", "'Float64'", "'Int64'", "'int64[pyarrow]'", "'string'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "02aebbbe16436923ebd160a95e13d6289dd497f1890f5fca503fa6150f330da5", "warmup_time": -1}, "series_methods.Iter.time_iter": {"code": "class Iter:\n    def time_iter(self, dtype):\n        for v in self.s:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iter:\n    def setup(self, dtype):\n        N = 10**5\n        if dtype in [\"bool\", \"boolean\"]:\n            data = np.repeat([True, False], N // 2)\n        elif dtype in [\"int64\", \"Int64\"]:\n            data = np.arange(N)\n        elif dtype in [\"float64\", \"Float64\"]:\n            data = np.random.randn(N)\n        elif dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(data, dtype=dtype)", "min_run_count": 2, "name": "series_methods.Iter.time_iter", "number": 0, "param_names": ["dtype"], "params": [["'bool'", "'boolean'", "'int64'", "'Int64'", "'float64'", "'Float64'", "'datetime64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8d4391387859c36e6cb82fe13b7d67993a73ba3541e8bc6e6e2c3d8c28a11a42", "warmup_time": -1}, "series_methods.Map.time_map": {"code": "class Map:\n    def time_map(self, mapper, dtype, na_action):\n        self.s.map(self.map_data, na_action=na_action)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Map:\n    def setup(self, mapper, dtype, na_action):\n        map_size = 1000\n        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\n    \n        # construct mapper\n        if mapper == \"Series\":\n            self.map_data = map_data\n        elif mapper == \"dict\":\n            self.map_data = map_data.to_dict()\n        elif mapper == \"lambda\":\n            map_dict = map_data.to_dict()\n            self.map_data = lambda x: map_dict[x]\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)", "min_run_count": 2, "name": "series_methods.Map.time_map", "number": 0, "param_names": ["mapper", "dtype", "na_action"], "params": [["'dict'", "'Series'", "'lambda'"], ["'object'", "'category'", "'int'"], ["None", "'ignore'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "823a6d9b510f81584335c722e2cf02561c44811ceea86875d37e212bfb7e71ad", "warmup_time": -1}, "series_methods.Mode.time_mode": {"code": "class Mode:\n    def time_mode(self, N, dtype):\n        self.s.mode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Mode:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)", "min_run_count": 2, "name": "series_methods.Mode.time_mode", "number": 0, "param_names": ["N", "dtype"], "params": [["1000", "10000", "100000"], ["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "293b41b446df29f5e77e19b14540c5af87a0168e4710d64dbb12037435ef4202", "warmup_time": -1}, "series_methods.ModeObjectDropNAFalse.time_mode": {"code": "class ModeObjectDropNAFalse:\n    def time_mode(self, N):\n        self.s.mode(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ModeObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")", "min_run_count": 2, "name": "series_methods.ModeObjectDropNAFalse.time_mode", "number": 0, "param_names": ["N"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e2488dac5c2fdbcfe29cc7e9e32e32b33227ebda39debbcf7e35dbc59aea3f4a", "warmup_time": -1}, "series_methods.NSort.time_nlargest": {"code": "class NSort:\n    def time_nlargest(self, keep):\n        self.s.nlargest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nlargest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b2d7318a10dc119adee969b91b3e8224c14af04542e29aea061c0c549cfbe264", "warmup_time": -1}, "series_methods.NSort.time_nsmallest": {"code": "class NSort:\n    def time_nsmallest(self, keep):\n        self.s.nsmallest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nsmallest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8b1f411ecb151ecb227a739c4be77e69ccde5647917c3adb93dca8fbcae978e1", "warmup_time": -1}, "series_methods.NanOps.time_func": {"code": "class NanOps:\n    def time_func(self, func, N, dtype):\n        self.func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NanOps:\n    def setup(self, func, N, dtype):\n        if func == \"argmax\" and dtype in {\"Int64\", \"boolean\"}:\n            # Skip argmax for nullable int since this doesn't work yet (GH-24382)\n            raise NotImplementedError\n        self.s = Series(np.ones(N), dtype=dtype)\n        self.func = getattr(self.s, func)", "min_run_count": 2, "name": "series_methods.NanOps.time_func", "number": 0, "param_names": ["func", "N", "dtype"], "params": [["'var'", "'mean'", "'median'", "'max'", "'min'", "'sum'", "'std'", "'sem'", "'argmax'", "'skew'", "'kurt'", "'prod'"], ["1000", "1000000"], ["'int8'", "'int32'", "'int64'", "'float64'", "'Int64'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4e7a30930490c8c97bb09a4b0301621652f43531dbe206b758cd0b8a25cde577", "warmup_time": -1}, "series_methods.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, dtype):\n        self.s.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(0, 1000, size=100000), dtype=dtype)", "min_run_count": 2, "name": "series_methods.Rank.time_rank", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cf912b236884d1fded0314151a2a53dce2cf23529a155f2103666ee9d002bff7", "warmup_time": -1}, "series_methods.Replace.peakmem_replace_dict": {"code": "class Replace:\n    def peakmem_replace_dict(self, num_to_replace):\n        self.ser.replace(self.replace_dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "name": "series_methods.Replace.peakmem_replace_dict", "param_names": ["num_to_replace"], "params": [["100", "1000"]], "type": "peakmemory", "unit": "bytes", "version": "82dfd71ffd244c5b1205af03154e4e4547227fe2551d07660db4b7656efdac03"}, "series_methods.Replace.peakmem_replace_list": {"code": "class Replace:\n    def peakmem_replace_list(self, num_to_replace):\n        self.ser.replace(self.to_replace_list, self.values_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "name": "series_methods.Replace.peakmem_replace_list", "param_names": ["num_to_replace"], "params": [["100", "1000"]], "type": "peakmemory", "unit": "bytes", "version": "11d050f21303f90f57bfaf0eef0535a9459a8ef82e29053f7e1a7090ef4b226c"}, "series_methods.Replace.time_replace_dict": {"code": "class Replace:\n    def time_replace_dict(self, num_to_replace):\n        self.ser.replace(self.replace_dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "min_run_count": 2, "name": "series_methods.Replace.time_replace_dict", "number": 0, "param_names": ["num_to_replace"], "params": [["100", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "61cb7f463d734dcaf1edbd292af75ede0994c5b2aed3311d7807aac689771d2d", "warmup_time": -1}, "series_methods.Replace.time_replace_list": {"code": "class Replace:\n    def time_replace_list(self, num_to_replace):\n        self.ser.replace(self.to_replace_list, self.values_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "min_run_count": 2, "name": "series_methods.Replace.time_replace_list", "number": 0, "param_names": ["num_to_replace"], "params": [["100", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bb772d4b5c8a9a6917a2f3b97f69478c55a246981d6e2350802c926011741b0a", "warmup_time": -1}, "series_methods.SearchSorted.time_searchsorted": {"code": "class SearchSorted:\n    def time_searchsorted(self, dtype):\n        key = \"2\" if dtype == \"str\" else 2\n        self.s.searchsorted(key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self, dtype):\n        N = 10**5\n        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\n        self.s = Series(data)", "min_run_count": 2, "name": "series_methods.SearchSorted.time_searchsorted", "number": 0, "param_names": ["dtype"], "params": [["'int8'", "'int16'", "'int32'", "'int64'", "'uint8'", "'uint16'", "'uint32'", "'uint64'", "'float16'", "'float32'", "'float64'", "'str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "323b35cab3b64f29d4f839af05bd6b12ad82170fc35bfee718e2e9d52b7fd61e", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor_dict": {"code": "class SeriesConstructor:\n    def time_constructor_dict(self):\n        Series(data=self.data, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e71f5d93471f71f757d994db2550ae233bb7f18e13e21aca22dafa53f833fb4e", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor_no_data": {"code": "class SeriesConstructor:\n    def time_constructor_no_data(self):\n        Series(data=None, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor_no_data", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c55e26955fd47febad07ecd223347b24a08ae3454ba16023ad6bb73ec4aaf43a", "warmup_time": -1}, "series_methods.SeriesGetattr.time_series_datetimeindex_repr": {"code": "class SeriesGetattr:\n    def time_series_datetimeindex_repr(self):\n        getattr(self.s, \"a\", None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesGetattr:\n    def setup(self):\n        self.s = Series(1, index=date_range(\"2012-01-01\", freq=\"s\", periods=10**6))", "min_run_count": 2, "name": "series_methods.SeriesGetattr.time_series_datetimeindex_repr", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a1c5e293ae62939d93cd88e2ea4047f3f42f8c318db822e2539805b7e16b72a7", "warmup_time": -1}, "series_methods.ToFrame.time_to_frame": {"code": "class ToFrame:\n    def time_to_frame(self, dtype, name):\n        self.ser.to_frame(name)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToFrame:\n    def setup(self, dtype, name):\n        arr = np.arange(10**5)\n        ser = Series(arr, dtype=dtype)\n        self.ser = ser", "min_run_count": 2, "name": "series_methods.ToFrame.time_to_frame", "number": 0, "param_names": ["dtype", "name"], "params": [["'int64'", "'datetime64[ns]'", "'category'", "'Int64'"], ["None", "'foo'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9837bd38099b9a8813a9b22a59b46e9e9afd7614361947eb24b302192b97eb20", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy": {"code": "class ToNumpy:\n    def time_to_numpy(self):\n        self.ser.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0ffdc5fb3536043b1cc8a7e1f7f402cf3fe4a601504d03eef9003017585b1037", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy_copy": {"code": "class ToNumpy:\n    def time_to_numpy_copy(self):\n        self.ser.to_numpy(copy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d702db82db43d7f93cd41a3786618d602a7938313ff783cfc0a836026c2997dd", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy_double_copy": {"code": "class ToNumpy:\n    def time_to_numpy_double_copy(self):\n        self.ser.to_numpy(dtype=\"float64\", copy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy_double_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5ef7c18c63ba7e87e2f511e1b4eb1466a36198dbd621bc47d2c7ac5cde81682d", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy_float_with_nan": {"code": "class ToNumpy:\n    def time_to_numpy_float_with_nan(self):\n        self.ser.to_numpy(dtype=\"float64\", na_value=np.nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy_float_with_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d62d4317f22ebf4486d4d6a4902963ccadd2a4c3a1ef2dd8cf1e8e4413545f18", "warmup_time": -1}, "series_methods.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, N, dtype):\n        self.s.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)", "min_run_count": 2, "name": "series_methods.ValueCounts.time_value_counts", "number": 0, "param_names": ["N", "dtype"], "params": [["1000", "10000", "100000"], ["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1f5bd690b4a0f777032140a9e0c26ed03c57e4402268b2e8a64b3e1a88d4ee63", "warmup_time": -1}, "series_methods.ValueCountsEA.time_value_counts": {"code": "class ValueCountsEA:\n    def time_value_counts(self, N, dropna):\n        self.s.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsEA:\n    def setup(self, N, dropna):\n        self.s = Series(np.random.randint(0, N, size=10 * N), dtype=\"Int64\")\n        self.s.loc[1] = NA", "min_run_count": 2, "name": "series_methods.ValueCountsEA.time_value_counts", "number": 0, "param_names": ["N", "dropna"], "params": [["1000", "10000", "100000"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b1c2f96329a2881dd15f3586facaa30e4405bf239449cae6534cde266ed71cd4", "warmup_time": -1}, "series_methods.ValueCountsObjectDropNAFalse.time_value_counts": {"code": "class ValueCountsObjectDropNAFalse:\n    def time_value_counts(self, N):\n        self.s.value_counts(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")", "min_run_count": 2, "name": "series_methods.ValueCountsObjectDropNAFalse.time_value_counts", "number": 0, "param_names": ["N"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a95ddcf5298c1d0d3e53729949f04ee80696bd4b75829dc18ba02781f93d57eb", "warmup_time": -1}, "sparse.Arithmetic.time_add": {"code": "class Arithmetic:\n    def time_add(self, dense_proportion, fill_value):\n        self.array1 + self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_add", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "de0c48747f8d85c11b89324f25d19e454599ce8ea41d8a20d4ad622ee0df72f2", "warmup_time": -1}, "sparse.Arithmetic.time_divide": {"code": "class Arithmetic:\n    def time_divide(self, dense_proportion, fill_value):\n        self.array1 / self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_divide", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3144ab0a952cbf5c353d0326f3901df201f82d17b53a4384714904cb31a1d650", "warmup_time": -1}, "sparse.Arithmetic.time_intersect": {"code": "class Arithmetic:\n    def time_intersect(self, dense_proportion, fill_value):\n        self.array1.sp_index.intersect(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_intersect", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7ac983ea31ec4919e8b0a02237314df70f5fc22fccdc3f2873c848da78bf7bf1", "warmup_time": -1}, "sparse.Arithmetic.time_make_union": {"code": "class Arithmetic:\n    def time_make_union(self, dense_proportion, fill_value):\n        self.array1.sp_index.make_union(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_make_union", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "024b326e3d80e2aa19a052c3e01a3a543974a28c12de2b047b91eb1b4a166106", "warmup_time": -1}, "sparse.ArithmeticBlock.time_addition": {"code": "class ArithmeticBlock:\n    def time_addition(self, fill_value):\n        self.arr1 + self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_addition", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "23ca7b349bf4efc6f2264729829fecf63394a0b3c46d61c3f2259d925bb9fc8f", "warmup_time": -1}, "sparse.ArithmeticBlock.time_division": {"code": "class ArithmeticBlock:\n    def time_division(self, fill_value):\n        self.arr1 / self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_division", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "642210e7c27c272426725acf65d9abba4f9ef4960d2f195e11b7a83598035d72", "warmup_time": -1}, "sparse.ArithmeticBlock.time_intersect": {"code": "class ArithmeticBlock:\n    def time_intersect(self, fill_value):\n        self.arr2.sp_index.intersect(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_intersect", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "163f2bc776313f35b5c130a63fa439494f45003c8ed9ad3fbf8d319b3d47d43f", "warmup_time": -1}, "sparse.ArithmeticBlock.time_make_union": {"code": "class ArithmeticBlock:\n    def time_make_union(self, fill_value):\n        self.arr1.sp_index.make_union(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_make_union", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7d3b3e09ca0bfcd7880498366bd319799da49101f951ebee8cac1a364a829ace", "warmup_time": -1}, "sparse.FromCoo.time_sparse_series_from_coo": {"code": "class FromCoo:\n    def time_sparse_series_from_coo(self):\n        Series.sparse.from_coo(self.matrix)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromCoo:\n    def setup(self):\n        self.matrix = scipy.sparse.coo_matrix(\n            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\n        )", "min_run_count": 2, "name": "sparse.FromCoo.time_sparse_series_from_coo", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "195924096fa77c5284cc4c2886c3e4e1ec58441bb83c1afe52ee2d94f9987a1a", "warmup_time": -1}, "sparse.GetItem.time_integer_indexing": {"code": "class GetItem:\n    def time_integer_indexing(self):\n        self.sp_arr[78]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)", "min_run_count": 2, "name": "sparse.GetItem.time_integer_indexing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "33a91e68a6e5a68dc11115130afb1282d75e72c695768deefdefa5cd05f90191", "warmup_time": -1}, "sparse.GetItem.time_slice": {"code": "class GetItem:\n    def time_slice(self):\n        self.sp_arr[1:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)", "min_run_count": 2, "name": "sparse.GetItem.time_slice", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b5ccb973e1258c02d5f387766bf0fea6895662936594235434c58e2ab78122e6", "warmup_time": -1}, "sparse.GetItemMask.time_mask": {"code": "class GetItemMask:\n    def time_mask(self, fill_value):\n        self.sp_arr[self.sp_b_arr]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemMask:\n    def setup(self, fill_value):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)\n        b_arr = np.full(shape=N, fill_value=fill_value, dtype=np.bool_)\n        fv_inds = np.unique(\n            np.random.randint(low=0, high=N - 1, size=int(N * d), dtype=np.int32)\n        )\n        b_arr[fv_inds] = True if pd.isna(fill_value) else not fill_value\n        self.sp_b_arr = SparseArray(b_arr, dtype=np.bool_, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.GetItemMask.time_mask", "number": 0, "param_names": ["fill_value"], "params": [["True", "False", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "faec0e7113d63984cae0b03f7857c1d88a455a72fd5f1dd15f082e047f8139c2", "warmup_time": -1}, "sparse.MinMax.time_min_max": {"code": "class MinMax:\n    def time_min_max(self, func, fill_value):\n        getattr(self.sp_arr, func)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MinMax:\n    def setup(self, func, fill_value):\n        N = 1_000_000\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.MinMax.time_min_max", "number": 0, "param_names": ["func", "fill_value"], "params": [["'min'", "'max'"], ["0.0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5666067aa9bdd3647031cbff0f601ab81231b8c4dc791adc44067a9f361d169a", "warmup_time": -1}, "sparse.SparseArrayConstructor.time_sparse_array": {"code": "class SparseArrayConstructor:\n    def time_sparse_array(self, dense_proportion, fill_value, dtype):\n        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseArrayConstructor:\n    def setup(self, dense_proportion, fill_value, dtype):\n        N = 10**6\n        self.array = make_array(N, dense_proportion, fill_value, dtype)", "min_run_count": 2, "name": "sparse.SparseArrayConstructor.time_sparse_array", "number": 0, "param_names": ["dense_proportion", "fill_value", "dtype"], "params": [["0.1", "0.01"], ["0", "nan"], ["<class 'numpy.int64'>", "<class 'numpy.float64'>", "<class 'object'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e55fb75aef7adab66fc35b1f00e5d38f4c21a7465625d0a1cce5873ce8096110", "warmup_time": -1}, "sparse.SparseDataFrameConstructor.time_from_scipy": {"code": "class SparseDataFrameConstructor:\n    def time_from_scipy(self):\n        pd.DataFrame.sparse.from_spmatrix(self.sparse)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.sparse = scipy.sparse.rand(N, N, 0.005)", "min_run_count": 2, "name": "sparse.SparseDataFrameConstructor.time_from_scipy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "177d56dfb0c583f7adb94c9adb8e996066558bf79bf5c7600620c4d85eac136f", "warmup_time": -1}, "sparse.SparseSeriesToFrame.time_series_to_frame": {"code": "class SparseSeriesToFrame:\n    def time_series_to_frame(self):\n        pd.DataFrame(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseSeriesToFrame:\n    def setup(self):\n        K = 50\n        N = 50001\n        rng = date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        self.series = {}\n        for i in range(1, K):\n            data = np.random.randn(N)[:-i]\n            idx = rng[:-i]\n            data[100:] = np.nan\n            self.series[i] = Series(SparseArray(data), index=idx)", "min_run_count": 2, "name": "sparse.SparseSeriesToFrame.time_series_to_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f2c3253236bf887dec28449ec4523175e3527457017bb55c9b937e6cd0911d3f", "warmup_time": -1}, "sparse.Take.time_take": {"code": "class Take:\n    def time_take(self, indices, allow_fill):\n        self.sp_arr.take(indices, allow_fill=allow_fill)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, indices, allow_fill):\n        N = 1_000_000\n        fill_value = 0.0\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Take.time_take", "number": 0, "param_names": ["indices", "allow_fill"], "params": [["array([0])", "array([    0,     1,     2, ..., 99997, 99998, 99999])", "array([-1, -1, -1, ..., -1, -1, -1])"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "de40b85a6b156eead56c80f2a8a02564cec85e5cda7f49c947f0385fc4552dbb", "warmup_time": -1}, "sparse.ToCoo.time_sparse_series_to_coo": {"code": "class ToCoo:\n    def time_sparse_series_to_coo(self, sort_labels):\n        self.ss_mult_lvl.sparse.to_coo(\n            row_levels=[0, 1], column_levels=[2, 3], sort_labels=sort_labels\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")", "min_run_count": 2, "name": "sparse.ToCoo.time_sparse_series_to_coo", "number": 0, "param_names": ["sort_labels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "30ca6ac73768cb7fe0d759bfd836f6ccc90dbdfcd666842cfe90d333c4063300", "warmup_time": -1}, "sparse.ToCoo.time_sparse_series_to_coo_single_level": {"code": "class ToCoo:\n    def time_sparse_series_to_coo_single_level(self, sort_labels):\n        self.ss_two_lvl.sparse.to_coo(sort_labels=sort_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")", "min_run_count": 2, "name": "sparse.ToCoo.time_sparse_series_to_coo_single_level", "number": 0, "param_names": ["sort_labels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9f146457117b9ef50ec361711446aad79f7c706f074b3b9d901b5536c47680c0", "warmup_time": -1}, "sparse.ToCooFrame.time_to_coo": {"code": "class ToCooFrame:\n    def time_to_coo(self):\n        self.df.sparse.to_coo()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCooFrame:\n    def setup(self):\n        N = 10000\n        k = 10\n        arr = np.zeros((N, k), dtype=float)\n        arr[0, 0] = 3.0\n        arr[12, 7] = -1.0\n        arr[0, 9] = 11.2\n        self.df = pd.DataFrame(arr, dtype=pd.SparseDtype(\"float\", fill_value=0.0))", "min_run_count": 2, "name": "sparse.ToCooFrame.time_to_coo", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "aa52b43e43b97a10066b7eb8a13b85c06203c3660e6293bf051b23418b51d48a", "warmup_time": -1}, "stat_ops.Correlation.peakmem_corr_wide": {"code": "class Correlation:\n    def peakmem_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "name": "stat_ops.Correlation.peakmem_corr_wide", "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "type": "peakmemory", "unit": "bytes", "version": "3ee8f436749f1f2d1f0a071b811c2fa8f22e5b7bfa05919d0449957533179b9a"}, "stat_ops.Correlation.time_corr": {"code": "class Correlation:\n    def time_corr(self, method):\n        self.df.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "985b3d9669fc0dfe69164a9a3e932c4cab6585326d0af33ff34da7dcfcc72ecd", "warmup_time": -1}, "stat_ops.Correlation.time_corr_series": {"code": "class Correlation:\n    def time_corr_series(self, method):\n        self.s.corr(self.s2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_series", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "15f8a4d1a6ad3002de031f6c6188e46257f89004dd83e0efb0133cda90ddfa33", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide": {"code": "class Correlation:\n    def time_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "54637cc9be24613ba7ed8eb9724167b189a287c89fc91fcc80840fa02444d657", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide_nans": {"code": "class Correlation:\n    def time_corr_wide_nans(self, method):\n        self.df_wide_nans.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide_nans", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "07c00330d5c6a030d9e77e6aaec677ed606490cdf7f574cf00748a8a8d00c6b9", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_cols": {"code": "class Correlation:\n    def time_corrwith_cols(self, method):\n        self.df.corrwith(self.df2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_cols", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5d0002de6d691b52406c99ef171a6bef8d6f9569a32c8223c1544b748f1cee3f", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_rows": {"code": "class Correlation:\n    def time_corrwith_rows(self, method):\n        self.df.corrwith(self.df2, axis=1, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_rows", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "537c1ca1a5384e46898eef91e2a713efab1b5f27bece96d73baa8c1084a319eb", "warmup_time": -1}, "stat_ops.Covariance.time_cov_series": {"code": "class Covariance:\n    def time_cov_series(self):\n        self.s.cov(self.s2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Covariance:\n    def setup(self):\n        self.s = pd.Series(np.random.randn(100000))\n        self.s2 = pd.Series(np.random.randn(100000))", "min_run_count": 2, "name": "stat_ops.Covariance.time_cov_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5127b263e3a6473e609cbc77952bf516e224e61656efd15280caf5a2bd93ac5f", "warmup_time": -1}, "stat_ops.FrameMixedDtypesOps.time_op": {"code": "class FrameMixedDtypesOps:\n    def time_op(self, op, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMixedDtypesOps:\n    def setup(self, op, axis):\n        if op in (\"sum\", \"skew\", \"kurt\", \"prod\", \"sem\", \"var\") or (\n            (op, axis)\n            in (\n                (\"mean\", 1),\n                (\"mean\", None),\n                (\"median\", 1),\n                (\"median\", None),\n                (\"std\", 1),\n                (\"std\", None),\n            )\n        ):\n            # Skipping cases where datetime aggregations are not implemented\n            raise NotImplementedError\n    \n        N = 1_000_000\n        df = pd.DataFrame(\n            {\n                \"f\": np.random.normal(0.0, 1.0, N),\n                \"i\": np.random.randint(0, N, N),\n                \"ts\": pd.date_range(start=\"1/1/2000\", periods=N, freq=\"h\"),\n            }\n        )\n    \n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameMixedDtypesOps.time_op", "number": 0, "param_names": ["op", "axis"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"], ["0", "1", "None"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "83f19b7e8442fd23c184fef4e499a97eb4a4b610ca5e20691dff8b1724a3058e", "warmup_time": -1}, "stat_ops.FrameMultiIndexOps.time_op": {"code": "class FrameMultiIndexOps:\n    def time_op(self, op):\n        self.df_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMultiIndexOps:\n    def setup(self, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        df = pd.DataFrame(np.random.randn(len(index), 4), index=index)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameMultiIndexOps.time_op", "number": 0, "param_names": ["op"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "13a0374ca338a8b54f1bd16d1ffe134ba780a1d942f5be7ac191ba76b2be4f8f", "warmup_time": -1}, "stat_ops.FrameOps.time_op": {"code": "class FrameOps:\n    def time_op(self, op, dtype, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameOps:\n    def setup(self, op, dtype, axis):\n        values = np.random.randn(100000, 4)\n        if dtype == \"Int64\":\n            values = values.astype(int)\n        df = pd.DataFrame(values).astype(dtype)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameOps.time_op", "number": 0, "param_names": ["op", "dtype", "axis"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'", "'Int64'"], ["0", "1", "None"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b07391c064482d2f0ffb065b28ce25a0cc9d57d9d0281a2d85490c669a986f7e", "warmup_time": -1}, "stat_ops.Rank.time_average_old": {"code": "class Rank:\n    def time_average_old(self, constructor, pct):\n        self.data.rank(pct=pct) / len(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_average_old", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "82f64cd32e871ed31fd99deb14e611ab16a04df9a99cf92bf1e12863d0d82bda", "warmup_time": -1}, "stat_ops.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, constructor, pct):\n        self.data.rank(pct=pct)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_rank", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f8b083c6f46cf347224b1f03549284db11f310cb7e3936a705627eddfeb01142", "warmup_time": -1}, "stat_ops.SeriesMultiIndexOps.time_op": {"code": "class SeriesMultiIndexOps:\n    def time_op(self, op):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesMultiIndexOps:\n    def setup(self, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        s = pd.Series(np.random.randn(len(index)), index=index)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesMultiIndexOps.time_op", "number": 0, "param_names": ["op"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fafe7c22ddf1ddd0aa6871d8d9537041f3e037adacdc1794d69166a0bfc9dbaa", "warmup_time": -1}, "stat_ops.SeriesOps.time_op": {"code": "class SeriesOps:\n    def time_op(self, op, dtype):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesOps:\n    def setup(self, op, dtype):\n        s = pd.Series(np.random.randn(100000)).astype(dtype)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesOps.time_op", "number": 0, "param_names": ["op", "dtype"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "32cfffab59594606bcaccdcd64c3521e5ffec20c0dcf9b1c864e4d0a6dc41bd4", "warmup_time": -1}, "strftime.BusinessHourStrftime.time_frame_offset_repr": {"code": "class BusinessHourStrftime:\n    def time_frame_offset_repr(self, nobs):\n        self.data[\"off\"].apply(repr)\n\n    def setup(self, nobs):\n        self.data = pd.DataFrame(\n            {\n                \"off\": [offsets.BusinessHour()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.BusinessHourStrftime.time_frame_offset_repr", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "a46e69099d417d6960551a9c61f7218c1c698b1a064f46cb71253c6e94b54baf", "warmup_time": -1}, "strftime.BusinessHourStrftime.time_frame_offset_str": {"code": "class BusinessHourStrftime:\n    def time_frame_offset_str(self, nobs):\n        self.data[\"off\"].apply(str)\n\n    def setup(self, nobs):\n        self.data = pd.DataFrame(\n            {\n                \"off\": [offsets.BusinessHour()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.BusinessHourStrftime.time_frame_offset_str", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "c6bd6a7c9015f044c74ec8ada5991b59b8e6811009465b189b2998771710e66c", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_formatting_custom": {"code": "class DatetimeStrftime:\n    def time_frame_date_formatting_custom(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=\"%Y---%m---%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_formatting_custom", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "d8c2ef0e234003004a808414432827b34b1314aec0c69a9322be2df115c12c28", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_formatting_default": {"code": "class DatetimeStrftime:\n    def time_frame_date_formatting_default(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_formatting_default", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "4d7dbcd663f6d27bf3c01012b2b750c048d3b893fbae2f63b59de0ff09ba544f", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_formatting_default_explicit": {"code": "class DatetimeStrftime:\n    def time_frame_date_formatting_default_explicit(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=\"%Y-%m-%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_formatting_default_explicit", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "413c43d2510bbf20e866c514a93a3d2f808f687f6cbf2c2d7fcb586332b29878", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_to_str": {"code": "class DatetimeStrftime:\n    def time_frame_date_to_str(self, nobs):\n        self.data[\"d\"].astype(str)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_to_str", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "054e08eca2d4a8767e953c76bde4ff267409bb5703360cece151bbe66a333160", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_custom": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_custom(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d --- %H:%M:%S\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_custom", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "45f78787f94eb5bc3a07ef4de1615aeb63966f4bc0323e6efd09f5e1a4466fc2", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "fa3e5c135498e5597fee3a7b0be426c176f10b8619cbee4f27ac55f095e64407", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_explicit(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "ec080e75b9842b184e4d1ffec10e5499756d68b597c0665dd44b755de1e5d72c", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit_date_only": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_explicit_date_only(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit_date_only", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "2d5a4bbcd37dd7efc7834d4fe604fa054058f030eaac3f245f2eed5c2a384df6", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_with_float": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_with_float(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S.%f\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_with_float", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "c3d5e3fc1b3d0590232afef2ae418ff61154bc7d430b0475e7e70cdf7dcc4723", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_to_str": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_to_str(self, nobs):\n        self.data[\"dt\"].astype(str)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_to_str", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "5a4c4ba96a951bbfd2b09497a9dfe6a72abfa1eac880c8f2d90e19c7bed5b98b", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_custom": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_custom(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%d --- %H:%M:%S\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_custom", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "16999601594a1d9cd57cfa7155f55be9da4b04ddd986430761e938fe4138d5ff", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_default": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_default(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_default", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "9043ba2fbb552e444f04b49a0bad1382d6e7d4e1f55d150b30bd5117704ca1a9", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_default_explicit": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_default_explicit(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=self.default_fmt)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_default_explicit", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "b18eda1cc34ea4b3062f32befb43ba338a0f37eb1ffae5221f65db35f7c86c2e", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_Z": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_iso8601_strftime_Z(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%dT%H:%M:%SZ\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_Z", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "f5de27264273a2cee140307660efbe5e2f798fdf298074c308d5029ca9c58d76", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_offset": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_iso8601_strftime_offset(self, nobs, freq):\n        \"\"\"Not optimized yet as %z is not supported by `convert_strftime_format`\"\"\"\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%dT%H:%M:%S%z\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_offset", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "5ba896f46eb860aff2aef5027c2302bd7b1b7eb8ec9d264467a11db4f4ffafe4", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_to_str": {"code": "class PeriodStrftime:\n    def time_frame_period_to_str(self, nobs, freq):\n        self.data[\"p\"].astype(str)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_to_str", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "1cdd45d58644445828a73b51075c943c00e4d5d0665144898cc6f8b8ffc16e19", "warmup_time": -1}, "strings.Cat.time_cat": {"code": "class Cat:\n    def time_cat(self, other_cols, sep, na_rep, na_frac):\n        # before the concatenation (one caller + other_cols columns), the total\n        # expected fraction of rows containing any NaN is:\n        # reduce(lambda t, _: t + (1 - t) * na_frac, range(other_cols + 1), 0)\n        # for other_cols=3 and na_frac=0.15, this works out to ~48%\n        self.s.str.cat(others=self.others, sep=sep, na_rep=na_rep)\n\n    def setup(self, other_cols, sep, na_rep, na_frac):\n        N = 10**5\n        mask_gen = lambda: np.random.choice([True, False], N, p=[1 - na_frac, na_frac])\n        self.s = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object)).where(\n            mask_gen()\n        )\n        if other_cols == 0:\n            # str.cat self-concatenates only for others=None\n            self.others = None\n        else:\n            self.others = DataFrame(\n                {\n                    i: Index([f\"i-{i}\" for i in range(N)], dtype=object).where(\n                        mask_gen()\n                    )\n                    for i in range(other_cols)\n                }\n            )", "min_run_count": 2, "name": "strings.Cat.time_cat", "number": 0, "param_names": ["other_cols", "sep", "na_rep", "na_frac"], "params": [["0", "3"], ["None", "','"], ["None", "'-'"], ["0.0", "0.001", "0.15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b52f18e7cc25692faed0025e10bc3626a9ae604f84505b3a27457ae00fed759a", "warmup_time": -1}, "strings.Construction.peakmem_construction": {"code": "class Construction:\n    def peakmem_construction(self, pd_type, dtype):\n        self.pd_mapping[pd_type](self.arr, dtype=dtype)\n\n    def setup(self, pd_type, dtype):\n        series_arr = np.array(\n            [str(i) * 10 for i in range(100_000)], dtype=self.dtype_mapping[dtype]\n        )\n        if pd_type == \"series\":\n            self.arr = series_arr\n        elif pd_type == \"frame\":\n            self.arr = series_arr.reshape((50_000, 2)).copy()\n        elif pd_type == \"categorical_series\":\n            # GH37371. Testing construction of string series/frames from ExtensionArrays\n            self.arr = Categorical(series_arr)", "name": "strings.Construction.peakmem_construction", "param_names": ["pd_type", "dtype"], "params": [["'series'", "'frame'", "'categorical_series'"], ["'str'", "'string[python]'", "'string[pyarrow]'"]], "type": "peakmemory", "unit": "bytes", "version": "388fe5a8cc42f895e1448afe8c9ef9f4345e9cdb97befbfa8ec7e38f4ff97a1d"}, "strings.Construction.time_construction": {"code": "class Construction:\n    def time_construction(self, pd_type, dtype):\n        self.pd_mapping[pd_type](self.arr, dtype=dtype)\n\n    def setup(self, pd_type, dtype):\n        series_arr = np.array(\n            [str(i) * 10 for i in range(100_000)], dtype=self.dtype_mapping[dtype]\n        )\n        if pd_type == \"series\":\n            self.arr = series_arr\n        elif pd_type == \"frame\":\n            self.arr = series_arr.reshape((50_000, 2)).copy()\n        elif pd_type == \"categorical_series\":\n            # GH37371. Testing construction of string series/frames from ExtensionArrays\n            self.arr = Categorical(series_arr)", "min_run_count": 2, "name": "strings.Construction.time_construction", "number": 0, "param_names": ["pd_type", "dtype"], "params": [["'series'", "'frame'", "'categorical_series'"], ["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c957bf7cd41d3cf91aba30f7a6a9da9ebfdb15a91e538ec7f97aca263e832104", "warmup_time": -1}, "strings.Contains.time_contains": {"code": "class Contains:\n    def time_contains(self, dtype, regex):\n        self.s.str.contains(\"A\", regex=regex)\n\n    def setup(self, dtype, regex):\n        super().setup(dtype)", "min_run_count": 2, "name": "strings.Contains.time_contains", "number": 0, "param_names": ["dtype", "regex"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "059d755b738e508f2767456a3bcb5561731b1d7d8ac1ad2e92fddc4828e30270", "warmup_time": -1}, "strings.Dummies.time_get_dummies": {"code": "class Dummies:\n    def time_get_dummies(self, dtype):\n        self.s.str.get_dummies(\"|\")\n\n    def setup(self, dtype):\n        super().setup(dtype)\n        N = len(self.s) // 5\n        self.s = self.s[:N].str.join(\"|\")", "min_run_count": 2, "name": "strings.Dummies.time_get_dummies", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3636a8f3b31beca3d40035add6c3a6c089964df164eebcdad0b37494708ed25d", "warmup_time": -1}, "strings.Encode.time_encode_decode": {"code": "class Encode:\n    def time_encode_decode(self):\n        self.ser.str.encode(\"utf-8\").str.decode(\"utf-8\")\n\n    def setup(self):\n        self.ser = Series(Index([f\"i-{i}\" for i in range(10_000)], dtype=object))", "min_run_count": 2, "name": "strings.Encode.time_encode_decode", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "98f6dd64fcea519c34e03c7f29d78170688c0d7b9dd676aac55e4f511c3f8f4c", "warmup_time": -1}, "strings.Extract.time_extract_single_group": {"code": "class Extract:\n    def time_extract_single_group(self, dtype, expand):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)", "min_run_count": 2, "name": "strings.Extract.time_extract_single_group", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4a4c5c7bdd1645c137d0f4bcafc4eb9b92be955e5bb27fd6fe7994d2466c32e7", "warmup_time": -1}, "strings.Iter.time_iter": {"code": "class Iter:\n    def time_iter(self, dtype):\n        for i in self.s:\n            pass\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Iter.time_iter", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "99048e2de430528987ca96a33415109d24b1dd34d4cb676f4b231d2b9aff3b8b", "warmup_time": -1}, "strings.Methods.time_center": {"code": "class Methods:\n    def time_center(self, dtype):\n        self.s.str.center(100)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_center", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "dfabd2c2c8e80cf9db6124aac4d32c245e22cc4575b5511d68c85b74670ae71f", "warmup_time": -1}, "strings.Methods.time_count": {"code": "class Methods:\n    def time_count(self, dtype):\n        self.s.str.count(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_count", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c5f611f3836ad7c1eba5910a47f2878bab4a45394f8b8509f1a697be4b228a84", "warmup_time": -1}, "strings.Methods.time_endswith": {"code": "class Methods:\n    def time_endswith(self, dtype):\n        self.s.str.endswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_endswith", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f9197c560ddedfee42d2f56aa147f186c719a1252e2510055356947eb1493611", "warmup_time": -1}, "strings.Methods.time_extract": {"code": "class Methods:\n    def time_extract(self, dtype):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A(\\\\w*)\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_extract", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "98472f6dea453c2b4940a283b32acb0b6016ddfad19469cc8a584c4c227bfef1", "warmup_time": -1}, "strings.Methods.time_find": {"code": "class Methods:\n    def time_find(self, dtype):\n        self.s.str.find(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_find", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "044081b6b2c59961aa6e9e4da5c63fc29009575ded9293310b6ea51e8ca6fe83", "warmup_time": -1}, "strings.Methods.time_findall": {"code": "class Methods:\n    def time_findall(self, dtype):\n        self.s.str.findall(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_findall", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d61679b2c211f5b801bfbd27f0a53c99409504239b2992449684331a4be39572", "warmup_time": -1}, "strings.Methods.time_fullmatch": {"code": "class Methods:\n    def time_fullmatch(self, dtype):\n        self.s.str.fullmatch(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_fullmatch", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e35eec9cf8a46f0139c766632d91d276dc10a435699f63602829b85e082c4da0", "warmup_time": -1}, "strings.Methods.time_get": {"code": "class Methods:\n    def time_get(self, dtype):\n        self.s.str.get(0)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_get", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bffc7305f03c22402d92a8d667aca1c6902341d79bba2c207702c4aac008896d", "warmup_time": -1}, "strings.Methods.time_isalnum": {"code": "class Methods:\n    def time_isalnum(self, dtype):\n        self.s.str.isalnum()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_isalnum", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "350d7a1e593e25179b2573f0e18b9a6e6cb2c055e4c9ee2feda18b3451b61cc0", "warmup_time": -1}, "strings.Methods.time_isalpha": {"code": "class Methods:\n    def time_isalpha(self, dtype):\n        self.s.str.isalpha()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_isalpha", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f61025f688fe65e123f289d71a146cf295cb2f743069c8ce97d40b25e8864728", "warmup_time": -1}, "strings.Methods.time_isdecimal": {"code": "class Methods:\n    def time_isdecimal(self, dtype):\n        self.s.str.isdecimal()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_isdecimal", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "742859be99c9ee213dbe9bea515f5e0189276d4e227d063af08f7449cd8147a7", "warmup_time": -1}, "strings.Methods.time_isdigit": {"code": "class Methods:\n    def time_isdigit(self, dtype):\n        self.s.str.isdigit()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_isdigit", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8e1a851ddb833d51dc5a70c3cf221399e7ac360c3572450e3df2a0870eccc6df", "warmup_time": -1}, "strings.Methods.time_islower": {"code": "class Methods:\n    def time_islower(self, dtype):\n        self.s.str.islower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_islower", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2cd6ca8660528de5f67d097c83a8306d2d637abda2721b1ab0e05b4b7088f100", "warmup_time": -1}, "strings.Methods.time_isnumeric": {"code": "class Methods:\n    def time_isnumeric(self, dtype):\n        self.s.str.isnumeric()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_isnumeric", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "93209b1b18f1417cbdc050726a9174b9fb76d43563303242b4f7617e3a94036b", "warmup_time": -1}, "strings.Methods.time_isspace": {"code": "class Methods:\n    def time_isspace(self, dtype):\n        self.s.str.isspace()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_isspace", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a9ba8663a43748c749f7e5b13fa37c790716199afa48b66e114a0660a68f4b41", "warmup_time": -1}, "strings.Methods.time_istitle": {"code": "class Methods:\n    def time_istitle(self, dtype):\n        self.s.str.istitle()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_istitle", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9d616462e52f19dd8270a6f747143737102c4056aa528613b839c29dfe751f67", "warmup_time": -1}, "strings.Methods.time_isupper": {"code": "class Methods:\n    def time_isupper(self, dtype):\n        self.s.str.isupper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_isupper", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b4f3172ccc98adcd21201b75f29adbe4f30202e5307f6e52cf62df633c7663c1", "warmup_time": -1}, "strings.Methods.time_join": {"code": "class Methods:\n    def time_join(self, dtype):\n        self.s.str.join(\" \")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_join", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "31e2bb80662edda7fba2732e3104d5e16bf85f26bcd65f83ddce2db39d042e02", "warmup_time": -1}, "strings.Methods.time_len": {"code": "class Methods:\n    def time_len(self, dtype):\n        self.s.str.len()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_len", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "15831f1f1fc1053f7d40396a1e8f06de2b9ce7d36a77263935795618fcf26473", "warmup_time": -1}, "strings.Methods.time_lower": {"code": "class Methods:\n    def time_lower(self, dtype):\n        self.s.str.lower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_lower", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2e0f8ba78ce20a15b2246f9e313459303cec518989e54b52c665208ef6e69070", "warmup_time": -1}, "strings.Methods.time_lstrip": {"code": "class Methods:\n    def time_lstrip(self, dtype):\n        self.s.str.lstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_lstrip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9c3141587e7b7809c1de02ebace59cd44a0cd5013b5383c14d95d70df242f699", "warmup_time": -1}, "strings.Methods.time_match": {"code": "class Methods:\n    def time_match(self, dtype):\n        self.s.str.match(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_match", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1875a652c9e9a2e4a398a590828e6977bba7a8e30f58c2a582c125f1b2287cec", "warmup_time": -1}, "strings.Methods.time_normalize": {"code": "class Methods:\n    def time_normalize(self, dtype):\n        self.s.str.normalize(\"NFC\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_normalize", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0029f0976f6b3cdafe05ce21172d6b1733929dcf148531c35b5e9daf472c7b14", "warmup_time": -1}, "strings.Methods.time_pad": {"code": "class Methods:\n    def time_pad(self, dtype):\n        self.s.str.pad(100, side=\"both\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_pad", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d2eb769aa07b3f253dcc0bafb6f7965322f8d510b09bdc57c905eadb28b7467f", "warmup_time": -1}, "strings.Methods.time_partition": {"code": "class Methods:\n    def time_partition(self, dtype):\n        self.s.str.partition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_partition", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4a17da39f63b92446009df4fe223405c2062b6e02e4ad0b75f6f589a447d43b6", "warmup_time": -1}, "strings.Methods.time_replace": {"code": "class Methods:\n    def time_replace(self, dtype):\n        self.s.str.replace(\"A\", \"\\x01\\x01\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_replace", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "86c5eb08ad17d3743614bdfafdccc89241f8a0dd7135d96e623688603bb9aeb9", "warmup_time": -1}, "strings.Methods.time_rfind": {"code": "class Methods:\n    def time_rfind(self, dtype):\n        self.s.str.rfind(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_rfind", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bff18b026560620448f6d9277e349128f6089973cedef619640ae1c024bf8c9b", "warmup_time": -1}, "strings.Methods.time_rpartition": {"code": "class Methods:\n    def time_rpartition(self, dtype):\n        self.s.str.rpartition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_rpartition", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "78fc7a482d33a89264eef3b15a11469b223b2129733dae9074d636311e2cbdd6", "warmup_time": -1}, "strings.Methods.time_rstrip": {"code": "class Methods:\n    def time_rstrip(self, dtype):\n        self.s.str.rstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_rstrip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "eda693ad14adab58cbce9e55efdaf6c2c46080dfc584c1ae93d306b125aa953f", "warmup_time": -1}, "strings.Methods.time_slice": {"code": "class Methods:\n    def time_slice(self, dtype):\n        self.s.str.slice(5, 15, 2)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_slice", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "533b86a28e89ae89262a20e75cb22c9cf750b8c7e9c0fa09683d784ee0e03357", "warmup_time": -1}, "strings.Methods.time_startswith": {"code": "class Methods:\n    def time_startswith(self, dtype):\n        self.s.str.startswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_startswith", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5c00f04f17e556c9ba519e01d190b425d603977100265c6fa3fd7bec0f12c92c", "warmup_time": -1}, "strings.Methods.time_strip": {"code": "class Methods:\n    def time_strip(self, dtype):\n        self.s.str.strip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_strip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a1d6a533499233d62a84e1f56f3b98f8319d9dff982c01f5a9599f2a1411f149", "warmup_time": -1}, "strings.Methods.time_title": {"code": "class Methods:\n    def time_title(self, dtype):\n        self.s.str.title()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_title", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fbfb0a2b913b93aa6344ba9b6c28d74680889c1b1714a1518fca0b905d0f6459", "warmup_time": -1}, "strings.Methods.time_translate": {"code": "class Methods:\n    def time_translate(self, dtype):\n        self.s.str.translate({\"A\": \"\\x01\\x01\"})\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_translate", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0ae15fa8fa4067f6f432f63d971644c286ebdee520d5edd17c9a448356c28f3a", "warmup_time": -1}, "strings.Methods.time_upper": {"code": "class Methods:\n    def time_upper(self, dtype):\n        self.s.str.upper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_upper", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7d79a2ac0817c85a6d5426ad30a0ced267a4c2477d924bd909ae9c9f1af896a5", "warmup_time": -1}, "strings.Methods.time_wrap": {"code": "class Methods:\n    def time_wrap(self, dtype):\n        self.s.str.wrap(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_wrap", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8118c3a07bfcff1b6eb842caef841ba5c8c0b85d21537b1d23fb01388a201035", "warmup_time": -1}, "strings.Methods.time_zfill": {"code": "class Methods:\n    def time_zfill(self, dtype):\n        self.s.str.zfill(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object)._values,\n                dtype=dtype,\n            )\n        except ImportError as err:\n            raise NotImplementedError from err", "min_run_count": 2, "name": "strings.Methods.time_zfill", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "89c50187e9898c6f7920175d3b698c14fef65ffc54c731c8c049e82081ab4851", "warmup_time": -1}, "strings.Repeat.time_repeat": {"code": "class Repeat:\n    def time_repeat(self, repeats):\n        self.s.str.repeat(self.values)\n\n    def setup(self, repeats):\n        N = 10**5\n        self.s = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        repeat = {\"int\": 1, \"array\": np.random.randint(1, 3, N)}\n        self.values = repeat[repeats]", "min_run_count": 2, "name": "strings.Repeat.time_repeat", "number": 0, "param_names": ["repeats"], "params": [["'int'", "'array'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1020d0debc1446a71cfda9efe059407dc390e74d806d2783566fdba4e7d1de98", "warmup_time": -1}, "strings.Slice.time_vector_slice": {"code": "class Slice:\n    def time_vector_slice(self):\n        # GH 2602\n        self.s.str[:5]\n\n    def setup(self):\n        self.s = Series([\"abcdefg\", np.nan] * 500000)", "min_run_count": 2, "name": "strings.Slice.time_vector_slice", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "aaf1ec9c90cc2539c76cae9af1c26b6b5ffb1d0311ec7d6dafe7d228d106ef86", "warmup_time": -1}, "strings.Split.time_rsplit": {"code": "class Split:\n    def time_rsplit(self, dtype, expand):\n        self.s.str.rsplit(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_rsplit", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c748bf724293b4083adf3d91ce7a5255043bddcd7ecaba38777cac47767ad1f0", "warmup_time": -1}, "strings.Split.time_split": {"code": "class Split:\n    def time_split(self, dtype, expand):\n        self.s.str.split(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_split", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "abecb3cbc4195a6fedc3bc41353ecd447d36060b1cd5e43944cda06edfa8a2e6", "warmup_time": -1}, "strings.StringArrayConstruction.peakmem_stringarray_construction": {"code": "class StringArrayConstruction:\n    def peakmem_stringarray_construction(self):\n        StringArray(self.series_arr)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "name": "strings.StringArrayConstruction.peakmem_stringarray_construction", "param_names": [], "params": [], "type": "peakmemory", "unit": "bytes", "version": "1644a62bd4fef4c7214ab6a613fb523651eb795bdc0eca8bafc1bceb6af4bc8d"}, "strings.StringArrayConstruction.time_string_array_construction": {"code": "class StringArrayConstruction:\n    def time_string_array_construction(self):\n        StringArray(self.series_arr)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "min_run_count": 2, "name": "strings.StringArrayConstruction.time_string_array_construction", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4ded60d6eacf6b7203c61d538380497e0dd86ed15910c739819f0c18299357a4", "warmup_time": -1}, "strings.StringArrayConstruction.time_string_array_with_nan_construction": {"code": "class StringArrayConstruction:\n    def time_string_array_with_nan_construction(self):\n        StringArray(self.series_arr_nan)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "min_run_count": 2, "name": "strings.StringArrayConstruction.time_string_array_with_nan_construction", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c7ef4a3758ceb79e8124d016a878c5be0d6bf37399e516da63b10e21cb3fc1d5", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, series):\n        series.dt\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "type": "time", "unit": "seconds", "version": "56ad9655f66a0485943ce9ca9547af9c97e48f5b12779c60896c3147c5422526", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_days": {"code": "class DatetimeAccessor:\n    def time_timedelta_days(self, series):\n        series.dt.days\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "type": "time", "unit": "seconds", "version": "06c603c515e826893772c4d64fe4de8ff76367d3c422060262604d4917fbec03", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_microseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_microseconds(self, series):\n        series.dt.microseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "type": "time", "unit": "seconds", "version": "6504e61d63ba227783a76d2cab32c1d791b1af813406a8c384fc386ca60b1898", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_nanoseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_nanoseconds(self, series):\n        series.dt.nanoseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "type": "time", "unit": "seconds", "version": "c1cc39aec7c93cb50ced4bf81ec26506de8bfddaaee6968142c0c018f91e296a", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_seconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_seconds(self, series):\n        series.dt.seconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "type": "time", "unit": "seconds", "version": "0514e9978f000e47c609125255de6d9536aed804334d426a9222e1347183702d", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_align": {"code": "class TimedeltaIndexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f5833d39497fb06bb05cac21fd9feeebace738d8e1cb626bea9fb0bbd86049ce", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_get_loc": {"code": "class TimedeltaIndexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.timedelta)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "25e9df433acdb6dcf3c1df99f789a41f9c774fba04d175a24c5b8688dad9a7f3", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_intersection": {"code": "class TimedeltaIndexing:\n    def time_intersection(self):\n        self.index.intersection(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c3f027dc76eb6a9ef0eff1bc06dd59ee562b54fbdb029d2a6a6c4865601424c1", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_series_loc": {"code": "class TimedeltaIndexing:\n    def time_series_loc(self):\n        self.series.loc[self.timedelta]\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_series_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5902b5b4b32fc27d85bee9808b6014b1f9664e7f28f444e498a7d04083c92e05", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_shallow_copy": {"code": "class TimedeltaIndexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fae422a896cb1cff9173dd94eb799be107e0957d5845004660eed3d30e0540ba", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_union": {"code": "class TimedeltaIndexing:\n    def time_union(self):\n        self.index.union(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_union", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "266034126c423f3e411bf2195dc68cd983b6a181466b383df54ba9341232ad71", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_unique": {"code": "class TimedeltaIndexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "17ea4667001a64a4f9df8c9594ca120a6491a18edd28102cd5712c88535ac416", "warmup_time": -1}, "timeseries.AsOf.time_asof": {"code": "class AsOf:\n    def time_asof(self, constructor):\n        self.ts.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "37bd4ce5386fd0b7c34272d255acd943468380376dc1ee5dd9dea070fb806805", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan": {"code": "class AsOf:\n    def time_asof_nan(self, constructor):\n        self.ts2.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "501dd990a898123eb091528ad6846c32abada27e5834f83a86729b32c4a0bcde", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan_single": {"code": "class AsOf:\n    def time_asof_nan_single(self, constructor):\n        self.ts3.asof(self.date_last)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5607d6a56f2adf8c34116da998623d2111a97c21c45c0d1287f625a3ecda0055", "warmup_time": -1}, "timeseries.AsOf.time_asof_single": {"code": "class AsOf:\n    def time_asof_single(self, constructor):\n        self.ts.asof(self.date)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "afe0b338280acc8cfed3251b3ee2abf5e165c63fe746d8032f062675bf9021ac", "warmup_time": -1}, "timeseries.AsOf.time_asof_single_early": {"code": "class AsOf:\n    def time_asof_single_early(self, constructor):\n        self.ts.asof(self.date_early)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single_early", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2ce4002d656f7b5513c14e1e36605c59ff9c7a0c53ce76a87dc70c83c7052b1c", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, tz):\n        self.series.dt\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c4654d6ecec4d6eb77017231cdf50af038043ea4902f77696dfe07ccf474acbd", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_date": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_date(self, tz):\n        self.series.dt.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_date", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "094be7aa69f4d56549e49c066b297e49081304a97ea4b4099a49b4dc4bd7a42b", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_day_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_day_name(self, tz):\n        self.series.dt.day_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_day_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "df76b5c41131ea1ca919a20e8df2e83bba306d899e8870b93f5d9384ce80faa1", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_month_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_month_name(self, tz):\n        self.series.dt.month_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_month_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "9b5673999481df055b0f075354fdf3e35bd5b1607adbe41ebe9f93f1ade8fbc4", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_normalize": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_normalize(self, tz):\n        self.series.dt.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_normalize", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f72f5ac1e6051cfb422cd5c2e7d24d223f12e59d0e999c03edad788b7a625078", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_time": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_time(self, tz):\n        self.series.dt.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_time", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7f9eb32f2fbf8aee4af73e69833ddc753487025f72b66b7880110bb5a972edc1", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_year": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_year(self, tz):\n        self.series.dt.year\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_year", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cc33ec3abfe516cac3685bdca04c77540a7b773f1f8ac33dbbea439353070373", "warmup_time": -1}, "timeseries.DatetimeIndex.time_add_timedelta": {"code": "class DatetimeIndex:\n    def time_add_timedelta(self, index_type):\n        self.index + timedelta(minutes=2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_add_timedelta", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1298590f12ff60438ee82782f6cb66df435c77f26bd8a574d98fed569ca2b127", "warmup_time": -1}, "timeseries.DatetimeIndex.time_get": {"code": "class DatetimeIndex:\n    def time_get(self, index_type):\n        self.index[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_get", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "89ec08b759e4b4b38fd3b04ca3b8c07579d2e76e771ddabc2dbf2e086be1206f", "warmup_time": -1}, "timeseries.DatetimeIndex.time_is_dates_only": {"code": "class DatetimeIndex:\n    def time_is_dates_only(self, index_type):\n        self.index._is_dates_only\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_is_dates_only", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "05d01dfb62d23729c918fb360748b143555963b32f4cf61cb539a8bc05ca358b", "warmup_time": -1}, "timeseries.DatetimeIndex.time_normalize": {"code": "class DatetimeIndex:\n    def time_normalize(self, index_type):\n        self.index.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_normalize", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ca5039cfd4ea100f42b401e5adc4fec5a27a4727e781e20af9e2cf6f74b07b68", "warmup_time": -1}, "timeseries.DatetimeIndex.time_timeseries_is_month_start": {"code": "class DatetimeIndex:\n    def time_timeseries_is_month_start(self, index_type):\n        self.index.is_month_start\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_timeseries_is_month_start", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "eff9b3be0946643635ef49382acfb8e570bda84292d1296f9f6e6213393d8f8e", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_date": {"code": "class DatetimeIndex:\n    def time_to_date(self, index_type):\n        self.index.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_date", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "dd2bebb8b3ed2ab476d0ef8661ecd7c8def6d4efbbed55849357f7781a3b0be8", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_pydatetime": {"code": "class DatetimeIndex:\n    def time_to_pydatetime(self, index_type):\n        self.index.to_pydatetime()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_pydatetime", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "54fb10c75741cf7897f5ac51da9f1c369bf503d921df5ed999155a06d9f669e7", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_time": {"code": "class DatetimeIndex:\n    def time_to_time(self, index_type):\n        self.index.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_time", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7c6798dd8a6859a5f62025b29470444fb1ffe43cfcb4a5738ba6c40619392699", "warmup_time": -1}, "timeseries.DatetimeIndex.time_unique": {"code": "class DatetimeIndex:\n    def time_unique(self, index_type):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N // 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_unique", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4a214dbb167f02d37caab9b8ba6fe10cb4acf8cb9588840b79e7f693da0f4095", "warmup_time": -1}, "timeseries.InferFreq.time_infer_freq": {"code": "class InferFreq:\n    def time_infer_freq(self, freq):\n        infer_freq(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InferFreq:\n    def setup(self, freq):\n        if freq is None:\n            self.idx = date_range(start=\"1/1/1700\", freq=\"D\", periods=10000)\n            self.idx._data._freq = None\n        else:\n            self.idx = date_range(start=\"1/1/1700\", freq=freq, periods=10000)", "min_run_count": 2, "name": "timeseries.InferFreq.time_infer_freq", "number": 0, "param_names": ["freq"], "params": [["None", "'D'", "'B'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "52f02044de50a1a68041e7526ab41b12d85500472c7652ce485fa54cfe87ecc0", "warmup_time": -1}, "timeseries.Iteration.time_iter": {"code": "class Iteration:\n    def time_iter(self, time_index):\n        for _ in self.idx:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"min\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"min\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter", "number": 0, "param_names": ["time_index"], "params": [["<function date_range>", "<function period_range>", "<function timedelta_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "7462a5f79cb42d4bd08d938457631a39d3b1fe203fef2eaca6dd612ccf0956a7", "warmup_time": -1}, "timeseries.Iteration.time_iter_preexit": {"code": "class Iteration:\n    def time_iter_preexit(self, time_index):\n        for i, _ in enumerate(self.idx):\n            if i > self.exit:\n                break\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"min\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"min\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter_preexit", "number": 0, "param_names": ["time_index"], "params": [["<function date_range>", "<function period_range>", "<function timedelta_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8c6848d29bdf8fb903dbbb06fcb0a6ef5405d6f4d2d02679fb20236f69ff6070", "warmup_time": -1}, "timeseries.Lookup.time_lookup_and_cleanup": {"code": "class Lookup:\n    def time_lookup_and_cleanup(self):\n        self.ts[self.lookup_val]\n        self.ts.index._cleanup()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        N = 1500000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.ts = Series(1, index=rng)\n        self.lookup_val = rng[N // 2]", "min_run_count": 2, "name": "timeseries.Lookup.time_lookup_and_cleanup", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "622243e3fbc3f77c3a07df1366425577e34f93696a149766f75e2f67ebbdfbfe", "warmup_time": -1}, "timeseries.ResampleDataFrame.time_method": {"code": "class ResampleDataFrame:\n    def time_method(self, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDataFrame:\n    def setup(self, method):\n        rng = date_range(start=\"20130101\", periods=100000, freq=\"50ms\")\n        df = DataFrame(np.random.randn(100000, 2), index=rng)\n        self.resample = getattr(df.resample(\"1s\"), method)", "min_run_count": 2, "name": "timeseries.ResampleDataFrame.time_method", "number": 0, "param_names": ["method"], "params": [["'max'", "'mean'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a4fb6ef3ce886b50c0e792fa873de3cd9aee12fb92d9f2952dd99045ea9ca6d4", "warmup_time": -1}, "timeseries.ResampleDatetetime64.time_resample": {"code": "class ResampleDatetetime64:\n    def time_resample(self):\n        self.dt_ts.resample(\"1s\").last()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDatetetime64:\n    def setup(self):\n        rng3 = date_range(\n            start=\"2000-01-01 00:00:00\", end=\"2000-01-01 10:00:00\", freq=\"555000us\"\n        )\n        self.dt_ts = Series(5, rng3, dtype=\"datetime64[ns]\")", "min_run_count": 2, "name": "timeseries.ResampleDatetetime64.time_resample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0983037197a0d6923106eac1e156d4ea4fbaeb06a934c6d00f4af0240931e319", "warmup_time": -1}, "timeseries.ResampleSeries.time_resample": {"code": "class ResampleSeries:\n    def time_resample(self, index, freq, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleSeries:\n    def setup(self, index, freq, method):\n        indexes = {\n            \"period\": period_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"min\"),\n            \"datetime\": date_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"min\"),\n        }\n        idx = indexes[index]\n        ts = Series(np.random.randn(len(idx)), index=idx)\n        self.resample = getattr(ts.resample(freq), method)", "min_run_count": 2, "name": "timeseries.ResampleSeries.time_resample", "number": 0, "param_names": ["index", "freq", "method"], "params": [["'period'", "'datetime'"], ["'5min'", "'1D'"], ["'mean'", "'ohlc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "55b0e708ae03f83acfe58adc721a2552d94d0f4c55f29b01731e881a672a4338", "warmup_time": -1}, "timeseries.ResetIndex.time_reset_datetimeindex": {"code": "class ResetIndex:\n    def time_reset_datetimeindex(self, tz):\n        self.df.reset_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResetIndex:\n    def setup(self, tz):\n        idx = date_range(start=\"1/1/2000\", periods=1000, freq=\"h\", tz=tz)\n        self.df = DataFrame(np.random.randn(1000, 2), index=idx)", "min_run_count": 2, "name": "timeseries.ResetIndex.time_reset_datetimeindex", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "69f268ece46afbbdef1c2696b72b004a1ea89cb77eef5125c1ef70576c922b24", "warmup_time": -1}, "timeseries.SortIndex.time_get_slice": {"code": "class SortIndex:\n    def time_get_slice(self, monotonic):\n        self.s[:10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_get_slice", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0a9e9e75d9711805af9e2bd23525b886c146db147bda183e7c62c68212a7d2af", "warmup_time": -1}, "timeseries.SortIndex.time_sort_index": {"code": "class SortIndex:\n    def time_sort_index(self, monotonic):\n        self.s.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_sort_index", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "4e3d97e97d12382b09d20e93cc00244951e5d85c15eb06dd5e57dc55c553db37", "warmup_time": -1}, "timeseries.TimeDatetimeConverter.time_convert": {"code": "class TimeDatetimeConverter:\n    def time_convert(self):\n        DatetimeConverter.convert(self.rng, None, None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeDatetimeConverter:\n    def setup(self):\n        N = 100000\n        self.rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")", "min_run_count": 2, "name": "timeseries.TimeDatetimeConverter.time_convert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "79f58665e747b6d28bf6b6a355cb6518597a5b4f0bb838b47ca93e0e6e7d19b7", "warmup_time": -1}, "timeseries.TzLocalize.time_infer_dst": {"code": "class TzLocalize:\n    def time_infer_dst(self, tz):\n        self.index.tz_localize(tz, ambiguous=\"infer\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TzLocalize:\n    def setup(self, tz):\n        dst_rng = date_range(\n            start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n        )\n        self.index = date_range(start=\"10/29/2000\", end=\"10/29/2000 00:59:59\", freq=\"s\")\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(\n            date_range(start=\"10/29/2000 2:00:00\", end=\"10/29/2000 3:00:00\", freq=\"s\")\n        )", "min_run_count": 2, "name": "timeseries.TzLocalize.time_infer_dst", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ed09ad3f4f73b8252ef5fb6874b8019d0077dae5d4ef1828a52519d880aef55b", "warmup_time": -1}, "tslibs.fields.TimeGetDateField.time_get_date_field": {"code": "class TimeGetDateField:\n    def time_get_date_field(self, size, field):\n        get_date_field(self.i8data, field)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeGetDateField:\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.fields.TimeGetDateField.time_get_date_field", "number": 0, "param_names": ["size", "field"], "params": [["0", "1", "100", "10000", "1000000"], ["'Y'", "'M'", "'D'", "'h'", "'m'", "'s'", "'us'", "'ns'", "'doy'", "'dow'", "'woy'", "'q'", "'dim'", "'is_leap_year'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fa11fee9605cb60559821a23f251696b5ee45b9cf0483c05fc58ee3da8954228", "warmup_time": -1}, "tslibs.fields.TimeGetStartEndField.time_get_start_end_field": {"code": "class TimeGetStartEndField:\n    def time_get_start_end_field(self, size, side, period, freqstr, month_kw):\n        get_start_end_field(self.i8data, self.attrname, freqstr, month_kw=month_kw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeGetStartEndField:\n    def setup(self, size, side, period, freqstr, month_kw):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n    \n        self.attrname = f\"is_{period}_{side}\"", "min_run_count": 2, "name": "tslibs.fields.TimeGetStartEndField.time_get_start_end_field", "number": 0, "param_names": ["size", "side", "period", "freqstr", "month_kw"], "params": [["0", "1", "100", "10000", "1000000"], ["'start'", "'end'"], ["'month'", "'quarter'", "'year'"], ["'B'", "None", "'QS'"], ["12", "3", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fa79a0f2cad977700429fcc398c6e468de4851429f899f1fd3468f6f3445b488", "warmup_time": -1}, "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field": {"code": "class TimeGetTimedeltaField:\n    def time_get_timedelta_field(self, size, field):\n        get_timedelta_field(self.i8data, field)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeGetTimedeltaField:\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n        arr = np.random.randint(-86400 * 1_000_000_000, 0, size=size, dtype=\"i8\")\n        self.i8data_negative = arr", "min_run_count": 2, "name": "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field", "number": 0, "param_names": ["size", "field"], "params": [["0", "1", "100", "10000", "1000000"], ["'seconds'", "'microseconds'", "'nanoseconds'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "2062d9b02d31b3cccc19774c8b4ffe829394496dd2967d6865382a6815150bd8", "warmup_time": -1}, "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field_negative_td": {"code": "class TimeGetTimedeltaField:\n    def time_get_timedelta_field_negative_td(self, size, field):\n        get_timedelta_field(self.i8data_negative, field)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeGetTimedeltaField:\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n        arr = np.random.randint(-86400 * 1_000_000_000, 0, size=size, dtype=\"i8\")\n        self.i8data_negative = arr", "min_run_count": 2, "name": "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field_negative_td", "number": 0, "param_names": ["size", "field"], "params": [["0", "1", "100", "10000", "1000000"], ["'seconds'", "'microseconds'", "'nanoseconds'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3214622052a495d757444a8caec211b0f78d5a29b9c47d223ce19cec7b3db21a", "warmup_time": -1}, "tslibs.normalize.Normalize.time_is_date_array_normalized": {"code": "class Normalize:\n    def time_is_date_array_normalized(self, size, tz):\n        # TODO: cases with different levels of short-circuiting\n        # 10 i.e. NPY_FR_ns\n        is_date_array_normalized(self.i8data, tz, 10)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError", "min_run_count": 2, "name": "tslibs.normalize.Normalize.time_is_date_array_normalized", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8a0062a64c2f0559eaee437a8eeefbae5c75e27db5faf86541286085b875a6d2", "warmup_time": -1}, "tslibs.normalize.Normalize.time_normalize_i8_timestamps": {"code": "class Normalize:\n    def time_normalize_i8_timestamps(self, size, tz):\n        # 10 i.e. NPY_FR_ns\n        normalize_i8_timestamps(self.i8data, tz, 10)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError", "min_run_count": 2, "name": "tslibs.normalize.Normalize.time_normalize_i8_timestamps", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "90e93c0bf30f84159194f95da549370de993eadd2b9924b3bc6dc1d0ac05889e", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add": {"code": "class OffestDatetimeArithmetic:\n    def time_add(self, offset):\n        self.date + offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "bfb2ef7f8d94ebf443a43ab768a426b24846a01bcb9e60873cfca5ac9d84acbb", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add_10": {"code": "class OffestDatetimeArithmetic:\n    def time_add_10(self, offset):\n        self.date + (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "412f51bfc037b5b10f23387d475123e2c8ebd62a69e6a5692a07f7924f5149ac", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add_np_dt64": {"code": "class OffestDatetimeArithmetic:\n    def time_add_np_dt64(self, offset):\n        offset + self.dt64\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_np_dt64", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1165522291f90bef9f0aa75d6407828206ad6efc49a2b7023f47fdfd998851fa", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract(self, offset):\n        self.date - offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "775bbe2574e947fdebb23ba6451a8510d68d5dfaf0e0813a6967a39209d770fc", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract_10(self, offset):\n        self.date - (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f0a5bf6590a5f4e89c95b4b22ecc27ec52e4cb03e8255cef5009879bb71dbc69", "warmup_time": -1}, "tslibs.offsets.OnOffset.time_on_offset": {"code": "class OnOffset:\n    def time_on_offset(self, offset):\n        for date in self.dates:\n            offset.is_on_offset(date)\n\n    def setup(self, offset):\n        self.dates = [\n            datetime(2016, m, d)\n            for m in [10, 11, 12]\n            for d in [1, 2, 3, 28, 29, 30, 31]\n            if not (m == 11 and d == 31)\n        ]", "min_run_count": 2, "name": "tslibs.offsets.OnOffset.time_on_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ae5cbac53a07afd70222f6a228bac6518d5df75e369f5e8450db66831ba8afa2", "warmup_time": -1}, "tslibs.period.PeriodConstructor.time_period_constructor": {"code": "class PeriodConstructor:\n    def time_period_constructor(self, freq, is_offset):\n        Period(\"2012-06-01\", freq=freq)\n\n    def setup(self, freq, is_offset):\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "tslibs.period.PeriodConstructor.time_period_constructor", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d98fc24ec3bee7645af5de9f3e7af5e28f028c74e4785bda4ceb36f1d46a671d", "warmup_time": -1}, "tslibs.period.PeriodProperties.time_property": {"code": "class PeriodProperties:\n    def time_property(self, freq, attr):\n        getattr(self.per, attr)\n\n    def setup(self, freq, attr):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodProperties.time_property", "number": 0, "param_names": ["freq", "attr"], "params": [["'M'", "'min'"], ["'year'", "'month'", "'day'", "'hour'", "'minute'", "'second'", "'is_leap_year'", "'quarter'", "'qyear'", "'week'", "'daysinmonth'", "'dayofweek'", "'dayofyear'", "'start_time'", "'end_time'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6c0fa44f9b9f197537446c79ae6f7ce95ab1d18e2e68b5acb2a96103c097f4c6", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_asfreq": {"code": "class PeriodUnaryMethods:\n    def time_asfreq(self, freq):\n        self.per.asfreq(\"Y\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_asfreq", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f7636fac37be75ac435c3f2c26c70c768d8d6ac6a2f2ec4147c53e28bd84e016", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_now": {"code": "class PeriodUnaryMethods:\n    def time_now(self, freq):\n        self.per.now(freq)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_now", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ca497c2d273dcef636fd17b5cea2c596ea5d0e00aeb08e468f29db99e141026b", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_repr": {"code": "class PeriodUnaryMethods:\n    def time_repr(self, freq):\n        repr(self.per)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_repr", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "61db62d1d01fccdc5715ddf23d9ee8a51342bcf44f53ef99823dc6c5c23ccd95", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_str": {"code": "class PeriodUnaryMethods:\n    def time_str(self, freq):\n        str(self.per)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_str", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8d0bcff5d02fdbae27d445ee63fb0f76ca46a7b3470124eb29f12fb7d2e8fe92", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_strftime_custom": {"code": "class PeriodUnaryMethods:\n    def time_strftime_custom(self, freq):\n        self.per.strftime(\"%b. %d, %Y was a %A\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_strftime_custom", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6c1e84f9e7ff08f4aa2690c6ffd1b1031f1c278b0054d9070885809726493eb5", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_strftime_default": {"code": "class PeriodUnaryMethods:\n    def time_strftime_default(self, freq):\n        self.per.strftime(None)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_strftime_default", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a72f29d38796a94ca930f1af6cc6420afa2c6a70670e067a947c4b6a5240d08b", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_strftime_default_explicit": {"code": "class PeriodUnaryMethods:\n    def time_strftime_default_explicit(self, freq):\n        self.per.strftime(self.default_fmt)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_strftime_default_explicit", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "68d6b14934e4f96084f7276c1f9cb2ca0f3cec4f1132c94b1347849287da909f", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_to_timestamp": {"code": "class PeriodUnaryMethods:\n    def time_to_timestamp(self, freq):\n        self.per.to_timestamp()\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_to_timestamp", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "622b732f215b2fcad912dbef729ddb69296d8e499bf7c12df2048003b7253980", "warmup_time": -1}, "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr": {"code": "class TimeDT64ArrToPeriodArr:\n    def time_dt64arr_to_periodarr(self, size, freq, tz):\n        dt64arr_to_periodarr(self.i8values, freq, tz)\n\n    def setup(self, size, freq, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        # we pick 2**55 because smaller values end up returning\n        # -1 from npy_datetimestruct_to_datetime with NPY_FR_Y frequency\n        # this artificially slows down functions since -1 is also the\n        # error sentinel\n        arr = np.arange(2**55, 2**55 + 10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr", "min_run_count": 2, "name": "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr", "number": 0, "param_names": ["size", "freq", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["1000", "1011", "2000", "2011", "3000", "4000", "4006", "5000", "6000", "7000", "8000", "9000", "10000", "11000", "12000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ae34f49e649e17a7c1cd4e91306253105adec71ba2612a4c890005782d8339c6", "warmup_time": -1}, "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr": {"code": "class TimePeriodArrToDT64Arr:\n    def time_periodarray_to_dt64arr(self, size, freq):\n        periodarr_to_dt64arr(self.i8values, freq)\n\n    def setup(self, size, freq):\n        arr = np.arange(10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr", "min_run_count": 2, "name": "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr", "number": 0, "param_names": ["size", "freq"], "params": [["0", "1", "100", "10000", "1000000"], ["1000", "1011", "2000", "2011", "3000", "4000", "4006", "5000", "6000", "7000", "8000", "9000", "10000", "11000", "12000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "780a003a3675ffce34b1163502be5f0eb10d3e9c8e10d3a8f2ce56387e643da2", "warmup_time": -1}, "tslibs.resolution.TimeResolution.time_get_resolution": {"code": "class TimeResolution:\n    def time_get_resolution(self, unit, size, tz):\n        get_resolution(self.i8data, tz)\n\n    def setup(self, unit, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        arr = arr.view(f\"M8[{unit}]\").astype(\"M8[ns]\").view(\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.resolution.TimeResolution.time_get_resolution", "number": 0, "param_names": ["unit", "size", "tz"], "params": [["'D'", "'h'", "'m'", "'s'", "'us'", "'ns'"], ["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "31259509175475d91c89e0d7ed2c1aeb7f584c1ef106af6b79c15883759acb97", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_components": {"code": "class TimedeltaConstructor:\n    def time_from_components(self):\n        Timedelta(\n            days=1,\n            hours=2,\n            minutes=3,\n            seconds=4,\n            milliseconds=5,\n            microseconds=6,\n            nanoseconds=7,\n        )\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_components", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "976de79734124e410aadd9f6fdb589658515fb75c3456c6c5003df04e31495c8", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_datetime_timedelta(self):\n        Timedelta(self.dttimedelta)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3326b70bfe99c2a6a044540b5db8b882ec1b999993fff273029767c5717f11db", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_int": {"code": "class TimedeltaConstructor:\n    def time_from_int(self):\n        Timedelta(123456789)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ebc3b0e00ba7cba6a0d3e95134a6f1c56543605b5c4f0337fd76a0b846078e4d", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format": {"code": "class TimedeltaConstructor:\n    def time_from_iso_format(self):\n        Timedelta(\"P4DT12H30M5S\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a16446c3495768b14e84c7b2e947bdfbb1fb7558e73cd969d79d2fddd94f4961", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_missing": {"code": "class TimedeltaConstructor:\n    def time_from_missing(self):\n        Timedelta(\"nat\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee87e86713ff7adca408473446c87ca651516e45b5a7c43b9142fead580aad84", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_np_timedelta(self):\n        Timedelta(self.nptimedelta64)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a8fe79df54c66d13d34089a76ce37bd86f35e6da129e6de26dd0235934789c8c", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_pd_timedelta(self):\n        Timedelta(self.td)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "831bac3969b78367fedc8c945ad8667ac98baab3994380c2c72b8a30c1516c50", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_string": {"code": "class TimedeltaConstructor:\n    def time_from_string(self):\n        Timedelta(\"1 days\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8da4af162b193652f720feee641b52568c67cc80c2eef6d146965283fb04bc8d", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_unit": {"code": "class TimedeltaConstructor:\n    def time_from_unit(self):\n        Timedelta(1, unit=\"D\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_unit", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "847323667685ed5b43d8b14581d093b940ce61c95df2d08c156c1da8cd993cd5", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_days": {"code": "class TimedeltaProperties:\n    def time_timedelta_days(self, td):\n        td.days\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:56", "type": "time", "unit": "seconds", "version": "027721dc928a0aac947e4eb804535d4414cc57804449f21a50097455e1eb34cc", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_microseconds(self, td):\n        td.microseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:56", "type": "time", "unit": "seconds", "version": "1c88f64d84fd4aa67383bda6396ed221e9b5a7fb816a7ff3ab0788a108b0c6c8", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_nanoseconds(self, td):\n        td.nanoseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:56", "type": "time", "unit": "seconds", "version": "458eb6a15687e81995044a9cf3b9938fdf6724c379b347d74c6fcb101204008b", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_seconds(self, td):\n        td.seconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:56", "type": "time", "unit": "seconds", "version": "16d230d4bbe759fe887153a89399d0eb5eebbf999155cbe9ec2fdfef09305b0c", "warmup_time": -1}, "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst": {"code": "class TimestampAcrossDst:\n    def time_replace_across_dst(self):\n        self.ts2.replace(tzinfo=self.tzinfo)\n\n    def setup(self):\n        dt = datetime(2016, 3, 27, 1, fold=0)\n        self.tzinfo = dt.astimezone(zoneinfo.ZoneInfo(\"Europe/Berlin\")).tzinfo\n        self.ts2 = Timestamp(dt)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "d6e90f7d3f0abfe1f318015d95176bae16b3feb28afb05377278fa7d790089f0", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware": {"code": "class TimestampConstruction:\n    def time_from_datetime_aware(self):\n        Timestamp(self.dttime_aware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "8a030bf8ec780cb4dc5e1625c8d736c9b81c2ff243e43d42f464f567e813d6e0", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware": {"code": "class TimestampConstruction:\n    def time_from_datetime_unaware(self):\n        Timestamp(self.dttime_unaware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "983c9adb7fdbba5a99bd19eb8252ca74c5dcb49c1a1cf758774b62e84f2a87f3", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64": {"code": "class TimestampConstruction:\n    def time_from_npdatetime64(self):\n        Timestamp(self.npdatetime64)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f1f26896f458efeef6da817aad5e1d4c30bc86b09d6ee0a8783fae7daf0443bf", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp": {"code": "class TimestampConstruction:\n    def time_from_pd_timestamp(self):\n        Timestamp(self.ts)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1c4fe914accb797d939c2c07e58cd473c68a7c8ac0027fb851219b69f5c2bed7", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromordinal": {"code": "class TimestampConstruction:\n    def time_fromordinal(self):\n        Timestamp.fromordinal(730120)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromordinal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "96b6e5064dce0499a6d4a0df4e3756e57651147b2bec00bd32a6cb5be90bd004", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromtimestamp": {"code": "class TimestampConstruction:\n    def time_fromtimestamp(self):\n        Timestamp.fromtimestamp(1515448538)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromtimestamp", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b3cb82296c78e7efb2c13f66d8221e5c7d13e42556333ed6bbbaf1df30f1e15d", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_dateutil": {"code": "class TimestampConstruction:\n    def time_parse_dateutil(self):\n        Timestamp(\"2017/08/25 08:16:14 AM\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_dateutil", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1b5e36ee973fd194d8b45f0e49c40d1b5ac8583640d7eee6ccf3378b8ae6a17e", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_no_tz(self):\n        Timestamp(\"2017-08-25 08:16:14\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e6370f5829a555c736196554bfab166d8886eb68763439e09b2cb5e22751db78", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_tz(self):\n        Timestamp(\"2017-08-25 08:16:14-0500\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1a1617ee722913b3a4942920b0e70ccb25c8e7a4dee81a6fae1a74ad0024045c", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_now": {"code": "class TimestampConstruction:\n    def time_parse_now(self):\n        Timestamp(\"now\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_now", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e6772d97c449c0d7504f5f31da90d9ac3ec9724dcf9209895c3f2146f5c604b8", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_today": {"code": "class TimestampConstruction:\n    def time_parse_today(self):\n        Timestamp(\"today\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, timezone.utc)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_today", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "08f0014d4ce59fd183e8d40386f2aa20ac9c28f5f9883a147e94c6d8c51d507c", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_ceil": {"code": "class TimestampOps:\n    def time_ceil(self, tz):\n        self.ts.ceil(\"5min\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_ceil", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "baf73e231e602f7995c8b34f3b99e8b6c695160889ca1f755f19fd2c8b6e776e", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_floor": {"code": "class TimestampOps:\n    def time_floor(self, tz):\n        self.ts.floor(\"5min\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_floor", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ad9343f6d07a8c951d0913deffcfa58ae1e8dd7f188610392b097ce3ca19e11b", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_normalize": {"code": "class TimestampOps:\n    def time_normalize(self, tz):\n        self.ts.normalize()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_normalize", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f7688ade61af780f34bdb840481260073c8bfb88a7504a06758c91f033fb951d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_None": {"code": "class TimestampOps:\n    def time_replace_None(self, tz):\n        self.ts.replace(tzinfo=None)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_None", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "395164d585e187bf1f2ecd1f965a26fe6f63a204fb26eb6daf8c2544e7895f5f", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_tz": {"code": "class TimestampOps:\n    def time_replace_tz(self, tz):\n        self.ts.replace(tzinfo=zoneinfo.ZoneInfo(\"US/Eastern\"))\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_tz", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "fce499c8af56c528f3342003a6a8b10ce5c348bb960f1508673fe58b3360e009", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_julian_date": {"code": "class TimestampOps:\n    def time_to_julian_date(self, tz):\n        self.ts.to_julian_date()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_julian_date", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "b986ab53361d72e7f0d0ea59b3584f48d6d6fc4994e87be9157f503231f22e70", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_pydatetime": {"code": "class TimestampOps:\n    def time_to_pydatetime(self, tz):\n        self.ts.to_pydatetime()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_pydatetime", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "1db879395196c84d3fd8f358a23b86aaef86f45475d0f83716f8a546e489a627", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_convert": {"code": "class TimestampOps:\n    def time_tz_convert(self, tz):\n        if self.ts.tz is not None:\n            self.ts.tz_convert(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_convert", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "43ec3d5f390c7c62a00c06c942395078df2cc729fd8f92a4b0276815f342896d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_localize": {"code": "class TimestampOps:\n    def time_tz_localize(self, tz):\n        if self.ts.tz is None:\n            self.ts.tz_localize(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_localize", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0ed9c18cc2666c8a010ac46b26f73181d886d5bad76c5a2e012111741777d94c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofweek": {"code": "class TimestampProperties:\n    def time_dayofweek(self, tz):\n        self.ts.dayofweek\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofweek", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e29f2f9d5602cdd3653692a09582476ebfd93e83ef6498019842c6cf6b8ec80a", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofyear": {"code": "class TimestampProperties:\n    def time_dayofyear(self, tz):\n        self.ts.dayofyear\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofyear", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "ee2f40845ecc6394591ee911396fc80479a217eeabf14738f0a9b516b7709a70", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_days_in_month": {"code": "class TimestampProperties:\n    def time_days_in_month(self, tz):\n        self.ts.days_in_month\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_days_in_month", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "17752b2964de1c685127ffa838ee3c5e3b0e2a8a63461dff3cba393207ee472e", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_leap_year": {"code": "class TimestampProperties:\n    def time_is_leap_year(self, tz):\n        self.ts.is_leap_year\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_leap_year", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e38d3b3704a4721bdc9af6bde865107faa0b6a19cceb1afc4db2be6abebcd5ef", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_end": {"code": "class TimestampProperties:\n    def time_is_month_end(self, tz):\n        self.ts.is_month_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "30c8d2e4ef76effa485342decbfb5349b1b96926523713ba746a85a9b4fc0819", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_start": {"code": "class TimestampProperties:\n    def time_is_month_start(self, tz):\n        self.ts.is_month_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "0c562c955215c96790f0242b5ba277157e69be2c739e9e95472aa6dd0416d299", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_end": {"code": "class TimestampProperties:\n    def time_is_quarter_end(self, tz):\n        self.ts.is_quarter_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "03313e5f8997f2a2420815b1bcafdef5fcda6334d1bd7ef80f122b59e7403ebe", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_start": {"code": "class TimestampProperties:\n    def time_is_quarter_start(self, tz):\n        self.ts.is_quarter_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "280e8892418c358b39acbba39be3acbd1c294f244e50db4c4ebb0c364fadad1d", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_end": {"code": "class TimestampProperties:\n    def time_is_year_end(self, tz):\n        self.ts.is_year_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "eb42a1cc4fe4177b738115226d04b4e2536031f7159767c9709bbb7556c64831", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_start": {"code": "class TimestampProperties:\n    def time_is_year_start(self, tz):\n        self.ts.is_year_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5db3d7d1a89f3a35fe2a867c9046efedb39a0d8d9295b0880d0182689cb78a94", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_microsecond": {"code": "class TimestampProperties:\n    def time_microsecond(self, tz):\n        self.ts.microsecond\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_microsecond", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "657d803a947bd2ee87ff6e4f5fb74034cac717ea6c7234a95be94a19f3a9d926", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_month_name": {"code": "class TimestampProperties:\n    def time_month_name(self, tz):\n        self.ts.month_name()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_month_name", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "601bf8fc4cd6762f48b99ed3cf7cc263fd851d65febdfa88735ffb31ed02e55d", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_quarter": {"code": "class TimestampProperties:\n    def time_quarter(self, tz):\n        self.ts.quarter\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_quarter", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f822d240b6aab8f16f5cb4b0b15eb282a11540a85c12eb391cbf3adcd0dea0dd", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_tz": {"code": "class TimestampProperties:\n    def time_tz(self, tz):\n        self.ts.tz\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_tz", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c7f2fb57fa5899b99e67eed5aed5efb470cddf82e1f2a8f1c6472ba40e5ea021", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_week": {"code": "class TimestampProperties:\n    def time_week(self, tz):\n        self.ts.week\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_week", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cf7c5eef5480fb665a78f4c97bb9d21ac5d4a0141c4b107f915bcef238c4ceca", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_weekday_name": {"code": "class TimestampProperties:\n    def time_weekday_name(self, tz):\n        self.ts.day_name()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_weekday_name", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "72364a32ce479df795dde42a507109f4f6ff8450ba4212e2469d7c7c09785e31", "warmup_time": -1}, "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime": {"code": "class TimeIntsToPydatetime:\n    def time_ints_to_pydatetime(self, box, size, tz):\n        ints_to_pydatetime(self.i8data, tz, box=box)\n\n    def setup(self, box, size, tz):\n        if box == \"date\" and tz is not None:\n            # tz is ignored, so avoid running redundant benchmarks\n            raise NotImplementedError  # skip benchmark\n        if size == 10**6 and tz is _tzs[-1]:\n            # This is cumbersomely-slow, so skip to trim runtime\n            raise NotImplementedError  # skip benchmark\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime", "number": 0, "param_names": ["box", "size", "tz"], "params": [["'time'", "'date'", "'datetime'", "'timestamp'"], ["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "cc992ad9ce5601940faa38dd855be6b5df8a12c763443caf43906b262537aa5b", "warmup_time": -1}, "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc": {"code": "class TimeTZConvert:\n    def time_tz_convert_from_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data, tz=tz)\n        #  dti.tz_localize(None)\n        if old_sig:\n            tz_convert_from_utc(self.i8data, timezone.utc, tz)\n        else:\n            tz_convert_from_utc(self.i8data, tz)\n\n    def setup(self, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "28c2d29c5fd5c54e8236ad66f2944a2805df7b88c82e32ff0d372b1f466cbe12", "warmup_time": -1}, "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc": {"code": "class TimeTZConvert:\n    def time_tz_localize_to_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data)\n        #  dti.tz_localize(tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n        tz_localize_to_utc(self.i8data, tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n\n    def setup(self, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "zoneinfo.ZoneInfo(key='US/Pacific')", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3bcf7f94df95f8ab82da03b954dc9d477df030167d67f9ead7d5549deb4025d2", "warmup_time": -1}}, "machines": {"asvrunner": {"machine": "asvrunner", "version": 1}}, "tags": {"0.3.0": 288, "v0.15.2pre": 11042, "v0.15pre": 10501, "v0.16.3": 12091, "v0.23.0rc1": 17526, "v0.4.0": 862, "debian/0.4.0-1": 874, "v0.4.1": 926, "debian/0.4.1-1": 933, "v0.4.2": 981, "v0.4.3": 1029, "debian/0.4.3-1": 1084, "v0.5.0": 1185, "debian/0.5.0+git7-gcf32be2-1": 1194, "v0.6.0": 1342, "v0.6.1": 1440, "debian/0.6.1-1": 1632, "v0.7.0rc1": 1812, "v0.7.0": 2072, "debian/0.7.0-1": 2077, "v0.7.1": 2196, "debian/0.7.1+git1-ga2e86c2-1": 2247, "v0.7.2": 2358, "v0.7.3": 2539, "debian/0.7.3-1": 2555, "v0.8.0b1": 3074, "v0.8.0b2": 3262, "debian/0.8.0_b2-1": 3266, "debian/0.8.0_b2+git68-g7240b87-1": 3344, "v0.8.0rc1": 3360, "v0.8.0rc2": 3361, "debian/0.8.0_rc2+git26-g76c6351-1": 3393, "v0.8.0": 3412, "debian/0.8.0-1": 3418, "debian/0.8.0-2": 3494, "v0.8.1": 3551, "debian/0.8.1-1": 3557, "v0.9.0rc1": 3912, "v0.9.0rc2": 3955, "v0.9.0": 4026, "v0.9.1rc1": 4249, "v0.9.1": 4289, "v0.10.0b1": 4723, "v0.10.0": 4816, "v0.10.1": 5022, "v0.11.0rc1": 5767, "v0.11.0": 5863, "v0.12.0rc1": 6664, "v0.12.0": 6794, "v0.13.0rc1": 7983, "v0.13.0": 8139, "v0.13.0_ahl1": 8234, "v0.13.0_ahl2": 8327, "v0.13.1": 8680, "v0.14.0rc1": 9617, "v0.14.0": 9713, "v0.14.1": 10140, "v0.15.0rc1": 10793, "v0.15.0": 10853, "v0.15.1": 10956, "v0.15.2": 11188, "v0.16.0rc1": 11528, "v0.16.0": 11564, "v0.16.1": 11906, "v0.16.2": 12077, "v0.17.0rc1": 12722, "v0.17.0rc2": 12860, "v0.17.0": 12889, "v0.17.1": 13158, "v0.18.0rc1": 13520, "v0.18.0rc2": 13611, "v0.18.0": 13622, "v0.18.1": 13832, "v0.19.0rc1": 14278, "v0.19.0": 14326, "v0.19.1": 14431, "v0.19.2": 14702, "v0.20.0rc1": 15296, "v0.20.0rc2": 15353, "v0.20.0": 15361, "v0.20.1": 15367, "v0.21.0.dev": 15368, "v0.20.2": 15570, "v0.20.3": 15682, "v0.21.0rc1": 16091, "v0.21.0": 16137, "v0.22.0.dev0": 16138, "v0.21.1": 16588, "v0.23.0.dev0": 16690, "v0.22.0": 16717, "v0.23.0rc2": 17528, "v0.23.0": 17585, "v0.24.0.dev0": 17586, "v0.23.1": 17742, "v0.23.2": 17912, "v0.23.3": 17939, "v0.23.4": 18114, "v0.24.0rc1": 19270, "v0.24.0": 19350, "v0.25.0.dev0": 19351, "v0.24.1": 19432, "v0.24.2": 19667, "v0.25.0rc0": 20326, "v0.25.0": 20419, "v0.25.1": 20693, "v0.26.0.dev0": 20420, "v0.25.2": 21092, "v0.25.3": 21228, "v1.0.0rc0": 22233, "v1.0.0": 22534, "v1.1.0.dev0": 22234, "v1.0.1": 22696, "v1.0.2": 23181, "v1.0.3": 23268, "v1.0.4": 24127, "v1.0.5": 24334, "v1.1.0rc0": 24589, "v1.1.0": 24599, "v1.2.0.dev0": 24600, "v1.1.1": 24766, "v1.1.2": 24985, "v1.1.3": 25335, "v1.1.4": 25721, "v1.1.5": 26254, "v1.2.0rc0": 26272, "v1.3.0.dev0": 26273, "v1.2.0": 26505, "v1.2.1": 26843, "v1.2.2": 27074, "v1.2.3": 27322, "v1.2.4": 27733, "v1.3.0rc0": 28346, "v1.4.0.dev0": 28347, "v1.3.0rc1": 28355, "v1.2.5": 28488, "v1.3.0": 28580, "v1.3.1": 28765, "v1.3.2": 28950, "v1.3.3": 29202, "v1.3.4": 29485, "v1.3.5": 29966, "v1.4.0rc0": 30178, "v1.5.0.dev0": 30179, "v1.4.0": 30387, "v1.4.1": 30635, "v1.4.2": 30959, "v1.4.3": 31382, "v1.5.0rc0": 31772, "v1.6.0.dev0": 31773, "v1.4.4": 31825, "v1.5.0": 31984, "v1.5.1": 32259, "v2.0.0.dev0": 31773, "v1.5.2": 32630, "v1.5.3": 33222, "v2.0.0rc0": 33589, "v2.1.0.dev0": 33590, "v2.0.0rc1": 33911, "v2.0.0": 34111, "v2.0.1": 34390, "v2.0.2": 34664, "v2.0.3": 34934, "v2.1.0rc0": 35294, "v2.1.0": 35491, "v2.2.0dev0": 35295, "v2.1.1": 35668, "v2.2.0.dev0": 35295, "v2.1.2": 35914, "v2.1.3": 36024, "v2.1.4": 36334, "v2.2.0rc0": 36458, "v3.0.0.dev0": 36457, "v2.2.0": 36666, "v2.2.1": 36994, "v2.2.2": 37314, "v2.2.3": 38143, "v2.3.0.dev0": 38187}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}